<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_language_translation</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Language-Translation">Language Translation<a class="anchor-link" href="#Language-Translation">&#182;</a></h1><p>In this project, you’re going to take a peek into the realm of neural network machine translation.  You’ll be training a sequence to sequence model on a dataset of English and French sentences that can translate new sentences from English to French.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="#Get-the-Data">&#182;</a></h2><p>Since translating the whole language of English to French will take lots of time to train, we have provided you with a small portion of the English corpus.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">source_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_en&#39;</span>
<span class="n">target_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_fr&#39;</span>
<span class="n">source_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">)</span>
<span class="n">target_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">target_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="#Explore-the-Data">&#182;</a></h2><p>Play around with view_sentence_range to view different parts of the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">view_sentence_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dataset Stats&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Roughly the number of unique words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">({</span><span class="n">word</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">()})))</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of sentences: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average number of words in a sentence: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;English sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;French sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset Stats
Roughly the number of unique words: 227
Number of sentences: 137861
Average number of words in a sentence: 13.225277634719028

English sentences 0 to 10:
new jersey is sometimes quiet during autumn , and it is snowy in april .
the united states is usually chilly during july , and it is usually freezing in november .
california is usually quiet during march , and it is usually hot in june .
the united states is sometimes mild during june , and it is cold in september .
your least liked fruit is the grape , but my least liked is the apple .
his favorite fruit is the orange , but my favorite is the grape .
paris is relaxing during december , but it is usually chilly in july .
new jersey is busy during spring , and it is never hot in march .
our least liked fruit is the lemon , but my least liked is the grape .
the united states is sometimes busy during january , and it is sometimes warm in november .

French sentences 0 to 10:
new jersey est parfois calme pendant l&#39; automne , et il est neigeux en avril .
les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .
california est généralement calme en mars , et il est généralement chaud en juin .
les états-unis est parfois légère en juin , et il fait froid en septembre .
votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .
son fruit préféré est l&#39;orange , mais mon préféré est le raisin .
paris est relaxant en décembre , mais il est généralement froid en juillet .
new jersey est occupé au printemps , et il est jamais chaude en mars .
notre fruit est moins aimé le citron , mais mon moins aimé est le raisin .
les états-unis est parfois occupé en janvier , et il est parfois chaud en novembre .
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocessing-Function">Implement Preprocessing Function<a class="anchor-link" href="#Implement-Preprocessing-Function">&#182;</a></h2><h3 id="Text-to-Word-Ids">Text to Word Ids<a class="anchor-link" href="#Text-to-Word-Ids">&#182;</a></h3><p>As you did with other RNNs, you must turn the text into a number so the computer can understand it. In the function <code>text_to_ids()</code>, you'll turn <code>source_text</code> and <code>target_text</code> from words to ids.  However, you need to add the <code>&lt;EOS&gt;</code> word id at the end of <code>target_text</code>.  This will help the neural network predict when the sentence should end.</p>
<p>You can get the <code>&lt;EOS&gt;</code> word id by doing:</p>
<div class="highlight"><pre><span></span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]</span>
</pre></div>
<p>You can get other word ids using <code>source_vocab_to_int</code> and <code>target_vocab_to_int</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">text_to_ids</span><span class="p">(</span><span class="n">source_text</span><span class="p">,</span> <span class="n">target_text</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert source and target text to proper word ids</span>
<span class="sd">    :param source_text: String that contains all the source text.</span>
<span class="sd">    :param target_text: String that contains all the target text.</span>
<span class="sd">    :param source_vocab_to_int: Dictionary to go from the source words to an id</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: A tuple of lists (source_id_text, target_id_text)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">source_id_text</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)):</span>
        <span class="n">source_id_text</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
            <span class="n">source_id_text</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        
    <span class="n">target_id_text</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)):</span>
        <span class="n">target_id_text</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
            <span class="n">target_id_text</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="n">target_id_text</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">])</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">source_id_text</span><span class="p">,</span> <span class="n">target_id_text</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_text_to_ids</span><span class="p">(</span><span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="#Preprocess-all-the-data-and-save-it">&#182;</a></h3><p>Running the code cell below will preprocess all the data and save it to file.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">,</span> <span class="n">target_path</span><span class="p">,</span> <span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Check-the-Version-of-TensorFlow-and-Access-to-GPU">Check the Version of TensorFlow and Access to GPU<a class="anchor-link" href="#Check-the-Version-of-TensorFlow-and-Access-to-GPU">&#182;</a></h3><p>This will check to make sure you have the correct version of TensorFlow and access to a GPU</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="k">import</span> <span class="n">LooseVersion</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.layers.core</span> <span class="k">import</span> <span class="n">Dense</span>

<span class="c1"># Check TensorFlow Version</span>
<span class="k">assert</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;1.1&#39;</span><span class="p">),</span> <span class="s1">&#39;Please use TensorFlow version 1.1 or newer&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TensorFlow Version: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>

<span class="c1"># Check for a GPU</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;No GPU found. Please use a GPU to train your neural network.&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Default GPU Device: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow Version: 1.2.1
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:15: UserWarning: No GPU found. Please use a GPU to train your neural network.
  from ipykernel import kernelapp as app
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h2><p>You'll build the components necessary to build a Sequence-to-Sequence model by implementing the following functions below:</p>
<ul>
<li><code>model_inputs</code></li>
<li><code>process_decoder_input</code></li>
<li><code>encoding_layer</code></li>
<li><code>decoding_layer_train</code></li>
<li><code>decoding_layer_infer</code></li>
<li><code>decoding_layer</code></li>
<li><code>seq2seq_model</code></li>
</ul>
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>Implement the <code>model_inputs()</code> function to create TF Placeholders for the Neural Network. It should create the following placeholders:</p>
<ul>
<li>Input text placeholder named "input" using the TF Placeholder name parameter with rank 2.</li>
<li>Targets placeholder with rank 2.</li>
<li>Learning rate placeholder with rank 0.</li>
<li>Keep probability placeholder named "keep_prob" using the TF Placeholder name parameter with rank 0.</li>
<li>Target sequence length placeholder named "target_sequence_length" with rank 1</li>
<li>Max target sequence length tensor named "max_target_len" getting its value from applying tf.reduce_max on the target_sequence_length placeholder. Rank 0.</li>
<li>Source sequence length placeholder named "source_sequence_length" with rank 1</li>
</ul>
<p>Return the placeholders in the following the tuple (input, targets, learning rate, keep probability, target sequence length, max target sequence length, source sequence length)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_inputs</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create TF Placeholders for input, targets, learning rate, and lengths of source and target sequences.</span>
<span class="sd">    :return: Tuple (input, targets, learning rate, keep probability, target sequence length,</span>
<span class="sd">    max target sequence length, source sequence length)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span> <span class="s2">&quot;input&quot;</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span> <span class="s2">&quot;targets&quot;</span><span class="p">)</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span> <span class="s2">&quot;learning_rate&quot;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span> <span class="s2">&quot;keep_prob&quot;</span><span class="p">)</span>
    <span class="n">target_sequence_lenth</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span> <span class="s2">&quot;target_sequence_length&quot;</span><span class="p">)</span>
    <span class="n">max_target_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">target_sequence_lenth</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span> <span class="s1">&#39;max_target_len&#39;</span><span class="p">)</span>
    <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span> <span class="s2">&quot;source_sequence_length&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_sequence_lenth</span><span class="p">,</span> <span class="n">max_target_len</span><span class="p">,</span> <span class="n">source_sequence_length</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_model_inputs</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>ERROR:tensorflow:==================================
Object was never used (type &lt;class &#39;tensorflow.python.framework.ops.Operation&#39;&gt;):
&lt;tf.Operation &#39;assert_rank_2/Assert/Assert&#39; type=Assert&gt;
If you want to mark it as used call its &#34;mark_used()&#34; method.
It was originally created here:
[&#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/runpy.py&#34;, line 170, in _run_module_as_main\n    &#34;__main__&#34;, mod_spec)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/runpy.py&#34;, line 85, in _run_code\n    exec(code, run_globals)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py&#34;, line 16, in &lt;module&gt;\n    app.launch_new_instance()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py&#34;, line 658, in launch_instance\n    app.start()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py&#34;, line 474, in start\n    ioloop.IOLoop.instance().start()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py&#34;, line 177, in start\n    super(ZMQIOLoop, self).start()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py&#34;, line 887, in start\n    handler_func(fd_obj, events)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py&#34;, line 275, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 440, in _handle_events\n    self._handle_recv()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 472, in _handle_recv\n    self._run_callback(callback, msg)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 414, in _run_callback\n    callback(*args, **kwargs)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py&#34;, line 275, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 228, in dispatch_shell\n    handler(stream, idents, msg)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 390, in execute_request\n    user_expressions, allow_stdin)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py&#34;, line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py&#34;, line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2827, in run_ast_nodes\n    if self.run_code(code, result):&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)&#39;, &#39;File &#34;&lt;ipython-input-24-214c04400709&gt;&#34;, line 22, in &lt;module&gt;\n    tests.test_model_inputs(model_inputs)&#39;, &#39;File &#34;/home/sergiocncruz/Codes/python/udacity/deep_learn/dlnd_language_translation/problem_unittests.py&#34;, line 106, in test_model_inputs\n    assert tf.assert_rank(lr, 0, message=\&#39;Learning Rate has wrong rank\&#39;)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/check_ops.py&#34;, line 617, in assert_rank\n    dynamic_condition, data, summarize)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/check_ops.py&#34;, line 571, in _assert_rank_condition\n    return control_flow_ops.Assert(condition, data, summarize=summarize)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 170, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 139, in _add_should_use_warning\n    wrapped = TFShouldUseWarningWrapper(x)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 96, in __init__\n    stack = [s.strip() for s in traceback.format_stack()]&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/traceback.py&#34;, line 189, in format_stack\n    return format_list(extract_stack(f, limit=limit))&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/traceback.py&#34;, line 201, in extract_stack\n    stack = StackSummary.extract(walk_stack(f), limit=limit)&#39;]
==================================
ERROR:tensorflow:==================================
Object was never used (type &lt;class &#39;tensorflow.python.framework.ops.Operation&#39;&gt;):
&lt;tf.Operation &#39;assert_rank_3/Assert/Assert&#39; type=Assert&gt;
If you want to mark it as used call its &#34;mark_used()&#34; method.
It was originally created here:
[&#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/runpy.py&#34;, line 170, in _run_module_as_main\n    &#34;__main__&#34;, mod_spec)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/runpy.py&#34;, line 85, in _run_code\n    exec(code, run_globals)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py&#34;, line 16, in &lt;module&gt;\n    app.launch_new_instance()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py&#34;, line 658, in launch_instance\n    app.start()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py&#34;, line 474, in start\n    ioloop.IOLoop.instance().start()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py&#34;, line 177, in start\n    super(ZMQIOLoop, self).start()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py&#34;, line 887, in start\n    handler_func(fd_obj, events)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py&#34;, line 275, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 440, in _handle_events\n    self._handle_recv()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 472, in _handle_recv\n    self._run_callback(callback, msg)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 414, in _run_callback\n    callback(*args, **kwargs)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py&#34;, line 275, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 228, in dispatch_shell\n    handler(stream, idents, msg)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 390, in execute_request\n    user_expressions, allow_stdin)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py&#34;, line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py&#34;, line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2827, in run_ast_nodes\n    if self.run_code(code, result):&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)&#39;, &#39;File &#34;&lt;ipython-input-24-214c04400709&gt;&#34;, line 22, in &lt;module&gt;\n    tests.test_model_inputs(model_inputs)&#39;, &#39;File &#34;/home/sergiocncruz/Codes/python/udacity/deep_learn/dlnd_language_translation/problem_unittests.py&#34;, line 107, in test_model_inputs\n    assert tf.assert_rank(keep_prob, 0, message=\&#39;Keep Probability has wrong rank\&#39;)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/check_ops.py&#34;, line 617, in assert_rank\n    dynamic_condition, data, summarize)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/check_ops.py&#34;, line 571, in _assert_rank_condition\n    return control_flow_ops.Assert(condition, data, summarize=summarize)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 170, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 139, in _add_should_use_warning\n    wrapped = TFShouldUseWarningWrapper(x)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 96, in __init__\n    stack = [s.strip() for s in traceback.format_stack()]&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/traceback.py&#34;, line 189, in format_stack\n    return format_list(extract_stack(f, limit=limit))&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/traceback.py&#34;, line 201, in extract_stack\n    stack = StackSummary.extract(walk_stack(f), limit=limit)&#39;]
==================================
Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Process-Decoder-Input">Process Decoder Input<a class="anchor-link" href="#Process-Decoder-Input">&#182;</a></h3><p>Implement <code>process_decoder_input</code> by removing the last word id from each batch in <code>target_data</code> and concat the GO ID to the begining of each batch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Preprocess target data for encoding</span>
<span class="sd">    :param target_data: Target Placehoder</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :return: Preprocessed target data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">go</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">preprocessed_target_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">go</span><span class="p">,</span><span class="n">target_data</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">preprocessed_target_data</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_process_encoding_input</span><span class="p">(</span><span class="n">process_decoder_input</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoding">Encoding<a class="anchor-link" href="#Encoding">&#182;</a></h3><p>Implement <code>encoding_layer()</code> to create a Encoder RNN layer:</p>
<ul>
<li>Embed the encoder input using <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence"><code>tf.contrib.layers.embed_sequence</code></a></li>
<li>Construct a <a href="https://github.com/tensorflow/tensorflow/blob/6947f65a374ebf29e74bb71e36fd82760056d82c/tensorflow/docs_src/tutorials/recurrent.md#stacking-multiple-lstms">stacked</a> <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LSTMCell"><code>tf.contrib.rnn.LSTMCell</code></a> wrapped in a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper"><code>tf.contrib.rnn.DropoutWrapper</code></a></li>
<li>Pass cell and embedded input to <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"><code>tf.nn.dynamic_rnn()</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">imp</span> <span class="k">import</span> <span class="n">reload</span>
<span class="n">reload</span><span class="p">(</span><span class="n">tests</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">encoding_layer</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> 
                   <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> 
                   <span class="n">encoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create encoding layer</span>
<span class="sd">    :param rnn_inputs: Inputs for the RNN</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :param source_sequence_length: a list of the lengths of each sequence in the batch</span>
<span class="sd">    :param source_vocab_size: vocabulary size of source data</span>
<span class="sd">    :param encoding_embedding_size: embedding size of source data</span>
<span class="sd">    :return: tuple (RNN output, RNN state)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="k">def</span> <span class="nf">build_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
        <span class="n">lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span>
        <span class="n">lstm_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">lstm_drop</span>


    <span class="n">stacked_lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">build_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
    <span class="n">embed_encoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">embed_sequence</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">=</span> <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span> <span class="o">=</span> <span class="n">encoding_embedding_size</span><span class="p">)</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">stacked_lstm</span><span class="p">,</span> <span class="n">embed_encoder</span><span class="p">,</span> <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_encoding_layer</span><span class="p">(</span><span class="n">encoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Training">Decoding - Training<a class="anchor-link" href="#Decoding---Training">&#182;</a></h3><p>Create a training decoding layer:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/TrainingHelper"><code>tf.contrib.seq2seq.TrainingHelper</code></a> </li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> 
                         <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_summary_length</span><span class="p">,</span> 
                         <span class="n">output_layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for training</span>
<span class="sd">    :param encoder_state: Encoder State</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embed_input: Decoder embedded input</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_summary_length: The length of the longest sequence in the batch</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing training logits and sample_id</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">trainig_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">TrainingHelper</span><span class="p">(</span>
        <span class="n">dec_embed_input</span><span class="p">,</span> 
        <span class="n">target_sequence_length</span>
    <span class="p">)</span>
    <span class="n">basic_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span>
        <span class="n">dec_cell</span><span class="p">,</span> 
        <span class="n">trainig_helper</span><span class="p">,</span> 
        <span class="n">encoder_state</span><span class="p">,</span> 
        <span class="n">output_layer</span>
    <span class="p">)</span>
    <span class="n">training_logits</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span>
        <span class="n">basic_decoder</span><span class="p">,</span>
        <span class="n">impute_finished</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_summary_length</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">training_logits</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_train</span><span class="p">(</span><span class="n">decoding_layer_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Inference">Decoding - Inference<a class="anchor-link" href="#Decoding---Inference">&#182;</a></h3><p>Create inference decoder:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/GreedyEmbeddingHelper"><code>tf.contrib.seq2seq.GreedyEmbeddingHelper</code></a></li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_of_sequence_id</span><span class="p">,</span>
                         <span class="n">end_of_sequence_id</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                         <span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for inference</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embeddings: Decoder embeddings</span>
<span class="sd">    :param start_of_sequence_id: GO ID</span>
<span class="sd">    :param end_of_sequence_id: EOS Id</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param vocab_size: Size of decoder/target vocabulary</span>
<span class="sd">    :param decoding_scope: TenorFlow Variable Scope for decoding</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param batch_size: Batch size</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing inference logits and sample_id</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">start_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">([</span><span class="n">start_of_sequence_id</span><span class="p">],</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">])</span>
    <span class="n">embedding_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">GreedyEmbeddingHelper</span><span class="p">(</span>
        <span class="n">dec_embeddings</span><span class="p">,</span> 
        <span class="n">start_ids</span><span class="p">,</span> 
        <span class="n">end_of_sequence_id</span>
    <span class="p">)</span>
    <span class="n">basic_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span>
        <span class="n">dec_cell</span><span class="p">,</span> 
        <span class="n">embedding_helper</span><span class="p">,</span> 
        <span class="n">encoder_state</span><span class="p">,</span> 
        <span class="n">output_layer</span>
    <span class="p">)</span>
    <span class="n">training_logits</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span>
        <span class="n">basic_decoder</span><span class="p">,</span>
        <span class="n">impute_finished</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_target_sequence_length</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">training_logits</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_infer</span><span class="p">(</span><span class="n">decoding_layer_infer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Decoding-Layer">Build the Decoding Layer<a class="anchor-link" href="#Build-the-Decoding-Layer">&#182;</a></h3><p>Implement <code>decoding_layer()</code> to create a Decoder RNN layer.</p>
<ul>
<li>Embed the target sequences</li>
<li>Construct the decoder LSTM cell (just like you constructed the encoder cell above)</li>
<li>Create an output layer to map the outputs of the decoder to the elements of our vocabulary</li>
<li>Use the your <code>decoding_layer_train(encoder_state, dec_cell, dec_embed_input, target_sequence_length, max_target_sequence_length, output_layer, keep_prob)</code> function to get the training logits.</li>
<li>Use your <code>decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, max_target_sequence_length, vocab_size, output_layer, batch_size, keep_prob)</code> function to get the inference logits.</li>
</ul>
<p>Note: You'll need to use <a href="https://www.tensorflow.org/api_docs/python/tf/variable_scope">tf.variable_scope</a> to share variables between training and inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span>
                   <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                   <span class="n">rnn_size</span><span class="p">,</span>
                   <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create decoding layer</span>
<span class="sd">    :param dec_input: Decoder input</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param target_vocab_size: Size of target vocabulary</span>
<span class="sd">    :param batch_size: The size of the batch</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :param decoding_embedding_size: Decoding embedding size</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="k">def</span> <span class="nf">build_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
        <span class="n">lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span>
        <span class="n">lstm_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">lstm_drop</span>

    <span class="n">stacked_lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">build_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
    
    <span class="n">dec_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">]))</span>
    <span class="n">dec_embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">)</span>

    <span class="n">dense_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span>
                    <span class="n">target_vocab_size</span><span class="p">,</span>
                    <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span><span class="n">mean</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
                  <span class="p">)</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;decode&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
        <span class="n">trainig_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer_train</span><span class="p">(</span>
            <span class="n">encoder_state</span><span class="p">,</span> 
            <span class="n">stacked_lstm</span><span class="p">,</span> 
            <span class="n">dec_embed_input</span><span class="p">,</span> 
            <span class="n">target_sequence_length</span><span class="p">,</span> 
            <span class="n">max_target_sequence_length</span><span class="p">,</span> 
            <span class="n">dense_layer</span><span class="p">,</span> 
            <span class="n">keep_prob</span>
        <span class="p">)</span>
        <span class="n">scope</span><span class="o">.</span><span class="n">reuse_variables</span><span class="p">()</span>
        <span class="n">inference_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer_infer</span><span class="p">(</span>
            <span class="n">encoder_state</span><span class="p">,</span> 
            <span class="n">stacked_lstm</span><span class="p">,</span> 
            <span class="n">dec_embeddings</span><span class="p">,</span> 
            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">],</span> 
            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">],</span> 
            <span class="n">max_target_sequence_length</span><span class="p">,</span> 
            <span class="n">target_vocab_size</span><span class="p">,</span> 
            <span class="n">dense_layer</span><span class="p">,</span> 
            <span class="n">batch_size</span><span class="p">,</span> 
            <span class="n">keep_prob</span>
        <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">trainig_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer</span><span class="p">(</span><span class="n">decoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h3><p>Apply the functions you implemented above to:</p>
<ul>
<li>Encode the input using your <code>encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob,  source_sequence_length, source_vocab_size, encoding_embedding_size)</code>.</li>
<li>Process target data using your <code>process_decoder_input(target_data, target_vocab_to_int, batch_size)</code> function.</li>
<li>Decode the encoded input using your <code>decoding_layer(dec_input, enc_state, target_sequence_length, max_target_sentence_length, rnn_size, num_layers, target_vocab_to_int, target_vocab_size, batch_size, keep_prob, dec_embedding_size)</code> function.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">seq2seq_model</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">target_data</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                  <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span>
                  <span class="n">max_target_sentence_length</span><span class="p">,</span>
                  <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                  <span class="n">enc_embedding_size</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">,</span>
                  <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build the Sequence-to-Sequence part of the neural network</span>
<span class="sd">    :param input_data: Input placeholder</span>
<span class="sd">    :param target_data: Target placeholder</span>
<span class="sd">    :param keep_prob: Dropout keep probability placeholder</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :param source_sequence_length: Sequence Lengths of source sequences in the batch</span>
<span class="sd">    :param target_sequence_length: Sequence Lengths of target sequences in the batch</span>
<span class="sd">    :param source_vocab_size: Source vocabulary size</span>
<span class="sd">    :param target_vocab_size: Target vocabulary size</span>
<span class="sd">    :param enc_embedding_size: Decoder embedding size</span>
<span class="sd">    :param dec_embedding_size: Encoder embedding size</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">encoding_layer</span><span class="p">(</span>
                        <span class="n">input_data</span><span class="p">,</span> 
                        <span class="n">rnn_size</span><span class="p">,</span> 
                        <span class="n">num_layers</span><span class="p">,</span> 
                        <span class="n">keep_prob</span><span class="p">,</span> 
                        <span class="n">source_sequence_length</span><span class="p">,</span> 
                        <span class="n">source_vocab_size</span><span class="p">,</span> 
                        <span class="n">enc_embedding_size</span>
                    <span class="p">)</span>
    
    <span class="n">processed_input</span> <span class="o">=</span> <span class="n">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    
    <span class="n">trainig_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer</span><span class="p">(</span>
                                                            <span class="n">processed_input</span><span class="p">,</span> 
                                                            <span class="n">state</span><span class="p">,</span>
                                                            <span class="n">target_sequence_length</span><span class="p">,</span> 
                                                            <span class="n">max_target_sentence_length</span><span class="p">,</span>
                                                            <span class="n">rnn_size</span><span class="p">,</span> 
                                                            <span class="n">num_layers</span><span class="p">,</span> 
                                                            <span class="n">target_vocab_to_int</span><span class="p">,</span> 
                                                            <span class="n">target_vocab_size</span><span class="p">,</span>
                                                            <span class="n">batch_size</span><span class="p">,</span> 
                                                            <span class="n">keep_prob</span><span class="p">,</span> 
                                                            <span class="n">dec_embedding_size</span>
                                                       <span class="p">)</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">trainig_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_seq2seq_model</span><span class="p">(</span><span class="n">seq2seq_model</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Network-Training">Neural Network Training<a class="anchor-link" href="#Neural-Network-Training">&#182;</a></h2><h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>epochs</code> to the number of epochs.</li>
<li>Set <code>batch_size</code> to the batch size.</li>
<li>Set <code>rnn_size</code> to the size of the RNNs.</li>
<li>Set <code>num_layers</code> to the number of layers.</li>
<li>Set <code>encoding_embedding_size</code> to the size of the embedding for the encoder.</li>
<li>Set <code>decoding_embedding_size</code> to the size of the embedding for the decoder.</li>
<li>Set <code>learning_rate</code> to the learning rate.</li>
<li>Set <code>keep_probability</code> to the Dropout keep probability</li>
<li>Set <code>display_step</code> to state how many steps between each debug output statement</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Number of Epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1"># Batch Size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="c1"># RNN Size</span>
<span class="n">rnn_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># Number of Layers</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Embedding Size</span>
<span class="n">encoding_embedding_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">decoding_embedding_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># Learning Rate</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="c1"># Dropout Keep Probability</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="mf">0.75</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Graph">Build the Graph<a class="anchor-link" href="#Build-the-Graph">&#182;</a></h3><p>Build the graph using the neural network you implemented.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[32]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="s1">&#39;checkpoints/dev&#39;</span>
<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">max_target_sentence_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_int_text</span><span class="p">])</span>

<span class="n">train_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">train_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">input_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">model_inputs</span><span class="p">()</span>

    <span class="c1">#sequence_length = tf.placeholder_with_default(max_target_sentence_length, None, name=&#39;sequence_length&#39;)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

    <span class="n">train_logits</span><span class="p">,</span> <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">seq2seq_model</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                                                   <span class="n">targets</span><span class="p">,</span>
                                                   <span class="n">keep_prob</span><span class="p">,</span>
                                                   <span class="n">batch_size</span><span class="p">,</span>
                                                   <span class="n">source_sequence_length</span><span class="p">,</span>
                                                   <span class="n">target_sequence_length</span><span class="p">,</span>
                                                   <span class="n">max_target_sequence_length</span><span class="p">,</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">),</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">),</span>
                                                   <span class="n">encoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">decoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">rnn_size</span><span class="p">,</span>
                                                   <span class="n">num_layers</span><span class="p">,</span>
                                                   <span class="n">target_vocab_to_int</span><span class="p">)</span>


    <span class="n">training_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">train_logits</span><span class="o">.</span><span class="n">rnn_output</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;logits&#39;</span><span class="p">)</span>
    <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">inference_logits</span><span class="o">.</span><span class="n">sample_id</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">)</span>

    <span class="n">masks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sequence_mask</span><span class="p">(</span><span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;masks&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;optimization&quot;</span><span class="p">):</span>
        <span class="c1"># Loss function</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span>
            <span class="n">training_logits</span><span class="p">,</span>
            <span class="n">targets</span><span class="p">,</span>
            <span class="n">masks</span><span class="p">)</span>

        <span class="c1"># Optimizer</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

        <span class="c1"># Gradient Clipping</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
        <span class="n">capped_gradients</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">gradients</span> <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_gradients</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Batch and pad the source and target sequences</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[33]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">pad_sentence_batch</span><span class="p">(</span><span class="n">sentence_batch</span><span class="p">,</span> <span class="n">pad_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pad sentences with &lt;PAD&gt; so that each sentence of a batch has the same length&quot;&quot;&quot;</span>
    <span class="n">max_sentence</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">+</span> <span class="p">[</span><span class="n">pad_int</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_sentence</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">get_batches</span><span class="p">(</span><span class="n">sources</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Batch targets, sources, and the lengths of their sentences together&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">batch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sources</span><span class="p">)</span><span class="o">//</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">start_i</span> <span class="o">=</span> <span class="n">batch_i</span> <span class="o">*</span> <span class="n">batch_size</span>

        <span class="c1"># Slice the right amount for the batch</span>
        <span class="n">sources_batch</span> <span class="o">=</span> <span class="n">sources</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">targets_batch</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>

        <span class="c1"># Pad</span>
        <span class="n">pad_sources_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">sources_batch</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">))</span>
        <span class="n">pad_targets_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">targets_batch</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">))</span>

        <span class="c1"># Need the lengths for the _lengths parameters</span>
        <span class="n">pad_targets_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">pad_targets_batch</span><span class="p">:</span>
            <span class="n">pad_targets_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">))</span>

        <span class="n">pad_source_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">pad_sources_batch</span><span class="p">:</span>
            <span class="n">pad_source_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">source</span><span class="p">))</span>

        <span class="k">yield</span> <span class="n">pad_sources_batch</span><span class="p">,</span> <span class="n">pad_targets_batch</span><span class="p">,</span> <span class="n">pad_source_lengths</span><span class="p">,</span> <span class="n">pad_targets_lengths</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train">Train<a class="anchor-link" href="#Train">&#182;</a></h3><p>Train the neural network on the preprocessed data. If you have a hard time getting a good loss, check the forms to see if anyone is having the same problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[34]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate accuracy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_seq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">logits</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">))</span>

<span class="c1"># Split data to training and validation sets</span>
<span class="n">train_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">train_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">valid_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="n">valid_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="p">(</span><span class="n">valid_sources_batch</span><span class="p">,</span> <span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">valid_sources_lengths</span><span class="p">,</span> <span class="n">valid_targets_lengths</span> <span class="p">)</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">get_batches</span><span class="p">(</span><span class="n">valid_source</span><span class="p">,</span>
                                                                                                             <span class="n">valid_target</span><span class="p">,</span>
                                                                                                             <span class="n">batch_size</span><span class="p">,</span>
                                                                                                             <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                                                                                                             <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">]))</span>                                                                                                  
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">train_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_i</span><span class="p">,</span> <span class="p">(</span><span class="n">source_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">,</span> <span class="n">sources_lengths</span><span class="p">,</span> <span class="n">targets_lengths</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="n">get_batches</span><span class="p">(</span><span class="n">train_source</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">])):</span>

            <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="p">[</span><span class="n">train_op</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                 <span class="n">targets</span><span class="p">:</span> <span class="n">target_batch</span><span class="p">,</span>
                 <span class="n">lr</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
                 <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                 <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_probability</span><span class="p">})</span>


            <span class="k">if</span> <span class="n">batch_i</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">batch_i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>


                <span class="n">batch_train_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>


                <span class="n">batch_valid_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">valid_sources_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">valid_sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">valid_targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>

                <span class="n">train_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">batch_train_logits</span><span class="p">)</span>

                <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">batch_valid_logits</span><span class="p">)</span>

                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;3}</span><span class="s1"> Batch </span><span class="si">{:&gt;4}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> - Train Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Validation Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Loss: </span><span class="si">{:&gt;6.4f}</span><span class="s1">&#39;</span>
                      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_i</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_int_text</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">valid_acc</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>

    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model Trained and Saved&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch   0 Batch    1/269 - Train Accuracy: 0.2330, Validation Accuracy: 0.3097, Loss: 5.7150
Epoch   0 Batch    2/269 - Train Accuracy: 0.2656, Validation Accuracy: 0.3097, Loss: 5.5056
Epoch   0 Batch    3/269 - Train Accuracy: 0.2444, Validation Accuracy: 0.3097, Loss: 5.3260
Epoch   0 Batch    4/269 - Train Accuracy: 0.2317, Validation Accuracy: 0.3097, Loss: 5.1244
Epoch   0 Batch    5/269 - Train Accuracy: 0.2325, Validation Accuracy: 0.3097, Loss: 4.9075
Epoch   0 Batch    6/269 - Train Accuracy: 0.2786, Validation Accuracy: 0.3097, Loss: 4.5460
Epoch   0 Batch    7/269 - Train Accuracy: 0.2764, Validation Accuracy: 0.3097, Loss: 4.3843
Epoch   0 Batch    8/269 - Train Accuracy: 0.2405, Validation Accuracy: 0.3097, Loss: 4.4412
Epoch   0 Batch    9/269 - Train Accuracy: 0.2793, Validation Accuracy: 0.3215, Loss: 4.2597
Epoch   0 Batch   10/269 - Train Accuracy: 0.2463, Validation Accuracy: 0.3222, Loss: 4.3488
Epoch   0 Batch   11/269 - Train Accuracy: 0.3030, Validation Accuracy: 0.3397, Loss: 4.0844
Epoch   0 Batch   12/269 - Train Accuracy: 0.2779, Validation Accuracy: 0.3411, Loss: 4.1003
Epoch   0 Batch   13/269 - Train Accuracy: 0.3434, Validation Accuracy: 0.3421, Loss: 3.6962
Epoch   0 Batch   14/269 - Train Accuracy: 0.3053, Validation Accuracy: 0.3428, Loss: 3.8078
Epoch   0 Batch   15/269 - Train Accuracy: 0.2961, Validation Accuracy: 0.3427, Loss: 3.7908
Epoch   0 Batch   16/269 - Train Accuracy: 0.3118, Validation Accuracy: 0.3427, Loss: 3.6825
Epoch   0 Batch   17/269 - Train Accuracy: 0.3022, Validation Accuracy: 0.3428, Loss: 3.6397
Epoch   0 Batch   18/269 - Train Accuracy: 0.2712, Validation Accuracy: 0.3428, Loss: 3.6867
Epoch   0 Batch   19/269 - Train Accuracy: 0.3412, Validation Accuracy: 0.3428, Loss: 3.3641
Epoch   0 Batch   20/269 - Train Accuracy: 0.2752, Validation Accuracy: 0.3428, Loss: 3.5733
Epoch   0 Batch   21/269 - Train Accuracy: 0.2838, Validation Accuracy: 0.3482, Loss: 3.5600
Epoch   0 Batch   22/269 - Train Accuracy: 0.3210, Validation Accuracy: 0.3483, Loss: 3.3592
Epoch   0 Batch   23/269 - Train Accuracy: 0.3488, Validation Accuracy: 0.3675, Loss: 3.3018
Epoch   0 Batch   24/269 - Train Accuracy: 0.3116, Validation Accuracy: 0.3777, Loss: 3.4377
Epoch   0 Batch   25/269 - Train Accuracy: 0.3181, Validation Accuracy: 0.3798, Loss: 3.3970
Epoch   0 Batch   26/269 - Train Accuracy: 0.3844, Validation Accuracy: 0.3831, Loss: 3.0847
Epoch   0 Batch   27/269 - Train Accuracy: 0.3477, Validation Accuracy: 0.3817, Loss: 3.1962
Epoch   0 Batch   28/269 - Train Accuracy: 0.3046, Validation Accuracy: 0.3815, Loss: 3.3504
Epoch   0 Batch   29/269 - Train Accuracy: 0.3143, Validation Accuracy: 0.3817, Loss: 3.2876
Epoch   0 Batch   30/269 - Train Accuracy: 0.3449, Validation Accuracy: 0.3820, Loss: 3.1255
Epoch   0 Batch   31/269 - Train Accuracy: 0.3565, Validation Accuracy: 0.3835, Loss: 3.0808
Epoch   0 Batch   32/269 - Train Accuracy: 0.3504, Validation Accuracy: 0.3869, Loss: 3.0984
Epoch   0 Batch   33/269 - Train Accuracy: 0.3559, Validation Accuracy: 0.3849, Loss: 3.0143
Epoch   0 Batch   34/269 - Train Accuracy: 0.3544, Validation Accuracy: 0.3861, Loss: 3.0156
Epoch   0 Batch   35/269 - Train Accuracy: 0.3597, Validation Accuracy: 0.3890, Loss: 2.9928
Epoch   0 Batch   36/269 - Train Accuracy: 0.3635, Validation Accuracy: 0.3934, Loss: 2.9746
Epoch   0 Batch   37/269 - Train Accuracy: 0.3687, Validation Accuracy: 0.3960, Loss: 2.9682
Epoch   0 Batch   38/269 - Train Accuracy: 0.3636, Validation Accuracy: 0.3952, Loss: 2.9490
Epoch   0 Batch   39/269 - Train Accuracy: 0.3650, Validation Accuracy: 0.4000, Loss: 2.9258
Epoch   0 Batch   40/269 - Train Accuracy: 0.3454, Validation Accuracy: 0.4058, Loss: 3.0400
Epoch   0 Batch   41/269 - Train Accuracy: 0.3742, Validation Accuracy: 0.4053, Loss: 2.9034
Epoch   0 Batch   42/269 - Train Accuracy: 0.4024, Validation Accuracy: 0.4061, Loss: 2.7566
Epoch   0 Batch   43/269 - Train Accuracy: 0.3576, Validation Accuracy: 0.4103, Loss: 2.9637
Epoch   0 Batch   44/269 - Train Accuracy: 0.3906, Validation Accuracy: 0.4146, Loss: 2.8335
Epoch   0 Batch   45/269 - Train Accuracy: 0.3590, Validation Accuracy: 0.4173, Loss: 2.9556
Epoch   0 Batch   46/269 - Train Accuracy: 0.3514, Validation Accuracy: 0.4170, Loss: 2.9859
Epoch   0 Batch   47/269 - Train Accuracy: 0.4181, Validation Accuracy: 0.4186, Loss: 2.6831
Epoch   0 Batch   48/269 - Train Accuracy: 0.4005, Validation Accuracy: 0.4264, Loss: 2.7644
Epoch   0 Batch   49/269 - Train Accuracy: 0.3724, Validation Accuracy: 0.4264, Loss: 2.8915
Epoch   0 Batch   50/269 - Train Accuracy: 0.3743, Validation Accuracy: 0.4270, Loss: 2.8858
Epoch   0 Batch   51/269 - Train Accuracy: 0.4003, Validation Accuracy: 0.4343, Loss: 2.7812
Epoch   0 Batch   52/269 - Train Accuracy: 0.4054, Validation Accuracy: 0.4322, Loss: 2.7396
Epoch   0 Batch   53/269 - Train Accuracy: 0.3721, Validation Accuracy: 0.4279, Loss: 2.8484
Epoch   0 Batch   54/269 - Train Accuracy: 0.3824, Validation Accuracy: 0.4374, Loss: 2.8373
Epoch   0 Batch   55/269 - Train Accuracy: 0.4066, Validation Accuracy: 0.4400, Loss: 2.7081
Epoch   0 Batch   56/269 - Train Accuracy: 0.4099, Validation Accuracy: 0.4368, Loss: 2.6851
Epoch   0 Batch   57/269 - Train Accuracy: 0.4129, Validation Accuracy: 0.4397, Loss: 2.6833
Epoch   0 Batch   58/269 - Train Accuracy: 0.4167, Validation Accuracy: 0.4404, Loss: 2.6633
Epoch   0 Batch   59/269 - Train Accuracy: 0.4071, Validation Accuracy: 0.4385, Loss: 2.6522
Epoch   0 Batch   60/269 - Train Accuracy: 0.4259, Validation Accuracy: 0.4441, Loss: 2.5824
Epoch   0 Batch   61/269 - Train Accuracy: 0.4443, Validation Accuracy: 0.4446, Loss: 2.5106
Epoch   0 Batch   62/269 - Train Accuracy: 0.4456, Validation Accuracy: 0.4513, Loss: 2.5226
Epoch   0 Batch   63/269 - Train Accuracy: 0.4275, Validation Accuracy: 0.4546, Loss: 2.6032
Epoch   0 Batch   64/269 - Train Accuracy: 0.4271, Validation Accuracy: 0.4569, Loss: 2.6120
Epoch   0 Batch   65/269 - Train Accuracy: 0.4346, Validation Accuracy: 0.4588, Loss: 2.5762
Epoch   0 Batch   66/269 - Train Accuracy: 0.4506, Validation Accuracy: 0.4632, Loss: 2.5031
Epoch   0 Batch   67/269 - Train Accuracy: 0.4321, Validation Accuracy: 0.4623, Loss: 2.5796
Epoch   0 Batch   68/269 - Train Accuracy: 0.4379, Validation Accuracy: 0.4683, Loss: 2.5664
Epoch   0 Batch   69/269 - Train Accuracy: 0.4118, Validation Accuracy: 0.4684, Loss: 2.6995
Epoch   0 Batch   70/269 - Train Accuracy: 0.4513, Validation Accuracy: 0.4726, Loss: 2.5140
Epoch   0 Batch   71/269 - Train Accuracy: 0.3945, Validation Accuracy: 0.4542, Loss: 2.6578
Epoch   0 Batch   72/269 - Train Accuracy: 0.4458, Validation Accuracy: 0.4499, Loss: 2.4750
Epoch   0 Batch   73/269 - Train Accuracy: 0.4383, Validation Accuracy: 0.4652, Loss: 2.5594
Epoch   0 Batch   74/269 - Train Accuracy: 0.4115, Validation Accuracy: 0.4642, Loss: 2.5815
Epoch   0 Batch   75/269 - Train Accuracy: 0.4441, Validation Accuracy: 0.4678, Loss: 2.4952
Epoch   0 Batch   76/269 - Train Accuracy: 0.4366, Validation Accuracy: 0.4723, Loss: 2.5383
Epoch   0 Batch   77/269 - Train Accuracy: 0.4382, Validation Accuracy: 0.4653, Loss: 2.4689
Epoch   0 Batch   78/269 - Train Accuracy: 0.4382, Validation Accuracy: 0.4696, Loss: 2.5142
Epoch   0 Batch   79/269 - Train Accuracy: 0.4391, Validation Accuracy: 0.4664, Loss: 2.4615
Epoch   0 Batch   80/269 - Train Accuracy: 0.4555, Validation Accuracy: 0.4727, Loss: 2.4152
Epoch   0 Batch   81/269 - Train Accuracy: 0.4344, Validation Accuracy: 0.4672, Loss: 2.4466
Epoch   0 Batch   82/269 - Train Accuracy: 0.4611, Validation Accuracy: 0.4744, Loss: 2.3970
Epoch   0 Batch   83/269 - Train Accuracy: 0.4602, Validation Accuracy: 0.4759, Loss: 2.3857
Epoch   0 Batch   84/269 - Train Accuracy: 0.4476, Validation Accuracy: 0.4751, Loss: 2.4175
Epoch   0 Batch   85/269 - Train Accuracy: 0.4365, Validation Accuracy: 0.4719, Loss: 2.4247
Epoch   0 Batch   86/269 - Train Accuracy: 0.4610, Validation Accuracy: 0.4837, Loss: 2.4201
Epoch   0 Batch   87/269 - Train Accuracy: 0.4192, Validation Accuracy: 0.4790, Loss: 2.5635
Epoch   0 Batch   88/269 - Train Accuracy: 0.4581, Validation Accuracy: 0.4815, Loss: 2.3727
Epoch   0 Batch   89/269 - Train Accuracy: 0.4696, Validation Accuracy: 0.4833, Loss: 2.3677
Epoch   0 Batch   90/269 - Train Accuracy: 0.4265, Validation Accuracy: 0.4820, Loss: 2.5069
Epoch   0 Batch   91/269 - Train Accuracy: 0.4529, Validation Accuracy: 0.4801, Loss: 2.3724
Epoch   0 Batch   92/269 - Train Accuracy: 0.4428, Validation Accuracy: 0.4714, Loss: 2.3429
Epoch   0 Batch   93/269 - Train Accuracy: 0.4837, Validation Accuracy: 0.4866, Loss: 2.2893
Epoch   0 Batch   94/269 - Train Accuracy: 0.4689, Validation Accuracy: 0.4838, Loss: 2.3351
Epoch   0 Batch   95/269 - Train Accuracy: 0.4598, Validation Accuracy: 0.4849, Loss: 2.3373
Epoch   0 Batch   96/269 - Train Accuracy: 0.4532, Validation Accuracy: 0.4798, Loss: 2.3220
Epoch   0 Batch   97/269 - Train Accuracy: 0.4670, Validation Accuracy: 0.4908, Loss: 2.3184
Epoch   0 Batch   98/269 - Train Accuracy: 0.4822, Validation Accuracy: 0.4880, Loss: 2.2825
Epoch   0 Batch   99/269 - Train Accuracy: 0.4173, Validation Accuracy: 0.4782, Loss: 2.4212
Epoch   0 Batch  100/269 - Train Accuracy: 0.4767, Validation Accuracy: 0.4833, Loss: 2.2478
Epoch   0 Batch  101/269 - Train Accuracy: 0.4375, Validation Accuracy: 0.4882, Loss: 2.4020
Epoch   0 Batch  102/269 - Train Accuracy: 0.4615, Validation Accuracy: 0.4905, Loss: 2.2762
Epoch   0 Batch  103/269 - Train Accuracy: 0.4492, Validation Accuracy: 0.4801, Loss: 2.2615
Epoch   0 Batch  104/269 - Train Accuracy: 0.4612, Validation Accuracy: 0.4929, Loss: 2.2746
Epoch   0 Batch  105/269 - Train Accuracy: 0.4664, Validation Accuracy: 0.4939, Loss: 2.2780
Epoch   0 Batch  106/269 - Train Accuracy: 0.4494, Validation Accuracy: 0.4882, Loss: 2.2690
Epoch   0 Batch  107/269 - Train Accuracy: 0.4204, Validation Accuracy: 0.4841, Loss: 2.3683
Epoch   0 Batch  108/269 - Train Accuracy: 0.4645, Validation Accuracy: 0.4931, Loss: 2.2451
Epoch   0 Batch  109/269 - Train Accuracy: 0.4569, Validation Accuracy: 0.4917, Loss: 2.2470
Epoch   0 Batch  110/269 - Train Accuracy: 0.4553, Validation Accuracy: 0.4903, Loss: 2.2299
Epoch   0 Batch  111/269 - Train Accuracy: 0.4328, Validation Accuracy: 0.4908, Loss: 2.3592
Epoch   0 Batch  112/269 - Train Accuracy: 0.4645, Validation Accuracy: 0.4910, Loss: 2.2037
Epoch   0 Batch  113/269 - Train Accuracy: 0.4852, Validation Accuracy: 0.4922, Loss: 2.1116
Epoch   0 Batch  114/269 - Train Accuracy: 0.4568, Validation Accuracy: 0.4910, Loss: 2.2018
Epoch   0 Batch  115/269 - Train Accuracy: 0.4314, Validation Accuracy: 0.4883, Loss: 2.2924
Epoch   0 Batch  116/269 - Train Accuracy: 0.4785, Validation Accuracy: 0.4976, Loss: 2.1884
Epoch   0 Batch  117/269 - Train Accuracy: 0.4563, Validation Accuracy: 0.4877, Loss: 2.1927
Epoch   0 Batch  118/269 - Train Accuracy: 0.4747, Validation Accuracy: 0.4855, Loss: 2.1145
Epoch   0 Batch  119/269 - Train Accuracy: 0.4585, Validation Accuracy: 0.4979, Loss: 2.2733
Epoch   0 Batch  120/269 - Train Accuracy: 0.4387, Validation Accuracy: 0.4925, Loss: 2.2714
Epoch   0 Batch  121/269 - Train Accuracy: 0.4600, Validation Accuracy: 0.4891, Loss: 2.1500
Epoch   0 Batch  122/269 - Train Accuracy: 0.4792, Validation Accuracy: 0.4972, Loss: 2.1290
Epoch   0 Batch  123/269 - Train Accuracy: 0.4284, Validation Accuracy: 0.4925, Loss: 2.2609
Epoch   0 Batch  124/269 - Train Accuracy: 0.4608, Validation Accuracy: 0.4898, Loss: 2.1235
Epoch   0 Batch  125/269 - Train Accuracy: 0.4683, Validation Accuracy: 0.4983, Loss: 2.1155
Epoch   0 Batch  126/269 - Train Accuracy: 0.4774, Validation Accuracy: 0.4947, Loss: 2.0965
Epoch   0 Batch  127/269 - Train Accuracy: 0.4303, Validation Accuracy: 0.4831, Loss: 2.2190
Epoch   0 Batch  128/269 - Train Accuracy: 0.4879, Validation Accuracy: 0.5006, Loss: 2.1063
Epoch   0 Batch  129/269 - Train Accuracy: 0.4684, Validation Accuracy: 0.4971, Loss: 2.1338
Epoch   0 Batch  130/269 - Train Accuracy: 0.4151, Validation Accuracy: 0.4840, Loss: 2.2441
Epoch   0 Batch  131/269 - Train Accuracy: 0.4615, Validation Accuracy: 0.5013, Loss: 2.1889
Epoch   0 Batch  132/269 - Train Accuracy: 0.4557, Validation Accuracy: 0.4884, Loss: 2.1106
Epoch   0 Batch  133/269 - Train Accuracy: 0.4744, Validation Accuracy: 0.5038, Loss: 2.0720
Epoch   0 Batch  134/269 - Train Accuracy: 0.4526, Validation Accuracy: 0.5069, Loss: 2.1475
Epoch   0 Batch  135/269 - Train Accuracy: 0.4362, Validation Accuracy: 0.4987, Loss: 2.2099
Epoch   0 Batch  136/269 - Train Accuracy: 0.4412, Validation Accuracy: 0.5042, Loss: 2.1723
Epoch   0 Batch  137/269 - Train Accuracy: 0.4644, Validation Accuracy: 0.5075, Loss: 2.1510
Epoch   0 Batch  138/269 - Train Accuracy: 0.4598, Validation Accuracy: 0.5051, Loss: 2.1069
Epoch   0 Batch  139/269 - Train Accuracy: 0.4836, Validation Accuracy: 0.4996, Loss: 2.0057
Epoch   0 Batch  140/269 - Train Accuracy: 0.4834, Validation Accuracy: 0.5066, Loss: 2.0223
Epoch   0 Batch  141/269 - Train Accuracy: 0.4775, Validation Accuracy: 0.5097, Loss: 2.0643
Epoch   0 Batch  142/269 - Train Accuracy: 0.4913, Validation Accuracy: 0.5100, Loss: 1.9937
Epoch   0 Batch  143/269 - Train Accuracy: 0.5042, Validation Accuracy: 0.5231, Loss: 2.0093
Epoch   0 Batch  144/269 - Train Accuracy: 0.4884, Validation Accuracy: 0.5106, Loss: 1.9927
Epoch   0 Batch  145/269 - Train Accuracy: 0.4878, Validation Accuracy: 0.5150, Loss: 1.9974
Epoch   0 Batch  146/269 - Train Accuracy: 0.4939, Validation Accuracy: 0.5158, Loss: 1.9669
Epoch   0 Batch  147/269 - Train Accuracy: 0.5093, Validation Accuracy: 0.5110, Loss: 1.8901
Epoch   0 Batch  148/269 - Train Accuracy: 0.4891, Validation Accuracy: 0.5231, Loss: 2.0069
Epoch   0 Batch  149/269 - Train Accuracy: 0.4977, Validation Accuracy: 0.5186, Loss: 1.9394
Epoch   0 Batch  150/269 - Train Accuracy: 0.4995, Validation Accuracy: 0.5232, Loss: 1.9481
Epoch   0 Batch  151/269 - Train Accuracy: 0.5310, Validation Accuracy: 0.5243, Loss: 1.8520
Epoch   0 Batch  152/269 - Train Accuracy: 0.4818, Validation Accuracy: 0.5126, Loss: 1.9359
Epoch   0 Batch  153/269 - Train Accuracy: 0.5137, Validation Accuracy: 0.5291, Loss: 1.9202
Epoch   0 Batch  154/269 - Train Accuracy: 0.4734, Validation Accuracy: 0.5269, Loss: 2.0213
Epoch   0 Batch  155/269 - Train Accuracy: 0.5308, Validation Accuracy: 0.5265, Loss: 1.7939
Epoch   0 Batch  156/269 - Train Accuracy: 0.4885, Validation Accuracy: 0.5222, Loss: 1.9483
Epoch   0 Batch  157/269 - Train Accuracy: 0.4880, Validation Accuracy: 0.5176, Loss: 1.8926
Epoch   0 Batch  158/269 - Train Accuracy: 0.5050, Validation Accuracy: 0.5248, Loss: 1.8641
Epoch   0 Batch  159/269 - Train Accuracy: 0.5080, Validation Accuracy: 0.5208, Loss: 1.8732
Epoch   0 Batch  160/269 - Train Accuracy: 0.4790, Validation Accuracy: 0.5093, Loss: 1.8850
Epoch   0 Batch  161/269 - Train Accuracy: 0.4930, Validation Accuracy: 0.5276, Loss: 1.8902
Epoch   0 Batch  162/269 - Train Accuracy: 0.5079, Validation Accuracy: 0.5260, Loss: 1.8380
Epoch   0 Batch  163/269 - Train Accuracy: 0.4792, Validation Accuracy: 0.5065, Loss: 1.8398
Epoch   0 Batch  164/269 - Train Accuracy: 0.5101, Validation Accuracy: 0.5264, Loss: 1.8509
Epoch   0 Batch  165/269 - Train Accuracy: 0.4797, Validation Accuracy: 0.5274, Loss: 1.8955
Epoch   0 Batch  166/269 - Train Accuracy: 0.5133, Validation Accuracy: 0.5126, Loss: 1.7212
Epoch   0 Batch  167/269 - Train Accuracy: 0.5132, Validation Accuracy: 0.5302, Loss: 1.8128
Epoch   0 Batch  168/269 - Train Accuracy: 0.5092, Validation Accuracy: 0.5275, Loss: 1.8132
Epoch   0 Batch  169/269 - Train Accuracy: 0.4822, Validation Accuracy: 0.5152, Loss: 1.7993
Epoch   0 Batch  170/269 - Train Accuracy: 0.5028, Validation Accuracy: 0.5264, Loss: 1.7888
Epoch   0 Batch  171/269 - Train Accuracy: 0.4892, Validation Accuracy: 0.5277, Loss: 1.8400
Epoch   0 Batch  172/269 - Train Accuracy: 0.4812, Validation Accuracy: 0.5134, Loss: 1.7934
Epoch   0 Batch  173/269 - Train Accuracy: 0.4927, Validation Accuracy: 0.5193, Loss: 1.7674
Epoch   0 Batch  174/269 - Train Accuracy: 0.5055, Validation Accuracy: 0.5298, Loss: 1.7678
Epoch   0 Batch  175/269 - Train Accuracy: 0.4965, Validation Accuracy: 0.5180, Loss: 1.7784
Epoch   0 Batch  176/269 - Train Accuracy: 0.4729, Validation Accuracy: 0.5145, Loss: 1.8337
Epoch   0 Batch  177/269 - Train Accuracy: 0.5201, Validation Accuracy: 0.5294, Loss: 1.6906
Epoch   0 Batch  178/269 - Train Accuracy: 0.4844, Validation Accuracy: 0.5257, Loss: 1.8020
Epoch   0 Batch  179/269 - Train Accuracy: 0.4951, Validation Accuracy: 0.5161, Loss: 1.7234
Epoch   0 Batch  180/269 - Train Accuracy: 0.5077, Validation Accuracy: 0.5355, Loss: 1.7117
Epoch   0 Batch  181/269 - Train Accuracy: 0.5033, Validation Accuracy: 0.5289, Loss: 1.7090
Epoch   0 Batch  182/269 - Train Accuracy: 0.4948, Validation Accuracy: 0.5183, Loss: 1.7169
Epoch   0 Batch  183/269 - Train Accuracy: 0.5675, Validation Accuracy: 0.5309, Loss: 1.4923
Epoch   0 Batch  184/269 - Train Accuracy: 0.4908, Validation Accuracy: 0.5319, Loss: 1.7683
Epoch   0 Batch  185/269 - Train Accuracy: 0.4967, Validation Accuracy: 0.5100, Loss: 1.6679
Epoch   0 Batch  186/269 - Train Accuracy: 0.4617, Validation Accuracy: 0.5163, Loss: 1.7575
Epoch   0 Batch  187/269 - Train Accuracy: 0.5114, Validation Accuracy: 0.5328, Loss: 1.6378
Epoch   0 Batch  188/269 - Train Accuracy: 0.4946, Validation Accuracy: 0.5065, Loss: 1.6295
Epoch   0 Batch  189/269 - Train Accuracy: 0.4915, Validation Accuracy: 0.5099, Loss: 1.6552
Epoch   0 Batch  190/269 - Train Accuracy: 0.5130, Validation Accuracy: 0.5348, Loss: 1.6513
Epoch   0 Batch  191/269 - Train Accuracy: 0.4982, Validation Accuracy: 0.5237, Loss: 1.6670
Epoch   0 Batch  192/269 - Train Accuracy: 0.4856, Validation Accuracy: 0.5105, Loss: 1.6593
Epoch   0 Batch  193/269 - Train Accuracy: 0.5007, Validation Accuracy: 0.5311, Loss: 1.6496
Epoch   0 Batch  194/269 - Train Accuracy: 0.5171, Validation Accuracy: 0.5397, Loss: 1.6507
Epoch   0 Batch  195/269 - Train Accuracy: 0.4888, Validation Accuracy: 0.5251, Loss: 1.6621
Epoch   0 Batch  196/269 - Train Accuracy: 0.5033, Validation Accuracy: 0.5359, Loss: 1.6374
Epoch   0 Batch  197/269 - Train Accuracy: 0.4852, Validation Accuracy: 0.5368, Loss: 1.6992
Epoch   0 Batch  198/269 - Train Accuracy: 0.4596, Validation Accuracy: 0.5167, Loss: 1.7216
Epoch   0 Batch  199/269 - Train Accuracy: 0.4990, Validation Accuracy: 0.5299, Loss: 1.6538
Epoch   0 Batch  200/269 - Train Accuracy: 0.4924, Validation Accuracy: 0.5261, Loss: 1.6611
Epoch   0 Batch  201/269 - Train Accuracy: 0.4999, Validation Accuracy: 0.5191, Loss: 1.6111
Epoch   0 Batch  202/269 - Train Accuracy: 0.4975, Validation Accuracy: 0.5266, Loss: 1.6215
Epoch   0 Batch  203/269 - Train Accuracy: 0.4915, Validation Accuracy: 0.5321, Loss: 1.6695
Epoch   0 Batch  204/269 - Train Accuracy: 0.4636, Validation Accuracy: 0.5142, Loss: 1.6496
Epoch   0 Batch  205/269 - Train Accuracy: 0.4882, Validation Accuracy: 0.5239, Loss: 1.5813
Epoch   0 Batch  206/269 - Train Accuracy: 0.4809, Validation Accuracy: 0.5289, Loss: 1.6761
Epoch   0 Batch  207/269 - Train Accuracy: 0.5146, Validation Accuracy: 0.5215, Loss: 1.5202
Epoch   0 Batch  208/269 - Train Accuracy: 0.4697, Validation Accuracy: 0.5203, Loss: 1.6593
Epoch   0 Batch  209/269 - Train Accuracy: 0.4777, Validation Accuracy: 0.5265, Loss: 1.6190
Epoch   0 Batch  210/269 - Train Accuracy: 0.5003, Validation Accuracy: 0.5210, Loss: 1.5490
Epoch   0 Batch  211/269 - Train Accuracy: 0.4974, Validation Accuracy: 0.5230, Loss: 1.5524
Epoch   0 Batch  212/269 - Train Accuracy: 0.5171, Validation Accuracy: 0.5250, Loss: 1.5185
Epoch   0 Batch  213/269 - Train Accuracy: 0.5019, Validation Accuracy: 0.5236, Loss: 1.5262
Epoch   0 Batch  214/269 - Train Accuracy: 0.4967, Validation Accuracy: 0.5188, Loss: 1.5312
Epoch   0 Batch  215/269 - Train Accuracy: 0.5235, Validation Accuracy: 0.5217, Loss: 1.4490
Epoch   0 Batch  216/269 - Train Accuracy: 0.4689, Validation Accuracy: 0.5244, Loss: 1.6311
Epoch   0 Batch  217/269 - Train Accuracy: 0.4512, Validation Accuracy: 0.5102, Loss: 1.6054
Epoch   0 Batch  218/269 - Train Accuracy: 0.4716, Validation Accuracy: 0.5181, Loss: 1.5989
Epoch   0 Batch  219/269 - Train Accuracy: 0.4739, Validation Accuracy: 0.5187, Loss: 1.5636
Epoch   0 Batch  220/269 - Train Accuracy: 0.5017, Validation Accuracy: 0.5154, Loss: 1.4576
Epoch   0 Batch  221/269 - Train Accuracy: 0.4877, Validation Accuracy: 0.5052, Loss: 1.4948
Epoch   0 Batch  222/269 - Train Accuracy: 0.4908, Validation Accuracy: 0.5146, Loss: 1.4669
Epoch   0 Batch  223/269 - Train Accuracy: 0.4927, Validation Accuracy: 0.5108, Loss: 1.4544
Epoch   0 Batch  224/269 - Train Accuracy: 0.4921, Validation Accuracy: 0.5122, Loss: 1.5037
Epoch   0 Batch  225/269 - Train Accuracy: 0.4792, Validation Accuracy: 0.5204, Loss: 1.5573
Epoch   0 Batch  226/269 - Train Accuracy: 0.4885, Validation Accuracy: 0.5127, Loss: 1.4825
Epoch   0 Batch  227/269 - Train Accuracy: 0.5545, Validation Accuracy: 0.5054, Loss: 1.2933
Epoch   0 Batch  228/269 - Train Accuracy: 0.4781, Validation Accuracy: 0.5125, Loss: 1.4897
Epoch   0 Batch  229/269 - Train Accuracy: 0.4957, Validation Accuracy: 0.5136, Loss: 1.4686
Epoch   0 Batch  230/269 - Train Accuracy: 0.4748, Validation Accuracy: 0.5082, Loss: 1.4796
Epoch   0 Batch  231/269 - Train Accuracy: 0.4573, Validation Accuracy: 0.5169, Loss: 1.5470
Epoch   0 Batch  232/269 - Train Accuracy: 0.4551, Validation Accuracy: 0.5189, Loss: 1.5410
Epoch   0 Batch  233/269 - Train Accuracy: 0.4890, Validation Accuracy: 0.5130, Loss: 1.4708
Epoch   0 Batch  234/269 - Train Accuracy: 0.4826, Validation Accuracy: 0.5107, Loss: 1.4621
Epoch   0 Batch  235/269 - Train Accuracy: 0.4887, Validation Accuracy: 0.5098, Loss: 1.4583
Epoch   0 Batch  236/269 - Train Accuracy: 0.4863, Validation Accuracy: 0.5149, Loss: 1.4417
Epoch   0 Batch  237/269 - Train Accuracy: 0.4855, Validation Accuracy: 0.5062, Loss: 1.4386
Epoch   0 Batch  238/269 - Train Accuracy: 0.4837, Validation Accuracy: 0.5117, Loss: 1.4478
Epoch   0 Batch  239/269 - Train Accuracy: 0.4877, Validation Accuracy: 0.5075, Loss: 1.4193
Epoch   0 Batch  240/269 - Train Accuracy: 0.5075, Validation Accuracy: 0.4965, Loss: 1.3291
Epoch   0 Batch  241/269 - Train Accuracy: 0.4879, Validation Accuracy: 0.5051, Loss: 1.4132
Epoch   0 Batch  242/269 - Train Accuracy: 0.4762, Validation Accuracy: 0.5123, Loss: 1.4193
Epoch   0 Batch  243/269 - Train Accuracy: 0.4833, Validation Accuracy: 0.4941, Loss: 1.3890
Epoch   0 Batch  244/269 - Train Accuracy: 0.4693, Validation Accuracy: 0.4987, Loss: 1.3995
Epoch   0 Batch  245/269 - Train Accuracy: 0.4649, Validation Accuracy: 0.5091, Loss: 1.4731
Epoch   0 Batch  246/269 - Train Accuracy: 0.4715, Validation Accuracy: 0.5065, Loss: 1.4090
Epoch   0 Batch  247/269 - Train Accuracy: 0.4520, Validation Accuracy: 0.4980, Loss: 1.4501
Epoch   0 Batch  248/269 - Train Accuracy: 0.4814, Validation Accuracy: 0.5091, Loss: 1.3969
Epoch   0 Batch  249/269 - Train Accuracy: 0.5090, Validation Accuracy: 0.5107, Loss: 1.3377
Epoch   0 Batch  250/269 - Train Accuracy: 0.4544, Validation Accuracy: 0.4932, Loss: 1.4295
Epoch   0 Batch  251/269 - Train Accuracy: 0.4769, Validation Accuracy: 0.4939, Loss: 1.3699
Epoch   0 Batch  252/269 - Train Accuracy: 0.4616, Validation Accuracy: 0.5005, Loss: 1.3956
Epoch   0 Batch  253/269 - Train Accuracy: 0.4583, Validation Accuracy: 0.4892, Loss: 1.3812
Epoch   0 Batch  254/269 - Train Accuracy: 0.4794, Validation Accuracy: 0.4990, Loss: 1.3568
Epoch   0 Batch  255/269 - Train Accuracy: 0.5052, Validation Accuracy: 0.5034, Loss: 1.3139
Epoch   0 Batch  256/269 - Train Accuracy: 0.4557, Validation Accuracy: 0.4961, Loss: 1.3951
Epoch   0 Batch  257/269 - Train Accuracy: 0.4820, Validation Accuracy: 0.5160, Loss: 1.3716
Epoch   0 Batch  258/269 - Train Accuracy: 0.4843, Validation Accuracy: 0.5157, Loss: 1.3634
Epoch   0 Batch  259/269 - Train Accuracy: 0.4815, Validation Accuracy: 0.5081, Loss: 1.3519
Epoch   0 Batch  260/269 - Train Accuracy: 0.4788, Validation Accuracy: 0.5176, Loss: 1.4163
Epoch   0 Batch  261/269 - Train Accuracy: 0.4554, Validation Accuracy: 0.5177, Loss: 1.4221
Epoch   0 Batch  262/269 - Train Accuracy: 0.4874, Validation Accuracy: 0.5162, Loss: 1.3501
Epoch   0 Batch  263/269 - Train Accuracy: 0.4799, Validation Accuracy: 0.5172, Loss: 1.3906
Epoch   0 Batch  264/269 - Train Accuracy: 0.4713, Validation Accuracy: 0.5189, Loss: 1.3937
Epoch   0 Batch  265/269 - Train Accuracy: 0.4648, Validation Accuracy: 0.5123, Loss: 1.3712
Epoch   0 Batch  266/269 - Train Accuracy: 0.4851, Validation Accuracy: 0.5095, Loss: 1.3045
Epoch   0 Batch  267/269 - Train Accuracy: 0.4905, Validation Accuracy: 0.5262, Loss: 1.3506
Epoch   1 Batch    1/269 - Train Accuracy: 0.4570, Validation Accuracy: 0.5127, Loss: 1.3618
Epoch   1 Batch    2/269 - Train Accuracy: 0.4791, Validation Accuracy: 0.5222, Loss: 1.3375
Epoch   1 Batch    3/269 - Train Accuracy: 0.4604, Validation Accuracy: 0.5114, Loss: 1.3497
Epoch   1 Batch    4/269 - Train Accuracy: 0.4613, Validation Accuracy: 0.5203, Loss: 1.3463
Epoch   1 Batch    5/269 - Train Accuracy: 0.4688, Validation Accuracy: 0.5230, Loss: 1.3548
Epoch   1 Batch    6/269 - Train Accuracy: 0.4749, Validation Accuracy: 0.5008, Loss: 1.2371
Epoch   1 Batch    7/269 - Train Accuracy: 0.4848, Validation Accuracy: 0.5037, Loss: 1.2706
Epoch   1 Batch    8/269 - Train Accuracy: 0.4742, Validation Accuracy: 0.5257, Loss: 1.3357
Epoch   1 Batch    9/269 - Train Accuracy: 0.4572, Validation Accuracy: 0.4999, Loss: 1.2891
Epoch   1 Batch   10/269 - Train Accuracy: 0.4321, Validation Accuracy: 0.4948, Loss: 1.3067
Epoch   1 Batch   11/269 - Train Accuracy: 0.4984, Validation Accuracy: 0.5244, Loss: 1.2858
Epoch   1 Batch   12/269 - Train Accuracy: 0.4613, Validation Accuracy: 0.5177, Loss: 1.3226
Epoch   1 Batch   13/269 - Train Accuracy: 0.5131, Validation Accuracy: 0.5120, Loss: 1.1780
Epoch   1 Batch   14/269 - Train Accuracy: 0.4887, Validation Accuracy: 0.5226, Loss: 1.2498
Epoch   1 Batch   15/269 - Train Accuracy: 0.4812, Validation Accuracy: 0.5202, Loss: 1.2528
Epoch   1 Batch   16/269 - Train Accuracy: 0.4959, Validation Accuracy: 0.5121, Loss: 1.2491
Epoch   1 Batch   17/269 - Train Accuracy: 0.4834, Validation Accuracy: 0.5146, Loss: 1.2218
Epoch   1 Batch   18/269 - Train Accuracy: 0.4670, Validation Accuracy: 0.5244, Loss: 1.2834
Epoch   1 Batch   19/269 - Train Accuracy: 0.5265, Validation Accuracy: 0.5234, Loss: 1.1765
Epoch   1 Batch   20/269 - Train Accuracy: 0.4805, Validation Accuracy: 0.5215, Loss: 1.2807
Epoch   1 Batch   21/269 - Train Accuracy: 0.4821, Validation Accuracy: 0.5240, Loss: 1.3060
Epoch   1 Batch   22/269 - Train Accuracy: 0.5070, Validation Accuracy: 0.5269, Loss: 1.2135
Epoch   1 Batch   23/269 - Train Accuracy: 0.5086, Validation Accuracy: 0.5256, Loss: 1.2217
Epoch   1 Batch   24/269 - Train Accuracy: 0.4749, Validation Accuracy: 0.5218, Loss: 1.2629
Epoch   1 Batch   25/269 - Train Accuracy: 0.4750, Validation Accuracy: 0.5181, Loss: 1.2710
Epoch   1 Batch   26/269 - Train Accuracy: 0.5319, Validation Accuracy: 0.5272, Loss: 1.1353
Epoch   1 Batch   27/269 - Train Accuracy: 0.5037, Validation Accuracy: 0.5315, Loss: 1.2019
Epoch   1 Batch   28/269 - Train Accuracy: 0.4743, Validation Accuracy: 0.5278, Loss: 1.2737
Epoch   1 Batch   29/269 - Train Accuracy: 0.4791, Validation Accuracy: 0.5243, Loss: 1.2348
Epoch   1 Batch   30/269 - Train Accuracy: 0.5167, Validation Accuracy: 0.5319, Loss: 1.1843
Epoch   1 Batch   31/269 - Train Accuracy: 0.5170, Validation Accuracy: 0.5293, Loss: 1.1764
Epoch   1 Batch   32/269 - Train Accuracy: 0.5028, Validation Accuracy: 0.5321, Loss: 1.1833
Epoch   1 Batch   33/269 - Train Accuracy: 0.5191, Validation Accuracy: 0.5326, Loss: 1.1535
Epoch   1 Batch   34/269 - Train Accuracy: 0.5111, Validation Accuracy: 0.5337, Loss: 1.1729
Epoch   1 Batch   35/269 - Train Accuracy: 0.5168, Validation Accuracy: 0.5299, Loss: 1.1670
Epoch   1 Batch   36/269 - Train Accuracy: 0.5151, Validation Accuracy: 0.5295, Loss: 1.1691
Epoch   1 Batch   37/269 - Train Accuracy: 0.5069, Validation Accuracy: 0.5318, Loss: 1.1729
Epoch   1 Batch   38/269 - Train Accuracy: 0.5176, Validation Accuracy: 0.5369, Loss: 1.1732
Epoch   1 Batch   39/269 - Train Accuracy: 0.5316, Validation Accuracy: 0.5431, Loss: 1.1498
Epoch   1 Batch   40/269 - Train Accuracy: 0.4931, Validation Accuracy: 0.5345, Loss: 1.1953
Epoch   1 Batch   41/269 - Train Accuracy: 0.5249, Validation Accuracy: 0.5416, Loss: 1.1601
Epoch   1 Batch   42/269 - Train Accuracy: 0.5555, Validation Accuracy: 0.5504, Loss: 1.0901
Epoch   1 Batch   43/269 - Train Accuracy: 0.5015, Validation Accuracy: 0.5395, Loss: 1.1818
Epoch   1 Batch   44/269 - Train Accuracy: 0.5332, Validation Accuracy: 0.5388, Loss: 1.1400
Epoch   1 Batch   45/269 - Train Accuracy: 0.5183, Validation Accuracy: 0.5515, Loss: 1.1886
Epoch   1 Batch   46/269 - Train Accuracy: 0.5223, Validation Accuracy: 0.5560, Loss: 1.1834
Epoch   1 Batch   47/269 - Train Accuracy: 0.5546, Validation Accuracy: 0.5482, Loss: 1.0628
Epoch   1 Batch   48/269 - Train Accuracy: 0.5359, Validation Accuracy: 0.5564, Loss: 1.0990
Epoch   1 Batch   49/269 - Train Accuracy: 0.5168, Validation Accuracy: 0.5588, Loss: 1.1505
Epoch   1 Batch   50/269 - Train Accuracy: 0.5056, Validation Accuracy: 0.5446, Loss: 1.1662
Epoch   1 Batch   51/269 - Train Accuracy: 0.5181, Validation Accuracy: 0.5510, Loss: 1.1356
Epoch   1 Batch   52/269 - Train Accuracy: 0.5332, Validation Accuracy: 0.5548, Loss: 1.0905
Epoch   1 Batch   53/269 - Train Accuracy: 0.5200, Validation Accuracy: 0.5590, Loss: 1.1711
Epoch   1 Batch   54/269 - Train Accuracy: 0.5195, Validation Accuracy: 0.5501, Loss: 1.1609
Epoch   1 Batch   55/269 - Train Accuracy: 0.5310, Validation Accuracy: 0.5502, Loss: 1.0897
Epoch   1 Batch   56/269 - Train Accuracy: 0.5467, Validation Accuracy: 0.5531, Loss: 1.1016
Epoch   1 Batch   57/269 - Train Accuracy: 0.5266, Validation Accuracy: 0.5369, Loss: 1.1088
Epoch   1 Batch   58/269 - Train Accuracy: 0.5372, Validation Accuracy: 0.5496, Loss: 1.0930
Epoch   1 Batch   59/269 - Train Accuracy: 0.5426, Validation Accuracy: 0.5502, Loss: 1.0667
Epoch   1 Batch   60/269 - Train Accuracy: 0.5390, Validation Accuracy: 0.5542, Loss: 1.0467
Epoch   1 Batch   61/269 - Train Accuracy: 0.5541, Validation Accuracy: 0.5528, Loss: 1.0214
Epoch   1 Batch   62/269 - Train Accuracy: 0.5413, Validation Accuracy: 0.5547, Loss: 1.0486
Epoch   1 Batch   63/269 - Train Accuracy: 0.5190, Validation Accuracy: 0.5520, Loss: 1.0805
Epoch   1 Batch   64/269 - Train Accuracy: 0.5273, Validation Accuracy: 0.5504, Loss: 1.0670
Epoch   1 Batch   65/269 - Train Accuracy: 0.5336, Validation Accuracy: 0.5481, Loss: 1.0528
Epoch   1 Batch   66/269 - Train Accuracy: 0.5395, Validation Accuracy: 0.5478, Loss: 1.0296
Epoch   1 Batch   67/269 - Train Accuracy: 0.5158, Validation Accuracy: 0.5376, Loss: 1.0782
Epoch   1 Batch   68/269 - Train Accuracy: 0.5126, Validation Accuracy: 0.5381, Loss: 1.0734
Epoch   1 Batch   69/269 - Train Accuracy: 0.5128, Validation Accuracy: 0.5497, Loss: 1.1450
Epoch   1 Batch   70/269 - Train Accuracy: 0.5572, Validation Accuracy: 0.5475, Loss: 1.0565
Epoch   1 Batch   71/269 - Train Accuracy: 0.5172, Validation Accuracy: 0.5495, Loss: 1.1047
Epoch   1 Batch   72/269 - Train Accuracy: 0.5487, Validation Accuracy: 0.5527, Loss: 1.0249
Epoch   1 Batch   73/269 - Train Accuracy: 0.5334, Validation Accuracy: 0.5606, Loss: 1.0726
Epoch   1 Batch   74/269 - Train Accuracy: 0.5415, Validation Accuracy: 0.5632, Loss: 1.0685
Epoch   1 Batch   75/269 - Train Accuracy: 0.5404, Validation Accuracy: 0.5599, Loss: 1.0396
Epoch   1 Batch   76/269 - Train Accuracy: 0.5243, Validation Accuracy: 0.5560, Loss: 1.0662
Epoch   1 Batch   77/269 - Train Accuracy: 0.5609, Validation Accuracy: 0.5579, Loss: 1.0291
Epoch   1 Batch   78/269 - Train Accuracy: 0.5401, Validation Accuracy: 0.5599, Loss: 1.0365
Epoch   1 Batch   79/269 - Train Accuracy: 0.5422, Validation Accuracy: 0.5570, Loss: 1.0247
Epoch   1 Batch   80/269 - Train Accuracy: 0.5618, Validation Accuracy: 0.5534, Loss: 1.0085
Epoch   1 Batch   81/269 - Train Accuracy: 0.5413, Validation Accuracy: 0.5581, Loss: 1.0469
Epoch   1 Batch   82/269 - Train Accuracy: 0.5510, Validation Accuracy: 0.5602, Loss: 0.9950
Epoch   1 Batch   83/269 - Train Accuracy: 0.5599, Validation Accuracy: 0.5563, Loss: 1.0092
Epoch   1 Batch   84/269 - Train Accuracy: 0.5418, Validation Accuracy: 0.5476, Loss: 0.9936
Epoch   1 Batch   85/269 - Train Accuracy: 0.5290, Validation Accuracy: 0.5445, Loss: 1.0184
Epoch   1 Batch   86/269 - Train Accuracy: 0.5126, Validation Accuracy: 0.5494, Loss: 1.0218
Epoch   1 Batch   87/269 - Train Accuracy: 0.4919, Validation Accuracy: 0.5457, Loss: 1.0836
Epoch   1 Batch   88/269 - Train Accuracy: 0.5462, Validation Accuracy: 0.5635, Loss: 1.0078
Epoch   1 Batch   89/269 - Train Accuracy: 0.5609, Validation Accuracy: 0.5603, Loss: 0.9954
Epoch   1 Batch   90/269 - Train Accuracy: 0.5042, Validation Accuracy: 0.5611, Loss: 1.0625
Epoch   1 Batch   91/269 - Train Accuracy: 0.5418, Validation Accuracy: 0.5620, Loss: 0.9932
Epoch   1 Batch   92/269 - Train Accuracy: 0.5485, Validation Accuracy: 0.5633, Loss: 0.9871
Epoch   1 Batch   93/269 - Train Accuracy: 0.5581, Validation Accuracy: 0.5655, Loss: 0.9602
Epoch   1 Batch   94/269 - Train Accuracy: 0.5480, Validation Accuracy: 0.5625, Loss: 1.0089
Epoch   1 Batch   95/269 - Train Accuracy: 0.5436, Validation Accuracy: 0.5584, Loss: 0.9947
Epoch   1 Batch   96/269 - Train Accuracy: 0.5484, Validation Accuracy: 0.5494, Loss: 0.9823
Epoch   1 Batch   97/269 - Train Accuracy: 0.5330, Validation Accuracy: 0.5565, Loss: 0.9889
Epoch   1 Batch   98/269 - Train Accuracy: 0.5620, Validation Accuracy: 0.5598, Loss: 0.9719
Epoch   1 Batch   99/269 - Train Accuracy: 0.5259, Validation Accuracy: 0.5591, Loss: 1.0312
Epoch   1 Batch  100/269 - Train Accuracy: 0.5592, Validation Accuracy: 0.5621, Loss: 0.9610
Epoch   1 Batch  101/269 - Train Accuracy: 0.5194, Validation Accuracy: 0.5576, Loss: 1.0236
Epoch   1 Batch  102/269 - Train Accuracy: 0.5425, Validation Accuracy: 0.5584, Loss: 0.9694
Epoch   1 Batch  103/269 - Train Accuracy: 0.5392, Validation Accuracy: 0.5581, Loss: 0.9742
Epoch   1 Batch  104/269 - Train Accuracy: 0.5334, Validation Accuracy: 0.5566, Loss: 0.9738
Epoch   1 Batch  105/269 - Train Accuracy: 0.5429, Validation Accuracy: 0.5569, Loss: 0.9797
Epoch   1 Batch  106/269 - Train Accuracy: 0.5340, Validation Accuracy: 0.5558, Loss: 0.9620
Epoch   1 Batch  107/269 - Train Accuracy: 0.5040, Validation Accuracy: 0.5537, Loss: 1.0172
Epoch   1 Batch  108/269 - Train Accuracy: 0.5446, Validation Accuracy: 0.5542, Loss: 0.9525
Epoch   1 Batch  109/269 - Train Accuracy: 0.5290, Validation Accuracy: 0.5564, Loss: 0.9778
Epoch   1 Batch  110/269 - Train Accuracy: 0.5419, Validation Accuracy: 0.5589, Loss: 0.9543
Epoch   1 Batch  111/269 - Train Accuracy: 0.5165, Validation Accuracy: 0.5559, Loss: 1.0276
Epoch   1 Batch  112/269 - Train Accuracy: 0.5540, Validation Accuracy: 0.5574, Loss: 0.9482
Epoch   1 Batch  113/269 - Train Accuracy: 0.5550, Validation Accuracy: 0.5612, Loss: 0.9099
Epoch   1 Batch  114/269 - Train Accuracy: 0.5382, Validation Accuracy: 0.5567, Loss: 0.9515
Epoch   1 Batch  115/269 - Train Accuracy: 0.5268, Validation Accuracy: 0.5565, Loss: 0.9700
Epoch   1 Batch  116/269 - Train Accuracy: 0.5510, Validation Accuracy: 0.5604, Loss: 0.9525
Epoch   1 Batch  117/269 - Train Accuracy: 0.5430, Validation Accuracy: 0.5600, Loss: 0.9357
Epoch   1 Batch  118/269 - Train Accuracy: 0.5698, Validation Accuracy: 0.5598, Loss: 0.9169
Epoch   1 Batch  119/269 - Train Accuracy: 0.5309, Validation Accuracy: 0.5583, Loss: 0.9916
Epoch   1 Batch  120/269 - Train Accuracy: 0.5158, Validation Accuracy: 0.5591, Loss: 0.9688
Epoch   1 Batch  121/269 - Train Accuracy: 0.5365, Validation Accuracy: 0.5626, Loss: 0.9271
Epoch   1 Batch  122/269 - Train Accuracy: 0.5458, Validation Accuracy: 0.5613, Loss: 0.9294
Epoch   1 Batch  123/269 - Train Accuracy: 0.5135, Validation Accuracy: 0.5597, Loss: 0.9710
Epoch   1 Batch  124/269 - Train Accuracy: 0.5473, Validation Accuracy: 0.5673, Loss: 0.9031
Epoch   1 Batch  125/269 - Train Accuracy: 0.5495, Validation Accuracy: 0.5679, Loss: 0.9048
Epoch   1 Batch  126/269 - Train Accuracy: 0.5580, Validation Accuracy: 0.5641, Loss: 0.9077
Epoch   1 Batch  127/269 - Train Accuracy: 0.5264, Validation Accuracy: 0.5627, Loss: 0.9676
Epoch   1 Batch  128/269 - Train Accuracy: 0.5674, Validation Accuracy: 0.5597, Loss: 0.9147
Epoch   1 Batch  129/269 - Train Accuracy: 0.5420, Validation Accuracy: 0.5629, Loss: 0.9348
Epoch   1 Batch  130/269 - Train Accuracy: 0.5240, Validation Accuracy: 0.5684, Loss: 0.9680
Epoch   1 Batch  131/269 - Train Accuracy: 0.5333, Validation Accuracy: 0.5637, Loss: 0.9399
Epoch   1 Batch  132/269 - Train Accuracy: 0.5478, Validation Accuracy: 0.5636, Loss: 0.9222
Epoch   1 Batch  133/269 - Train Accuracy: 0.5388, Validation Accuracy: 0.5599, Loss: 0.8911
Epoch   1 Batch  134/269 - Train Accuracy: 0.5101, Validation Accuracy: 0.5599, Loss: 0.9478
Epoch   1 Batch  135/269 - Train Accuracy: 0.5129, Validation Accuracy: 0.5602, Loss: 0.9724
Epoch   1 Batch  136/269 - Train Accuracy: 0.5077, Validation Accuracy: 0.5607, Loss: 0.9691
Epoch   1 Batch  137/269 - Train Accuracy: 0.5301, Validation Accuracy: 0.5601, Loss: 0.9489
Epoch   1 Batch  138/269 - Train Accuracy: 0.5314, Validation Accuracy: 0.5572, Loss: 0.9233
Epoch   1 Batch  139/269 - Train Accuracy: 0.5520, Validation Accuracy: 0.5624, Loss: 0.8885
Epoch   1 Batch  140/269 - Train Accuracy: 0.5558, Validation Accuracy: 0.5627, Loss: 0.9127
Epoch   1 Batch  141/269 - Train Accuracy: 0.5437, Validation Accuracy: 0.5625, Loss: 0.9195
Epoch   1 Batch  142/269 - Train Accuracy: 0.5552, Validation Accuracy: 0.5645, Loss: 0.8795
Epoch   1 Batch  143/269 - Train Accuracy: 0.5507, Validation Accuracy: 0.5608, Loss: 0.8931
Epoch   1 Batch  144/269 - Train Accuracy: 0.5411, Validation Accuracy: 0.5588, Loss: 0.8713
Epoch   1 Batch  145/269 - Train Accuracy: 0.5448, Validation Accuracy: 0.5649, Loss: 0.8880
Epoch   1 Batch  146/269 - Train Accuracy: 0.5543, Validation Accuracy: 0.5658, Loss: 0.8774
Epoch   1 Batch  147/269 - Train Accuracy: 0.5797, Validation Accuracy: 0.5629, Loss: 0.8496
Epoch   1 Batch  148/269 - Train Accuracy: 0.5394, Validation Accuracy: 0.5599, Loss: 0.9057
Epoch   1 Batch  149/269 - Train Accuracy: 0.5624, Validation Accuracy: 0.5614, Loss: 0.8889
Epoch   1 Batch  150/269 - Train Accuracy: 0.5611, Validation Accuracy: 0.5684, Loss: 0.9016
Epoch   1 Batch  151/269 - Train Accuracy: 0.5939, Validation Accuracy: 0.5727, Loss: 0.8525
Epoch   1 Batch  152/269 - Train Accuracy: 0.5570, Validation Accuracy: 0.5734, Loss: 0.8841
Epoch   1 Batch  153/269 - Train Accuracy: 0.5651, Validation Accuracy: 0.5777, Loss: 0.8650
Epoch   1 Batch  154/269 - Train Accuracy: 0.5366, Validation Accuracy: 0.5777, Loss: 0.9042
Epoch   1 Batch  155/269 - Train Accuracy: 0.5936, Validation Accuracy: 0.5736, Loss: 0.8245
Epoch   1 Batch  156/269 - Train Accuracy: 0.5476, Validation Accuracy: 0.5683, Loss: 0.9093
Epoch   1 Batch  157/269 - Train Accuracy: 0.5592, Validation Accuracy: 0.5700, Loss: 0.8726
Epoch   1 Batch  158/269 - Train Accuracy: 0.5685, Validation Accuracy: 0.5716, Loss: 0.8640
Epoch   1 Batch  159/269 - Train Accuracy: 0.5668, Validation Accuracy: 0.5721, Loss: 0.8752
Epoch   1 Batch  160/269 - Train Accuracy: 0.5536, Validation Accuracy: 0.5662, Loss: 0.8704
Epoch   1 Batch  161/269 - Train Accuracy: 0.5481, Validation Accuracy: 0.5637, Loss: 0.8686
Epoch   1 Batch  162/269 - Train Accuracy: 0.5590, Validation Accuracy: 0.5692, Loss: 0.8583
Epoch   1 Batch  163/269 - Train Accuracy: 0.5786, Validation Accuracy: 0.5760, Loss: 0.8557
Epoch   1 Batch  164/269 - Train Accuracy: 0.5708, Validation Accuracy: 0.5750, Loss: 0.8532
Epoch   1 Batch  165/269 - Train Accuracy: 0.5374, Validation Accuracy: 0.5736, Loss: 0.8734
Epoch   1 Batch  166/269 - Train Accuracy: 0.5953, Validation Accuracy: 0.5747, Loss: 0.8100
Epoch   1 Batch  167/269 - Train Accuracy: 0.5643, Validation Accuracy: 0.5754, Loss: 0.8557
Epoch   1 Batch  168/269 - Train Accuracy: 0.5484, Validation Accuracy: 0.5740, Loss: 0.8682
Epoch   1 Batch  169/269 - Train Accuracy: 0.5685, Validation Accuracy: 0.5710, Loss: 0.8526
Epoch   1 Batch  170/269 - Train Accuracy: 0.5658, Validation Accuracy: 0.5675, Loss: 0.8449
Epoch   1 Batch  171/269 - Train Accuracy: 0.5582, Validation Accuracy: 0.5760, Loss: 0.8828
Epoch   1 Batch  172/269 - Train Accuracy: 0.5690, Validation Accuracy: 0.5771, Loss: 0.8550
Epoch   1 Batch  173/269 - Train Accuracy: 0.5708, Validation Accuracy: 0.5760, Loss: 0.8382
Epoch   1 Batch  174/269 - Train Accuracy: 0.5605, Validation Accuracy: 0.5707, Loss: 0.8476
Epoch   1 Batch  175/269 - Train Accuracy: 0.5711, Validation Accuracy: 0.5663, Loss: 0.8556
Epoch   1 Batch  176/269 - Train Accuracy: 0.5496, Validation Accuracy: 0.5676, Loss: 0.8918
Epoch   1 Batch  177/269 - Train Accuracy: 0.5835, Validation Accuracy: 0.5715, Loss: 0.8128
Epoch   1 Batch  178/269 - Train Accuracy: 0.5696, Validation Accuracy: 0.5798, Loss: 0.8616
Epoch   1 Batch  179/269 - Train Accuracy: 0.5725, Validation Accuracy: 0.5788, Loss: 0.8436
Epoch   1 Batch  180/269 - Train Accuracy: 0.5722, Validation Accuracy: 0.5765, Loss: 0.8263
Epoch   1 Batch  181/269 - Train Accuracy: 0.5618, Validation Accuracy: 0.5743, Loss: 0.8435
Epoch   1 Batch  182/269 - Train Accuracy: 0.5677, Validation Accuracy: 0.5696, Loss: 0.8411
Epoch   1 Batch  183/269 - Train Accuracy: 0.6309, Validation Accuracy: 0.5740, Loss: 0.7199
Epoch   1 Batch  184/269 - Train Accuracy: 0.5569, Validation Accuracy: 0.5769, Loss: 0.8663
Epoch   1 Batch  185/269 - Train Accuracy: 0.5718, Validation Accuracy: 0.5816, Loss: 0.8249
Epoch   1 Batch  186/269 - Train Accuracy: 0.5422, Validation Accuracy: 0.5796, Loss: 0.8444
Epoch   1 Batch  187/269 - Train Accuracy: 0.5791, Validation Accuracy: 0.5803, Loss: 0.8167
Epoch   1 Batch  188/269 - Train Accuracy: 0.5816, Validation Accuracy: 0.5767, Loss: 0.8061
Epoch   1 Batch  189/269 - Train Accuracy: 0.5731, Validation Accuracy: 0.5760, Loss: 0.8134
Epoch   1 Batch  190/269 - Train Accuracy: 0.5636, Validation Accuracy: 0.5696, Loss: 0.8098
Epoch   1 Batch  191/269 - Train Accuracy: 0.5762, Validation Accuracy: 0.5691, Loss: 0.8126
Epoch   1 Batch  192/269 - Train Accuracy: 0.5694, Validation Accuracy: 0.5680, Loss: 0.8207
Epoch   1 Batch  193/269 - Train Accuracy: 0.5672, Validation Accuracy: 0.5712, Loss: 0.8166
Epoch   1 Batch  194/269 - Train Accuracy: 0.5790, Validation Accuracy: 0.5727, Loss: 0.8213
Epoch   1 Batch  195/269 - Train Accuracy: 0.5629, Validation Accuracy: 0.5716, Loss: 0.8208
Epoch   1 Batch  196/269 - Train Accuracy: 0.5473, Validation Accuracy: 0.5637, Loss: 0.8163
Epoch   1 Batch  197/269 - Train Accuracy: 0.5495, Validation Accuracy: 0.5669, Loss: 0.8465
Epoch   1 Batch  198/269 - Train Accuracy: 0.5450, Validation Accuracy: 0.5748, Loss: 0.8649
Epoch   1 Batch  199/269 - Train Accuracy: 0.5579, Validation Accuracy: 0.5769, Loss: 0.8307
Epoch   1 Batch  200/269 - Train Accuracy: 0.5574, Validation Accuracy: 0.5771, Loss: 0.8371
Epoch   1 Batch  201/269 - Train Accuracy: 0.5683, Validation Accuracy: 0.5786, Loss: 0.8073
Epoch   1 Batch  202/269 - Train Accuracy: 0.5773, Validation Accuracy: 0.5810, Loss: 0.8061
Epoch   1 Batch  203/269 - Train Accuracy: 0.5477, Validation Accuracy: 0.5784, Loss: 0.8554
Epoch   1 Batch  204/269 - Train Accuracy: 0.5521, Validation Accuracy: 0.5771, Loss: 0.8369
Epoch   1 Batch  205/269 - Train Accuracy: 0.5592, Validation Accuracy: 0.5812, Loss: 0.7930
Epoch   1 Batch  206/269 - Train Accuracy: 0.5542, Validation Accuracy: 0.5809, Loss: 0.8379
Epoch   1 Batch  207/269 - Train Accuracy: 0.6003, Validation Accuracy: 0.5813, Loss: 0.7720
Epoch   1 Batch  208/269 - Train Accuracy: 0.5482, Validation Accuracy: 0.5827, Loss: 0.8416
Epoch   1 Batch  209/269 - Train Accuracy: 0.5721, Validation Accuracy: 0.5847, Loss: 0.8117
Epoch   1 Batch  210/269 - Train Accuracy: 0.5847, Validation Accuracy: 0.5870, Loss: 0.7827
Epoch   1 Batch  211/269 - Train Accuracy: 0.5818, Validation Accuracy: 0.5892, Loss: 0.8073
Epoch   1 Batch  212/269 - Train Accuracy: 0.5905, Validation Accuracy: 0.5875, Loss: 0.7803
Epoch   1 Batch  213/269 - Train Accuracy: 0.5830, Validation Accuracy: 0.5904, Loss: 0.7865
Epoch   1 Batch  214/269 - Train Accuracy: 0.5837, Validation Accuracy: 0.5911, Loss: 0.7816
Epoch   1 Batch  215/269 - Train Accuracy: 0.6171, Validation Accuracy: 0.5890, Loss: 0.7418
Epoch   1 Batch  216/269 - Train Accuracy: 0.5547, Validation Accuracy: 0.5938, Loss: 0.8470
Epoch   1 Batch  217/269 - Train Accuracy: 0.5518, Validation Accuracy: 0.5864, Loss: 0.8237
Epoch   1 Batch  218/269 - Train Accuracy: 0.5729, Validation Accuracy: 0.5816, Loss: 0.8145
Epoch   1 Batch  219/269 - Train Accuracy: 0.5766, Validation Accuracy: 0.5824, Loss: 0.8167
Epoch   1 Batch  220/269 - Train Accuracy: 0.5835, Validation Accuracy: 0.5838, Loss: 0.7480
Epoch   1 Batch  221/269 - Train Accuracy: 0.6061, Validation Accuracy: 0.5894, Loss: 0.7748
Epoch   1 Batch  222/269 - Train Accuracy: 0.5878, Validation Accuracy: 0.5898, Loss: 0.7550
Epoch   1 Batch  223/269 - Train Accuracy: 0.5781, Validation Accuracy: 0.5900, Loss: 0.7578
Epoch   1 Batch  224/269 - Train Accuracy: 0.5935, Validation Accuracy: 0.5917, Loss: 0.8022
Epoch   1 Batch  225/269 - Train Accuracy: 0.5711, Validation Accuracy: 0.5858, Loss: 0.7967
Epoch   1 Batch  226/269 - Train Accuracy: 0.5714, Validation Accuracy: 0.5830, Loss: 0.7739
Epoch   1 Batch  227/269 - Train Accuracy: 0.6412, Validation Accuracy: 0.5849, Loss: 0.6854
Epoch   1 Batch  228/269 - Train Accuracy: 0.5862, Validation Accuracy: 0.5867, Loss: 0.7749
Epoch   1 Batch  229/269 - Train Accuracy: 0.5840, Validation Accuracy: 0.5845, Loss: 0.7654
Epoch   1 Batch  230/269 - Train Accuracy: 0.5704, Validation Accuracy: 0.5805, Loss: 0.7753
Epoch   1 Batch  231/269 - Train Accuracy: 0.5523, Validation Accuracy: 0.5799, Loss: 0.8118
Epoch   1 Batch  232/269 - Train Accuracy: 0.5569, Validation Accuracy: 0.5891, Loss: 0.8036
Epoch   1 Batch  233/269 - Train Accuracy: 0.5951, Validation Accuracy: 0.5985, Loss: 0.7737
Epoch   1 Batch  234/269 - Train Accuracy: 0.5947, Validation Accuracy: 0.5977, Loss: 0.7669
Epoch   1 Batch  235/269 - Train Accuracy: 0.5939, Validation Accuracy: 0.5919, Loss: 0.7585
Epoch   1 Batch  236/269 - Train Accuracy: 0.5706, Validation Accuracy: 0.5945, Loss: 0.7624
Epoch   1 Batch  237/269 - Train Accuracy: 0.5858, Validation Accuracy: 0.5984, Loss: 0.7588
Epoch   1 Batch  238/269 - Train Accuracy: 0.6062, Validation Accuracy: 0.6005, Loss: 0.7548
Epoch   1 Batch  239/269 - Train Accuracy: 0.6026, Validation Accuracy: 0.5960, Loss: 0.7593
Epoch   1 Batch  240/269 - Train Accuracy: 0.6223, Validation Accuracy: 0.5906, Loss: 0.7004
Epoch   1 Batch  241/269 - Train Accuracy: 0.5947, Validation Accuracy: 0.5929, Loss: 0.7704
Epoch   1 Batch  242/269 - Train Accuracy: 0.5842, Validation Accuracy: 0.5971, Loss: 0.7612
Epoch   1 Batch  243/269 - Train Accuracy: 0.6061, Validation Accuracy: 0.5999, Loss: 0.7354
Epoch   1 Batch  244/269 - Train Accuracy: 0.5870, Validation Accuracy: 0.5971, Loss: 0.7572
Epoch   1 Batch  245/269 - Train Accuracy: 0.5766, Validation Accuracy: 0.5980, Loss: 0.8019
Epoch   1 Batch  246/269 - Train Accuracy: 0.5815, Validation Accuracy: 0.6033, Loss: 0.7582
Epoch   1 Batch  247/269 - Train Accuracy: 0.5910, Validation Accuracy: 0.6059, Loss: 0.7910
Epoch   1 Batch  248/269 - Train Accuracy: 0.5944, Validation Accuracy: 0.6080, Loss: 0.7506
Epoch   1 Batch  249/269 - Train Accuracy: 0.6168, Validation Accuracy: 0.5979, Loss: 0.7181
Epoch   1 Batch  250/269 - Train Accuracy: 0.5780, Validation Accuracy: 0.5979, Loss: 0.7780
Epoch   1 Batch  251/269 - Train Accuracy: 0.6072, Validation Accuracy: 0.6028, Loss: 0.7395
Epoch   1 Batch  252/269 - Train Accuracy: 0.5926, Validation Accuracy: 0.6009, Loss: 0.7581
Epoch   1 Batch  253/269 - Train Accuracy: 0.5774, Validation Accuracy: 0.5996, Loss: 0.7630
Epoch   1 Batch  254/269 - Train Accuracy: 0.5921, Validation Accuracy: 0.6035, Loss: 0.7461
Epoch   1 Batch  255/269 - Train Accuracy: 0.6183, Validation Accuracy: 0.5962, Loss: 0.7204
Epoch   1 Batch  256/269 - Train Accuracy: 0.5791, Validation Accuracy: 0.6003, Loss: 0.7587
Epoch   1 Batch  257/269 - Train Accuracy: 0.5758, Validation Accuracy: 0.6060, Loss: 0.7571
Epoch   1 Batch  258/269 - Train Accuracy: 0.5904, Validation Accuracy: 0.6065, Loss: 0.7538
Epoch   1 Batch  259/269 - Train Accuracy: 0.6205, Validation Accuracy: 0.6081, Loss: 0.7478
Epoch   1 Batch  260/269 - Train Accuracy: 0.5916, Validation Accuracy: 0.6069, Loss: 0.7780
Epoch   1 Batch  261/269 - Train Accuracy: 0.5601, Validation Accuracy: 0.6105, Loss: 0.7886
Epoch   1 Batch  262/269 - Train Accuracy: 0.6090, Validation Accuracy: 0.6105, Loss: 0.7417
Epoch   1 Batch  263/269 - Train Accuracy: 0.5976, Validation Accuracy: 0.6072, Loss: 0.7662
Epoch   1 Batch  264/269 - Train Accuracy: 0.5771, Validation Accuracy: 0.6070, Loss: 0.7745
Epoch   1 Batch  265/269 - Train Accuracy: 0.5811, Validation Accuracy: 0.6026, Loss: 0.7617
Epoch   1 Batch  266/269 - Train Accuracy: 0.6050, Validation Accuracy: 0.6048, Loss: 0.7255
Epoch   1 Batch  267/269 - Train Accuracy: 0.5941, Validation Accuracy: 0.6004, Loss: 0.7545
Epoch   2 Batch    1/269 - Train Accuracy: 0.5764, Validation Accuracy: 0.5993, Loss: 0.7577
Epoch   2 Batch    2/269 - Train Accuracy: 0.5782, Validation Accuracy: 0.6037, Loss: 0.7413
Epoch   2 Batch    3/269 - Train Accuracy: 0.5894, Validation Accuracy: 0.6010, Loss: 0.7566
Epoch   2 Batch    4/269 - Train Accuracy: 0.5736, Validation Accuracy: 0.6047, Loss: 0.7596
Epoch   2 Batch    5/269 - Train Accuracy: 0.5756, Validation Accuracy: 0.6042, Loss: 0.7627
Epoch   2 Batch    6/269 - Train Accuracy: 0.5960, Validation Accuracy: 0.6049, Loss: 0.7069
Epoch   2 Batch    7/269 - Train Accuracy: 0.5972, Validation Accuracy: 0.6075, Loss: 0.7198
Epoch   2 Batch    8/269 - Train Accuracy: 0.5812, Validation Accuracy: 0.6080, Loss: 0.7650
Epoch   2 Batch    9/269 - Train Accuracy: 0.5994, Validation Accuracy: 0.6122, Loss: 0.7439
Epoch   2 Batch   10/269 - Train Accuracy: 0.5940, Validation Accuracy: 0.6143, Loss: 0.7461
Epoch   2 Batch   11/269 - Train Accuracy: 0.5985, Validation Accuracy: 0.6127, Loss: 0.7400
Epoch   2 Batch   12/269 - Train Accuracy: 0.5794, Validation Accuracy: 0.6149, Loss: 0.7671
Epoch   2 Batch   13/269 - Train Accuracy: 0.6317, Validation Accuracy: 0.6099, Loss: 0.6820
Epoch   2 Batch   14/269 - Train Accuracy: 0.6055, Validation Accuracy: 0.6072, Loss: 0.7234
Epoch   2 Batch   15/269 - Train Accuracy: 0.5957, Validation Accuracy: 0.6106, Loss: 0.7115
Epoch   2 Batch   16/269 - Train Accuracy: 0.6196, Validation Accuracy: 0.6132, Loss: 0.7188
Epoch   2 Batch   17/269 - Train Accuracy: 0.6127, Validation Accuracy: 0.6151, Loss: 0.7090
Epoch   2 Batch   18/269 - Train Accuracy: 0.5832, Validation Accuracy: 0.6127, Loss: 0.7429
Epoch   2 Batch   19/269 - Train Accuracy: 0.6261, Validation Accuracy: 0.6130, Loss: 0.6772
Epoch   2 Batch   20/269 - Train Accuracy: 0.5947, Validation Accuracy: 0.6150, Loss: 0.7427
Epoch   2 Batch   21/269 - Train Accuracy: 0.5907, Validation Accuracy: 0.6129, Loss: 0.7598
Epoch   2 Batch   22/269 - Train Accuracy: 0.6056, Validation Accuracy: 0.6087, Loss: 0.6977
Epoch   2 Batch   23/269 - Train Accuracy: 0.6122, Validation Accuracy: 0.6131, Loss: 0.7131
Epoch   2 Batch   24/269 - Train Accuracy: 0.5981, Validation Accuracy: 0.6174, Loss: 0.7515
Epoch   2 Batch   25/269 - Train Accuracy: 0.5839, Validation Accuracy: 0.6146, Loss: 0.7593
Epoch   2 Batch   26/269 - Train Accuracy: 0.6266, Validation Accuracy: 0.6120, Loss: 0.6661
Epoch   2 Batch   27/269 - Train Accuracy: 0.5989, Validation Accuracy: 0.6110, Loss: 0.7080
Epoch   2 Batch   28/269 - Train Accuracy: 0.5648, Validation Accuracy: 0.6144, Loss: 0.7663
Epoch   2 Batch   29/269 - Train Accuracy: 0.5959, Validation Accuracy: 0.6166, Loss: 0.7317
Epoch   2 Batch   30/269 - Train Accuracy: 0.6115, Validation Accuracy: 0.6139, Loss: 0.6984
Epoch   2 Batch   31/269 - Train Accuracy: 0.6160, Validation Accuracy: 0.6134, Loss: 0.6956
Epoch   2 Batch   32/269 - Train Accuracy: 0.6064, Validation Accuracy: 0.6161, Loss: 0.6995
Epoch   2 Batch   33/269 - Train Accuracy: 0.6158, Validation Accuracy: 0.6166, Loss: 0.6882
Epoch   2 Batch   34/269 - Train Accuracy: 0.6088, Validation Accuracy: 0.6162, Loss: 0.7012
Epoch   2 Batch   35/269 - Train Accuracy: 0.6141, Validation Accuracy: 0.6145, Loss: 0.7105
Epoch   2 Batch   36/269 - Train Accuracy: 0.6089, Validation Accuracy: 0.6140, Loss: 0.7055
Epoch   2 Batch   37/269 - Train Accuracy: 0.6184, Validation Accuracy: 0.6140, Loss: 0.7013
Epoch   2 Batch   38/269 - Train Accuracy: 0.6087, Validation Accuracy: 0.6148, Loss: 0.6973
Epoch   2 Batch   39/269 - Train Accuracy: 0.6160, Validation Accuracy: 0.6146, Loss: 0.6980
Epoch   2 Batch   40/269 - Train Accuracy: 0.5985, Validation Accuracy: 0.6153, Loss: 0.7333
Epoch   2 Batch   41/269 - Train Accuracy: 0.6027, Validation Accuracy: 0.6158, Loss: 0.7107
Epoch   2 Batch   42/269 - Train Accuracy: 0.6362, Validation Accuracy: 0.6171, Loss: 0.6641
Epoch   2 Batch   43/269 - Train Accuracy: 0.6102, Validation Accuracy: 0.6175, Loss: 0.7230
Epoch   2 Batch   44/269 - Train Accuracy: 0.6187, Validation Accuracy: 0.6143, Loss: 0.7002
Epoch   2 Batch   45/269 - Train Accuracy: 0.5949, Validation Accuracy: 0.6119, Loss: 0.7238
Epoch   2 Batch   46/269 - Train Accuracy: 0.6005, Validation Accuracy: 0.6152, Loss: 0.7197
Epoch   2 Batch   47/269 - Train Accuracy: 0.6364, Validation Accuracy: 0.6141, Loss: 0.6480
Epoch   2 Batch   48/269 - Train Accuracy: 0.6139, Validation Accuracy: 0.6128, Loss: 0.6781
Epoch   2 Batch   49/269 - Train Accuracy: 0.5900, Validation Accuracy: 0.6167, Loss: 0.7089
Epoch   2 Batch   50/269 - Train Accuracy: 0.6013, Validation Accuracy: 0.6175, Loss: 0.7184
Epoch   2 Batch   51/269 - Train Accuracy: 0.6020, Validation Accuracy: 0.6175, Loss: 0.6990
Epoch   2 Batch   52/269 - Train Accuracy: 0.6044, Validation Accuracy: 0.6178, Loss: 0.6712
Epoch   2 Batch   53/269 - Train Accuracy: 0.5926, Validation Accuracy: 0.6181, Loss: 0.7247
Epoch   2 Batch   54/269 - Train Accuracy: 0.6064, Validation Accuracy: 0.6209, Loss: 0.7103
Epoch   2 Batch   55/269 - Train Accuracy: 0.6285, Validation Accuracy: 0.6191, Loss: 0.6808
Epoch   2 Batch   56/269 - Train Accuracy: 0.6334, Validation Accuracy: 0.6171, Loss: 0.6866
Epoch   2 Batch   57/269 - Train Accuracy: 0.6200, Validation Accuracy: 0.6174, Loss: 0.6989
Epoch   2 Batch   58/269 - Train Accuracy: 0.6196, Validation Accuracy: 0.6208, Loss: 0.6763
Epoch   2 Batch   59/269 - Train Accuracy: 0.6246, Validation Accuracy: 0.6195, Loss: 0.6625
Epoch   2 Batch   60/269 - Train Accuracy: 0.6231, Validation Accuracy: 0.6195, Loss: 0.6518
Epoch   2 Batch   61/269 - Train Accuracy: 0.6341, Validation Accuracy: 0.6200, Loss: 0.6388
Epoch   2 Batch   62/269 - Train Accuracy: 0.6242, Validation Accuracy: 0.6214, Loss: 0.6630
Epoch   2 Batch   63/269 - Train Accuracy: 0.6066, Validation Accuracy: 0.6245, Loss: 0.6913
Epoch   2 Batch   64/269 - Train Accuracy: 0.6090, Validation Accuracy: 0.6249, Loss: 0.6774
Epoch   2 Batch   65/269 - Train Accuracy: 0.6105, Validation Accuracy: 0.6273, Loss: 0.6767
Epoch   2 Batch   66/269 - Train Accuracy: 0.6206, Validation Accuracy: 0.6264, Loss: 0.6605
Epoch   2 Batch   67/269 - Train Accuracy: 0.6122, Validation Accuracy: 0.6242, Loss: 0.6913
Epoch   2 Batch   68/269 - Train Accuracy: 0.6044, Validation Accuracy: 0.6225, Loss: 0.6893
Epoch   2 Batch   69/269 - Train Accuracy: 0.5917, Validation Accuracy: 0.6241, Loss: 0.7439
Epoch   2 Batch   70/269 - Train Accuracy: 0.6356, Validation Accuracy: 0.6285, Loss: 0.6851
Epoch   2 Batch   71/269 - Train Accuracy: 0.6026, Validation Accuracy: 0.6222, Loss: 0.7096
Epoch   2 Batch   72/269 - Train Accuracy: 0.6271, Validation Accuracy: 0.6225, Loss: 0.6729
Epoch   2 Batch   73/269 - Train Accuracy: 0.6154, Validation Accuracy: 0.6238, Loss: 0.6947
Epoch   2 Batch   74/269 - Train Accuracy: 0.6166, Validation Accuracy: 0.6252, Loss: 0.6883
Epoch   2 Batch   75/269 - Train Accuracy: 0.6133, Validation Accuracy: 0.6228, Loss: 0.6696
Epoch   2 Batch   76/269 - Train Accuracy: 0.6046, Validation Accuracy: 0.6251, Loss: 0.6888
Epoch   2 Batch   77/269 - Train Accuracy: 0.6338, Validation Accuracy: 0.6242, Loss: 0.6698
Epoch   2 Batch   78/269 - Train Accuracy: 0.6201, Validation Accuracy: 0.6261, Loss: 0.6678
Epoch   2 Batch   79/269 - Train Accuracy: 0.6157, Validation Accuracy: 0.6257, Loss: 0.6674
Epoch   2 Batch   80/269 - Train Accuracy: 0.6333, Validation Accuracy: 0.6232, Loss: 0.6632
Epoch   2 Batch   81/269 - Train Accuracy: 0.6218, Validation Accuracy: 0.6210, Loss: 0.6811
Epoch   2 Batch   82/269 - Train Accuracy: 0.6256, Validation Accuracy: 0.6254, Loss: 0.6459
Epoch   2 Batch   83/269 - Train Accuracy: 0.6250, Validation Accuracy: 0.6270, Loss: 0.6762
Epoch   2 Batch   84/269 - Train Accuracy: 0.6269, Validation Accuracy: 0.6289, Loss: 0.6505
Epoch   2 Batch   85/269 - Train Accuracy: 0.6087, Validation Accuracy: 0.6254, Loss: 0.6700
Epoch   2 Batch   86/269 - Train Accuracy: 0.5977, Validation Accuracy: 0.6297, Loss: 0.6639
Epoch   2 Batch   87/269 - Train Accuracy: 0.5969, Validation Accuracy: 0.6293, Loss: 0.7076
Epoch   2 Batch   88/269 - Train Accuracy: 0.6095, Validation Accuracy: 0.6265, Loss: 0.6703
Epoch   2 Batch   89/269 - Train Accuracy: 0.6275, Validation Accuracy: 0.6263, Loss: 0.6643
Epoch   2 Batch   90/269 - Train Accuracy: 0.5900, Validation Accuracy: 0.6265, Loss: 0.7007
Epoch   2 Batch   91/269 - Train Accuracy: 0.6203, Validation Accuracy: 0.6285, Loss: 0.6479
Epoch   2 Batch   92/269 - Train Accuracy: 0.6155, Validation Accuracy: 0.6301, Loss: 0.6601
Epoch   2 Batch   93/269 - Train Accuracy: 0.6410, Validation Accuracy: 0.6310, Loss: 0.6332
Epoch   2 Batch   94/269 - Train Accuracy: 0.6211, Validation Accuracy: 0.6341, Loss: 0.6708
Epoch   2 Batch   95/269 - Train Accuracy: 0.6254, Validation Accuracy: 0.6345, Loss: 0.6658
Epoch   2 Batch   96/269 - Train Accuracy: 0.6269, Validation Accuracy: 0.6323, Loss: 0.6659
Epoch   2 Batch   97/269 - Train Accuracy: 0.6089, Validation Accuracy: 0.6301, Loss: 0.6542
Epoch   2 Batch   98/269 - Train Accuracy: 0.6210, Validation Accuracy: 0.6296, Loss: 0.6607
Epoch   2 Batch   99/269 - Train Accuracy: 0.6092, Validation Accuracy: 0.6288, Loss: 0.6819
Epoch   2 Batch  100/269 - Train Accuracy: 0.6430, Validation Accuracy: 0.6288, Loss: 0.6486
Epoch   2 Batch  101/269 - Train Accuracy: 0.5848, Validation Accuracy: 0.6254, Loss: 0.6974
Epoch   2 Batch  102/269 - Train Accuracy: 0.6195, Validation Accuracy: 0.6306, Loss: 0.6599
Epoch   2 Batch  103/269 - Train Accuracy: 0.6166, Validation Accuracy: 0.6328, Loss: 0.6479
Epoch   2 Batch  104/269 - Train Accuracy: 0.6087, Validation Accuracy: 0.6340, Loss: 0.6531
Epoch   2 Batch  105/269 - Train Accuracy: 0.6168, Validation Accuracy: 0.6364, Loss: 0.6742
Epoch   2 Batch  106/269 - Train Accuracy: 0.6199, Validation Accuracy: 0.6361, Loss: 0.6491
Epoch   2 Batch  107/269 - Train Accuracy: 0.5938, Validation Accuracy: 0.6352, Loss: 0.6924
Epoch   2 Batch  108/269 - Train Accuracy: 0.6190, Validation Accuracy: 0.6335, Loss: 0.6501
Epoch   2 Batch  109/269 - Train Accuracy: 0.6097, Validation Accuracy: 0.6378, Loss: 0.6629
Epoch   2 Batch  110/269 - Train Accuracy: 0.6199, Validation Accuracy: 0.6381, Loss: 0.6428
Epoch   2 Batch  111/269 - Train Accuracy: 0.5928, Validation Accuracy: 0.6357, Loss: 0.6943
Epoch   2 Batch  112/269 - Train Accuracy: 0.6258, Validation Accuracy: 0.6303, Loss: 0.6526
Epoch   2 Batch  113/269 - Train Accuracy: 0.6316, Validation Accuracy: 0.6320, Loss: 0.6218
Epoch   2 Batch  114/269 - Train Accuracy: 0.6196, Validation Accuracy: 0.6312, Loss: 0.6517
Epoch   2 Batch  115/269 - Train Accuracy: 0.6105, Validation Accuracy: 0.6327, Loss: 0.6738
Epoch   2 Batch  116/269 - Train Accuracy: 0.6189, Validation Accuracy: 0.6289, Loss: 0.6568
Epoch   2 Batch  117/269 - Train Accuracy: 0.6168, Validation Accuracy: 0.6310, Loss: 0.6461
Epoch   2 Batch  118/269 - Train Accuracy: 0.6430, Validation Accuracy: 0.6342, Loss: 0.6316
Epoch   2 Batch  119/269 - Train Accuracy: 0.6079, Validation Accuracy: 0.6349, Loss: 0.6780
Epoch   2 Batch  120/269 - Train Accuracy: 0.6199, Validation Accuracy: 0.6330, Loss: 0.6635
Epoch   2 Batch  121/269 - Train Accuracy: 0.6201, Validation Accuracy: 0.6306, Loss: 0.6391
Epoch   2 Batch  122/269 - Train Accuracy: 0.6257, Validation Accuracy: 0.6289, Loss: 0.6413
Epoch   2 Batch  123/269 - Train Accuracy: 0.6018, Validation Accuracy: 0.6317, Loss: 0.6727
Epoch   2 Batch  124/269 - Train Accuracy: 0.6139, Validation Accuracy: 0.6344, Loss: 0.6316
Epoch   2 Batch  125/269 - Train Accuracy: 0.6309, Validation Accuracy: 0.6356, Loss: 0.6316
Epoch   2 Batch  126/269 - Train Accuracy: 0.6286, Validation Accuracy: 0.6356, Loss: 0.6329
Epoch   2 Batch  127/269 - Train Accuracy: 0.6124, Validation Accuracy: 0.6383, Loss: 0.6682
Epoch   2 Batch  128/269 - Train Accuracy: 0.6425, Validation Accuracy: 0.6439, Loss: 0.6409
Epoch   2 Batch  129/269 - Train Accuracy: 0.6199, Validation Accuracy: 0.6404, Loss: 0.6424
Epoch   2 Batch  130/269 - Train Accuracy: 0.6027, Validation Accuracy: 0.6364, Loss: 0.6711
Epoch   2 Batch  131/269 - Train Accuracy: 0.6078, Validation Accuracy: 0.6404, Loss: 0.6581
Epoch   2 Batch  132/269 - Train Accuracy: 0.6307, Validation Accuracy: 0.6404, Loss: 0.6479
Epoch   2 Batch  133/269 - Train Accuracy: 0.6383, Validation Accuracy: 0.6409, Loss: 0.6224
Epoch   2 Batch  134/269 - Train Accuracy: 0.6113, Validation Accuracy: 0.6330, Loss: 0.6579
Epoch   2 Batch  135/269 - Train Accuracy: 0.6033, Validation Accuracy: 0.6367, Loss: 0.6860
Epoch   2 Batch  136/269 - Train Accuracy: 0.6030, Validation Accuracy: 0.6406, Loss: 0.6817
Epoch   2 Batch  137/269 - Train Accuracy: 0.6169, Validation Accuracy: 0.6365, Loss: 0.6636
Epoch   2 Batch  138/269 - Train Accuracy: 0.6147, Validation Accuracy: 0.6362, Loss: 0.6552
Epoch   2 Batch  139/269 - Train Accuracy: 0.6465, Validation Accuracy: 0.6379, Loss: 0.6120
Epoch   2 Batch  140/269 - Train Accuracy: 0.6364, Validation Accuracy: 0.6368, Loss: 0.6413
Epoch   2 Batch  141/269 - Train Accuracy: 0.6267, Validation Accuracy: 0.6377, Loss: 0.6461
Epoch   2 Batch  142/269 - Train Accuracy: 0.6338, Validation Accuracy: 0.6388, Loss: 0.6137
Epoch   2 Batch  143/269 - Train Accuracy: 0.6308, Validation Accuracy: 0.6391, Loss: 0.6239
Epoch   2 Batch  144/269 - Train Accuracy: 0.6305, Validation Accuracy: 0.6426, Loss: 0.6079
Epoch   2 Batch  145/269 - Train Accuracy: 0.6353, Validation Accuracy: 0.6365, Loss: 0.6241
Epoch   2 Batch  146/269 - Train Accuracy: 0.6294, Validation Accuracy: 0.6412, Loss: 0.6159
Epoch   2 Batch  147/269 - Train Accuracy: 0.6468, Validation Accuracy: 0.6388, Loss: 0.6017
Epoch   2 Batch  148/269 - Train Accuracy: 0.6328, Validation Accuracy: 0.6482, Loss: 0.6306
Epoch   2 Batch  149/269 - Train Accuracy: 0.6385, Validation Accuracy: 0.6401, Loss: 0.6329
Epoch   2 Batch  150/269 - Train Accuracy: 0.6299, Validation Accuracy: 0.6420, Loss: 0.6313
Epoch   2 Batch  151/269 - Train Accuracy: 0.6558, Validation Accuracy: 0.6431, Loss: 0.6027
Epoch   2 Batch  152/269 - Train Accuracy: 0.6304, Validation Accuracy: 0.6458, Loss: 0.6278
Epoch   2 Batch  153/269 - Train Accuracy: 0.6297, Validation Accuracy: 0.6456, Loss: 0.6170
Epoch   2 Batch  154/269 - Train Accuracy: 0.6076, Validation Accuracy: 0.6419, Loss: 0.6355
Epoch   2 Batch  155/269 - Train Accuracy: 0.6690, Validation Accuracy: 0.6428, Loss: 0.5896
Epoch   2 Batch  156/269 - Train Accuracy: 0.6143, Validation Accuracy: 0.6403, Loss: 0.6495
Epoch   2 Batch  157/269 - Train Accuracy: 0.6347, Validation Accuracy: 0.6480, Loss: 0.6251
Epoch   2 Batch  158/269 - Train Accuracy: 0.6373, Validation Accuracy: 0.6483, Loss: 0.6209
Epoch   2 Batch  159/269 - Train Accuracy: 0.6255, Validation Accuracy: 0.6511, Loss: 0.6271
Epoch   2 Batch  160/269 - Train Accuracy: 0.6322, Validation Accuracy: 0.6438, Loss: 0.6171
Epoch   2 Batch  161/269 - Train Accuracy: 0.6281, Validation Accuracy: 0.6507, Loss: 0.6247
Epoch   2 Batch  162/269 - Train Accuracy: 0.6307, Validation Accuracy: 0.6447, Loss: 0.6153
Epoch   2 Batch  163/269 - Train Accuracy: 0.6373, Validation Accuracy: 0.6477, Loss: 0.6128
Epoch   2 Batch  164/269 - Train Accuracy: 0.6484, Validation Accuracy: 0.6485, Loss: 0.6078
Epoch   2 Batch  165/269 - Train Accuracy: 0.6103, Validation Accuracy: 0.6491, Loss: 0.6368
Epoch   2 Batch  166/269 - Train Accuracy: 0.6463, Validation Accuracy: 0.6452, Loss: 0.5867
Epoch   2 Batch  167/269 - Train Accuracy: 0.6324, Validation Accuracy: 0.6476, Loss: 0.6157
Epoch   2 Batch  168/269 - Train Accuracy: 0.6231, Validation Accuracy: 0.6455, Loss: 0.6261
Epoch   2 Batch  169/269 - Train Accuracy: 0.6407, Validation Accuracy: 0.6468, Loss: 0.6161
Epoch   2 Batch  170/269 - Train Accuracy: 0.6298, Validation Accuracy: 0.6487, Loss: 0.6097
Epoch   2 Batch  171/269 - Train Accuracy: 0.6261, Validation Accuracy: 0.6432, Loss: 0.6408
Epoch   2 Batch  172/269 - Train Accuracy: 0.6285, Validation Accuracy: 0.6516, Loss: 0.6198
Epoch   2 Batch  173/269 - Train Accuracy: 0.6358, Validation Accuracy: 0.6481, Loss: 0.5993
Epoch   2 Batch  174/269 - Train Accuracy: 0.6269, Validation Accuracy: 0.6403, Loss: 0.6179
Epoch   2 Batch  175/269 - Train Accuracy: 0.6384, Validation Accuracy: 0.6408, Loss: 0.6267
Epoch   2 Batch  176/269 - Train Accuracy: 0.6217, Validation Accuracy: 0.6464, Loss: 0.6544
Epoch   2 Batch  177/269 - Train Accuracy: 0.6420, Validation Accuracy: 0.6474, Loss: 0.5821
Epoch   2 Batch  178/269 - Train Accuracy: 0.6149, Validation Accuracy: 0.6455, Loss: 0.6216
Epoch   2 Batch  179/269 - Train Accuracy: 0.6361, Validation Accuracy: 0.6467, Loss: 0.6144
Epoch   2 Batch  180/269 - Train Accuracy: 0.6342, Validation Accuracy: 0.6521, Loss: 0.6064
Epoch   2 Batch  181/269 - Train Accuracy: 0.6235, Validation Accuracy: 0.6554, Loss: 0.6121
Epoch   2 Batch  182/269 - Train Accuracy: 0.6461, Validation Accuracy: 0.6526, Loss: 0.6071
Epoch   2 Batch  183/269 - Train Accuracy: 0.6836, Validation Accuracy: 0.6494, Loss: 0.5251
Epoch   2 Batch  184/269 - Train Accuracy: 0.6233, Validation Accuracy: 0.6521, Loss: 0.6341
Epoch   2 Batch  185/269 - Train Accuracy: 0.6528, Validation Accuracy: 0.6515, Loss: 0.6001
Epoch   2 Batch  186/269 - Train Accuracy: 0.6189, Validation Accuracy: 0.6500, Loss: 0.6250
Epoch   2 Batch  187/269 - Train Accuracy: 0.6370, Validation Accuracy: 0.6509, Loss: 0.5948
Epoch   2 Batch  188/269 - Train Accuracy: 0.6468, Validation Accuracy: 0.6518, Loss: 0.5898
Epoch   2 Batch  189/269 - Train Accuracy: 0.6314, Validation Accuracy: 0.6536, Loss: 0.5929
Epoch   2 Batch  190/269 - Train Accuracy: 0.6396, Validation Accuracy: 0.6538, Loss: 0.5954
Epoch   2 Batch  191/269 - Train Accuracy: 0.6455, Validation Accuracy: 0.6497, Loss: 0.5888
Epoch   2 Batch  192/269 - Train Accuracy: 0.6503, Validation Accuracy: 0.6491, Loss: 0.6063
Epoch   2 Batch  193/269 - Train Accuracy: 0.6353, Validation Accuracy: 0.6518, Loss: 0.5964
Epoch   2 Batch  194/269 - Train Accuracy: 0.6516, Validation Accuracy: 0.6482, Loss: 0.6107
Epoch   2 Batch  195/269 - Train Accuracy: 0.6307, Validation Accuracy: 0.6444, Loss: 0.5976
Epoch   2 Batch  196/269 - Train Accuracy: 0.6283, Validation Accuracy: 0.6507, Loss: 0.6009
Epoch   2 Batch  197/269 - Train Accuracy: 0.6137, Validation Accuracy: 0.6485, Loss: 0.6174
Epoch   2 Batch  198/269 - Train Accuracy: 0.6249, Validation Accuracy: 0.6545, Loss: 0.6331
Epoch   2 Batch  199/269 - Train Accuracy: 0.6257, Validation Accuracy: 0.6511, Loss: 0.6070
Epoch   2 Batch  200/269 - Train Accuracy: 0.6314, Validation Accuracy: 0.6491, Loss: 0.6124
Epoch   2 Batch  201/269 - Train Accuracy: 0.6373, Validation Accuracy: 0.6541, Loss: 0.5957
Epoch   2 Batch  202/269 - Train Accuracy: 0.6344, Validation Accuracy: 0.6550, Loss: 0.5928
Epoch   2 Batch  203/269 - Train Accuracy: 0.6237, Validation Accuracy: 0.6493, Loss: 0.6324
Epoch   2 Batch  204/269 - Train Accuracy: 0.6256, Validation Accuracy: 0.6474, Loss: 0.6210
Epoch   2 Batch  205/269 - Train Accuracy: 0.6358, Validation Accuracy: 0.6558, Loss: 0.5891
Epoch   2 Batch  206/269 - Train Accuracy: 0.6276, Validation Accuracy: 0.6484, Loss: 0.6123
Epoch   2 Batch  207/269 - Train Accuracy: 0.6554, Validation Accuracy: 0.6483, Loss: 0.5753
Epoch   2 Batch  208/269 - Train Accuracy: 0.6254, Validation Accuracy: 0.6472, Loss: 0.6157
Epoch   2 Batch  209/269 - Train Accuracy: 0.6399, Validation Accuracy: 0.6535, Loss: 0.5998
Epoch   2 Batch  210/269 - Train Accuracy: 0.6518, Validation Accuracy: 0.6542, Loss: 0.5740
Epoch   2 Batch  211/269 - Train Accuracy: 0.6363, Validation Accuracy: 0.6540, Loss: 0.6042
Epoch   2 Batch  212/269 - Train Accuracy: 0.6605, Validation Accuracy: 0.6526, Loss: 0.5799
Epoch   2 Batch  213/269 - Train Accuracy: 0.6430, Validation Accuracy: 0.6570, Loss: 0.5927
Epoch   2 Batch  214/269 - Train Accuracy: 0.6621, Validation Accuracy: 0.6588, Loss: 0.5871
Epoch   2 Batch  215/269 - Train Accuracy: 0.6695, Validation Accuracy: 0.6541, Loss: 0.5500
Epoch   2 Batch  216/269 - Train Accuracy: 0.6244, Validation Accuracy: 0.6645, Loss: 0.6253
Epoch   2 Batch  217/269 - Train Accuracy: 0.6116, Validation Accuracy: 0.6531, Loss: 0.6116
Epoch   2 Batch  218/269 - Train Accuracy: 0.6357, Validation Accuracy: 0.6581, Loss: 0.6107
Epoch   2 Batch  219/269 - Train Accuracy: 0.6393, Validation Accuracy: 0.6547, Loss: 0.6069
Epoch   2 Batch  220/269 - Train Accuracy: 0.6470, Validation Accuracy: 0.6572, Loss: 0.5581
Epoch   2 Batch  221/269 - Train Accuracy: 0.6699, Validation Accuracy: 0.6588, Loss: 0.5821
Epoch   2 Batch  222/269 - Train Accuracy: 0.6613, Validation Accuracy: 0.6575, Loss: 0.5638
Epoch   2 Batch  223/269 - Train Accuracy: 0.6496, Validation Accuracy: 0.6657, Loss: 0.5707
Epoch   2 Batch  224/269 - Train Accuracy: 0.6587, Validation Accuracy: 0.6617, Loss: 0.5952
Epoch   2 Batch  225/269 - Train Accuracy: 0.6405, Validation Accuracy: 0.6620, Loss: 0.5898
Epoch   2 Batch  226/269 - Train Accuracy: 0.6381, Validation Accuracy: 0.6554, Loss: 0.5762
Epoch   2 Batch  227/269 - Train Accuracy: 0.6956, Validation Accuracy: 0.6615, Loss: 0.5142
Epoch   2 Batch  228/269 - Train Accuracy: 0.6389, Validation Accuracy: 0.6588, Loss: 0.5754
Epoch   2 Batch  229/269 - Train Accuracy: 0.6416, Validation Accuracy: 0.6547, Loss: 0.5667
Epoch   2 Batch  230/269 - Train Accuracy: 0.6478, Validation Accuracy: 0.6607, Loss: 0.5742
Epoch   2 Batch  231/269 - Train Accuracy: 0.6254, Validation Accuracy: 0.6632, Loss: 0.6084
Epoch   2 Batch  232/269 - Train Accuracy: 0.6196, Validation Accuracy: 0.6591, Loss: 0.6112
Epoch   2 Batch  233/269 - Train Accuracy: 0.6535, Validation Accuracy: 0.6631, Loss: 0.5801
Epoch   2 Batch  234/269 - Train Accuracy: 0.6461, Validation Accuracy: 0.6650, Loss: 0.5728
Epoch   2 Batch  235/269 - Train Accuracy: 0.6568, Validation Accuracy: 0.6665, Loss: 0.5667
Epoch   2 Batch  236/269 - Train Accuracy: 0.6434, Validation Accuracy: 0.6698, Loss: 0.5630
Epoch   2 Batch  237/269 - Train Accuracy: 0.6325, Validation Accuracy: 0.6696, Loss: 0.5695
Epoch   2 Batch  238/269 - Train Accuracy: 0.6682, Validation Accuracy: 0.6698, Loss: 0.5597
Epoch   2 Batch  239/269 - Train Accuracy: 0.6567, Validation Accuracy: 0.6631, Loss: 0.5707
Epoch   2 Batch  240/269 - Train Accuracy: 0.6753, Validation Accuracy: 0.6609, Loss: 0.5218
Epoch   2 Batch  241/269 - Train Accuracy: 0.6554, Validation Accuracy: 0.6634, Loss: 0.5734
Epoch   2 Batch  242/269 - Train Accuracy: 0.6384, Validation Accuracy: 0.6629, Loss: 0.5672
Epoch   2 Batch  243/269 - Train Accuracy: 0.6616, Validation Accuracy: 0.6612, Loss: 0.5483
Epoch   2 Batch  244/269 - Train Accuracy: 0.6564, Validation Accuracy: 0.6583, Loss: 0.5632
Epoch   2 Batch  245/269 - Train Accuracy: 0.6298, Validation Accuracy: 0.6633, Loss: 0.5973
Epoch   2 Batch  246/269 - Train Accuracy: 0.6313, Validation Accuracy: 0.6641, Loss: 0.5680
Epoch   2 Batch  247/269 - Train Accuracy: 0.6377, Validation Accuracy: 0.6618, Loss: 0.5929
Epoch   2 Batch  248/269 - Train Accuracy: 0.6430, Validation Accuracy: 0.6589, Loss: 0.5605
Epoch   2 Batch  249/269 - Train Accuracy: 0.6707, Validation Accuracy: 0.6585, Loss: 0.5400
Epoch   2 Batch  250/269 - Train Accuracy: 0.6420, Validation Accuracy: 0.6609, Loss: 0.5799
Epoch   2 Batch  251/269 - Train Accuracy: 0.6741, Validation Accuracy: 0.6622, Loss: 0.5480
Epoch   2 Batch  252/269 - Train Accuracy: 0.6499, Validation Accuracy: 0.6590, Loss: 0.5710
Epoch   2 Batch  253/269 - Train Accuracy: 0.6360, Validation Accuracy: 0.6634, Loss: 0.5748
Epoch   2 Batch  254/269 - Train Accuracy: 0.6489, Validation Accuracy: 0.6607, Loss: 0.5572
Epoch   2 Batch  255/269 - Train Accuracy: 0.6601, Validation Accuracy: 0.6532, Loss: 0.5427
Epoch   2 Batch  256/269 - Train Accuracy: 0.6317, Validation Accuracy: 0.6634, Loss: 0.5748
Epoch   2 Batch  257/269 - Train Accuracy: 0.6368, Validation Accuracy: 0.6599, Loss: 0.5727
Epoch   2 Batch  258/269 - Train Accuracy: 0.6362, Validation Accuracy: 0.6531, Loss: 0.5664
Epoch   2 Batch  259/269 - Train Accuracy: 0.6589, Validation Accuracy: 0.6592, Loss: 0.5601
Epoch   2 Batch  260/269 - Train Accuracy: 0.6425, Validation Accuracy: 0.6625, Loss: 0.5857
Epoch   2 Batch  261/269 - Train Accuracy: 0.6226, Validation Accuracy: 0.6615, Loss: 0.5866
Epoch   2 Batch  262/269 - Train Accuracy: 0.6513, Validation Accuracy: 0.6624, Loss: 0.5601
Epoch   2 Batch  263/269 - Train Accuracy: 0.6496, Validation Accuracy: 0.6626, Loss: 0.5784
Epoch   2 Batch  264/269 - Train Accuracy: 0.6321, Validation Accuracy: 0.6640, Loss: 0.5807
Epoch   2 Batch  265/269 - Train Accuracy: 0.6386, Validation Accuracy: 0.6658, Loss: 0.5724
Epoch   2 Batch  266/269 - Train Accuracy: 0.6556, Validation Accuracy: 0.6661, Loss: 0.5488
Epoch   2 Batch  267/269 - Train Accuracy: 0.6575, Validation Accuracy: 0.6671, Loss: 0.5639
Epoch   3 Batch    1/269 - Train Accuracy: 0.6403, Validation Accuracy: 0.6695, Loss: 0.5732
Epoch   3 Batch    2/269 - Train Accuracy: 0.6495, Validation Accuracy: 0.6666, Loss: 0.5598
Epoch   3 Batch    3/269 - Train Accuracy: 0.6600, Validation Accuracy: 0.6640, Loss: 0.5657
Epoch   3 Batch    4/269 - Train Accuracy: 0.6353, Validation Accuracy: 0.6656, Loss: 0.5766
Epoch   3 Batch    5/269 - Train Accuracy: 0.6218, Validation Accuracy: 0.6585, Loss: 0.5716
Epoch   3 Batch    6/269 - Train Accuracy: 0.6563, Validation Accuracy: 0.6599, Loss: 0.5352
Epoch   3 Batch    7/269 - Train Accuracy: 0.6511, Validation Accuracy: 0.6673, Loss: 0.5436
Epoch   3 Batch    8/269 - Train Accuracy: 0.6240, Validation Accuracy: 0.6530, Loss: 0.5830
Epoch   3 Batch    9/269 - Train Accuracy: 0.6405, Validation Accuracy: 0.6565, Loss: 0.5681
Epoch   3 Batch   10/269 - Train Accuracy: 0.6514, Validation Accuracy: 0.6630, Loss: 0.5745
Epoch   3 Batch   11/269 - Train Accuracy: 0.6438, Validation Accuracy: 0.6523, Loss: 0.5722
Epoch   3 Batch   12/269 - Train Accuracy: 0.6331, Validation Accuracy: 0.6582, Loss: 0.5904
Epoch   3 Batch   13/269 - Train Accuracy: 0.6759, Validation Accuracy: 0.6636, Loss: 0.5171
Epoch   3 Batch   14/269 - Train Accuracy: 0.6405, Validation Accuracy: 0.6453, Loss: 0.5471
Epoch   3 Batch   15/269 - Train Accuracy: 0.6487, Validation Accuracy: 0.6601, Loss: 0.5453
Epoch   3 Batch   16/269 - Train Accuracy: 0.6675, Validation Accuracy: 0.6618, Loss: 0.5471
Epoch   3 Batch   17/269 - Train Accuracy: 0.6581, Validation Accuracy: 0.6668, Loss: 0.5468
Epoch   3 Batch   18/269 - Train Accuracy: 0.6348, Validation Accuracy: 0.6591, Loss: 0.5581
Epoch   3 Batch   19/269 - Train Accuracy: 0.6839, Validation Accuracy: 0.6662, Loss: 0.5128
Epoch   3 Batch   20/269 - Train Accuracy: 0.6470, Validation Accuracy: 0.6689, Loss: 0.5610
Epoch   3 Batch   21/269 - Train Accuracy: 0.6390, Validation Accuracy: 0.6661, Loss: 0.5818
Epoch   3 Batch   22/269 - Train Accuracy: 0.6748, Validation Accuracy: 0.6705, Loss: 0.5301
Epoch   3 Batch   23/269 - Train Accuracy: 0.6612, Validation Accuracy: 0.6743, Loss: 0.5393
Epoch   3 Batch   24/269 - Train Accuracy: 0.6534, Validation Accuracy: 0.6705, Loss: 0.5743
Epoch   3 Batch   25/269 - Train Accuracy: 0.6355, Validation Accuracy: 0.6646, Loss: 0.5832
Epoch   3 Batch   26/269 - Train Accuracy: 0.6707, Validation Accuracy: 0.6603, Loss: 0.5078
Epoch   3 Batch   27/269 - Train Accuracy: 0.6466, Validation Accuracy: 0.6642, Loss: 0.5374
Epoch   3 Batch   28/269 - Train Accuracy: 0.6070, Validation Accuracy: 0.6602, Loss: 0.5897
Epoch   3 Batch   29/269 - Train Accuracy: 0.6361, Validation Accuracy: 0.6544, Loss: 0.5608
Epoch   3 Batch   30/269 - Train Accuracy: 0.6610, Validation Accuracy: 0.6650, Loss: 0.5368
Epoch   3 Batch   31/269 - Train Accuracy: 0.6588, Validation Accuracy: 0.6656, Loss: 0.5281
Epoch   3 Batch   32/269 - Train Accuracy: 0.6613, Validation Accuracy: 0.6607, Loss: 0.5301
Epoch   3 Batch   33/269 - Train Accuracy: 0.6713, Validation Accuracy: 0.6664, Loss: 0.5312
Epoch   3 Batch   34/269 - Train Accuracy: 0.6547, Validation Accuracy: 0.6705, Loss: 0.5404
Epoch   3 Batch   35/269 - Train Accuracy: 0.6626, Validation Accuracy: 0.6712, Loss: 0.5432
Epoch   3 Batch   36/269 - Train Accuracy: 0.6580, Validation Accuracy: 0.6690, Loss: 0.5348
Epoch   3 Batch   37/269 - Train Accuracy: 0.6683, Validation Accuracy: 0.6687, Loss: 0.5324
Epoch   3 Batch   38/269 - Train Accuracy: 0.6619, Validation Accuracy: 0.6681, Loss: 0.5310
Epoch   3 Batch   39/269 - Train Accuracy: 0.6642, Validation Accuracy: 0.6651, Loss: 0.5325
Epoch   3 Batch   40/269 - Train Accuracy: 0.6508, Validation Accuracy: 0.6665, Loss: 0.5574
Epoch   3 Batch   41/269 - Train Accuracy: 0.6531, Validation Accuracy: 0.6677, Loss: 0.5415
Epoch   3 Batch   42/269 - Train Accuracy: 0.6732, Validation Accuracy: 0.6661, Loss: 0.5034
Epoch   3 Batch   43/269 - Train Accuracy: 0.6506, Validation Accuracy: 0.6680, Loss: 0.5512
Epoch   3 Batch   44/269 - Train Accuracy: 0.6581, Validation Accuracy: 0.6732, Loss: 0.5338
Epoch   3 Batch   45/269 - Train Accuracy: 0.6448, Validation Accuracy: 0.6589, Loss: 0.5608
Epoch   3 Batch   46/269 - Train Accuracy: 0.6597, Validation Accuracy: 0.6736, Loss: 0.5535
Epoch   3 Batch   47/269 - Train Accuracy: 0.6973, Validation Accuracy: 0.6781, Loss: 0.4934
Epoch   3 Batch   48/269 - Train Accuracy: 0.6605, Validation Accuracy: 0.6651, Loss: 0.5162
Epoch   3 Batch   49/269 - Train Accuracy: 0.6509, Validation Accuracy: 0.6730, Loss: 0.5487
Epoch   3 Batch   50/269 - Train Accuracy: 0.6559, Validation Accuracy: 0.6780, Loss: 0.5467
Epoch   3 Batch   51/269 - Train Accuracy: 0.6510, Validation Accuracy: 0.6690, Loss: 0.5336
Epoch   3 Batch   52/269 - Train Accuracy: 0.6505, Validation Accuracy: 0.6669, Loss: 0.5097
Epoch   3 Batch   53/269 - Train Accuracy: 0.6415, Validation Accuracy: 0.6720, Loss: 0.5590
Epoch   3 Batch   54/269 - Train Accuracy: 0.6572, Validation Accuracy: 0.6707, Loss: 0.5394
Epoch   3 Batch   55/269 - Train Accuracy: 0.6715, Validation Accuracy: 0.6702, Loss: 0.5128
Epoch   3 Batch   56/269 - Train Accuracy: 0.6804, Validation Accuracy: 0.6780, Loss: 0.5316
Epoch   3 Batch   57/269 - Train Accuracy: 0.6693, Validation Accuracy: 0.6755, Loss: 0.5390
Epoch   3 Batch   58/269 - Train Accuracy: 0.6662, Validation Accuracy: 0.6710, Loss: 0.5213
Epoch   3 Batch   59/269 - Train Accuracy: 0.6770, Validation Accuracy: 0.6752, Loss: 0.5025
Epoch   3 Batch   60/269 - Train Accuracy: 0.6749, Validation Accuracy: 0.6772, Loss: 0.5032
Epoch   3 Batch   61/269 - Train Accuracy: 0.6821, Validation Accuracy: 0.6697, Loss: 0.4878
Epoch   3 Batch   62/269 - Train Accuracy: 0.6835, Validation Accuracy: 0.6736, Loss: 0.5093
Epoch   3 Batch   63/269 - Train Accuracy: 0.6642, Validation Accuracy: 0.6744, Loss: 0.5293
Epoch   3 Batch   64/269 - Train Accuracy: 0.6547, Validation Accuracy: 0.6701, Loss: 0.5204
Epoch   3 Batch   65/269 - Train Accuracy: 0.6657, Validation Accuracy: 0.6750, Loss: 0.5210
Epoch   3 Batch   66/269 - Train Accuracy: 0.6621, Validation Accuracy: 0.6752, Loss: 0.5046
Epoch   3 Batch   67/269 - Train Accuracy: 0.6550, Validation Accuracy: 0.6694, Loss: 0.5295
Epoch   3 Batch   68/269 - Train Accuracy: 0.6460, Validation Accuracy: 0.6686, Loss: 0.5224
Epoch   3 Batch   69/269 - Train Accuracy: 0.6312, Validation Accuracy: 0.6743, Loss: 0.5662
Epoch   3 Batch   70/269 - Train Accuracy: 0.6759, Validation Accuracy: 0.6702, Loss: 0.5298
Epoch   3 Batch   71/269 - Train Accuracy: 0.6516, Validation Accuracy: 0.6717, Loss: 0.5417
Epoch   3 Batch   72/269 - Train Accuracy: 0.6545, Validation Accuracy: 0.6763, Loss: 0.5165
Epoch   3 Batch   73/269 - Train Accuracy: 0.6641, Validation Accuracy: 0.6745, Loss: 0.5270
Epoch   3 Batch   74/269 - Train Accuracy: 0.6691, Validation Accuracy: 0.6731, Loss: 0.5243
Epoch   3 Batch   75/269 - Train Accuracy: 0.6680, Validation Accuracy: 0.6729, Loss: 0.5074
Epoch   3 Batch   76/269 - Train Accuracy: 0.6536, Validation Accuracy: 0.6730, Loss: 0.5223
Epoch   3 Batch   77/269 - Train Accuracy: 0.6782, Validation Accuracy: 0.6760, Loss: 0.5136
Epoch   3 Batch   78/269 - Train Accuracy: 0.6716, Validation Accuracy: 0.6808, Loss: 0.5062
Epoch   3 Batch   79/269 - Train Accuracy: 0.6709, Validation Accuracy: 0.6761, Loss: 0.5110
Epoch   3 Batch   80/269 - Train Accuracy: 0.6786, Validation Accuracy: 0.6760, Loss: 0.5063
Epoch   3 Batch   81/269 - Train Accuracy: 0.6788, Validation Accuracy: 0.6768, Loss: 0.5273
Epoch   3 Batch   82/269 - Train Accuracy: 0.6772, Validation Accuracy: 0.6757, Loss: 0.4966
Epoch   3 Batch   83/269 - Train Accuracy: 0.6739, Validation Accuracy: 0.6737, Loss: 0.5181
Epoch   3 Batch   84/269 - Train Accuracy: 0.6700, Validation Accuracy: 0.6782, Loss: 0.5008
Epoch   3 Batch   85/269 - Train Accuracy: 0.6612, Validation Accuracy: 0.6749, Loss: 0.5084
Epoch   3 Batch   86/269 - Train Accuracy: 0.6506, Validation Accuracy: 0.6771, Loss: 0.5044
Epoch   3 Batch   87/269 - Train Accuracy: 0.6471, Validation Accuracy: 0.6784, Loss: 0.5413
Epoch   3 Batch   88/269 - Train Accuracy: 0.6527, Validation Accuracy: 0.6736, Loss: 0.5073
Epoch   3 Batch   89/269 - Train Accuracy: 0.6798, Validation Accuracy: 0.6776, Loss: 0.5069
Epoch   3 Batch   90/269 - Train Accuracy: 0.6301, Validation Accuracy: 0.6736, Loss: 0.5373
Epoch   3 Batch   91/269 - Train Accuracy: 0.6799, Validation Accuracy: 0.6727, Loss: 0.4939
Epoch   3 Batch   92/269 - Train Accuracy: 0.6720, Validation Accuracy: 0.6741, Loss: 0.5017
Epoch   3 Batch   93/269 - Train Accuracy: 0.6793, Validation Accuracy: 0.6767, Loss: 0.4829
Epoch   3 Batch   94/269 - Train Accuracy: 0.6688, Validation Accuracy: 0.6769, Loss: 0.5157
Epoch   3 Batch   95/269 - Train Accuracy: 0.6659, Validation Accuracy: 0.6798, Loss: 0.5045
Epoch   3 Batch   96/269 - Train Accuracy: 0.6717, Validation Accuracy: 0.6717, Loss: 0.5049
Epoch   3 Batch   97/269 - Train Accuracy: 0.6645, Validation Accuracy: 0.6805, Loss: 0.5040
Epoch   3 Batch   98/269 - Train Accuracy: 0.6700, Validation Accuracy: 0.6826, Loss: 0.5063
Epoch   3 Batch   99/269 - Train Accuracy: 0.6575, Validation Accuracy: 0.6690, Loss: 0.5153
Epoch   3 Batch  100/269 - Train Accuracy: 0.6915, Validation Accuracy: 0.6777, Loss: 0.5033
Epoch   3 Batch  101/269 - Train Accuracy: 0.6495, Validation Accuracy: 0.6812, Loss: 0.5341
Epoch   3 Batch  102/269 - Train Accuracy: 0.6717, Validation Accuracy: 0.6738, Loss: 0.4991
Epoch   3 Batch  103/269 - Train Accuracy: 0.6777, Validation Accuracy: 0.6838, Loss: 0.4992
Epoch   3 Batch  104/269 - Train Accuracy: 0.6732, Validation Accuracy: 0.6868, Loss: 0.4980
Epoch   3 Batch  105/269 - Train Accuracy: 0.6612, Validation Accuracy: 0.6824, Loss: 0.5058
Epoch   3 Batch  106/269 - Train Accuracy: 0.6694, Validation Accuracy: 0.6834, Loss: 0.4960
Epoch   3 Batch  107/269 - Train Accuracy: 0.6523, Validation Accuracy: 0.6831, Loss: 0.5319
Epoch   3 Batch  108/269 - Train Accuracy: 0.6595, Validation Accuracy: 0.6805, Loss: 0.5064
Epoch   3 Batch  109/269 - Train Accuracy: 0.6603, Validation Accuracy: 0.6848, Loss: 0.5062
Epoch   3 Batch  110/269 - Train Accuracy: 0.6663, Validation Accuracy: 0.6786, Loss: 0.4905
Epoch   3 Batch  111/269 - Train Accuracy: 0.6304, Validation Accuracy: 0.6733, Loss: 0.5345
Epoch   3 Batch  112/269 - Train Accuracy: 0.6744, Validation Accuracy: 0.6777, Loss: 0.5002
Epoch   3 Batch  113/269 - Train Accuracy: 0.6824, Validation Accuracy: 0.6786, Loss: 0.4798
Epoch   3 Batch  114/269 - Train Accuracy: 0.6775, Validation Accuracy: 0.6756, Loss: 0.4986
Epoch   3 Batch  115/269 - Train Accuracy: 0.6621, Validation Accuracy: 0.6778, Loss: 0.5243
Epoch   3 Batch  116/269 - Train Accuracy: 0.6743, Validation Accuracy: 0.6764, Loss: 0.5107
Epoch   3 Batch  117/269 - Train Accuracy: 0.6729, Validation Accuracy: 0.6824, Loss: 0.4923
Epoch   3 Batch  118/269 - Train Accuracy: 0.6943, Validation Accuracy: 0.6815, Loss: 0.4830
Epoch   3 Batch  119/269 - Train Accuracy: 0.6742, Validation Accuracy: 0.6830, Loss: 0.5202
Epoch   3 Batch  120/269 - Train Accuracy: 0.6605, Validation Accuracy: 0.6844, Loss: 0.5057
Epoch   3 Batch  121/269 - Train Accuracy: 0.6709, Validation Accuracy: 0.6813, Loss: 0.4883
Epoch   3 Batch  122/269 - Train Accuracy: 0.6707, Validation Accuracy: 0.6793, Loss: 0.4865
Epoch   3 Batch  123/269 - Train Accuracy: 0.6658, Validation Accuracy: 0.6821, Loss: 0.5110
Epoch   3 Batch  124/269 - Train Accuracy: 0.6656, Validation Accuracy: 0.6843, Loss: 0.4849
Epoch   3 Batch  125/269 - Train Accuracy: 0.6722, Validation Accuracy: 0.6847, Loss: 0.4825
Epoch   3 Batch  126/269 - Train Accuracy: 0.6856, Validation Accuracy: 0.6913, Loss: 0.4858
Epoch   3 Batch  127/269 - Train Accuracy: 0.6546, Validation Accuracy: 0.6919, Loss: 0.5143
Epoch   3 Batch  128/269 - Train Accuracy: 0.6902, Validation Accuracy: 0.6897, Loss: 0.4929
Epoch   3 Batch  129/269 - Train Accuracy: 0.6810, Validation Accuracy: 0.6870, Loss: 0.4913
Epoch   3 Batch  130/269 - Train Accuracy: 0.6559, Validation Accuracy: 0.6798, Loss: 0.5087
Epoch   3 Batch  131/269 - Train Accuracy: 0.6618, Validation Accuracy: 0.6820, Loss: 0.5047
Epoch   3 Batch  132/269 - Train Accuracy: 0.6729, Validation Accuracy: 0.6880, Loss: 0.5025
Epoch   3 Batch  133/269 - Train Accuracy: 0.6801, Validation Accuracy: 0.6814, Loss: 0.4791
Epoch   3 Batch  134/269 - Train Accuracy: 0.6650, Validation Accuracy: 0.6851, Loss: 0.5001
Epoch   3 Batch  135/269 - Train Accuracy: 0.6416, Validation Accuracy: 0.6827, Loss: 0.5234
Epoch   3 Batch  136/269 - Train Accuracy: 0.6512, Validation Accuracy: 0.6805, Loss: 0.5203
Epoch   3 Batch  137/269 - Train Accuracy: 0.6762, Validation Accuracy: 0.6778, Loss: 0.5132
Epoch   3 Batch  138/269 - Train Accuracy: 0.6704, Validation Accuracy: 0.6862, Loss: 0.4964
Epoch   3 Batch  139/269 - Train Accuracy: 0.7070, Validation Accuracy: 0.6824, Loss: 0.4689
Epoch   3 Batch  140/269 - Train Accuracy: 0.6770, Validation Accuracy: 0.6829, Loss: 0.4899
Epoch   3 Batch  141/269 - Train Accuracy: 0.6678, Validation Accuracy: 0.6824, Loss: 0.5002
Epoch   3 Batch  142/269 - Train Accuracy: 0.6841, Validation Accuracy: 0.6845, Loss: 0.4745
Epoch   3 Batch  143/269 - Train Accuracy: 0.6755, Validation Accuracy: 0.6861, Loss: 0.4818
Epoch   3 Batch  144/269 - Train Accuracy: 0.6759, Validation Accuracy: 0.6867, Loss: 0.4603
Epoch   3 Batch  145/269 - Train Accuracy: 0.6830, Validation Accuracy: 0.6800, Loss: 0.4811
Epoch   3 Batch  146/269 - Train Accuracy: 0.6846, Validation Accuracy: 0.6841, Loss: 0.4750
Epoch   3 Batch  147/269 - Train Accuracy: 0.6953, Validation Accuracy: 0.6868, Loss: 0.4637
Epoch   3 Batch  148/269 - Train Accuracy: 0.6608, Validation Accuracy: 0.6919, Loss: 0.4866
Epoch   3 Batch  149/269 - Train Accuracy: 0.6820, Validation Accuracy: 0.6903, Loss: 0.4903
Epoch   3 Batch  150/269 - Train Accuracy: 0.6898, Validation Accuracy: 0.6885, Loss: 0.4839
Epoch   3 Batch  151/269 - Train Accuracy: 0.7029, Validation Accuracy: 0.6897, Loss: 0.4631
Epoch   3 Batch  152/269 - Train Accuracy: 0.6864, Validation Accuracy: 0.6872, Loss: 0.4823
Epoch   3 Batch  153/269 - Train Accuracy: 0.6772, Validation Accuracy: 0.6899, Loss: 0.4726
Epoch   3 Batch  154/269 - Train Accuracy: 0.6738, Validation Accuracy: 0.6933, Loss: 0.4887
Epoch   3 Batch  155/269 - Train Accuracy: 0.6979, Validation Accuracy: 0.6854, Loss: 0.4547
Epoch   3 Batch  156/269 - Train Accuracy: 0.6650, Validation Accuracy: 0.6816, Loss: 0.5021
Epoch   3 Batch  157/269 - Train Accuracy: 0.6783, Validation Accuracy: 0.6902, Loss: 0.4759
Epoch   3 Batch  158/269 - Train Accuracy: 0.6933, Validation Accuracy: 0.7005, Loss: 0.4729
Epoch   3 Batch  159/269 - Train Accuracy: 0.6907, Validation Accuracy: 0.6975, Loss: 0.4762
Epoch   3 Batch  160/269 - Train Accuracy: 0.6955, Validation Accuracy: 0.6859, Loss: 0.4751
Epoch   3 Batch  161/269 - Train Accuracy: 0.6747, Validation Accuracy: 0.6888, Loss: 0.4807
Epoch   3 Batch  162/269 - Train Accuracy: 0.6856, Validation Accuracy: 0.6911, Loss: 0.4725
Epoch   3 Batch  163/269 - Train Accuracy: 0.6895, Validation Accuracy: 0.6881, Loss: 0.4829
Epoch   3 Batch  164/269 - Train Accuracy: 0.6925, Validation Accuracy: 0.6936, Loss: 0.4727
Epoch   3 Batch  165/269 - Train Accuracy: 0.6681, Validation Accuracy: 0.6942, Loss: 0.4880
Epoch   3 Batch  166/269 - Train Accuracy: 0.6920, Validation Accuracy: 0.6862, Loss: 0.4528
Epoch   3 Batch  167/269 - Train Accuracy: 0.6846, Validation Accuracy: 0.6849, Loss: 0.4798
Epoch   3 Batch  168/269 - Train Accuracy: 0.6638, Validation Accuracy: 0.6910, Loss: 0.4769
Epoch   3 Batch  169/269 - Train Accuracy: 0.6838, Validation Accuracy: 0.6949, Loss: 0.4810
Epoch   3 Batch  170/269 - Train Accuracy: 0.6827, Validation Accuracy: 0.6973, Loss: 0.4665
Epoch   3 Batch  171/269 - Train Accuracy: 0.6836, Validation Accuracy: 0.6899, Loss: 0.4886
Epoch   3 Batch  172/269 - Train Accuracy: 0.6774, Validation Accuracy: 0.6879, Loss: 0.4882
Epoch   3 Batch  173/269 - Train Accuracy: 0.6862, Validation Accuracy: 0.6979, Loss: 0.4654
Epoch   3 Batch  174/269 - Train Accuracy: 0.6792, Validation Accuracy: 0.6984, Loss: 0.4790
Epoch   3 Batch  175/269 - Train Accuracy: 0.6884, Validation Accuracy: 0.6954, Loss: 0.4881
Epoch   3 Batch  176/269 - Train Accuracy: 0.6651, Validation Accuracy: 0.6856, Loss: 0.5030
Epoch   3 Batch  177/269 - Train Accuracy: 0.7018, Validation Accuracy: 0.6971, Loss: 0.4514
Epoch   3 Batch  178/269 - Train Accuracy: 0.6783, Validation Accuracy: 0.7060, Loss: 0.4757
Epoch   3 Batch  179/269 - Train Accuracy: 0.6803, Validation Accuracy: 0.7055, Loss: 0.4682
Epoch   3 Batch  180/269 - Train Accuracy: 0.6954, Validation Accuracy: 0.6974, Loss: 0.4638
Epoch   3 Batch  181/269 - Train Accuracy: 0.6894, Validation Accuracy: 0.6988, Loss: 0.4756
Epoch   3 Batch  182/269 - Train Accuracy: 0.6974, Validation Accuracy: 0.6979, Loss: 0.4681
Epoch   3 Batch  183/269 - Train Accuracy: 0.7323, Validation Accuracy: 0.6918, Loss: 0.4061
Epoch   3 Batch  184/269 - Train Accuracy: 0.6763, Validation Accuracy: 0.7008, Loss: 0.4848
Epoch   3 Batch  185/269 - Train Accuracy: 0.6972, Validation Accuracy: 0.6981, Loss: 0.4558
Epoch   3 Batch  186/269 - Train Accuracy: 0.6787, Validation Accuracy: 0.6972, Loss: 0.4758
Epoch   3 Batch  187/269 - Train Accuracy: 0.7077, Validation Accuracy: 0.7005, Loss: 0.4518
Epoch   3 Batch  188/269 - Train Accuracy: 0.7045, Validation Accuracy: 0.6995, Loss: 0.4522
Epoch   3 Batch  189/269 - Train Accuracy: 0.6987, Validation Accuracy: 0.7014, Loss: 0.4531
Epoch   3 Batch  190/269 - Train Accuracy: 0.6891, Validation Accuracy: 0.7019, Loss: 0.4560
Epoch   3 Batch  191/269 - Train Accuracy: 0.7002, Validation Accuracy: 0.6973, Loss: 0.4596
Epoch   3 Batch  192/269 - Train Accuracy: 0.6918, Validation Accuracy: 0.6934, Loss: 0.4687
Epoch   3 Batch  193/269 - Train Accuracy: 0.6998, Validation Accuracy: 0.6972, Loss: 0.4590
Epoch   3 Batch  194/269 - Train Accuracy: 0.7165, Validation Accuracy: 0.6950, Loss: 0.4591
Epoch   3 Batch  195/269 - Train Accuracy: 0.6817, Validation Accuracy: 0.6942, Loss: 0.4633
Epoch   3 Batch  196/269 - Train Accuracy: 0.6881, Validation Accuracy: 0.7006, Loss: 0.4581
Epoch   3 Batch  197/269 - Train Accuracy: 0.6564, Validation Accuracy: 0.7031, Loss: 0.4757
Epoch   3 Batch  198/269 - Train Accuracy: 0.6797, Validation Accuracy: 0.7040, Loss: 0.4870
Epoch   3 Batch  199/269 - Train Accuracy: 0.6840, Validation Accuracy: 0.6978, Loss: 0.4715
Epoch   3 Batch  200/269 - Train Accuracy: 0.6834, Validation Accuracy: 0.7022, Loss: 0.4728
Epoch   3 Batch  201/269 - Train Accuracy: 0.6827, Validation Accuracy: 0.7013, Loss: 0.4599
Epoch   3 Batch  202/269 - Train Accuracy: 0.6729, Validation Accuracy: 0.7022, Loss: 0.4527
Epoch   3 Batch  203/269 - Train Accuracy: 0.6968, Validation Accuracy: 0.7039, Loss: 0.4863
Epoch   3 Batch  204/269 - Train Accuracy: 0.6715, Validation Accuracy: 0.6955, Loss: 0.4833
Epoch   3 Batch  205/269 - Train Accuracy: 0.7038, Validation Accuracy: 0.6991, Loss: 0.4543
Epoch   3 Batch  206/269 - Train Accuracy: 0.6837, Validation Accuracy: 0.7054, Loss: 0.4721
Epoch   3 Batch  207/269 - Train Accuracy: 0.6977, Validation Accuracy: 0.6985, Loss: 0.4463
Epoch   3 Batch  208/269 - Train Accuracy: 0.6774, Validation Accuracy: 0.6942, Loss: 0.4772
Epoch   3 Batch  209/269 - Train Accuracy: 0.6939, Validation Accuracy: 0.7034, Loss: 0.4623
Epoch   3 Batch  210/269 - Train Accuracy: 0.7004, Validation Accuracy: 0.7000, Loss: 0.4503
Epoch   3 Batch  211/269 - Train Accuracy: 0.6832, Validation Accuracy: 0.7002, Loss: 0.4643
Epoch   3 Batch  212/269 - Train Accuracy: 0.7105, Validation Accuracy: 0.7032, Loss: 0.4486
Epoch   3 Batch  213/269 - Train Accuracy: 0.6941, Validation Accuracy: 0.6966, Loss: 0.4550
Epoch   3 Batch  214/269 - Train Accuracy: 0.7237, Validation Accuracy: 0.7063, Loss: 0.4560
Epoch   3 Batch  215/269 - Train Accuracy: 0.7374, Validation Accuracy: 0.7060, Loss: 0.4237
Epoch   3 Batch  216/269 - Train Accuracy: 0.6760, Validation Accuracy: 0.7055, Loss: 0.4799
Epoch   3 Batch  217/269 - Train Accuracy: 0.6832, Validation Accuracy: 0.7072, Loss: 0.4733
Epoch   3 Batch  218/269 - Train Accuracy: 0.6906, Validation Accuracy: 0.7037, Loss: 0.4679
Epoch   3 Batch  219/269 - Train Accuracy: 0.7037, Validation Accuracy: 0.7021, Loss: 0.4681
Epoch   3 Batch  220/269 - Train Accuracy: 0.7037, Validation Accuracy: 0.7022, Loss: 0.4280
Epoch   3 Batch  221/269 - Train Accuracy: 0.7076, Validation Accuracy: 0.7049, Loss: 0.4522
Epoch   3 Batch  222/269 - Train Accuracy: 0.7120, Validation Accuracy: 0.7102, Loss: 0.4365
Epoch   3 Batch  223/269 - Train Accuracy: 0.6809, Validation Accuracy: 0.7055, Loss: 0.4423
Epoch   3 Batch  224/269 - Train Accuracy: 0.7111, Validation Accuracy: 0.7041, Loss: 0.4660
Epoch   3 Batch  225/269 - Train Accuracy: 0.6944, Validation Accuracy: 0.7088, Loss: 0.4484
Epoch   3 Batch  226/269 - Train Accuracy: 0.7127, Validation Accuracy: 0.6990, Loss: 0.4441
Epoch   3 Batch  227/269 - Train Accuracy: 0.7441, Validation Accuracy: 0.7025, Loss: 0.4006
Epoch   3 Batch  228/269 - Train Accuracy: 0.6869, Validation Accuracy: 0.7014, Loss: 0.4489
Epoch   3 Batch  229/269 - Train Accuracy: 0.6945, Validation Accuracy: 0.7029, Loss: 0.4379
Epoch   3 Batch  230/269 - Train Accuracy: 0.7057, Validation Accuracy: 0.7035, Loss: 0.4449
Epoch   3 Batch  231/269 - Train Accuracy: 0.7026, Validation Accuracy: 0.7053, Loss: 0.4720
Epoch   3 Batch  232/269 - Train Accuracy: 0.6854, Validation Accuracy: 0.7070, Loss: 0.4652
Epoch   3 Batch  233/269 - Train Accuracy: 0.7170, Validation Accuracy: 0.7090, Loss: 0.4510
Epoch   3 Batch  234/269 - Train Accuracy: 0.7143, Validation Accuracy: 0.7125, Loss: 0.4402
Epoch   3 Batch  235/269 - Train Accuracy: 0.7220, Validation Accuracy: 0.7071, Loss: 0.4344
Epoch   3 Batch  236/269 - Train Accuracy: 0.7014, Validation Accuracy: 0.7082, Loss: 0.4358
Epoch   3 Batch  237/269 - Train Accuracy: 0.6899, Validation Accuracy: 0.7099, Loss: 0.4384
Epoch   3 Batch  238/269 - Train Accuracy: 0.7151, Validation Accuracy: 0.7084, Loss: 0.4326
Epoch   3 Batch  239/269 - Train Accuracy: 0.7092, Validation Accuracy: 0.7028, Loss: 0.4429
Epoch   3 Batch  240/269 - Train Accuracy: 0.7258, Validation Accuracy: 0.7043, Loss: 0.4013
Epoch   3 Batch  241/269 - Train Accuracy: 0.7042, Validation Accuracy: 0.7051, Loss: 0.4577
Epoch   3 Batch  242/269 - Train Accuracy: 0.7010, Validation Accuracy: 0.7116, Loss: 0.4385
Epoch   3 Batch  243/269 - Train Accuracy: 0.7137, Validation Accuracy: 0.7096, Loss: 0.4282
Epoch   3 Batch  244/269 - Train Accuracy: 0.6970, Validation Accuracy: 0.7043, Loss: 0.4436
Epoch   3 Batch  245/269 - Train Accuracy: 0.6856, Validation Accuracy: 0.7102, Loss: 0.4691
Epoch   3 Batch  246/269 - Train Accuracy: 0.6895, Validation Accuracy: 0.7041, Loss: 0.4384
Epoch   3 Batch  247/269 - Train Accuracy: 0.6913, Validation Accuracy: 0.7092, Loss: 0.4599
Epoch   3 Batch  248/269 - Train Accuracy: 0.7016, Validation Accuracy: 0.7066, Loss: 0.4343
Epoch   3 Batch  249/269 - Train Accuracy: 0.7411, Validation Accuracy: 0.7138, Loss: 0.4140
Epoch   3 Batch  250/269 - Train Accuracy: 0.7102, Validation Accuracy: 0.7058, Loss: 0.4499
Epoch   3 Batch  251/269 - Train Accuracy: 0.7243, Validation Accuracy: 0.7002, Loss: 0.4262
Epoch   3 Batch  252/269 - Train Accuracy: 0.7020, Validation Accuracy: 0.7020, Loss: 0.4431
Epoch   3 Batch  253/269 - Train Accuracy: 0.6813, Validation Accuracy: 0.7108, Loss: 0.4477
Epoch   3 Batch  254/269 - Train Accuracy: 0.7052, Validation Accuracy: 0.7160, Loss: 0.4330
Epoch   3 Batch  255/269 - Train Accuracy: 0.7164, Validation Accuracy: 0.7066, Loss: 0.4256
Epoch   3 Batch  256/269 - Train Accuracy: 0.7032, Validation Accuracy: 0.7129, Loss: 0.4452
Epoch   3 Batch  257/269 - Train Accuracy: 0.7060, Validation Accuracy: 0.7076, Loss: 0.4393
Epoch   3 Batch  258/269 - Train Accuracy: 0.7029, Validation Accuracy: 0.7044, Loss: 0.4406
Epoch   3 Batch  259/269 - Train Accuracy: 0.7216, Validation Accuracy: 0.7119, Loss: 0.4400
Epoch   3 Batch  260/269 - Train Accuracy: 0.6833, Validation Accuracy: 0.7050, Loss: 0.4538
Epoch   3 Batch  261/269 - Train Accuracy: 0.6974, Validation Accuracy: 0.7134, Loss: 0.4591
Epoch   3 Batch  262/269 - Train Accuracy: 0.7251, Validation Accuracy: 0.7104, Loss: 0.4355
Epoch   3 Batch  263/269 - Train Accuracy: 0.7154, Validation Accuracy: 0.7072, Loss: 0.4497
Epoch   3 Batch  264/269 - Train Accuracy: 0.7033, Validation Accuracy: 0.7148, Loss: 0.4544
Epoch   3 Batch  265/269 - Train Accuracy: 0.7139, Validation Accuracy: 0.7068, Loss: 0.4516
Epoch   3 Batch  266/269 - Train Accuracy: 0.7146, Validation Accuracy: 0.7013, Loss: 0.4261
Epoch   3 Batch  267/269 - Train Accuracy: 0.7154, Validation Accuracy: 0.7148, Loss: 0.4379
Epoch   4 Batch    1/269 - Train Accuracy: 0.6966, Validation Accuracy: 0.7146, Loss: 0.4459
Epoch   4 Batch    2/269 - Train Accuracy: 0.6875, Validation Accuracy: 0.7143, Loss: 0.4326
Epoch   4 Batch    3/269 - Train Accuracy: 0.7242, Validation Accuracy: 0.7098, Loss: 0.4392
Epoch   4 Batch    4/269 - Train Accuracy: 0.6993, Validation Accuracy: 0.7153, Loss: 0.4472
Epoch   4 Batch    5/269 - Train Accuracy: 0.7013, Validation Accuracy: 0.7119, Loss: 0.4449
Epoch   4 Batch    6/269 - Train Accuracy: 0.7227, Validation Accuracy: 0.7074, Loss: 0.4178
Epoch   4 Batch    7/269 - Train Accuracy: 0.7100, Validation Accuracy: 0.7090, Loss: 0.4207
Epoch   4 Batch    8/269 - Train Accuracy: 0.6806, Validation Accuracy: 0.7145, Loss: 0.4466
Epoch   4 Batch    9/269 - Train Accuracy: 0.7047, Validation Accuracy: 0.7186, Loss: 0.4358
Epoch   4 Batch   10/269 - Train Accuracy: 0.7053, Validation Accuracy: 0.7153, Loss: 0.4437
Epoch   4 Batch   11/269 - Train Accuracy: 0.7156, Validation Accuracy: 0.7228, Loss: 0.4375
Epoch   4 Batch   12/269 - Train Accuracy: 0.7086, Validation Accuracy: 0.7218, Loss: 0.4543
Epoch   4 Batch   13/269 - Train Accuracy: 0.7257, Validation Accuracy: 0.7174, Loss: 0.3983
Epoch   4 Batch   14/269 - Train Accuracy: 0.7135, Validation Accuracy: 0.7195, Loss: 0.4217
Epoch   4 Batch   15/269 - Train Accuracy: 0.7058, Validation Accuracy: 0.7254, Loss: 0.4112
Epoch   4 Batch   16/269 - Train Accuracy: 0.7281, Validation Accuracy: 0.7250, Loss: 0.4282
Epoch   4 Batch   17/269 - Train Accuracy: 0.7279, Validation Accuracy: 0.7218, Loss: 0.4139
Epoch   4 Batch   18/269 - Train Accuracy: 0.7069, Validation Accuracy: 0.7201, Loss: 0.4388
Epoch   4 Batch   19/269 - Train Accuracy: 0.7331, Validation Accuracy: 0.7161, Loss: 0.3959
Epoch   4 Batch   20/269 - Train Accuracy: 0.7118, Validation Accuracy: 0.7226, Loss: 0.4297
Epoch   4 Batch   21/269 - Train Accuracy: 0.6941, Validation Accuracy: 0.7188, Loss: 0.4473
Epoch   4 Batch   22/269 - Train Accuracy: 0.7306, Validation Accuracy: 0.7226, Loss: 0.4099
Epoch   4 Batch   23/269 - Train Accuracy: 0.7166, Validation Accuracy: 0.7238, Loss: 0.4163
Epoch   4 Batch   24/269 - Train Accuracy: 0.7106, Validation Accuracy: 0.7166, Loss: 0.4412
Epoch   4 Batch   25/269 - Train Accuracy: 0.7112, Validation Accuracy: 0.7180, Loss: 0.4485
Epoch   4 Batch   26/269 - Train Accuracy: 0.7289, Validation Accuracy: 0.7179, Loss: 0.3967
Epoch   4 Batch   27/269 - Train Accuracy: 0.7171, Validation Accuracy: 0.7243, Loss: 0.4138
Epoch   4 Batch   28/269 - Train Accuracy: 0.6860, Validation Accuracy: 0.7230, Loss: 0.4499
Epoch   4 Batch   29/269 - Train Accuracy: 0.7106, Validation Accuracy: 0.7120, Loss: 0.4397
Epoch   4 Batch   30/269 - Train Accuracy: 0.7152, Validation Accuracy: 0.7206, Loss: 0.4157
Epoch   4 Batch   31/269 - Train Accuracy: 0.7279, Validation Accuracy: 0.7244, Loss: 0.4107
Epoch   4 Batch   32/269 - Train Accuracy: 0.7209, Validation Accuracy: 0.7251, Loss: 0.4076
Epoch   4 Batch   33/269 - Train Accuracy: 0.7381, Validation Accuracy: 0.7191, Loss: 0.4081
Epoch   4 Batch   34/269 - Train Accuracy: 0.7179, Validation Accuracy: 0.7189, Loss: 0.4166
Epoch   4 Batch   35/269 - Train Accuracy: 0.7130, Validation Accuracy: 0.7212, Loss: 0.4301
Epoch   4 Batch   36/269 - Train Accuracy: 0.7228, Validation Accuracy: 0.7197, Loss: 0.4096
Epoch   4 Batch   37/269 - Train Accuracy: 0.7363, Validation Accuracy: 0.7227, Loss: 0.4110
Epoch   4 Batch   38/269 - Train Accuracy: 0.7241, Validation Accuracy: 0.7291, Loss: 0.4148
Epoch   4 Batch   39/269 - Train Accuracy: 0.7158, Validation Accuracy: 0.7209, Loss: 0.4110
Epoch   4 Batch   40/269 - Train Accuracy: 0.6946, Validation Accuracy: 0.7188, Loss: 0.4276
Epoch   4 Batch   41/269 - Train Accuracy: 0.7121, Validation Accuracy: 0.7243, Loss: 0.4195
Epoch   4 Batch   42/269 - Train Accuracy: 0.7353, Validation Accuracy: 0.7201, Loss: 0.3904
Epoch   4 Batch   43/269 - Train Accuracy: 0.7312, Validation Accuracy: 0.7316, Loss: 0.4238
Epoch   4 Batch   44/269 - Train Accuracy: 0.7252, Validation Accuracy: 0.7353, Loss: 0.4117
Epoch   4 Batch   45/269 - Train Accuracy: 0.7123, Validation Accuracy: 0.7203, Loss: 0.4307
Epoch   4 Batch   46/269 - Train Accuracy: 0.7203, Validation Accuracy: 0.7264, Loss: 0.4240
Epoch   4 Batch   47/269 - Train Accuracy: 0.7511, Validation Accuracy: 0.7302, Loss: 0.3840
Epoch   4 Batch   48/269 - Train Accuracy: 0.7347, Validation Accuracy: 0.7279, Loss: 0.4013
Epoch   4 Batch   49/269 - Train Accuracy: 0.7181, Validation Accuracy: 0.7230, Loss: 0.4228
Epoch   4 Batch   50/269 - Train Accuracy: 0.7154, Validation Accuracy: 0.7278, Loss: 0.4278
Epoch   4 Batch   51/269 - Train Accuracy: 0.7180, Validation Accuracy: 0.7298, Loss: 0.4086
Epoch   4 Batch   52/269 - Train Accuracy: 0.7013, Validation Accuracy: 0.7195, Loss: 0.3935
Epoch   4 Batch   53/269 - Train Accuracy: 0.7116, Validation Accuracy: 0.7267, Loss: 0.4285
Epoch   4 Batch   54/269 - Train Accuracy: 0.7274, Validation Accuracy: 0.7259, Loss: 0.4216
Epoch   4 Batch   55/269 - Train Accuracy: 0.7519, Validation Accuracy: 0.7251, Loss: 0.3934
Epoch   4 Batch   56/269 - Train Accuracy: 0.7442, Validation Accuracy: 0.7332, Loss: 0.4153
Epoch   4 Batch   57/269 - Train Accuracy: 0.7314, Validation Accuracy: 0.7383, Loss: 0.4179
Epoch   4 Batch   58/269 - Train Accuracy: 0.7343, Validation Accuracy: 0.7285, Loss: 0.4007
Epoch   4 Batch   59/269 - Train Accuracy: 0.7500, Validation Accuracy: 0.7259, Loss: 0.3846
Epoch   4 Batch   60/269 - Train Accuracy: 0.7352, Validation Accuracy: 0.7301, Loss: 0.3795
Epoch   4 Batch   61/269 - Train Accuracy: 0.7388, Validation Accuracy: 0.7286, Loss: 0.3789
Epoch   4 Batch   62/269 - Train Accuracy: 0.7414, Validation Accuracy: 0.7358, Loss: 0.3934
Epoch   4 Batch   63/269 - Train Accuracy: 0.7444, Validation Accuracy: 0.7412, Loss: 0.4084
Epoch   4 Batch   64/269 - Train Accuracy: 0.7192, Validation Accuracy: 0.7308, Loss: 0.3906
Epoch   4 Batch   65/269 - Train Accuracy: 0.7234, Validation Accuracy: 0.7324, Loss: 0.4075
Epoch   4 Batch   66/269 - Train Accuracy: 0.7283, Validation Accuracy: 0.7300, Loss: 0.3916
Epoch   4 Batch   67/269 - Train Accuracy: 0.7246, Validation Accuracy: 0.7313, Loss: 0.4111
Epoch   4 Batch   68/269 - Train Accuracy: 0.7151, Validation Accuracy: 0.7354, Loss: 0.4041
Epoch   4 Batch   69/269 - Train Accuracy: 0.7188, Validation Accuracy: 0.7364, Loss: 0.4388
Epoch   4 Batch   70/269 - Train Accuracy: 0.7507, Validation Accuracy: 0.7306, Loss: 0.4079
Epoch   4 Batch   71/269 - Train Accuracy: 0.7354, Validation Accuracy: 0.7331, Loss: 0.4198
Epoch   4 Batch   72/269 - Train Accuracy: 0.7380, Validation Accuracy: 0.7320, Loss: 0.3984
Epoch   4 Batch   73/269 - Train Accuracy: 0.7371, Validation Accuracy: 0.7317, Loss: 0.4115
Epoch   4 Batch   74/269 - Train Accuracy: 0.7453, Validation Accuracy: 0.7333, Loss: 0.4040
Epoch   4 Batch   75/269 - Train Accuracy: 0.7256, Validation Accuracy: 0.7319, Loss: 0.3927
Epoch   4 Batch   76/269 - Train Accuracy: 0.7188, Validation Accuracy: 0.7323, Loss: 0.4022
Epoch   4 Batch   77/269 - Train Accuracy: 0.7384, Validation Accuracy: 0.7262, Loss: 0.3953
Epoch   4 Batch   78/269 - Train Accuracy: 0.7467, Validation Accuracy: 0.7330, Loss: 0.3926
Epoch   4 Batch   79/269 - Train Accuracy: 0.7462, Validation Accuracy: 0.7334, Loss: 0.3972
Epoch   4 Batch   80/269 - Train Accuracy: 0.7457, Validation Accuracy: 0.7361, Loss: 0.3887
Epoch   4 Batch   81/269 - Train Accuracy: 0.7506, Validation Accuracy: 0.7429, Loss: 0.4147
Epoch   4 Batch   82/269 - Train Accuracy: 0.7456, Validation Accuracy: 0.7363, Loss: 0.3799
Epoch   4 Batch   83/269 - Train Accuracy: 0.7443, Validation Accuracy: 0.7379, Loss: 0.4027
Epoch   4 Batch   84/269 - Train Accuracy: 0.7430, Validation Accuracy: 0.7423, Loss: 0.3847
Epoch   4 Batch   85/269 - Train Accuracy: 0.7357, Validation Accuracy: 0.7368, Loss: 0.3887
Epoch   4 Batch   86/269 - Train Accuracy: 0.7351, Validation Accuracy: 0.7415, Loss: 0.3936
Epoch   4 Batch   87/269 - Train Accuracy: 0.7102, Validation Accuracy: 0.7326, Loss: 0.4149
Epoch   4 Batch   88/269 - Train Accuracy: 0.7144, Validation Accuracy: 0.7350, Loss: 0.3932
Epoch   4 Batch   89/269 - Train Accuracy: 0.7538, Validation Accuracy: 0.7292, Loss: 0.3904
Epoch   4 Batch   90/269 - Train Accuracy: 0.7156, Validation Accuracy: 0.7312, Loss: 0.4150
Epoch   4 Batch   91/269 - Train Accuracy: 0.7599, Validation Accuracy: 0.7427, Loss: 0.3893
Epoch   4 Batch   92/269 - Train Accuracy: 0.7305, Validation Accuracy: 0.7313, Loss: 0.3861
Epoch   4 Batch   93/269 - Train Accuracy: 0.7348, Validation Accuracy: 0.7290, Loss: 0.3823
Epoch   4 Batch   94/269 - Train Accuracy: 0.7429, Validation Accuracy: 0.7385, Loss: 0.4090
Epoch   4 Batch   95/269 - Train Accuracy: 0.7241, Validation Accuracy: 0.7276, Loss: 0.3916
Epoch   4 Batch   96/269 - Train Accuracy: 0.7075, Validation Accuracy: 0.7092, Loss: 0.3998
Epoch   4 Batch   97/269 - Train Accuracy: 0.7356, Validation Accuracy: 0.7430, Loss: 0.4018
Epoch   4 Batch   98/269 - Train Accuracy: 0.7202, Validation Accuracy: 0.7233, Loss: 0.3942
Epoch   4 Batch   99/269 - Train Accuracy: 0.6992, Validation Accuracy: 0.7362, Loss: 0.4178
Epoch   4 Batch  100/269 - Train Accuracy: 0.7419, Validation Accuracy: 0.7227, Loss: 0.3870
Epoch   4 Batch  101/269 - Train Accuracy: 0.7007, Validation Accuracy: 0.7223, Loss: 0.4158
Epoch   4 Batch  102/269 - Train Accuracy: 0.7344, Validation Accuracy: 0.7263, Loss: 0.3919
Epoch   4 Batch  103/269 - Train Accuracy: 0.7108, Validation Accuracy: 0.7045, Loss: 0.3919
Epoch   4 Batch  104/269 - Train Accuracy: 0.7281, Validation Accuracy: 0.7389, Loss: 0.3933
Epoch   4 Batch  105/269 - Train Accuracy: 0.7070, Validation Accuracy: 0.7120, Loss: 0.3904
Epoch   4 Batch  106/269 - Train Accuracy: 0.7294, Validation Accuracy: 0.7365, Loss: 0.3979
Epoch   4 Batch  107/269 - Train Accuracy: 0.6921, Validation Accuracy: 0.7067, Loss: 0.4112
Epoch   4 Batch  108/269 - Train Accuracy: 0.7262, Validation Accuracy: 0.7267, Loss: 0.3999
Epoch   4 Batch  109/269 - Train Accuracy: 0.7051, Validation Accuracy: 0.7210, Loss: 0.3927
Epoch   4 Batch  110/269 - Train Accuracy: 0.7080, Validation Accuracy: 0.7272, Loss: 0.3911
Epoch   4 Batch  111/269 - Train Accuracy: 0.7268, Validation Accuracy: 0.7345, Loss: 0.4251
Epoch   4 Batch  112/269 - Train Accuracy: 0.7233, Validation Accuracy: 0.7253, Loss: 0.3970
Epoch   4 Batch  113/269 - Train Accuracy: 0.7496, Validation Accuracy: 0.7399, Loss: 0.3769
Epoch   4 Batch  114/269 - Train Accuracy: 0.7290, Validation Accuracy: 0.7201, Loss: 0.3919
Epoch   4 Batch  115/269 - Train Accuracy: 0.7264, Validation Accuracy: 0.7365, Loss: 0.4036
Epoch   4 Batch  116/269 - Train Accuracy: 0.7522, Validation Accuracy: 0.7320, Loss: 0.3941
Epoch   4 Batch  117/269 - Train Accuracy: 0.7410, Validation Accuracy: 0.7387, Loss: 0.3869
Epoch   4 Batch  118/269 - Train Accuracy: 0.7539, Validation Accuracy: 0.7357, Loss: 0.3789
Epoch   4 Batch  119/269 - Train Accuracy: 0.7355, Validation Accuracy: 0.7360, Loss: 0.4029
Epoch   4 Batch  120/269 - Train Accuracy: 0.7346, Validation Accuracy: 0.7496, Loss: 0.3913
Epoch   4 Batch  121/269 - Train Accuracy: 0.7428, Validation Accuracy: 0.7323, Loss: 0.3784
Epoch   4 Batch  122/269 - Train Accuracy: 0.7272, Validation Accuracy: 0.7439, Loss: 0.3738
Epoch   4 Batch  123/269 - Train Accuracy: 0.7299, Validation Accuracy: 0.7436, Loss: 0.3986
Epoch   4 Batch  124/269 - Train Accuracy: 0.7497, Validation Accuracy: 0.7354, Loss: 0.3667
Epoch   4 Batch  125/269 - Train Accuracy: 0.7421, Validation Accuracy: 0.7446, Loss: 0.3742
Epoch   4 Batch  126/269 - Train Accuracy: 0.7429, Validation Accuracy: 0.7419, Loss: 0.3768
Epoch   4 Batch  127/269 - Train Accuracy: 0.7334, Validation Accuracy: 0.7426, Loss: 0.3962
Epoch   4 Batch  128/269 - Train Accuracy: 0.7555, Validation Accuracy: 0.7450, Loss: 0.3768
Epoch   4 Batch  129/269 - Train Accuracy: 0.7500, Validation Accuracy: 0.7490, Loss: 0.3761
Epoch   4 Batch  130/269 - Train Accuracy: 0.7345, Validation Accuracy: 0.7432, Loss: 0.3945
Epoch   4 Batch  131/269 - Train Accuracy: 0.7256, Validation Accuracy: 0.7458, Loss: 0.3890
Epoch   4 Batch  132/269 - Train Accuracy: 0.7467, Validation Accuracy: 0.7454, Loss: 0.3848
Epoch   4 Batch  133/269 - Train Accuracy: 0.7610, Validation Accuracy: 0.7379, Loss: 0.3641
Epoch   4 Batch  134/269 - Train Accuracy: 0.7427, Validation Accuracy: 0.7398, Loss: 0.3789
Epoch   4 Batch  135/269 - Train Accuracy: 0.7163, Validation Accuracy: 0.7515, Loss: 0.4025
Epoch   4 Batch  136/269 - Train Accuracy: 0.7211, Validation Accuracy: 0.7485, Loss: 0.4018
Epoch   4 Batch  137/269 - Train Accuracy: 0.7415, Validation Accuracy: 0.7445, Loss: 0.4066
Epoch   4 Batch  138/269 - Train Accuracy: 0.7497, Validation Accuracy: 0.7486, Loss: 0.3823
Epoch   4 Batch  139/269 - Train Accuracy: 0.7590, Validation Accuracy: 0.7467, Loss: 0.3638
Epoch   4 Batch  140/269 - Train Accuracy: 0.7453, Validation Accuracy: 0.7494, Loss: 0.3842
Epoch   4 Batch  141/269 - Train Accuracy: 0.7467, Validation Accuracy: 0.7462, Loss: 0.3822
Epoch   4 Batch  142/269 - Train Accuracy: 0.7514, Validation Accuracy: 0.7504, Loss: 0.3663
Epoch   4 Batch  143/269 - Train Accuracy: 0.7415, Validation Accuracy: 0.7497, Loss: 0.3688
Epoch   4 Batch  144/269 - Train Accuracy: 0.7508, Validation Accuracy: 0.7521, Loss: 0.3585
Epoch   4 Batch  145/269 - Train Accuracy: 0.7495, Validation Accuracy: 0.7534, Loss: 0.3654
Epoch   4 Batch  146/269 - Train Accuracy: 0.7680, Validation Accuracy: 0.7488, Loss: 0.3640
Epoch   4 Batch  147/269 - Train Accuracy: 0.7615, Validation Accuracy: 0.7577, Loss: 0.3536
Epoch   4 Batch  148/269 - Train Accuracy: 0.7591, Validation Accuracy: 0.7538, Loss: 0.3738
Epoch   4 Batch  149/269 - Train Accuracy: 0.7573, Validation Accuracy: 0.7567, Loss: 0.3747
Epoch   4 Batch  150/269 - Train Accuracy: 0.7495, Validation Accuracy: 0.7516, Loss: 0.3694
Epoch   4 Batch  151/269 - Train Accuracy: 0.7777, Validation Accuracy: 0.7544, Loss: 0.3543
Epoch   4 Batch  152/269 - Train Accuracy: 0.7605, Validation Accuracy: 0.7458, Loss: 0.3705
Epoch   4 Batch  153/269 - Train Accuracy: 0.7446, Validation Accuracy: 0.7480, Loss: 0.3633
Epoch   4 Batch  154/269 - Train Accuracy: 0.7556, Validation Accuracy: 0.7509, Loss: 0.3733
Epoch   4 Batch  155/269 - Train Accuracy: 0.7591, Validation Accuracy: 0.7516, Loss: 0.3486
Epoch   4 Batch  156/269 - Train Accuracy: 0.7368, Validation Accuracy: 0.7521, Loss: 0.3857
Epoch   4 Batch  157/269 - Train Accuracy: 0.7590, Validation Accuracy: 0.7548, Loss: 0.3602
Epoch   4 Batch  158/269 - Train Accuracy: 0.7589, Validation Accuracy: 0.7537, Loss: 0.3629
Epoch   4 Batch  159/269 - Train Accuracy: 0.7484, Validation Accuracy: 0.7530, Loss: 0.3661
Epoch   4 Batch  160/269 - Train Accuracy: 0.7573, Validation Accuracy: 0.7569, Loss: 0.3662
Epoch   4 Batch  161/269 - Train Accuracy: 0.7466, Validation Accuracy: 0.7533, Loss: 0.3608
Epoch   4 Batch  162/269 - Train Accuracy: 0.7653, Validation Accuracy: 0.7530, Loss: 0.3523
Epoch   4 Batch  163/269 - Train Accuracy: 0.7632, Validation Accuracy: 0.7551, Loss: 0.3660
Epoch   4 Batch  164/269 - Train Accuracy: 0.7632, Validation Accuracy: 0.7539, Loss: 0.3658
Epoch   4 Batch  165/269 - Train Accuracy: 0.7636, Validation Accuracy: 0.7590, Loss: 0.3731
Epoch   4 Batch  166/269 - Train Accuracy: 0.7713, Validation Accuracy: 0.7573, Loss: 0.3439
Epoch   4 Batch  167/269 - Train Accuracy: 0.7547, Validation Accuracy: 0.7488, Loss: 0.3626
Epoch   4 Batch  168/269 - Train Accuracy: 0.7590, Validation Accuracy: 0.7549, Loss: 0.3680
Epoch   4 Batch  169/269 - Train Accuracy: 0.7733, Validation Accuracy: 0.7581, Loss: 0.3673
Epoch   4 Batch  170/269 - Train Accuracy: 0.7464, Validation Accuracy: 0.7446, Loss: 0.3530
Epoch   4 Batch  171/269 - Train Accuracy: 0.7726, Validation Accuracy: 0.7549, Loss: 0.3778
Epoch   4 Batch  172/269 - Train Accuracy: 0.7569, Validation Accuracy: 0.7568, Loss: 0.3774
Epoch   4 Batch  173/269 - Train Accuracy: 0.7543, Validation Accuracy: 0.7446, Loss: 0.3483
Epoch   4 Batch  174/269 - Train Accuracy: 0.7667, Validation Accuracy: 0.7574, Loss: 0.3680
Epoch   4 Batch  175/269 - Train Accuracy: 0.7554, Validation Accuracy: 0.7544, Loss: 0.3770
Epoch   4 Batch  176/269 - Train Accuracy: 0.7301, Validation Accuracy: 0.7496, Loss: 0.3836
Epoch   4 Batch  177/269 - Train Accuracy: 0.7697, Validation Accuracy: 0.7623, Loss: 0.3475
Epoch   4 Batch  178/269 - Train Accuracy: 0.7698, Validation Accuracy: 0.7628, Loss: 0.3615
Epoch   4 Batch  179/269 - Train Accuracy: 0.7392, Validation Accuracy: 0.7511, Loss: 0.3584
Epoch   4 Batch  180/269 - Train Accuracy: 0.7727, Validation Accuracy: 0.7585, Loss: 0.3548
Epoch   4 Batch  181/269 - Train Accuracy: 0.7769, Validation Accuracy: 0.7605, Loss: 0.3581
Epoch   4 Batch  182/269 - Train Accuracy: 0.7614, Validation Accuracy: 0.7559, Loss: 0.3580
Epoch   4 Batch  183/269 - Train Accuracy: 0.8031, Validation Accuracy: 0.7575, Loss: 0.3164
Epoch   4 Batch  184/269 - Train Accuracy: 0.7669, Validation Accuracy: 0.7603, Loss: 0.3687
Epoch   4 Batch  185/269 - Train Accuracy: 0.7702, Validation Accuracy: 0.7573, Loss: 0.3505
Epoch   4 Batch  186/269 - Train Accuracy: 0.7581, Validation Accuracy: 0.7595, Loss: 0.3549
Epoch   4 Batch  187/269 - Train Accuracy: 0.7738, Validation Accuracy: 0.7612, Loss: 0.3501
Epoch   4 Batch  188/269 - Train Accuracy: 0.7805, Validation Accuracy: 0.7669, Loss: 0.3518
Epoch   4 Batch  189/269 - Train Accuracy: 0.7759, Validation Accuracy: 0.7568, Loss: 0.3401
Epoch   4 Batch  190/269 - Train Accuracy: 0.7707, Validation Accuracy: 0.7623, Loss: 0.3503
Epoch   4 Batch  191/269 - Train Accuracy: 0.7653, Validation Accuracy: 0.7658, Loss: 0.3523
Epoch   4 Batch  192/269 - Train Accuracy: 0.7699, Validation Accuracy: 0.7578, Loss: 0.3570
Epoch   4 Batch  193/269 - Train Accuracy: 0.7666, Validation Accuracy: 0.7654, Loss: 0.3468
Epoch   4 Batch  194/269 - Train Accuracy: 0.7807, Validation Accuracy: 0.7613, Loss: 0.3481
Epoch   4 Batch  195/269 - Train Accuracy: 0.7538, Validation Accuracy: 0.7631, Loss: 0.3519
Epoch   4 Batch  196/269 - Train Accuracy: 0.7628, Validation Accuracy: 0.7595, Loss: 0.3424
Epoch   4 Batch  197/269 - Train Accuracy: 0.7532, Validation Accuracy: 0.7615, Loss: 0.3644
Epoch   4 Batch  198/269 - Train Accuracy: 0.7520, Validation Accuracy: 0.7604, Loss: 0.3715
Epoch   4 Batch  199/269 - Train Accuracy: 0.7533, Validation Accuracy: 0.7578, Loss: 0.3566
Epoch   4 Batch  200/269 - Train Accuracy: 0.7625, Validation Accuracy: 0.7622, Loss: 0.3579
Epoch   4 Batch  201/269 - Train Accuracy: 0.7710, Validation Accuracy: 0.7620, Loss: 0.3549
Epoch   4 Batch  202/269 - Train Accuracy: 0.7557, Validation Accuracy: 0.7663, Loss: 0.3419
Epoch   4 Batch  203/269 - Train Accuracy: 0.7752, Validation Accuracy: 0.7623, Loss: 0.3655
Epoch   4 Batch  204/269 - Train Accuracy: 0.7635, Validation Accuracy: 0.7689, Loss: 0.3680
Epoch   4 Batch  205/269 - Train Accuracy: 0.7716, Validation Accuracy: 0.7678, Loss: 0.3423
Epoch   4 Batch  206/269 - Train Accuracy: 0.7548, Validation Accuracy: 0.7662, Loss: 0.3592
Epoch   4 Batch  207/269 - Train Accuracy: 0.7798, Validation Accuracy: 0.7614, Loss: 0.3357
Epoch   4 Batch  208/269 - Train Accuracy: 0.7721, Validation Accuracy: 0.7647, Loss: 0.3570
Epoch   4 Batch  209/269 - Train Accuracy: 0.7739, Validation Accuracy: 0.7709, Loss: 0.3470
Epoch   4 Batch  210/269 - Train Accuracy: 0.7771, Validation Accuracy: 0.7653, Loss: 0.3340
Epoch   4 Batch  211/269 - Train Accuracy: 0.7809, Validation Accuracy: 0.7711, Loss: 0.3460
Epoch   4 Batch  212/269 - Train Accuracy: 0.7740, Validation Accuracy: 0.7710, Loss: 0.3387
Epoch   4 Batch  213/269 - Train Accuracy: 0.7651, Validation Accuracy: 0.7623, Loss: 0.3376
Epoch   4 Batch  214/269 - Train Accuracy: 0.7693, Validation Accuracy: 0.7596, Loss: 0.3469
Epoch   4 Batch  215/269 - Train Accuracy: 0.7852, Validation Accuracy: 0.7613, Loss: 0.3195
Epoch   4 Batch  216/269 - Train Accuracy: 0.7398, Validation Accuracy: 0.7601, Loss: 0.3705
Epoch   4 Batch  217/269 - Train Accuracy: 0.7549, Validation Accuracy: 0.7609, Loss: 0.3512
Epoch   4 Batch  218/269 - Train Accuracy: 0.7589, Validation Accuracy: 0.7627, Loss: 0.3496
Epoch   4 Batch  219/269 - Train Accuracy: 0.7752, Validation Accuracy: 0.7739, Loss: 0.3534
Epoch   4 Batch  220/269 - Train Accuracy: 0.7813, Validation Accuracy: 0.7719, Loss: 0.3189
Epoch   4 Batch  221/269 - Train Accuracy: 0.7900, Validation Accuracy: 0.7670, Loss: 0.3382
Epoch   4 Batch  222/269 - Train Accuracy: 0.7916, Validation Accuracy: 0.7695, Loss: 0.3279
Epoch   4 Batch  223/269 - Train Accuracy: 0.7648, Validation Accuracy: 0.7712, Loss: 0.3270
Epoch   4 Batch  224/269 - Train Accuracy: 0.7782, Validation Accuracy: 0.7714, Loss: 0.3498
Epoch   4 Batch  225/269 - Train Accuracy: 0.7682, Validation Accuracy: 0.7720, Loss: 0.3368
Epoch   4 Batch  226/269 - Train Accuracy: 0.7821, Validation Accuracy: 0.7710, Loss: 0.3334
Epoch   4 Batch  227/269 - Train Accuracy: 0.8046, Validation Accuracy: 0.7783, Loss: 0.3062
Epoch   4 Batch  228/269 - Train Accuracy: 0.7794, Validation Accuracy: 0.7822, Loss: 0.3392
Epoch   4 Batch  229/269 - Train Accuracy: 0.7803, Validation Accuracy: 0.7805, Loss: 0.3263
Epoch   4 Batch  230/269 - Train Accuracy: 0.7855, Validation Accuracy: 0.7759, Loss: 0.3289
Epoch   4 Batch  231/269 - Train Accuracy: 0.7720, Validation Accuracy: 0.7813, Loss: 0.3557
Epoch   4 Batch  232/269 - Train Accuracy: 0.7653, Validation Accuracy: 0.7727, Loss: 0.3463
Epoch   4 Batch  233/269 - Train Accuracy: 0.7956, Validation Accuracy: 0.7719, Loss: 0.3439
Epoch   4 Batch  234/269 - Train Accuracy: 0.7909, Validation Accuracy: 0.7810, Loss: 0.3299
Epoch   4 Batch  235/269 - Train Accuracy: 0.7861, Validation Accuracy: 0.7804, Loss: 0.3251
Epoch   4 Batch  236/269 - Train Accuracy: 0.7816, Validation Accuracy: 0.7787, Loss: 0.3192
Epoch   4 Batch  237/269 - Train Accuracy: 0.7716, Validation Accuracy: 0.7813, Loss: 0.3288
Epoch   4 Batch  238/269 - Train Accuracy: 0.7823, Validation Accuracy: 0.7780, Loss: 0.3280
Epoch   4 Batch  239/269 - Train Accuracy: 0.7924, Validation Accuracy: 0.7752, Loss: 0.3285
Epoch   4 Batch  240/269 - Train Accuracy: 0.7933, Validation Accuracy: 0.7667, Loss: 0.3008
Epoch   4 Batch  241/269 - Train Accuracy: 0.7769, Validation Accuracy: 0.7733, Loss: 0.3429
Epoch   4 Batch  242/269 - Train Accuracy: 0.7862, Validation Accuracy: 0.7734, Loss: 0.3143
Epoch   4 Batch  243/269 - Train Accuracy: 0.7914, Validation Accuracy: 0.7781, Loss: 0.3100
Epoch   4 Batch  244/269 - Train Accuracy: 0.7759, Validation Accuracy: 0.7767, Loss: 0.3270
Epoch   4 Batch  245/269 - Train Accuracy: 0.7688, Validation Accuracy: 0.7757, Loss: 0.3453
Epoch   4 Batch  246/269 - Train Accuracy: 0.7700, Validation Accuracy: 0.7761, Loss: 0.3304
Epoch   4 Batch  247/269 - Train Accuracy: 0.7648, Validation Accuracy: 0.7798, Loss: 0.3377
Epoch   4 Batch  248/269 - Train Accuracy: 0.7837, Validation Accuracy: 0.7791, Loss: 0.3183
Epoch   4 Batch  249/269 - Train Accuracy: 0.8131, Validation Accuracy: 0.7908, Loss: 0.3096
Epoch   4 Batch  250/269 - Train Accuracy: 0.7961, Validation Accuracy: 0.7903, Loss: 0.3340
Epoch   4 Batch  251/269 - Train Accuracy: 0.8014, Validation Accuracy: 0.7863, Loss: 0.3093
Epoch   4 Batch  252/269 - Train Accuracy: 0.7948, Validation Accuracy: 0.7869, Loss: 0.3281
Epoch   4 Batch  253/269 - Train Accuracy: 0.7706, Validation Accuracy: 0.7930, Loss: 0.3364
Epoch   4 Batch  254/269 - Train Accuracy: 0.7796, Validation Accuracy: 0.7789, Loss: 0.3212
Epoch   4 Batch  255/269 - Train Accuracy: 0.8055, Validation Accuracy: 0.7950, Loss: 0.3192
Epoch   4 Batch  256/269 - Train Accuracy: 0.7846, Validation Accuracy: 0.7913, Loss: 0.3294
Epoch   4 Batch  257/269 - Train Accuracy: 0.7896, Validation Accuracy: 0.7857, Loss: 0.3306
Epoch   4 Batch  258/269 - Train Accuracy: 0.7932, Validation Accuracy: 0.7778, Loss: 0.3252
Epoch   4 Batch  259/269 - Train Accuracy: 0.7982, Validation Accuracy: 0.7858, Loss: 0.3237
Epoch   4 Batch  260/269 - Train Accuracy: 0.7734, Validation Accuracy: 0.7829, Loss: 0.3353
Epoch   4 Batch  261/269 - Train Accuracy: 0.7667, Validation Accuracy: 0.7912, Loss: 0.3308
Epoch   4 Batch  262/269 - Train Accuracy: 0.7846, Validation Accuracy: 0.7780, Loss: 0.3232
Epoch   4 Batch  263/269 - Train Accuracy: 0.7837, Validation Accuracy: 0.7813, Loss: 0.3352
Epoch   4 Batch  264/269 - Train Accuracy: 0.7712, Validation Accuracy: 0.7812, Loss: 0.3342
Epoch   4 Batch  265/269 - Train Accuracy: 0.7962, Validation Accuracy: 0.7790, Loss: 0.3259
Epoch   4 Batch  266/269 - Train Accuracy: 0.7981, Validation Accuracy: 0.7753, Loss: 0.3099
Epoch   4 Batch  267/269 - Train Accuracy: 0.7894, Validation Accuracy: 0.7794, Loss: 0.3188
Epoch   5 Batch    1/269 - Train Accuracy: 0.7843, Validation Accuracy: 0.7785, Loss: 0.3216
Epoch   5 Batch    2/269 - Train Accuracy: 0.7826, Validation Accuracy: 0.7765, Loss: 0.3208
Epoch   5 Batch    3/269 - Train Accuracy: 0.8032, Validation Accuracy: 0.7803, Loss: 0.3241
Epoch   5 Batch    4/269 - Train Accuracy: 0.7687, Validation Accuracy: 0.7812, Loss: 0.3276
Epoch   5 Batch    5/269 - Train Accuracy: 0.7810, Validation Accuracy: 0.7844, Loss: 0.3199
Epoch   5 Batch    6/269 - Train Accuracy: 0.7993, Validation Accuracy: 0.7808, Loss: 0.3046
Epoch   5 Batch    7/269 - Train Accuracy: 0.7983, Validation Accuracy: 0.7787, Loss: 0.3082
Epoch   5 Batch    8/269 - Train Accuracy: 0.7761, Validation Accuracy: 0.7748, Loss: 0.3383
Epoch   5 Batch    9/269 - Train Accuracy: 0.7956, Validation Accuracy: 0.7868, Loss: 0.3307
Epoch   5 Batch   10/269 - Train Accuracy: 0.7747, Validation Accuracy: 0.7816, Loss: 0.3220
Epoch   5 Batch   11/269 - Train Accuracy: 0.7813, Validation Accuracy: 0.7738, Loss: 0.3349
Epoch   5 Batch   12/269 - Train Accuracy: 0.7812, Validation Accuracy: 0.7856, Loss: 0.3403
Epoch   5 Batch   13/269 - Train Accuracy: 0.7915, Validation Accuracy: 0.7876, Loss: 0.2915
Epoch   5 Batch   14/269 - Train Accuracy: 0.7850, Validation Accuracy: 0.7816, Loss: 0.3110
Epoch   5 Batch   15/269 - Train Accuracy: 0.8041, Validation Accuracy: 0.7971, Loss: 0.2992
Epoch   5 Batch   16/269 - Train Accuracy: 0.7964, Validation Accuracy: 0.7908, Loss: 0.3170
Epoch   5 Batch   17/269 - Train Accuracy: 0.8078, Validation Accuracy: 0.7922, Loss: 0.3068
Epoch   5 Batch   18/269 - Train Accuracy: 0.7891, Validation Accuracy: 0.7937, Loss: 0.3127
Epoch   5 Batch   19/269 - Train Accuracy: 0.8058, Validation Accuracy: 0.7995, Loss: 0.2891
Epoch   5 Batch   20/269 - Train Accuracy: 0.8033, Validation Accuracy: 0.8012, Loss: 0.3110
Epoch   5 Batch   21/269 - Train Accuracy: 0.7768, Validation Accuracy: 0.7887, Loss: 0.3227
Epoch   5 Batch   22/269 - Train Accuracy: 0.8136, Validation Accuracy: 0.8020, Loss: 0.2923
Epoch   5 Batch   23/269 - Train Accuracy: 0.7848, Validation Accuracy: 0.8091, Loss: 0.3049
Epoch   5 Batch   24/269 - Train Accuracy: 0.8097, Validation Accuracy: 0.8041, Loss: 0.3225
Epoch   5 Batch   25/269 - Train Accuracy: 0.7870, Validation Accuracy: 0.7995, Loss: 0.3272
Epoch   5 Batch   26/269 - Train Accuracy: 0.8258, Validation Accuracy: 0.8027, Loss: 0.2862
Epoch   5 Batch   27/269 - Train Accuracy: 0.8082, Validation Accuracy: 0.8030, Loss: 0.2938
Epoch   5 Batch   28/269 - Train Accuracy: 0.7855, Validation Accuracy: 0.8081, Loss: 0.3318
Epoch   5 Batch   29/269 - Train Accuracy: 0.8063, Validation Accuracy: 0.8055, Loss: 0.3179
Epoch   5 Batch   30/269 - Train Accuracy: 0.8074, Validation Accuracy: 0.8099, Loss: 0.2950
Epoch   5 Batch   31/269 - Train Accuracy: 0.8194, Validation Accuracy: 0.8088, Loss: 0.2968
Epoch   5 Batch   32/269 - Train Accuracy: 0.8014, Validation Accuracy: 0.7981, Loss: 0.2948
Epoch   5 Batch   33/269 - Train Accuracy: 0.7962, Validation Accuracy: 0.7967, Loss: 0.2895
Epoch   5 Batch   34/269 - Train Accuracy: 0.8136, Validation Accuracy: 0.8056, Loss: 0.2966
Epoch   5 Batch   35/269 - Train Accuracy: 0.8041, Validation Accuracy: 0.8031, Loss: 0.3076
Epoch   5 Batch   36/269 - Train Accuracy: 0.7973, Validation Accuracy: 0.8060, Loss: 0.2983
Epoch   5 Batch   37/269 - Train Accuracy: 0.8134, Validation Accuracy: 0.8013, Loss: 0.3035
Epoch   5 Batch   38/269 - Train Accuracy: 0.7899, Validation Accuracy: 0.7900, Loss: 0.2984
Epoch   5 Batch   39/269 - Train Accuracy: 0.8161, Validation Accuracy: 0.8070, Loss: 0.2954
Epoch   5 Batch   40/269 - Train Accuracy: 0.7901, Validation Accuracy: 0.8032, Loss: 0.3125
Epoch   5 Batch   41/269 - Train Accuracy: 0.8134, Validation Accuracy: 0.8081, Loss: 0.2950
Epoch   5 Batch   42/269 - Train Accuracy: 0.8105, Validation Accuracy: 0.7954, Loss: 0.2762
Epoch   5 Batch   43/269 - Train Accuracy: 0.8121, Validation Accuracy: 0.8075, Loss: 0.3093
Epoch   5 Batch   44/269 - Train Accuracy: 0.8067, Validation Accuracy: 0.8093, Loss: 0.2973
Epoch   5 Batch   45/269 - Train Accuracy: 0.8057, Validation Accuracy: 0.8113, Loss: 0.3013
Epoch   5 Batch   46/269 - Train Accuracy: 0.8051, Validation Accuracy: 0.8097, Loss: 0.3013
Epoch   5 Batch   47/269 - Train Accuracy: 0.8179, Validation Accuracy: 0.8111, Loss: 0.2717
Epoch   5 Batch   48/269 - Train Accuracy: 0.8370, Validation Accuracy: 0.8200, Loss: 0.2862
Epoch   5 Batch   49/269 - Train Accuracy: 0.8120, Validation Accuracy: 0.8105, Loss: 0.2948
Epoch   5 Batch   50/269 - Train Accuracy: 0.7971, Validation Accuracy: 0.8058, Loss: 0.3098
Epoch   5 Batch   51/269 - Train Accuracy: 0.8081, Validation Accuracy: 0.8131, Loss: 0.2939
Epoch   5 Batch   52/269 - Train Accuracy: 0.8049, Validation Accuracy: 0.8198, Loss: 0.2788
Epoch   5 Batch   53/269 - Train Accuracy: 0.8088, Validation Accuracy: 0.8153, Loss: 0.3110
Epoch   5 Batch   54/269 - Train Accuracy: 0.8280, Validation Accuracy: 0.8149, Loss: 0.3014
Epoch   5 Batch   55/269 - Train Accuracy: 0.8241, Validation Accuracy: 0.8076, Loss: 0.2828
Epoch   5 Batch   56/269 - Train Accuracy: 0.8116, Validation Accuracy: 0.8115, Loss: 0.2928
Epoch   5 Batch   57/269 - Train Accuracy: 0.8182, Validation Accuracy: 0.8208, Loss: 0.3042
Epoch   5 Batch   58/269 - Train Accuracy: 0.8306, Validation Accuracy: 0.8267, Loss: 0.2851
Epoch   5 Batch   59/269 - Train Accuracy: 0.8420, Validation Accuracy: 0.8309, Loss: 0.2700
Epoch   5 Batch   60/269 - Train Accuracy: 0.8224, Validation Accuracy: 0.8220, Loss: 0.2714
Epoch   5 Batch   61/269 - Train Accuracy: 0.8267, Validation Accuracy: 0.8128, Loss: 0.2678
Epoch   5 Batch   62/269 - Train Accuracy: 0.8244, Validation Accuracy: 0.8223, Loss: 0.2852
Epoch   5 Batch   63/269 - Train Accuracy: 0.8190, Validation Accuracy: 0.8284, Loss: 0.2988
Epoch   5 Batch   64/269 - Train Accuracy: 0.8265, Validation Accuracy: 0.8208, Loss: 0.2767
Epoch   5 Batch   65/269 - Train Accuracy: 0.8088, Validation Accuracy: 0.8208, Loss: 0.2793
Epoch   5 Batch   66/269 - Train Accuracy: 0.8143, Validation Accuracy: 0.8193, Loss: 0.2817
Epoch   5 Batch   67/269 - Train Accuracy: 0.8165, Validation Accuracy: 0.8215, Loss: 0.2937
Epoch   5 Batch   68/269 - Train Accuracy: 0.8078, Validation Accuracy: 0.8251, Loss: 0.2940
Epoch   5 Batch   69/269 - Train Accuracy: 0.8073, Validation Accuracy: 0.8111, Loss: 0.3166
Epoch   5 Batch   70/269 - Train Accuracy: 0.8303, Validation Accuracy: 0.8116, Loss: 0.2877
Epoch   5 Batch   71/269 - Train Accuracy: 0.8169, Validation Accuracy: 0.8107, Loss: 0.3009
Epoch   5 Batch   72/269 - Train Accuracy: 0.8225, Validation Accuracy: 0.8161, Loss: 0.2904
Epoch   5 Batch   73/269 - Train Accuracy: 0.8145, Validation Accuracy: 0.8059, Loss: 0.2917
Epoch   5 Batch   74/269 - Train Accuracy: 0.8242, Validation Accuracy: 0.8181, Loss: 0.2903
Epoch   5 Batch   75/269 - Train Accuracy: 0.8183, Validation Accuracy: 0.8142, Loss: 0.2792
Epoch   5 Batch   76/269 - Train Accuracy: 0.8088, Validation Accuracy: 0.8205, Loss: 0.2824
Epoch   5 Batch   77/269 - Train Accuracy: 0.8244, Validation Accuracy: 0.8137, Loss: 0.2779
Epoch   5 Batch   78/269 - Train Accuracy: 0.8340, Validation Accuracy: 0.8216, Loss: 0.2761
Epoch   5 Batch   79/269 - Train Accuracy: 0.8195, Validation Accuracy: 0.8262, Loss: 0.2809
Epoch   5 Batch   80/269 - Train Accuracy: 0.8329, Validation Accuracy: 0.8265, Loss: 0.2741
Epoch   5 Batch   81/269 - Train Accuracy: 0.8070, Validation Accuracy: 0.8313, Loss: 0.2954
Epoch   5 Batch   82/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8309, Loss: 0.2662
Epoch   5 Batch   83/269 - Train Accuracy: 0.8343, Validation Accuracy: 0.8275, Loss: 0.2886
Epoch   5 Batch   84/269 - Train Accuracy: 0.8251, Validation Accuracy: 0.8303, Loss: 0.2728
Epoch   5 Batch   85/269 - Train Accuracy: 0.8274, Validation Accuracy: 0.8255, Loss: 0.2746
Epoch   5 Batch   86/269 - Train Accuracy: 0.8202, Validation Accuracy: 0.8229, Loss: 0.2740
Epoch   5 Batch   87/269 - Train Accuracy: 0.8079, Validation Accuracy: 0.8232, Loss: 0.2948
Epoch   5 Batch   88/269 - Train Accuracy: 0.8145, Validation Accuracy: 0.8319, Loss: 0.2815
Epoch   5 Batch   89/269 - Train Accuracy: 0.8398, Validation Accuracy: 0.8271, Loss: 0.2686
Epoch   5 Batch   90/269 - Train Accuracy: 0.8261, Validation Accuracy: 0.8215, Loss: 0.2875
Epoch   5 Batch   91/269 - Train Accuracy: 0.8236, Validation Accuracy: 0.8173, Loss: 0.2603
Epoch   5 Batch   92/269 - Train Accuracy: 0.8257, Validation Accuracy: 0.8147, Loss: 0.2681
Epoch   5 Batch   93/269 - Train Accuracy: 0.8329, Validation Accuracy: 0.8153, Loss: 0.2631
Epoch   5 Batch   94/269 - Train Accuracy: 0.8258, Validation Accuracy: 0.8239, Loss: 0.2857
Epoch   5 Batch   95/269 - Train Accuracy: 0.8424, Validation Accuracy: 0.8299, Loss: 0.2659
Epoch   5 Batch   96/269 - Train Accuracy: 0.8265, Validation Accuracy: 0.8300, Loss: 0.2819
Epoch   5 Batch   97/269 - Train Accuracy: 0.8299, Validation Accuracy: 0.8358, Loss: 0.2723
Epoch   5 Batch   98/269 - Train Accuracy: 0.8164, Validation Accuracy: 0.8314, Loss: 0.2765
Epoch   5 Batch   99/269 - Train Accuracy: 0.8104, Validation Accuracy: 0.8194, Loss: 0.2783
Epoch   5 Batch  100/269 - Train Accuracy: 0.8397, Validation Accuracy: 0.8165, Loss: 0.2645
Epoch   5 Batch  101/269 - Train Accuracy: 0.8240, Validation Accuracy: 0.8414, Loss: 0.2915
Epoch   5 Batch  102/269 - Train Accuracy: 0.8361, Validation Accuracy: 0.8374, Loss: 0.2628
Epoch   5 Batch  103/269 - Train Accuracy: 0.8414, Validation Accuracy: 0.8381, Loss: 0.2801
Epoch   5 Batch  104/269 - Train Accuracy: 0.8360, Validation Accuracy: 0.8305, Loss: 0.2647
Epoch   5 Batch  105/269 - Train Accuracy: 0.8270, Validation Accuracy: 0.8260, Loss: 0.2673
Epoch   5 Batch  106/269 - Train Accuracy: 0.8345, Validation Accuracy: 0.8356, Loss: 0.2605
Epoch   5 Batch  107/269 - Train Accuracy: 0.8270, Validation Accuracy: 0.8337, Loss: 0.2840
Epoch   5 Batch  108/269 - Train Accuracy: 0.8379, Validation Accuracy: 0.8348, Loss: 0.2750
Epoch   5 Batch  109/269 - Train Accuracy: 0.8241, Validation Accuracy: 0.8315, Loss: 0.2738
Epoch   5 Batch  110/269 - Train Accuracy: 0.8330, Validation Accuracy: 0.8280, Loss: 0.2668
Epoch   5 Batch  111/269 - Train Accuracy: 0.8256, Validation Accuracy: 0.8268, Loss: 0.2955
Epoch   5 Batch  112/269 - Train Accuracy: 0.8413, Validation Accuracy: 0.8277, Loss: 0.2689
Epoch   5 Batch  113/269 - Train Accuracy: 0.8419, Validation Accuracy: 0.8271, Loss: 0.2580
Epoch   5 Batch  114/269 - Train Accuracy: 0.8401, Validation Accuracy: 0.8290, Loss: 0.2711
Epoch   5 Batch  115/269 - Train Accuracy: 0.8331, Validation Accuracy: 0.8319, Loss: 0.2758
Epoch   5 Batch  116/269 - Train Accuracy: 0.8484, Validation Accuracy: 0.8329, Loss: 0.2755
Epoch   5 Batch  117/269 - Train Accuracy: 0.8317, Validation Accuracy: 0.8362, Loss: 0.2622
Epoch   5 Batch  118/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8347, Loss: 0.2574
Epoch   5 Batch  119/269 - Train Accuracy: 0.8164, Validation Accuracy: 0.8279, Loss: 0.2821
Epoch   5 Batch  120/269 - Train Accuracy: 0.8373, Validation Accuracy: 0.8358, Loss: 0.2697
Epoch   5 Batch  121/269 - Train Accuracy: 0.8350, Validation Accuracy: 0.8301, Loss: 0.2588
Epoch   5 Batch  122/269 - Train Accuracy: 0.8251, Validation Accuracy: 0.8371, Loss: 0.2583
Epoch   5 Batch  123/269 - Train Accuracy: 0.8520, Validation Accuracy: 0.8424, Loss: 0.2690
Epoch   5 Batch  124/269 - Train Accuracy: 0.8444, Validation Accuracy: 0.8422, Loss: 0.2487
Epoch   5 Batch  125/269 - Train Accuracy: 0.8313, Validation Accuracy: 0.8285, Loss: 0.2519
Epoch   5 Batch  126/269 - Train Accuracy: 0.8228, Validation Accuracy: 0.8229, Loss: 0.2647
Epoch   5 Batch  127/269 - Train Accuracy: 0.8245, Validation Accuracy: 0.8327, Loss: 0.2707
Epoch   5 Batch  128/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8397, Loss: 0.2516
Epoch   5 Batch  129/269 - Train Accuracy: 0.8330, Validation Accuracy: 0.8397, Loss: 0.2571
Epoch   5 Batch  130/269 - Train Accuracy: 0.8327, Validation Accuracy: 0.8429, Loss: 0.2704
Epoch   5 Batch  131/269 - Train Accuracy: 0.8196, Validation Accuracy: 0.8352, Loss: 0.2701
Epoch   5 Batch  132/269 - Train Accuracy: 0.8261, Validation Accuracy: 0.8352, Loss: 0.2678
Epoch   5 Batch  133/269 - Train Accuracy: 0.8352, Validation Accuracy: 0.8341, Loss: 0.2471
Epoch   5 Batch  134/269 - Train Accuracy: 0.8265, Validation Accuracy: 0.8392, Loss: 0.2640
Epoch   5 Batch  135/269 - Train Accuracy: 0.8232, Validation Accuracy: 0.8382, Loss: 0.2702
Epoch   5 Batch  136/269 - Train Accuracy: 0.8118, Validation Accuracy: 0.8414, Loss: 0.2821
Epoch   5 Batch  137/269 - Train Accuracy: 0.8278, Validation Accuracy: 0.8209, Loss: 0.2772
Epoch   5 Batch  138/269 - Train Accuracy: 0.8474, Validation Accuracy: 0.8398, Loss: 0.2627
Epoch   5 Batch  139/269 - Train Accuracy: 0.8459, Validation Accuracy: 0.8385, Loss: 0.2517
Epoch   5 Batch  140/269 - Train Accuracy: 0.8340, Validation Accuracy: 0.8292, Loss: 0.2670
Epoch   5 Batch  141/269 - Train Accuracy: 0.8355, Validation Accuracy: 0.8444, Loss: 0.2624
Epoch   5 Batch  142/269 - Train Accuracy: 0.8297, Validation Accuracy: 0.8441, Loss: 0.2515
Epoch   5 Batch  143/269 - Train Accuracy: 0.8510, Validation Accuracy: 0.8386, Loss: 0.2551
Epoch   5 Batch  144/269 - Train Accuracy: 0.8476, Validation Accuracy: 0.8353, Loss: 0.2413
Epoch   5 Batch  145/269 - Train Accuracy: 0.8253, Validation Accuracy: 0.8379, Loss: 0.2431
Epoch   5 Batch  146/269 - Train Accuracy: 0.8479, Validation Accuracy: 0.8359, Loss: 0.2498
Epoch   5 Batch  147/269 - Train Accuracy: 0.8430, Validation Accuracy: 0.8252, Loss: 0.2448
Epoch   5 Batch  148/269 - Train Accuracy: 0.8413, Validation Accuracy: 0.8426, Loss: 0.2596
Epoch   5 Batch  149/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8466, Loss: 0.2607
Epoch   5 Batch  150/269 - Train Accuracy: 0.8438, Validation Accuracy: 0.8467, Loss: 0.2499
Epoch   5 Batch  151/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8474, Loss: 0.2454
Epoch   5 Batch  152/269 - Train Accuracy: 0.8446, Validation Accuracy: 0.8422, Loss: 0.2514
Epoch   5 Batch  153/269 - Train Accuracy: 0.8477, Validation Accuracy: 0.8356, Loss: 0.2513
Epoch   5 Batch  154/269 - Train Accuracy: 0.8484, Validation Accuracy: 0.8354, Loss: 0.2533
Epoch   5 Batch  155/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8487, Loss: 0.2428
Epoch   5 Batch  156/269 - Train Accuracy: 0.8307, Validation Accuracy: 0.8463, Loss: 0.2543
Epoch   5 Batch  157/269 - Train Accuracy: 0.8435, Validation Accuracy: 0.8386, Loss: 0.2455
Epoch   5 Batch  158/269 - Train Accuracy: 0.8470, Validation Accuracy: 0.8406, Loss: 0.2461
Epoch   5 Batch  159/269 - Train Accuracy: 0.8224, Validation Accuracy: 0.8403, Loss: 0.2504
Epoch   5 Batch  160/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8259, Loss: 0.2477
Epoch   5 Batch  161/269 - Train Accuracy: 0.8397, Validation Accuracy: 0.8382, Loss: 0.2473
Epoch   5 Batch  162/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8482, Loss: 0.2370
Epoch   5 Batch  163/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8517, Loss: 0.2471
Epoch   5 Batch  164/269 - Train Accuracy: 0.8539, Validation Accuracy: 0.8526, Loss: 0.2470
Epoch   5 Batch  165/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8469, Loss: 0.2527
Epoch   5 Batch  166/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8468, Loss: 0.2361
Epoch   5 Batch  167/269 - Train Accuracy: 0.8463, Validation Accuracy: 0.8383, Loss: 0.2422
Epoch   5 Batch  168/269 - Train Accuracy: 0.8483, Validation Accuracy: 0.8423, Loss: 0.2492
Epoch   5 Batch  169/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8409, Loss: 0.2454
Epoch   5 Batch  170/269 - Train Accuracy: 0.8553, Validation Accuracy: 0.8465, Loss: 0.2394
Epoch   5 Batch  171/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8358, Loss: 0.2508
Epoch   5 Batch  172/269 - Train Accuracy: 0.8429, Validation Accuracy: 0.8445, Loss: 0.2529
Epoch   5 Batch  173/269 - Train Accuracy: 0.8529, Validation Accuracy: 0.8435, Loss: 0.2360
Epoch   5 Batch  174/269 - Train Accuracy: 0.8484, Validation Accuracy: 0.8314, Loss: 0.2442
Epoch   5 Batch  175/269 - Train Accuracy: 0.8417, Validation Accuracy: 0.8500, Loss: 0.2592
Epoch   5 Batch  176/269 - Train Accuracy: 0.8401, Validation Accuracy: 0.8448, Loss: 0.2632
Epoch   5 Batch  177/269 - Train Accuracy: 0.8414, Validation Accuracy: 0.8331, Loss: 0.2379
Epoch   5 Batch  178/269 - Train Accuracy: 0.8474, Validation Accuracy: 0.8368, Loss: 0.2391
Epoch   5 Batch  179/269 - Train Accuracy: 0.8320, Validation Accuracy: 0.8459, Loss: 0.2420
Epoch   5 Batch  180/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8434, Loss: 0.2356
Epoch   5 Batch  181/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8499, Loss: 0.2525
Epoch   5 Batch  182/269 - Train Accuracy: 0.8493, Validation Accuracy: 0.8413, Loss: 0.2340
Epoch   5 Batch  183/269 - Train Accuracy: 0.8785, Validation Accuracy: 0.8444, Loss: 0.2107
Epoch   5 Batch  184/269 - Train Accuracy: 0.8536, Validation Accuracy: 0.8484, Loss: 0.2518
Epoch   5 Batch  185/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8491, Loss: 0.2362
Epoch   5 Batch  186/269 - Train Accuracy: 0.8459, Validation Accuracy: 0.8464, Loss: 0.2355
Epoch   5 Batch  187/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8481, Loss: 0.2285
Epoch   5 Batch  188/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8451, Loss: 0.2307
Epoch   5 Batch  189/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8527, Loss: 0.2310
Epoch   5 Batch  190/269 - Train Accuracy: 0.8456, Validation Accuracy: 0.8480, Loss: 0.2262
Epoch   5 Batch  191/269 - Train Accuracy: 0.8461, Validation Accuracy: 0.8480, Loss: 0.2343
Epoch   5 Batch  192/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8433, Loss: 0.2332
Epoch   5 Batch  193/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8484, Loss: 0.2320
Epoch   5 Batch  194/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8564, Loss: 0.2379
Epoch   5 Batch  195/269 - Train Accuracy: 0.8432, Validation Accuracy: 0.8567, Loss: 0.2334
Epoch   5 Batch  196/269 - Train Accuracy: 0.8474, Validation Accuracy: 0.8511, Loss: 0.2301
Epoch   5 Batch  197/269 - Train Accuracy: 0.8423, Validation Accuracy: 0.8547, Loss: 0.2484
Epoch   5 Batch  198/269 - Train Accuracy: 0.8415, Validation Accuracy: 0.8541, Loss: 0.2544
Epoch   5 Batch  199/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8466, Loss: 0.2469
Epoch   5 Batch  200/269 - Train Accuracy: 0.8423, Validation Accuracy: 0.8505, Loss: 0.2445
Epoch   5 Batch  201/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8501, Loss: 0.2408
Epoch   5 Batch  202/269 - Train Accuracy: 0.8343, Validation Accuracy: 0.8430, Loss: 0.2398
Epoch   5 Batch  203/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8373, Loss: 0.2506
Epoch   5 Batch  204/269 - Train Accuracy: 0.8409, Validation Accuracy: 0.8510, Loss: 0.2513
Epoch   5 Batch  205/269 - Train Accuracy: 0.8511, Validation Accuracy: 0.8532, Loss: 0.2326
Epoch   5 Batch  206/269 - Train Accuracy: 0.8553, Validation Accuracy: 0.8441, Loss: 0.2432
Epoch   5 Batch  207/269 - Train Accuracy: 0.8539, Validation Accuracy: 0.8415, Loss: 0.2319
Epoch   5 Batch  208/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8469, Loss: 0.2449
Epoch   5 Batch  209/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8543, Loss: 0.2296
Epoch   5 Batch  210/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8525, Loss: 0.2233
Epoch   5 Batch  211/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8511, Loss: 0.2400
Epoch   5 Batch  212/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8581, Loss: 0.2362
Epoch   5 Batch  213/269 - Train Accuracy: 0.8510, Validation Accuracy: 0.8542, Loss: 0.2335
Epoch   5 Batch  214/269 - Train Accuracy: 0.8405, Validation Accuracy: 0.8463, Loss: 0.2344
Epoch   5 Batch  215/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8526, Loss: 0.2230
Epoch   5 Batch  216/269 - Train Accuracy: 0.8252, Validation Accuracy: 0.8556, Loss: 0.2570
Epoch   5 Batch  217/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8521, Loss: 0.2387
Epoch   5 Batch  218/269 - Train Accuracy: 0.8586, Validation Accuracy: 0.8562, Loss: 0.2316
Epoch   5 Batch  219/269 - Train Accuracy: 0.8509, Validation Accuracy: 0.8518, Loss: 0.2410
Epoch   5 Batch  220/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8515, Loss: 0.2154
Epoch   5 Batch  221/269 - Train Accuracy: 0.8547, Validation Accuracy: 0.8550, Loss: 0.2282
Epoch   5 Batch  222/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8531, Loss: 0.2227
Epoch   5 Batch  223/269 - Train Accuracy: 0.8421, Validation Accuracy: 0.8483, Loss: 0.2274
Epoch   5 Batch  224/269 - Train Accuracy: 0.8547, Validation Accuracy: 0.8479, Loss: 0.2334
Epoch   5 Batch  225/269 - Train Accuracy: 0.8374, Validation Accuracy: 0.8501, Loss: 0.2275
Epoch   5 Batch  226/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8556, Loss: 0.2274
Epoch   5 Batch  227/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8551, Loss: 0.2101
Epoch   5 Batch  228/269 - Train Accuracy: 0.8480, Validation Accuracy: 0.8571, Loss: 0.2211
Epoch   5 Batch  229/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8588, Loss: 0.2234
Epoch   5 Batch  230/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8608, Loss: 0.2189
Epoch   5 Batch  231/269 - Train Accuracy: 0.8509, Validation Accuracy: 0.8642, Loss: 0.2333
Epoch   5 Batch  232/269 - Train Accuracy: 0.8502, Validation Accuracy: 0.8582, Loss: 0.2303
Epoch   5 Batch  233/269 - Train Accuracy: 0.8852, Validation Accuracy: 0.8588, Loss: 0.2273
Epoch   5 Batch  234/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8556, Loss: 0.2219
Epoch   5 Batch  235/269 - Train Accuracy: 0.8737, Validation Accuracy: 0.8525, Loss: 0.2192
Epoch   5 Batch  236/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8566, Loss: 0.2165
Epoch   5 Batch  237/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8589, Loss: 0.2241
Epoch   5 Batch  238/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8588, Loss: 0.2204
Epoch   5 Batch  239/269 - Train Accuracy: 0.8566, Validation Accuracy: 0.8652, Loss: 0.2214
Epoch   5 Batch  240/269 - Train Accuracy: 0.8727, Validation Accuracy: 0.8585, Loss: 0.2026
Epoch   5 Batch  241/269 - Train Accuracy: 0.8479, Validation Accuracy: 0.8559, Loss: 0.2312
Epoch   5 Batch  242/269 - Train Accuracy: 0.8799, Validation Accuracy: 0.8591, Loss: 0.2097
Epoch   5 Batch  243/269 - Train Accuracy: 0.8842, Validation Accuracy: 0.8587, Loss: 0.2072
Epoch   5 Batch  244/269 - Train Accuracy: 0.8542, Validation Accuracy: 0.8588, Loss: 0.2238
Epoch   5 Batch  245/269 - Train Accuracy: 0.8450, Validation Accuracy: 0.8562, Loss: 0.2306
Epoch   5 Batch  246/269 - Train Accuracy: 0.8419, Validation Accuracy: 0.8602, Loss: 0.2206
Epoch   5 Batch  247/269 - Train Accuracy: 0.8552, Validation Accuracy: 0.8646, Loss: 0.2240
Epoch   5 Batch  248/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8571, Loss: 0.2119
Epoch   5 Batch  249/269 - Train Accuracy: 0.8833, Validation Accuracy: 0.8651, Loss: 0.2048
Epoch   5 Batch  250/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8564, Loss: 0.2211
Epoch   5 Batch  251/269 - Train Accuracy: 0.8932, Validation Accuracy: 0.8648, Loss: 0.2087
Epoch   5 Batch  252/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8599, Loss: 0.2165
Epoch   5 Batch  253/269 - Train Accuracy: 0.8371, Validation Accuracy: 0.8637, Loss: 0.2257
Epoch   5 Batch  254/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8640, Loss: 0.2161
Epoch   5 Batch  255/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8593, Loss: 0.2130
Epoch   5 Batch  256/269 - Train Accuracy: 0.8534, Validation Accuracy: 0.8532, Loss: 0.2170
Epoch   5 Batch  257/269 - Train Accuracy: 0.8431, Validation Accuracy: 0.8615, Loss: 0.2265
Epoch   5 Batch  258/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8587, Loss: 0.2167
Epoch   5 Batch  259/269 - Train Accuracy: 0.8561, Validation Accuracy: 0.8655, Loss: 0.2216
Epoch   5 Batch  260/269 - Train Accuracy: 0.8445, Validation Accuracy: 0.8623, Loss: 0.2276
Epoch   5 Batch  261/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8582, Loss: 0.2190
Epoch   5 Batch  262/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8612, Loss: 0.2135
Epoch   5 Batch  263/269 - Train Accuracy: 0.8503, Validation Accuracy: 0.8621, Loss: 0.2215
Epoch   5 Batch  264/269 - Train Accuracy: 0.8339, Validation Accuracy: 0.8604, Loss: 0.2270
Epoch   5 Batch  265/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8634, Loss: 0.2169
Epoch   5 Batch  266/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8614, Loss: 0.2082
Epoch   5 Batch  267/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8604, Loss: 0.2190
Epoch   6 Batch    1/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8636, Loss: 0.2190
Epoch   6 Batch    2/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8652, Loss: 0.2184
Epoch   6 Batch    3/269 - Train Accuracy: 0.8818, Validation Accuracy: 0.8565, Loss: 0.2133
Epoch   6 Batch    4/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8593, Loss: 0.2169
Epoch   6 Batch    5/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8651, Loss: 0.2155
Epoch   6 Batch    6/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8604, Loss: 0.2073
Epoch   6 Batch    7/269 - Train Accuracy: 0.8721, Validation Accuracy: 0.8635, Loss: 0.2026
Epoch   6 Batch    8/269 - Train Accuracy: 0.8693, Validation Accuracy: 0.8627, Loss: 0.2213
Epoch   6 Batch    9/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8594, Loss: 0.2146
Epoch   6 Batch   10/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8649, Loss: 0.2136
Epoch   6 Batch   11/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8643, Loss: 0.2206
Epoch   6 Batch   12/269 - Train Accuracy: 0.8618, Validation Accuracy: 0.8585, Loss: 0.2269
Epoch   6 Batch   13/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8576, Loss: 0.1884
Epoch   6 Batch   14/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8706, Loss: 0.2081
Epoch   6 Batch   15/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.8682, Loss: 0.1992
Epoch   6 Batch   16/269 - Train Accuracy: 0.8552, Validation Accuracy: 0.8714, Loss: 0.2107
Epoch   6 Batch   17/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8604, Loss: 0.1972
Epoch   6 Batch   18/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8650, Loss: 0.2119
Epoch   6 Batch   19/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8630, Loss: 0.1935
Epoch   6 Batch   20/269 - Train Accuracy: 0.8678, Validation Accuracy: 0.8629, Loss: 0.2058
Epoch   6 Batch   21/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8679, Loss: 0.2255
Epoch   6 Batch   22/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.8730, Loss: 0.1947
Epoch   6 Batch   23/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8689, Loss: 0.2075
Epoch   6 Batch   24/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8619, Loss: 0.2107
Epoch   6 Batch   25/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8649, Loss: 0.2238
Epoch   6 Batch   26/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8661, Loss: 0.1893
Epoch   6 Batch   27/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8660, Loss: 0.2015
Epoch   6 Batch   28/269 - Train Accuracy: 0.8413, Validation Accuracy: 0.8694, Loss: 0.2193
Epoch   6 Batch   29/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8721, Loss: 0.2205
Epoch   6 Batch   30/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8647, Loss: 0.1980
Epoch   6 Batch   31/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8660, Loss: 0.2002
Epoch   6 Batch   32/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8586, Loss: 0.2026
Epoch   6 Batch   33/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8598, Loss: 0.1996
Epoch   6 Batch   34/269 - Train Accuracy: 0.8773, Validation Accuracy: 0.8630, Loss: 0.2050
Epoch   6 Batch   35/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8596, Loss: 0.2089
Epoch   6 Batch   36/269 - Train Accuracy: 0.8528, Validation Accuracy: 0.8628, Loss: 0.2100
Epoch   6 Batch   37/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8704, Loss: 0.2074
Epoch   6 Batch   38/269 - Train Accuracy: 0.8507, Validation Accuracy: 0.8578, Loss: 0.2036
Epoch   6 Batch   39/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8607, Loss: 0.2031
Epoch   6 Batch   40/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8651, Loss: 0.2131
Epoch   6 Batch   41/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8722, Loss: 0.2125
Epoch   6 Batch   42/269 - Train Accuracy: 0.8847, Validation Accuracy: 0.8674, Loss: 0.1865
Epoch   6 Batch   43/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8712, Loss: 0.2081
Epoch   6 Batch   44/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8619, Loss: 0.2058
Epoch   6 Batch   45/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8658, Loss: 0.2074
Epoch   6 Batch   46/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8608, Loss: 0.2059
Epoch   6 Batch   47/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8638, Loss: 0.1851
Epoch   6 Batch   48/269 - Train Accuracy: 0.8883, Validation Accuracy: 0.8714, Loss: 0.1991
Epoch   6 Batch   49/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8659, Loss: 0.1959
Epoch   6 Batch   50/269 - Train Accuracy: 0.8534, Validation Accuracy: 0.8637, Loss: 0.2124
Epoch   6 Batch   51/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8720, Loss: 0.2012
Epoch   6 Batch   52/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8773, Loss: 0.1818
Epoch   6 Batch   53/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8654, Loss: 0.2190
Epoch   6 Batch   54/269 - Train Accuracy: 0.8829, Validation Accuracy: 0.8699, Loss: 0.2032
Epoch   6 Batch   55/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.8707, Loss: 0.1935
Epoch   6 Batch   56/269 - Train Accuracy: 0.8739, Validation Accuracy: 0.8630, Loss: 0.2036
Epoch   6 Batch   57/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8721, Loss: 0.2073
Epoch   6 Batch   58/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8762, Loss: 0.1990
Epoch   6 Batch   59/269 - Train Accuracy: 0.8937, Validation Accuracy: 0.8742, Loss: 0.1830
Epoch   6 Batch   60/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8797, Loss: 0.1887
Epoch   6 Batch   61/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.8738, Loss: 0.1862
Epoch   6 Batch   62/269 - Train Accuracy: 0.8827, Validation Accuracy: 0.8743, Loss: 0.1901
Epoch   6 Batch   63/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8733, Loss: 0.2064
Epoch   6 Batch   64/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8678, Loss: 0.1916
Epoch   6 Batch   65/269 - Train Accuracy: 0.8567, Validation Accuracy: 0.8604, Loss: 0.1980
Epoch   6 Batch   66/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8723, Loss: 0.1955
Epoch   6 Batch   67/269 - Train Accuracy: 0.8710, Validation Accuracy: 0.8689, Loss: 0.2072
Epoch   6 Batch   68/269 - Train Accuracy: 0.8553, Validation Accuracy: 0.8703, Loss: 0.2086
Epoch   6 Batch   69/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8706, Loss: 0.2221
Epoch   6 Batch   70/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8724, Loss: 0.1987
Epoch   6 Batch   71/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8712, Loss: 0.2131
Epoch   6 Batch   72/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8695, Loss: 0.1956
Epoch   6 Batch   73/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8650, Loss: 0.2002
Epoch   6 Batch   74/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8675, Loss: 0.1914
Epoch   6 Batch   75/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8644, Loss: 0.1923
Epoch   6 Batch   76/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8736, Loss: 0.1911
Epoch   6 Batch   77/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8672, Loss: 0.1862
Epoch   6 Batch   78/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8755, Loss: 0.1932
Epoch   6 Batch   79/269 - Train Accuracy: 0.8625, Validation Accuracy: 0.8763, Loss: 0.1876
Epoch   6 Batch   80/269 - Train Accuracy: 0.8787, Validation Accuracy: 0.8741, Loss: 0.1874
Epoch   6 Batch   81/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8764, Loss: 0.2066
Epoch   6 Batch   82/269 - Train Accuracy: 0.8868, Validation Accuracy: 0.8831, Loss: 0.1792
Epoch   6 Batch   83/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8751, Loss: 0.2035
Epoch   6 Batch   84/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8667, Loss: 0.1859
Epoch   6 Batch   85/269 - Train Accuracy: 0.8710, Validation Accuracy: 0.8700, Loss: 0.1850
Epoch   6 Batch   86/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8722, Loss: 0.1848
Epoch   6 Batch   87/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8748, Loss: 0.2052
Epoch   6 Batch   88/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8746, Loss: 0.1943
Epoch   6 Batch   89/269 - Train Accuracy: 0.8883, Validation Accuracy: 0.8706, Loss: 0.1875
Epoch   6 Batch   90/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8700, Loss: 0.1951
Epoch   6 Batch   91/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8687, Loss: 0.1805
Epoch   6 Batch   92/269 - Train Accuracy: 0.8853, Validation Accuracy: 0.8741, Loss: 0.1822
Epoch   6 Batch   93/269 - Train Accuracy: 0.8835, Validation Accuracy: 0.8771, Loss: 0.1805
Epoch   6 Batch   94/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8758, Loss: 0.1998
Epoch   6 Batch   95/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.8751, Loss: 0.1811
Epoch   6 Batch   96/269 - Train Accuracy: 0.8490, Validation Accuracy: 0.8846, Loss: 0.1887
Epoch   6 Batch   97/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8796, Loss: 0.1861
Epoch   6 Batch   98/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8847, Loss: 0.1923
Epoch   6 Batch   99/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8801, Loss: 0.1882
Epoch   6 Batch  100/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8801, Loss: 0.1827
Epoch   6 Batch  101/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8792, Loss: 0.2051
Epoch   6 Batch  102/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8837, Loss: 0.1783
Epoch   6 Batch  103/269 - Train Accuracy: 0.8855, Validation Accuracy: 0.8775, Loss: 0.1905
Epoch   6 Batch  104/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8762, Loss: 0.1806
Epoch   6 Batch  105/269 - Train Accuracy: 0.8773, Validation Accuracy: 0.8845, Loss: 0.1909
Epoch   6 Batch  106/269 - Train Accuracy: 0.8807, Validation Accuracy: 0.8819, Loss: 0.1696
Epoch   6 Batch  107/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8750, Loss: 0.1938
Epoch   6 Batch  108/269 - Train Accuracy: 0.8839, Validation Accuracy: 0.8812, Loss: 0.1816
Epoch   6 Batch  109/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8635, Loss: 0.1873
Epoch   6 Batch  110/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8703, Loss: 0.1866
Epoch   6 Batch  111/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8651, Loss: 0.1994
Epoch   6 Batch  112/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8759, Loss: 0.1860
Epoch   6 Batch  113/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8815, Loss: 0.1749
Epoch   6 Batch  114/269 - Train Accuracy: 0.8908, Validation Accuracy: 0.8788, Loss: 0.1830
Epoch   6 Batch  115/269 - Train Accuracy: 0.8693, Validation Accuracy: 0.8798, Loss: 0.1893
Epoch   6 Batch  116/269 - Train Accuracy: 0.8951, Validation Accuracy: 0.8770, Loss: 0.1897
Epoch   6 Batch  117/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8764, Loss: 0.1776
Epoch   6 Batch  118/269 - Train Accuracy: 0.8923, Validation Accuracy: 0.8790, Loss: 0.1741
Epoch   6 Batch  119/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8824, Loss: 0.2018
Epoch   6 Batch  120/269 - Train Accuracy: 0.8825, Validation Accuracy: 0.8676, Loss: 0.1740
Epoch   6 Batch  121/269 - Train Accuracy: 0.8864, Validation Accuracy: 0.8793, Loss: 0.1714
Epoch   6 Batch  122/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8739, Loss: 0.1733
Epoch   6 Batch  123/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8738, Loss: 0.1872
Epoch   6 Batch  124/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8797, Loss: 0.1724
Epoch   6 Batch  125/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.8807, Loss: 0.1698
Epoch   6 Batch  126/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8843, Loss: 0.1753
Epoch   6 Batch  127/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.8776, Loss: 0.1857
Epoch   6 Batch  128/269 - Train Accuracy: 0.8938, Validation Accuracy: 0.8777, Loss: 0.1775
Epoch   6 Batch  129/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8753, Loss: 0.1796
Epoch   6 Batch  130/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8809, Loss: 0.1871
Epoch   6 Batch  131/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8872, Loss: 0.1796
Epoch   6 Batch  132/269 - Train Accuracy: 0.8765, Validation Accuracy: 0.8864, Loss: 0.1859
Epoch   6 Batch  133/269 - Train Accuracy: 0.8922, Validation Accuracy: 0.8851, Loss: 0.1679
Epoch   6 Batch  134/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8822, Loss: 0.1736
Epoch   6 Batch  135/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.8816, Loss: 0.1930
Epoch   6 Batch  136/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8835, Loss: 0.1917
Epoch   6 Batch  137/269 - Train Accuracy: 0.8865, Validation Accuracy: 0.8809, Loss: 0.1914
Epoch   6 Batch  138/269 - Train Accuracy: 0.8922, Validation Accuracy: 0.8772, Loss: 0.1726
Epoch   6 Batch  139/269 - Train Accuracy: 0.8788, Validation Accuracy: 0.8773, Loss: 0.1752
Epoch   6 Batch  140/269 - Train Accuracy: 0.8816, Validation Accuracy: 0.8813, Loss: 0.1807
Epoch   6 Batch  141/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8765, Loss: 0.1844
Epoch   6 Batch  142/269 - Train Accuracy: 0.8712, Validation Accuracy: 0.8777, Loss: 0.1755
Epoch   6 Batch  143/269 - Train Accuracy: 0.8904, Validation Accuracy: 0.8786, Loss: 0.1729
Epoch   6 Batch  144/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8784, Loss: 0.1640
Epoch   6 Batch  145/269 - Train Accuracy: 0.8829, Validation Accuracy: 0.8712, Loss: 0.1707
Epoch   6 Batch  146/269 - Train Accuracy: 0.8814, Validation Accuracy: 0.8718, Loss: 0.1719
Epoch   6 Batch  147/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8753, Loss: 0.1723
Epoch   6 Batch  148/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.8765, Loss: 0.1763
Epoch   6 Batch  149/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8828, Loss: 0.1884
Epoch   6 Batch  150/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8838, Loss: 0.1758
Epoch   6 Batch  151/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8834, Loss: 0.1691
Epoch   6 Batch  152/269 - Train Accuracy: 0.8853, Validation Accuracy: 0.8939, Loss: 0.1861
Epoch   6 Batch  153/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8873, Loss: 0.1699
Epoch   6 Batch  154/269 - Train Accuracy: 0.9014, Validation Accuracy: 0.8784, Loss: 0.1732
Epoch   6 Batch  155/269 - Train Accuracy: 0.8816, Validation Accuracy: 0.8798, Loss: 0.1713
Epoch   6 Batch  156/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8847, Loss: 0.1845
Epoch   6 Batch  157/269 - Train Accuracy: 0.8832, Validation Accuracy: 0.8874, Loss: 0.1696
Epoch   6 Batch  158/269 - Train Accuracy: 0.8892, Validation Accuracy: 0.8908, Loss: 0.1709
Epoch   6 Batch  159/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8899, Loss: 0.1775
Epoch   6 Batch  160/269 - Train Accuracy: 0.8897, Validation Accuracy: 0.8866, Loss: 0.1778
Epoch   6 Batch  161/269 - Train Accuracy: 0.8872, Validation Accuracy: 0.8817, Loss: 0.1748
Epoch   6 Batch  162/269 - Train Accuracy: 0.9032, Validation Accuracy: 0.8903, Loss: 0.1660
Epoch   6 Batch  163/269 - Train Accuracy: 0.8912, Validation Accuracy: 0.8886, Loss: 0.1752
Epoch   6 Batch  164/269 - Train Accuracy: 0.8969, Validation Accuracy: 0.8828, Loss: 0.1741
Epoch   6 Batch  165/269 - Train Accuracy: 0.8833, Validation Accuracy: 0.8838, Loss: 0.1746
Epoch   6 Batch  166/269 - Train Accuracy: 0.8774, Validation Accuracy: 0.8860, Loss: 0.1655
Epoch   6 Batch  167/269 - Train Accuracy: 0.8834, Validation Accuracy: 0.8885, Loss: 0.1706
Epoch   6 Batch  168/269 - Train Accuracy: 0.8850, Validation Accuracy: 0.8840, Loss: 0.1711
Epoch   6 Batch  169/269 - Train Accuracy: 0.8885, Validation Accuracy: 0.8835, Loss: 0.1759
Epoch   6 Batch  170/269 - Train Accuracy: 0.8825, Validation Accuracy: 0.8870, Loss: 0.1666
Epoch   6 Batch  171/269 - Train Accuracy: 0.9040, Validation Accuracy: 0.8797, Loss: 0.1727
Epoch   6 Batch  172/269 - Train Accuracy: 0.8702, Validation Accuracy: 0.8857, Loss: 0.1880
Epoch   6 Batch  173/269 - Train Accuracy: 0.8942, Validation Accuracy: 0.8828, Loss: 0.1640
Epoch   6 Batch  174/269 - Train Accuracy: 0.8869, Validation Accuracy: 0.8778, Loss: 0.1700
Epoch   6 Batch  175/269 - Train Accuracy: 0.8750, Validation Accuracy: 0.8866, Loss: 0.1870
Epoch   6 Batch  176/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8876, Loss: 0.1793
Epoch   6 Batch  177/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.8912, Loss: 0.1636
Epoch   6 Batch  178/269 - Train Accuracy: 0.8975, Validation Accuracy: 0.8964, Loss: 0.1663
Epoch   6 Batch  179/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8833, Loss: 0.1683
Epoch   6 Batch  180/269 - Train Accuracy: 0.9002, Validation Accuracy: 0.8954, Loss: 0.1651
Epoch   6 Batch  181/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.8960, Loss: 0.1748
Epoch   6 Batch  182/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8922, Loss: 0.1722
Epoch   6 Batch  183/269 - Train Accuracy: 0.9083, Validation Accuracy: 0.8939, Loss: 0.1478
Epoch   6 Batch  184/269 - Train Accuracy: 0.8870, Validation Accuracy: 0.8872, Loss: 0.1717
Epoch   6 Batch  185/269 - Train Accuracy: 0.9079, Validation Accuracy: 0.8933, Loss: 0.1660
Epoch   6 Batch  186/269 - Train Accuracy: 0.8882, Validation Accuracy: 0.8980, Loss: 0.1669
Epoch   6 Batch  187/269 - Train Accuracy: 0.8985, Validation Accuracy: 0.8999, Loss: 0.1612
Epoch   6 Batch  188/269 - Train Accuracy: 0.8965, Validation Accuracy: 0.8968, Loss: 0.1566
Epoch   6 Batch  189/269 - Train Accuracy: 0.8870, Validation Accuracy: 0.8923, Loss: 0.1622
Epoch   6 Batch  190/269 - Train Accuracy: 0.8924, Validation Accuracy: 0.8857, Loss: 0.1571
Epoch   6 Batch  191/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8869, Loss: 0.1663
Epoch   6 Batch  192/269 - Train Accuracy: 0.8923, Validation Accuracy: 0.8904, Loss: 0.1671
Epoch   6 Batch  193/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.8836, Loss: 0.1625
Epoch   6 Batch  194/269 - Train Accuracy: 0.8879, Validation Accuracy: 0.8868, Loss: 0.1651
Epoch   6 Batch  195/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8869, Loss: 0.1677
Epoch   6 Batch  196/269 - Train Accuracy: 0.8678, Validation Accuracy: 0.8821, Loss: 0.1620
Epoch   6 Batch  197/269 - Train Accuracy: 0.8812, Validation Accuracy: 0.8810, Loss: 0.1723
Epoch   6 Batch  198/269 - Train Accuracy: 0.8868, Validation Accuracy: 0.8886, Loss: 0.1736
Epoch   6 Batch  199/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8847, Loss: 0.1703
Epoch   6 Batch  200/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8947, Loss: 0.1673
Epoch   6 Batch  201/269 - Train Accuracy: 0.8905, Validation Accuracy: 0.8919, Loss: 0.1711
Epoch   6 Batch  202/269 - Train Accuracy: 0.8864, Validation Accuracy: 0.8911, Loss: 0.1644
Epoch   6 Batch  203/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.8946, Loss: 0.1763
Epoch   6 Batch  204/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.8944, Loss: 0.1725
Epoch   6 Batch  205/269 - Train Accuracy: 0.8905, Validation Accuracy: 0.8919, Loss: 0.1614
Epoch   6 Batch  206/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8874, Loss: 0.1713
Epoch   6 Batch  207/269 - Train Accuracy: 0.8861, Validation Accuracy: 0.8831, Loss: 0.1616
Epoch   6 Batch  208/269 - Train Accuracy: 0.8889, Validation Accuracy: 0.8851, Loss: 0.1701
Epoch   6 Batch  209/269 - Train Accuracy: 0.8983, Validation Accuracy: 0.8857, Loss: 0.1590
Epoch   6 Batch  210/269 - Train Accuracy: 0.8978, Validation Accuracy: 0.8816, Loss: 0.1502
Epoch   6 Batch  211/269 - Train Accuracy: 0.8791, Validation Accuracy: 0.8774, Loss: 0.1643
Epoch   6 Batch  212/269 - Train Accuracy: 0.8907, Validation Accuracy: 0.8864, Loss: 0.1667
Epoch   6 Batch  213/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8857, Loss: 0.1595
Epoch   6 Batch  214/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8945, Loss: 0.1592
Epoch   6 Batch  215/269 - Train Accuracy: 0.9031, Validation Accuracy: 0.8835, Loss: 0.1483
Epoch   6 Batch  216/269 - Train Accuracy: 0.8668, Validation Accuracy: 0.8828, Loss: 0.1806
Epoch   6 Batch  217/269 - Train Accuracy: 0.8858, Validation Accuracy: 0.8866, Loss: 0.1701
Epoch   6 Batch  218/269 - Train Accuracy: 0.9018, Validation Accuracy: 0.8900, Loss: 0.1632
Epoch   6 Batch  219/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8840, Loss: 0.1673
Epoch   6 Batch  220/269 - Train Accuracy: 0.8994, Validation Accuracy: 0.8944, Loss: 0.1534
Epoch   6 Batch  221/269 - Train Accuracy: 0.8921, Validation Accuracy: 0.8970, Loss: 0.1597
Epoch   6 Batch  222/269 - Train Accuracy: 0.9042, Validation Accuracy: 0.8968, Loss: 0.1546
Epoch   6 Batch  223/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8896, Loss: 0.1535
Epoch   6 Batch  224/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8898, Loss: 0.1679
Epoch   6 Batch  225/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.8956, Loss: 0.1580
Epoch   6 Batch  226/269 - Train Accuracy: 0.8943, Validation Accuracy: 0.8953, Loss: 0.1590
Epoch   6 Batch  227/269 - Train Accuracy: 0.9093, Validation Accuracy: 0.8956, Loss: 0.1544
Epoch   6 Batch  228/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8876, Loss: 0.1566
Epoch   6 Batch  229/269 - Train Accuracy: 0.8892, Validation Accuracy: 0.8870, Loss: 0.1594
Epoch   6 Batch  230/269 - Train Accuracy: 0.8924, Validation Accuracy: 0.8947, Loss: 0.1537
Epoch   6 Batch  231/269 - Train Accuracy: 0.8860, Validation Accuracy: 0.8974, Loss: 0.1644
Epoch   6 Batch  232/269 - Train Accuracy: 0.8955, Validation Accuracy: 0.8944, Loss: 0.1551
Epoch   6 Batch  233/269 - Train Accuracy: 0.9107, Validation Accuracy: 0.8977, Loss: 0.1605
Epoch   6 Batch  234/269 - Train Accuracy: 0.8942, Validation Accuracy: 0.8969, Loss: 0.1586
Epoch   6 Batch  235/269 - Train Accuracy: 0.9137, Validation Accuracy: 0.8976, Loss: 0.1513
Epoch   6 Batch  236/269 - Train Accuracy: 0.8851, Validation Accuracy: 0.8950, Loss: 0.1491
Epoch   6 Batch  237/269 - Train Accuracy: 0.8782, Validation Accuracy: 0.8980, Loss: 0.1510
Epoch   6 Batch  238/269 - Train Accuracy: 0.8953, Validation Accuracy: 0.8968, Loss: 0.1530
Epoch   6 Batch  239/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.8946, Loss: 0.1562
Epoch   6 Batch  240/269 - Train Accuracy: 0.8974, Validation Accuracy: 0.8780, Loss: 0.1434
Epoch   6 Batch  241/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8874, Loss: 0.1707
Epoch   6 Batch  242/269 - Train Accuracy: 0.9091, Validation Accuracy: 0.8933, Loss: 0.1494
Epoch   6 Batch  243/269 - Train Accuracy: 0.8982, Validation Accuracy: 0.8943, Loss: 0.1441
Epoch   6 Batch  244/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8715, Loss: 0.1588
Epoch   6 Batch  245/269 - Train Accuracy: 0.8750, Validation Accuracy: 0.8966, Loss: 0.1638
Epoch   6 Batch  246/269 - Train Accuracy: 0.8874, Validation Accuracy: 0.8926, Loss: 0.1566
Epoch   6 Batch  247/269 - Train Accuracy: 0.9034, Validation Accuracy: 0.8936, Loss: 0.1566
Epoch   6 Batch  248/269 - Train Accuracy: 0.9000, Validation Accuracy: 0.8928, Loss: 0.1478
Epoch   6 Batch  249/269 - Train Accuracy: 0.9078, Validation Accuracy: 0.8952, Loss: 0.1445
Epoch   6 Batch  250/269 - Train Accuracy: 0.9112, Validation Accuracy: 0.8982, Loss: 0.1539
Epoch   6 Batch  251/269 - Train Accuracy: 0.9207, Validation Accuracy: 0.8999, Loss: 0.1447
Epoch   6 Batch  252/269 - Train Accuracy: 0.9016, Validation Accuracy: 0.9053, Loss: 0.1435
Epoch   6 Batch  253/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.9029, Loss: 0.1600
Epoch   6 Batch  254/269 - Train Accuracy: 0.8919, Validation Accuracy: 0.9042, Loss: 0.1474
Epoch   6 Batch  255/269 - Train Accuracy: 0.8870, Validation Accuracy: 0.8966, Loss: 0.1514
Epoch   6 Batch  256/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8988, Loss: 0.1536
Epoch   6 Batch  257/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8907, Loss: 0.1621
Epoch   6 Batch  258/269 - Train Accuracy: 0.8988, Validation Accuracy: 0.8930, Loss: 0.1607
Epoch   6 Batch  259/269 - Train Accuracy: 0.8969, Validation Accuracy: 0.8919, Loss: 0.1558
Epoch   6 Batch  260/269 - Train Accuracy: 0.8898, Validation Accuracy: 0.9039, Loss: 0.1643
Epoch   6 Batch  261/269 - Train Accuracy: 0.8877, Validation Accuracy: 0.8903, Loss: 0.1501
Epoch   6 Batch  262/269 - Train Accuracy: 0.9001, Validation Accuracy: 0.8853, Loss: 0.1541
Epoch   6 Batch  263/269 - Train Accuracy: 0.8868, Validation Accuracy: 0.8906, Loss: 0.1632
Epoch   6 Batch  264/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8939, Loss: 0.1658
Epoch   6 Batch  265/269 - Train Accuracy: 0.9008, Validation Accuracy: 0.8981, Loss: 0.1543
Epoch   6 Batch  266/269 - Train Accuracy: 0.8950, Validation Accuracy: 0.8924, Loss: 0.1516
Epoch   6 Batch  267/269 - Train Accuracy: 0.9032, Validation Accuracy: 0.8958, Loss: 0.1566
Epoch   7 Batch    1/269 - Train Accuracy: 0.8982, Validation Accuracy: 0.9047, Loss: 0.1576
Epoch   7 Batch    2/269 - Train Accuracy: 0.8922, Validation Accuracy: 0.9015, Loss: 0.1549
Epoch   7 Batch    3/269 - Train Accuracy: 0.9188, Validation Accuracy: 0.8998, Loss: 0.1575
Epoch   7 Batch    4/269 - Train Accuracy: 0.8862, Validation Accuracy: 0.8874, Loss: 0.1566
Epoch   7 Batch    5/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.8915, Loss: 0.1489
Epoch   7 Batch    6/269 - Train Accuracy: 0.9133, Validation Accuracy: 0.8900, Loss: 0.1400
Epoch   7 Batch    7/269 - Train Accuracy: 0.9040, Validation Accuracy: 0.8975, Loss: 0.1455
Epoch   7 Batch    8/269 - Train Accuracy: 0.9029, Validation Accuracy: 0.8968, Loss: 0.1554
Epoch   7 Batch    9/269 - Train Accuracy: 0.8943, Validation Accuracy: 0.8976, Loss: 0.1580
Epoch   7 Batch   10/269 - Train Accuracy: 0.9030, Validation Accuracy: 0.8952, Loss: 0.1436
Epoch   7 Batch   11/269 - Train Accuracy: 0.9059, Validation Accuracy: 0.8967, Loss: 0.1579
Epoch   7 Batch   12/269 - Train Accuracy: 0.8789, Validation Accuracy: 0.9001, Loss: 0.1625
Epoch   7 Batch   13/269 - Train Accuracy: 0.8974, Validation Accuracy: 0.9011, Loss: 0.1336
Epoch   7 Batch   14/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.9065, Loss: 0.1478
Epoch   7 Batch   15/269 - Train Accuracy: 0.8995, Validation Accuracy: 0.8999, Loss: 0.1395
Epoch   7 Batch   16/269 - Train Accuracy: 0.8899, Validation Accuracy: 0.9002, Loss: 0.1493
Epoch   7 Batch   17/269 - Train Accuracy: 0.9040, Validation Accuracy: 0.9021, Loss: 0.1392
Epoch   7 Batch   18/269 - Train Accuracy: 0.8880, Validation Accuracy: 0.8964, Loss: 0.1456
Epoch   7 Batch   19/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.8953, Loss: 0.1349
Epoch   7 Batch   20/269 - Train Accuracy: 0.8939, Validation Accuracy: 0.8911, Loss: 0.1458
Epoch   7 Batch   21/269 - Train Accuracy: 0.8884, Validation Accuracy: 0.8998, Loss: 0.1636
Epoch   7 Batch   22/269 - Train Accuracy: 0.9107, Validation Accuracy: 0.8939, Loss: 0.1348
Epoch   7 Batch   23/269 - Train Accuracy: 0.8899, Validation Accuracy: 0.8934, Loss: 0.1527
Epoch   7 Batch   24/269 - Train Accuracy: 0.8980, Validation Accuracy: 0.8935, Loss: 0.1486
Epoch   7 Batch   25/269 - Train Accuracy: 0.8832, Validation Accuracy: 0.9050, Loss: 0.1642
Epoch   7 Batch   26/269 - Train Accuracy: 0.8888, Validation Accuracy: 0.8997, Loss: 0.1351
Epoch   7 Batch   27/269 - Train Accuracy: 0.8904, Validation Accuracy: 0.9031, Loss: 0.1400
Epoch   7 Batch   28/269 - Train Accuracy: 0.8855, Validation Accuracy: 0.8983, Loss: 0.1554
Epoch   7 Batch   29/269 - Train Accuracy: 0.9059, Validation Accuracy: 0.9000, Loss: 0.1508
Epoch   7 Batch   30/269 - Train Accuracy: 0.8979, Validation Accuracy: 0.9026, Loss: 0.1436
Epoch   7 Batch   31/269 - Train Accuracy: 0.9085, Validation Accuracy: 0.9079, Loss: 0.1400
Epoch   7 Batch   32/269 - Train Accuracy: 0.9051, Validation Accuracy: 0.8980, Loss: 0.1421
Epoch   7 Batch   33/269 - Train Accuracy: 0.9127, Validation Accuracy: 0.8948, Loss: 0.1353
Epoch   7 Batch   34/269 - Train Accuracy: 0.9062, Validation Accuracy: 0.8951, Loss: 0.1439
Epoch   7 Batch   35/269 - Train Accuracy: 0.9018, Validation Accuracy: 0.8979, Loss: 0.1463
Epoch   7 Batch   36/269 - Train Accuracy: 0.8920, Validation Accuracy: 0.8983, Loss: 0.1442
Epoch   7 Batch   37/269 - Train Accuracy: 0.8963, Validation Accuracy: 0.8936, Loss: 0.1401
Epoch   7 Batch   38/269 - Train Accuracy: 0.8973, Validation Accuracy: 0.8981, Loss: 0.1412
Epoch   7 Batch   39/269 - Train Accuracy: 0.8979, Validation Accuracy: 0.8975, Loss: 0.1399
Epoch   7 Batch   40/269 - Train Accuracy: 0.8947, Validation Accuracy: 0.9021, Loss: 0.1467
Epoch   7 Batch   41/269 - Train Accuracy: 0.8850, Validation Accuracy: 0.8963, Loss: 0.1489
Epoch   7 Batch   42/269 - Train Accuracy: 0.9101, Validation Accuracy: 0.9020, Loss: 0.1350
Epoch   7 Batch   43/269 - Train Accuracy: 0.9009, Validation Accuracy: 0.9014, Loss: 0.1392
Epoch   7 Batch   44/269 - Train Accuracy: 0.8986, Validation Accuracy: 0.9015, Loss: 0.1470
Epoch   7 Batch   45/269 - Train Accuracy: 0.8878, Validation Accuracy: 0.8983, Loss: 0.1459
Epoch   7 Batch   46/269 - Train Accuracy: 0.9043, Validation Accuracy: 0.9023, Loss: 0.1353
Epoch   7 Batch   47/269 - Train Accuracy: 0.9102, Validation Accuracy: 0.9009, Loss: 0.1299
Epoch   7 Batch   48/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.9009, Loss: 0.1358
Epoch   7 Batch   49/269 - Train Accuracy: 0.9000, Validation Accuracy: 0.9024, Loss: 0.1378
Epoch   7 Batch   50/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8965, Loss: 0.1477
Epoch   7 Batch   51/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.8953, Loss: 0.1441
Epoch   7 Batch   52/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.8998, Loss: 0.1299
Epoch   7 Batch   53/269 - Train Accuracy: 0.8875, Validation Accuracy: 0.8991, Loss: 0.1543
Epoch   7 Batch   54/269 - Train Accuracy: 0.9092, Validation Accuracy: 0.8973, Loss: 0.1418
Epoch   7 Batch   55/269 - Train Accuracy: 0.8964, Validation Accuracy: 0.8917, Loss: 0.1369
Epoch   7 Batch   56/269 - Train Accuracy: 0.8917, Validation Accuracy: 0.9072, Loss: 0.1452
Epoch   7 Batch   57/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.9009, Loss: 0.1401
Epoch   7 Batch   58/269 - Train Accuracy: 0.9002, Validation Accuracy: 0.9036, Loss: 0.1415
Epoch   7 Batch   59/269 - Train Accuracy: 0.9169, Validation Accuracy: 0.9047, Loss: 0.1276
Epoch   7 Batch   60/269 - Train Accuracy: 0.9059, Validation Accuracy: 0.8995, Loss: 0.1315
Epoch   7 Batch   61/269 - Train Accuracy: 0.9154, Validation Accuracy: 0.8986, Loss: 0.1301
Epoch   7 Batch   62/269 - Train Accuracy: 0.9005, Validation Accuracy: 0.8985, Loss: 0.1381
Epoch   7 Batch   63/269 - Train Accuracy: 0.8885, Validation Accuracy: 0.9004, Loss: 0.1430
Epoch   7 Batch   64/269 - Train Accuracy: 0.9074, Validation Accuracy: 0.8987, Loss: 0.1322
Epoch   7 Batch   65/269 - Train Accuracy: 0.8938, Validation Accuracy: 0.8943, Loss: 0.1313
Epoch   7 Batch   66/269 - Train Accuracy: 0.8968, Validation Accuracy: 0.8957, Loss: 0.1386
Epoch   7 Batch   67/269 - Train Accuracy: 0.8945, Validation Accuracy: 0.8950, Loss: 0.1442
Epoch   7 Batch   68/269 - Train Accuracy: 0.8852, Validation Accuracy: 0.8973, Loss: 0.1503
Epoch   7 Batch   69/269 - Train Accuracy: 0.8878, Validation Accuracy: 0.8930, Loss: 0.1564
Epoch   7 Batch   70/269 - Train Accuracy: 0.9058, Validation Accuracy: 0.8945, Loss: 0.1432
Epoch   7 Batch   71/269 - Train Accuracy: 0.9064, Validation Accuracy: 0.9039, Loss: 0.1439
Epoch   7 Batch   72/269 - Train Accuracy: 0.8959, Validation Accuracy: 0.9017, Loss: 0.1468
Epoch   7 Batch   73/269 - Train Accuracy: 0.8975, Validation Accuracy: 0.9062, Loss: 0.1409
Epoch   7 Batch   74/269 - Train Accuracy: 0.9078, Validation Accuracy: 0.8953, Loss: 0.1338
Epoch   7 Batch   75/269 - Train Accuracy: 0.9076, Validation Accuracy: 0.8925, Loss: 0.1374
Epoch   7 Batch   76/269 - Train Accuracy: 0.8838, Validation Accuracy: 0.8956, Loss: 0.1382
Epoch   7 Batch   77/269 - Train Accuracy: 0.8983, Validation Accuracy: 0.8976, Loss: 0.1316
Epoch   7 Batch   78/269 - Train Accuracy: 0.9107, Validation Accuracy: 0.8994, Loss: 0.1368
Epoch   7 Batch   79/269 - Train Accuracy: 0.8875, Validation Accuracy: 0.8985, Loss: 0.1328
Epoch   7 Batch   80/269 - Train Accuracy: 0.9060, Validation Accuracy: 0.8974, Loss: 0.1289
Epoch   7 Batch   81/269 - Train Accuracy: 0.8991, Validation Accuracy: 0.9031, Loss: 0.1521
Epoch   7 Batch   82/269 - Train Accuracy: 0.9142, Validation Accuracy: 0.9037, Loss: 0.1291
Epoch   7 Batch   83/269 - Train Accuracy: 0.8972, Validation Accuracy: 0.9058, Loss: 0.1415
Epoch   7 Batch   84/269 - Train Accuracy: 0.8992, Validation Accuracy: 0.9007, Loss: 0.1354
Epoch   7 Batch   85/269 - Train Accuracy: 0.8933, Validation Accuracy: 0.8986, Loss: 0.1322
Epoch   7 Batch   86/269 - Train Accuracy: 0.8958, Validation Accuracy: 0.9015, Loss: 0.1280
Epoch   7 Batch   87/269 - Train Accuracy: 0.8859, Validation Accuracy: 0.9011, Loss: 0.1417
Epoch   7 Batch   88/269 - Train Accuracy: 0.8829, Validation Accuracy: 0.9046, Loss: 0.1342
Epoch   7 Batch   89/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.9011, Loss: 0.1377
Epoch   7 Batch   90/269 - Train Accuracy: 0.9038, Validation Accuracy: 0.9036, Loss: 0.1375
Epoch   7 Batch   91/269 - Train Accuracy: 0.9027, Validation Accuracy: 0.9089, Loss: 0.1275
Epoch   7 Batch   92/269 - Train Accuracy: 0.9114, Validation Accuracy: 0.9118, Loss: 0.1284
Epoch   7 Batch   93/269 - Train Accuracy: 0.9094, Validation Accuracy: 0.9067, Loss: 0.1291
Epoch   7 Batch   94/269 - Train Accuracy: 0.8988, Validation Accuracy: 0.9033, Loss: 0.1464
Epoch   7 Batch   95/269 - Train Accuracy: 0.9148, Validation Accuracy: 0.9002, Loss: 0.1254
Epoch   7 Batch   96/269 - Train Accuracy: 0.8812, Validation Accuracy: 0.9052, Loss: 0.1384
Epoch   7 Batch   97/269 - Train Accuracy: 0.9025, Validation Accuracy: 0.9086, Loss: 0.1358
Epoch   7 Batch   98/269 - Train Accuracy: 0.9016, Validation Accuracy: 0.9094, Loss: 0.1359
Epoch   7 Batch   99/269 - Train Accuracy: 0.8921, Validation Accuracy: 0.9059, Loss: 0.1306
Epoch   7 Batch  100/269 - Train Accuracy: 0.9118, Validation Accuracy: 0.9104, Loss: 0.1253
Epoch   7 Batch  101/269 - Train Accuracy: 0.8938, Validation Accuracy: 0.9127, Loss: 0.1429
Epoch   7 Batch  102/269 - Train Accuracy: 0.9076, Validation Accuracy: 0.9085, Loss: 0.1243
Epoch   7 Batch  103/269 - Train Accuracy: 0.9033, Validation Accuracy: 0.9033, Loss: 0.1367
Epoch   7 Batch  104/269 - Train Accuracy: 0.9046, Validation Accuracy: 0.9099, Loss: 0.1277
Epoch   7 Batch  105/269 - Train Accuracy: 0.9026, Validation Accuracy: 0.9097, Loss: 0.1323
Epoch   7 Batch  106/269 - Train Accuracy: 0.9092, Validation Accuracy: 0.9078, Loss: 0.1210
Epoch   7 Batch  107/269 - Train Accuracy: 0.9135, Validation Accuracy: 0.9072, Loss: 0.1325
Epoch   7 Batch  108/269 - Train Accuracy: 0.9138, Validation Accuracy: 0.9096, Loss: 0.1252
Epoch   7 Batch  109/269 - Train Accuracy: 0.8895, Validation Accuracy: 0.9058, Loss: 0.1396
Epoch   7 Batch  110/269 - Train Accuracy: 0.8957, Validation Accuracy: 0.9110, Loss: 0.1265
Epoch   7 Batch  111/269 - Train Accuracy: 0.9015, Validation Accuracy: 0.9023, Loss: 0.1439
Epoch   7 Batch  112/269 - Train Accuracy: 0.9041, Validation Accuracy: 0.9021, Loss: 0.1368
Epoch   7 Batch  113/269 - Train Accuracy: 0.9044, Validation Accuracy: 0.9032, Loss: 0.1234
Epoch   7 Batch  114/269 - Train Accuracy: 0.9089, Validation Accuracy: 0.8971, Loss: 0.1325
Epoch   7 Batch  115/269 - Train Accuracy: 0.8830, Validation Accuracy: 0.8878, Loss: 0.1325
Epoch   7 Batch  116/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.8968, Loss: 0.1397
Epoch   7 Batch  117/269 - Train Accuracy: 0.9021, Validation Accuracy: 0.9024, Loss: 0.1294
Epoch   7 Batch  118/269 - Train Accuracy: 0.9217, Validation Accuracy: 0.9042, Loss: 0.1222
Epoch   7 Batch  119/269 - Train Accuracy: 0.8964, Validation Accuracy: 0.8976, Loss: 0.1381
Epoch   7 Batch  120/269 - Train Accuracy: 0.9004, Validation Accuracy: 0.9045, Loss: 0.1256
Epoch   7 Batch  121/269 - Train Accuracy: 0.9171, Validation Accuracy: 0.8993, Loss: 0.1221
Epoch   7 Batch  122/269 - Train Accuracy: 0.8969, Validation Accuracy: 0.9069, Loss: 0.1302
Epoch   7 Batch  123/269 - Train Accuracy: 0.9122, Validation Accuracy: 0.9073, Loss: 0.1311
Epoch   7 Batch  124/269 - Train Accuracy: 0.9024, Validation Accuracy: 0.9041, Loss: 0.1217
Epoch   7 Batch  125/269 - Train Accuracy: 0.9105, Validation Accuracy: 0.9082, Loss: 0.1211
Epoch   7 Batch  126/269 - Train Accuracy: 0.8839, Validation Accuracy: 0.8944, Loss: 0.1284
Epoch   7 Batch  127/269 - Train Accuracy: 0.9048, Validation Accuracy: 0.9118, Loss: 0.1277
Epoch   7 Batch  128/269 - Train Accuracy: 0.9148, Validation Accuracy: 0.9072, Loss: 0.1269
Epoch   7 Batch  129/269 - Train Accuracy: 0.8932, Validation Accuracy: 0.8996, Loss: 0.1300
Epoch   7 Batch  130/269 - Train Accuracy: 0.8896, Validation Accuracy: 0.9022, Loss: 0.1385
Epoch   7 Batch  131/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.9039, Loss: 0.1274
Epoch   7 Batch  132/269 - Train Accuracy: 0.8966, Validation Accuracy: 0.9031, Loss: 0.1345
Epoch   7 Batch  133/269 - Train Accuracy: 0.9134, Validation Accuracy: 0.9059, Loss: 0.1179
Epoch   7 Batch  134/269 - Train Accuracy: 0.9028, Validation Accuracy: 0.9069, Loss: 0.1257
Epoch   7 Batch  135/269 - Train Accuracy: 0.9110, Validation Accuracy: 0.9040, Loss: 0.1361
Epoch   7 Batch  136/269 - Train Accuracy: 0.8860, Validation Accuracy: 0.9094, Loss: 0.1464
Epoch   7 Batch  137/269 - Train Accuracy: 0.8905, Validation Accuracy: 0.9067, Loss: 0.1379
Epoch   7 Batch  138/269 - Train Accuracy: 0.9095, Validation Accuracy: 0.9070, Loss: 0.1211
Epoch   7 Batch  139/269 - Train Accuracy: 0.9006, Validation Accuracy: 0.9042, Loss: 0.1226
Epoch   7 Batch  140/269 - Train Accuracy: 0.9009, Validation Accuracy: 0.8965, Loss: 0.1342
Epoch   7 Batch  141/269 - Train Accuracy: 0.8992, Validation Accuracy: 0.9071, Loss: 0.1298
Epoch   7 Batch  142/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.9069, Loss: 0.1260
Epoch   7 Batch  143/269 - Train Accuracy: 0.9157, Validation Accuracy: 0.9101, Loss: 0.1184
Epoch   7 Batch  144/269 - Train Accuracy: 0.9083, Validation Accuracy: 0.9087, Loss: 0.1169
Epoch   7 Batch  145/269 - Train Accuracy: 0.9039, Validation Accuracy: 0.9096, Loss: 0.1158
Epoch   7 Batch  146/269 - Train Accuracy: 0.9046, Validation Accuracy: 0.9135, Loss: 0.1285
Epoch   7 Batch  147/269 - Train Accuracy: 0.8994, Validation Accuracy: 0.9122, Loss: 0.1256
Epoch   7 Batch  148/269 - Train Accuracy: 0.9168, Validation Accuracy: 0.9062, Loss: 0.1271
Epoch   7 Batch  149/269 - Train Accuracy: 0.8904, Validation Accuracy: 0.9110, Loss: 0.1374
Epoch   7 Batch  150/269 - Train Accuracy: 0.8947, Validation Accuracy: 0.9030, Loss: 0.1227
Epoch   7 Batch  151/269 - Train Accuracy: 0.9094, Validation Accuracy: 0.9085, Loss: 0.1243
Epoch   7 Batch  152/269 - Train Accuracy: 0.8984, Validation Accuracy: 0.9059, Loss: 0.1249
Epoch   7 Batch  153/269 - Train Accuracy: 0.8984, Validation Accuracy: 0.9064, Loss: 0.1225
Epoch   7 Batch  154/269 - Train Accuracy: 0.9216, Validation Accuracy: 0.9056, Loss: 0.1188
Epoch   7 Batch  155/269 - Train Accuracy: 0.9031, Validation Accuracy: 0.9090, Loss: 0.1231
Epoch   7 Batch  156/269 - Train Accuracy: 0.9020, Validation Accuracy: 0.9044, Loss: 0.1278
Epoch   7 Batch  157/269 - Train Accuracy: 0.8954, Validation Accuracy: 0.9084, Loss: 0.1192
Epoch   7 Batch  158/269 - Train Accuracy: 0.9086, Validation Accuracy: 0.9118, Loss: 0.1178
Epoch   7 Batch  159/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.9120, Loss: 0.1286
Epoch   7 Batch  160/269 - Train Accuracy: 0.9123, Validation Accuracy: 0.9103, Loss: 0.1243
Epoch   7 Batch  161/269 - Train Accuracy: 0.9123, Validation Accuracy: 0.9090, Loss: 0.1209
Epoch   7 Batch  162/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9086, Loss: 0.1186
Epoch   7 Batch  163/269 - Train Accuracy: 0.9112, Validation Accuracy: 0.9092, Loss: 0.1204
Epoch   7 Batch  164/269 - Train Accuracy: 0.9165, Validation Accuracy: 0.9101, Loss: 0.1249
Epoch   7 Batch  165/269 - Train Accuracy: 0.9022, Validation Accuracy: 0.9062, Loss: 0.1211
Epoch   7 Batch  166/269 - Train Accuracy: 0.9122, Validation Accuracy: 0.9042, Loss: 0.1193
Epoch   7 Batch  167/269 - Train Accuracy: 0.9039, Validation Accuracy: 0.9129, Loss: 0.1174
Epoch   7 Batch  168/269 - Train Accuracy: 0.9010, Validation Accuracy: 0.9110, Loss: 0.1283
Epoch   7 Batch  169/269 - Train Accuracy: 0.8964, Validation Accuracy: 0.9022, Loss: 0.1214
Epoch   7 Batch  170/269 - Train Accuracy: 0.8946, Validation Accuracy: 0.9074, Loss: 0.1132
Epoch   7 Batch  171/269 - Train Accuracy: 0.9269, Validation Accuracy: 0.9105, Loss: 0.1225
Epoch   7 Batch  172/269 - Train Accuracy: 0.8972, Validation Accuracy: 0.9113, Loss: 0.1280
Epoch   7 Batch  173/269 - Train Accuracy: 0.9206, Validation Accuracy: 0.9120, Loss: 0.1142
Epoch   7 Batch  174/269 - Train Accuracy: 0.9110, Validation Accuracy: 0.9063, Loss: 0.1207
Epoch   7 Batch  175/269 - Train Accuracy: 0.8947, Validation Accuracy: 0.9034, Loss: 0.1397
Epoch   7 Batch  176/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.9125, Loss: 0.1357
Epoch   7 Batch  177/269 - Train Accuracy: 0.9143, Validation Accuracy: 0.9125, Loss: 0.1145
Epoch   7 Batch  178/269 - Train Accuracy: 0.9170, Validation Accuracy: 0.9143, Loss: 0.1146
Epoch   7 Batch  179/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.9155, Loss: 0.1234
Epoch   7 Batch  180/269 - Train Accuracy: 0.9147, Validation Accuracy: 0.9097, Loss: 0.1157
Epoch   7 Batch  181/269 - Train Accuracy: 0.8974, Validation Accuracy: 0.9104, Loss: 0.1272
Epoch   7 Batch  182/269 - Train Accuracy: 0.9120, Validation Accuracy: 0.9132, Loss: 0.1129
Epoch   7 Batch  183/269 - Train Accuracy: 0.9273, Validation Accuracy: 0.9125, Loss: 0.1030
Epoch   7 Batch  184/269 - Train Accuracy: 0.9056, Validation Accuracy: 0.9055, Loss: 0.1233
Epoch   7 Batch  185/269 - Train Accuracy: 0.9257, Validation Accuracy: 0.9074, Loss: 0.1182
Epoch   7 Batch  186/269 - Train Accuracy: 0.9031, Validation Accuracy: 0.9106, Loss: 0.1148
Epoch   7 Batch  187/269 - Train Accuracy: 0.9107, Validation Accuracy: 0.9126, Loss: 0.1173
Epoch   7 Batch  188/269 - Train Accuracy: 0.9165, Validation Accuracy: 0.9103, Loss: 0.1138
Epoch   7 Batch  189/269 - Train Accuracy: 0.9113, Validation Accuracy: 0.9067, Loss: 0.1135
Epoch   7 Batch  190/269 - Train Accuracy: 0.9094, Validation Accuracy: 0.9146, Loss: 0.1152
Epoch   7 Batch  191/269 - Train Accuracy: 0.9040, Validation Accuracy: 0.9146, Loss: 0.1155
Epoch   7 Batch  192/269 - Train Accuracy: 0.9187, Validation Accuracy: 0.9120, Loss: 0.1220
Epoch   7 Batch  193/269 - Train Accuracy: 0.9110, Validation Accuracy: 0.8980, Loss: 0.1176
Epoch   7 Batch  194/269 - Train Accuracy: 0.9031, Validation Accuracy: 0.9087, Loss: 0.1258
Epoch   7 Batch  195/269 - Train Accuracy: 0.8994, Validation Accuracy: 0.9075, Loss: 0.1224
Epoch   7 Batch  196/269 - Train Accuracy: 0.8901, Validation Accuracy: 0.9044, Loss: 0.1199
Epoch   7 Batch  197/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.9070, Loss: 0.1278
Epoch   7 Batch  198/269 - Train Accuracy: 0.9122, Validation Accuracy: 0.9144, Loss: 0.1253
Epoch   7 Batch  199/269 - Train Accuracy: 0.9009, Validation Accuracy: 0.9187, Loss: 0.1244
Epoch   7 Batch  200/269 - Train Accuracy: 0.9069, Validation Accuracy: 0.9213, Loss: 0.1205
Epoch   7 Batch  201/269 - Train Accuracy: 0.9112, Validation Accuracy: 0.9210, Loss: 0.1197
Epoch   7 Batch  202/269 - Train Accuracy: 0.9075, Validation Accuracy: 0.9206, Loss: 0.1175
Epoch   7 Batch  203/269 - Train Accuracy: 0.9134, Validation Accuracy: 0.9153, Loss: 0.1239
Epoch   7 Batch  204/269 - Train Accuracy: 0.9021, Validation Accuracy: 0.9157, Loss: 0.1234
Epoch   7 Batch  205/269 - Train Accuracy: 0.9056, Validation Accuracy: 0.9144, Loss: 0.1153
Epoch   7 Batch  206/269 - Train Accuracy: 0.8948, Validation Accuracy: 0.9157, Loss: 0.1273
Epoch   7 Batch  207/269 - Train Accuracy: 0.8983, Validation Accuracy: 0.9133, Loss: 0.1131
Epoch   7 Batch  208/269 - Train Accuracy: 0.9079, Validation Accuracy: 0.9166, Loss: 0.1220
Epoch   7 Batch  209/269 - Train Accuracy: 0.9104, Validation Accuracy: 0.9173, Loss: 0.1105
Epoch   7 Batch  210/269 - Train Accuracy: 0.9230, Validation Accuracy: 0.9191, Loss: 0.1108
Epoch   7 Batch  211/269 - Train Accuracy: 0.9068, Validation Accuracy: 0.9187, Loss: 0.1216
Epoch   7 Batch  212/269 - Train Accuracy: 0.9146, Validation Accuracy: 0.9157, Loss: 0.1180
Epoch   7 Batch  213/269 - Train Accuracy: 0.8961, Validation Accuracy: 0.9163, Loss: 0.1145
Epoch   7 Batch  214/269 - Train Accuracy: 0.9040, Validation Accuracy: 0.9185, Loss: 0.1176
Epoch   7 Batch  215/269 - Train Accuracy: 0.9252, Validation Accuracy: 0.9149, Loss: 0.1077
Epoch   7 Batch  216/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.9172, Loss: 0.1323
Epoch   7 Batch  217/269 - Train Accuracy: 0.9039, Validation Accuracy: 0.9157, Loss: 0.1225
Epoch   7 Batch  218/269 - Train Accuracy: 0.9170, Validation Accuracy: 0.9162, Loss: 0.1150
Epoch   7 Batch  219/269 - Train Accuracy: 0.9105, Validation Accuracy: 0.9130, Loss: 0.1228
Epoch   7 Batch  220/269 - Train Accuracy: 0.9214, Validation Accuracy: 0.9072, Loss: 0.1056
Epoch   7 Batch  221/269 - Train Accuracy: 0.9073, Validation Accuracy: 0.9086, Loss: 0.1200
Epoch   7 Batch  222/269 - Train Accuracy: 0.9269, Validation Accuracy: 0.9122, Loss: 0.1082
Epoch   7 Batch  223/269 - Train Accuracy: 0.9130, Validation Accuracy: 0.9147, Loss: 0.1067
Epoch   7 Batch  224/269 - Train Accuracy: 0.9104, Validation Accuracy: 0.9165, Loss: 0.1245
Epoch   7 Batch  225/269 - Train Accuracy: 0.8923, Validation Accuracy: 0.9134, Loss: 0.1124
Epoch   7 Batch  226/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.9124, Loss: 0.1191
Epoch   7 Batch  227/269 - Train Accuracy: 0.9240, Validation Accuracy: 0.9180, Loss: 0.1154
Epoch   7 Batch  228/269 - Train Accuracy: 0.8998, Validation Accuracy: 0.9165, Loss: 0.1128
Epoch   7 Batch  229/269 - Train Accuracy: 0.9102, Validation Accuracy: 0.9179, Loss: 0.1153
Epoch   7 Batch  230/269 - Train Accuracy: 0.9132, Validation Accuracy: 0.9160, Loss: 0.1111
Epoch   7 Batch  231/269 - Train Accuracy: 0.9134, Validation Accuracy: 0.9200, Loss: 0.1177
Epoch   7 Batch  232/269 - Train Accuracy: 0.9059, Validation Accuracy: 0.9160, Loss: 0.1125
Epoch   7 Batch  233/269 - Train Accuracy: 0.9269, Validation Accuracy: 0.9198, Loss: 0.1188
Epoch   7 Batch  234/269 - Train Accuracy: 0.9153, Validation Accuracy: 0.9211, Loss: 0.1107
Epoch   7 Batch  235/269 - Train Accuracy: 0.9219, Validation Accuracy: 0.9225, Loss: 0.1032
Epoch   7 Batch  236/269 - Train Accuracy: 0.9041, Validation Accuracy: 0.9173, Loss: 0.1074
Epoch   7 Batch  237/269 - Train Accuracy: 0.9077, Validation Accuracy: 0.9208, Loss: 0.1095
Epoch   7 Batch  238/269 - Train Accuracy: 0.9160, Validation Accuracy: 0.9205, Loss: 0.1145
Epoch   7 Batch  239/269 - Train Accuracy: 0.9088, Validation Accuracy: 0.9182, Loss: 0.1110
Epoch   7 Batch  240/269 - Train Accuracy: 0.9183, Validation Accuracy: 0.9193, Loss: 0.1037
Epoch   7 Batch  241/269 - Train Accuracy: 0.8993, Validation Accuracy: 0.9180, Loss: 0.1254
Epoch   7 Batch  242/269 - Train Accuracy: 0.9347, Validation Accuracy: 0.9119, Loss: 0.1068
Epoch   7 Batch  243/269 - Train Accuracy: 0.9137, Validation Accuracy: 0.9154, Loss: 0.0994
Epoch   7 Batch  244/269 - Train Accuracy: 0.9006, Validation Accuracy: 0.9116, Loss: 0.1151
Epoch   7 Batch  245/269 - Train Accuracy: 0.8885, Validation Accuracy: 0.9140, Loss: 0.1157
Epoch   7 Batch  246/269 - Train Accuracy: 0.9071, Validation Accuracy: 0.9159, Loss: 0.1142
Epoch   7 Batch  247/269 - Train Accuracy: 0.9151, Validation Accuracy: 0.9110, Loss: 0.1120
Epoch   7 Batch  248/269 - Train Accuracy: 0.9132, Validation Accuracy: 0.9134, Loss: 0.1065
Epoch   7 Batch  249/269 - Train Accuracy: 0.9142, Validation Accuracy: 0.9137, Loss: 0.1044
Epoch   7 Batch  250/269 - Train Accuracy: 0.9249, Validation Accuracy: 0.9136, Loss: 0.1090
Epoch   7 Batch  251/269 - Train Accuracy: 0.9410, Validation Accuracy: 0.9128, Loss: 0.0996
Epoch   7 Batch  252/269 - Train Accuracy: 0.9176, Validation Accuracy: 0.9194, Loss: 0.1019
Epoch   7 Batch  253/269 - Train Accuracy: 0.8995, Validation Accuracy: 0.9175, Loss: 0.1149
Epoch   7 Batch  254/269 - Train Accuracy: 0.9164, Validation Accuracy: 0.9135, Loss: 0.1053
Epoch   7 Batch  255/269 - Train Accuracy: 0.9017, Validation Accuracy: 0.9142, Loss: 0.1104
Epoch   7 Batch  256/269 - Train Accuracy: 0.8967, Validation Accuracy: 0.9143, Loss: 0.1140
Epoch   7 Batch  257/269 - Train Accuracy: 0.8948, Validation Accuracy: 0.9139, Loss: 0.1186
Epoch   7 Batch  258/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.9169, Loss: 0.1174
Epoch   7 Batch  259/269 - Train Accuracy: 0.9137, Validation Accuracy: 0.9189, Loss: 0.1152
Epoch   7 Batch  260/269 - Train Accuracy: 0.9175, Validation Accuracy: 0.9196, Loss: 0.1157
Epoch   7 Batch  261/269 - Train Accuracy: 0.9048, Validation Accuracy: 0.9229, Loss: 0.1084
Epoch   7 Batch  262/269 - Train Accuracy: 0.9142, Validation Accuracy: 0.9212, Loss: 0.1135
Epoch   7 Batch  263/269 - Train Accuracy: 0.9075, Validation Accuracy: 0.9087, Loss: 0.1173
Epoch   7 Batch  264/269 - Train Accuracy: 0.8872, Validation Accuracy: 0.9114, Loss: 0.1131
Epoch   7 Batch  265/269 - Train Accuracy: 0.9165, Validation Accuracy: 0.9142, Loss: 0.1112
Epoch   7 Batch  266/269 - Train Accuracy: 0.9160, Validation Accuracy: 0.9183, Loss: 0.1033
Epoch   7 Batch  267/269 - Train Accuracy: 0.9128, Validation Accuracy: 0.9175, Loss: 0.1160
Epoch   8 Batch    1/269 - Train Accuracy: 0.9124, Validation Accuracy: 0.9131, Loss: 0.1079
Epoch   8 Batch    2/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.9067, Loss: 0.1145
Epoch   8 Batch    3/269 - Train Accuracy: 0.9272, Validation Accuracy: 0.9114, Loss: 0.1099
Epoch   8 Batch    4/269 - Train Accuracy: 0.9050, Validation Accuracy: 0.9194, Loss: 0.1129
Epoch   8 Batch    5/269 - Train Accuracy: 0.9130, Validation Accuracy: 0.9163, Loss: 0.1038
Epoch   8 Batch    6/269 - Train Accuracy: 0.9274, Validation Accuracy: 0.9197, Loss: 0.1026
Epoch   8 Batch    7/269 - Train Accuracy: 0.9163, Validation Accuracy: 0.9179, Loss: 0.1042
Epoch   8 Batch    8/269 - Train Accuracy: 0.9174, Validation Accuracy: 0.9145, Loss: 0.1166
Epoch   8 Batch    9/269 - Train Accuracy: 0.9061, Validation Accuracy: 0.9140, Loss: 0.1068
Epoch   8 Batch   10/269 - Train Accuracy: 0.9161, Validation Accuracy: 0.9173, Loss: 0.1027
Epoch   8 Batch   11/269 - Train Accuracy: 0.9215, Validation Accuracy: 0.9174, Loss: 0.1185
Epoch   8 Batch   12/269 - Train Accuracy: 0.9031, Validation Accuracy: 0.9160, Loss: 0.1209
Epoch   8 Batch   13/269 - Train Accuracy: 0.9151, Validation Accuracy: 0.9161, Loss: 0.1009
Epoch   8 Batch   14/269 - Train Accuracy: 0.9021, Validation Accuracy: 0.9163, Loss: 0.1052
Epoch   8 Batch   15/269 - Train Accuracy: 0.9159, Validation Accuracy: 0.9141, Loss: 0.0953
Epoch   8 Batch   16/269 - Train Accuracy: 0.9063, Validation Accuracy: 0.9167, Loss: 0.1127
Epoch   8 Batch   17/269 - Train Accuracy: 0.9147, Validation Accuracy: 0.9194, Loss: 0.1003
Epoch   8 Batch   18/269 - Train Accuracy: 0.9048, Validation Accuracy: 0.9134, Loss: 0.1082
Epoch   8 Batch   19/269 - Train Accuracy: 0.9220, Validation Accuracy: 0.9194, Loss: 0.0947
Epoch   8 Batch   20/269 - Train Accuracy: 0.9062, Validation Accuracy: 0.9173, Loss: 0.0993
Epoch   8 Batch   21/269 - Train Accuracy: 0.8923, Validation Accuracy: 0.9153, Loss: 0.1229
Epoch   8 Batch   22/269 - Train Accuracy: 0.9319, Validation Accuracy: 0.9135, Loss: 0.0994
Epoch   8 Batch   23/269 - Train Accuracy: 0.9060, Validation Accuracy: 0.9148, Loss: 0.1094
Epoch   8 Batch   24/269 - Train Accuracy: 0.9062, Validation Accuracy: 0.9126, Loss: 0.1077
Epoch   8 Batch   25/269 - Train Accuracy: 0.8946, Validation Accuracy: 0.9157, Loss: 0.1261
Epoch   8 Batch   26/269 - Train Accuracy: 0.9067, Validation Accuracy: 0.9129, Loss: 0.0999
Epoch   8 Batch   27/269 - Train Accuracy: 0.9076, Validation Accuracy: 0.9148, Loss: 0.1036
Epoch   8 Batch   28/269 - Train Accuracy: 0.8940, Validation Accuracy: 0.9152, Loss: 0.1194
Epoch   8 Batch   29/269 - Train Accuracy: 0.9129, Validation Accuracy: 0.9150, Loss: 0.1110
Epoch   8 Batch   30/269 - Train Accuracy: 0.9075, Validation Accuracy: 0.9164, Loss: 0.1086
Epoch   8 Batch   31/269 - Train Accuracy: 0.9316, Validation Accuracy: 0.9195, Loss: 0.1038
Epoch   8 Batch   32/269 - Train Accuracy: 0.9159, Validation Accuracy: 0.9206, Loss: 0.1096
Epoch   8 Batch   33/269 - Train Accuracy: 0.9175, Validation Accuracy: 0.9148, Loss: 0.1052
Epoch   8 Batch   34/269 - Train Accuracy: 0.9095, Validation Accuracy: 0.9115, Loss: 0.1048
Epoch   8 Batch   35/269 - Train Accuracy: 0.9191, Validation Accuracy: 0.9171, Loss: 0.1193
Epoch   8 Batch   36/269 - Train Accuracy: 0.9127, Validation Accuracy: 0.9173, Loss: 0.1033
Epoch   8 Batch   37/269 - Train Accuracy: 0.9088, Validation Accuracy: 0.9145, Loss: 0.1104
Epoch   8 Batch   38/269 - Train Accuracy: 0.9113, Validation Accuracy: 0.9122, Loss: 0.1074
Epoch   8 Batch   39/269 - Train Accuracy: 0.9079, Validation Accuracy: 0.9203, Loss: 0.1045
Epoch   8 Batch   40/269 - Train Accuracy: 0.9050, Validation Accuracy: 0.9171, Loss: 0.1095
Epoch   8 Batch   41/269 - Train Accuracy: 0.9054, Validation Accuracy: 0.9117, Loss: 0.1119
Epoch   8 Batch   42/269 - Train Accuracy: 0.9197, Validation Accuracy: 0.9082, Loss: 0.0953
Epoch   8 Batch   43/269 - Train Accuracy: 0.9154, Validation Accuracy: 0.9117, Loss: 0.1072
Epoch   8 Batch   44/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9139, Loss: 0.1074
Epoch   8 Batch   45/269 - Train Accuracy: 0.9043, Validation Accuracy: 0.9080, Loss: 0.1112
Epoch   8 Batch   46/269 - Train Accuracy: 0.9161, Validation Accuracy: 0.9091, Loss: 0.0997
Epoch   8 Batch   47/269 - Train Accuracy: 0.9160, Validation Accuracy: 0.9171, Loss: 0.0959
Epoch   8 Batch   48/269 - Train Accuracy: 0.9103, Validation Accuracy: 0.9165, Loss: 0.1030
Epoch   8 Batch   49/269 - Train Accuracy: 0.9153, Validation Accuracy: 0.9150, Loss: 0.1047
Epoch   8 Batch   50/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.9159, Loss: 0.1147
Epoch   8 Batch   51/269 - Train Accuracy: 0.9161, Validation Accuracy: 0.9205, Loss: 0.1028
Epoch   8 Batch   52/269 - Train Accuracy: 0.9072, Validation Accuracy: 0.9213, Loss: 0.0940
Epoch   8 Batch   53/269 - Train Accuracy: 0.9216, Validation Accuracy: 0.9162, Loss: 0.1113
Epoch   8 Batch   54/269 - Train Accuracy: 0.9277, Validation Accuracy: 0.9173, Loss: 0.1052
Epoch   8 Batch   55/269 - Train Accuracy: 0.9259, Validation Accuracy: 0.9161, Loss: 0.1040
Epoch   8 Batch   56/269 - Train Accuracy: 0.9098, Validation Accuracy: 0.9139, Loss: 0.1070
Epoch   8 Batch   57/269 - Train Accuracy: 0.9176, Validation Accuracy: 0.9157, Loss: 0.1081
Epoch   8 Batch   58/269 - Train Accuracy: 0.9155, Validation Accuracy: 0.9127, Loss: 0.1047
Epoch   8 Batch   59/269 - Train Accuracy: 0.9362, Validation Accuracy: 0.9211, Loss: 0.0938
Epoch   8 Batch   60/269 - Train Accuracy: 0.9252, Validation Accuracy: 0.9136, Loss: 0.0969
Epoch   8 Batch   61/269 - Train Accuracy: 0.9252, Validation Accuracy: 0.9206, Loss: 0.0987
Epoch   8 Batch   62/269 - Train Accuracy: 0.9062, Validation Accuracy: 0.9106, Loss: 0.1062
Epoch   8 Batch   63/269 - Train Accuracy: 0.9082, Validation Accuracy: 0.9191, Loss: 0.1162
Epoch   8 Batch   64/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9197, Loss: 0.1001
Epoch   8 Batch   65/269 - Train Accuracy: 0.9085, Validation Accuracy: 0.9243, Loss: 0.1061
Epoch   8 Batch   66/269 - Train Accuracy: 0.9137, Validation Accuracy: 0.9130, Loss: 0.1034
Epoch   8 Batch   67/269 - Train Accuracy: 0.9033, Validation Accuracy: 0.9108, Loss: 0.1156
Epoch   8 Batch   68/269 - Train Accuracy: 0.9024, Validation Accuracy: 0.9102, Loss: 0.1124
Epoch   8 Batch   69/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.9183, Loss: 0.1290
Epoch   8 Batch   70/269 - Train Accuracy: 0.9230, Validation Accuracy: 0.9177, Loss: 0.1096
Epoch   8 Batch   71/269 - Train Accuracy: 0.9003, Validation Accuracy: 0.9076, Loss: 0.1151
Epoch   8 Batch   72/269 - Train Accuracy: 0.9078, Validation Accuracy: 0.9072, Loss: 0.1129
Epoch   8 Batch   73/269 - Train Accuracy: 0.8991, Validation Accuracy: 0.9165, Loss: 0.1151
Epoch   8 Batch   74/269 - Train Accuracy: 0.9271, Validation Accuracy: 0.9149, Loss: 0.1009
Epoch   8 Batch   75/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9127, Loss: 0.1062
Epoch   8 Batch   76/269 - Train Accuracy: 0.8975, Validation Accuracy: 0.9094, Loss: 0.1040
Epoch   8 Batch   77/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9203, Loss: 0.0966
Epoch   8 Batch   78/269 - Train Accuracy: 0.9160, Validation Accuracy: 0.9215, Loss: 0.1067
Epoch   8 Batch   79/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.9180, Loss: 0.1005
Epoch   8 Batch   80/269 - Train Accuracy: 0.9115, Validation Accuracy: 0.9128, Loss: 0.1015
Epoch   8 Batch   81/269 - Train Accuracy: 0.9008, Validation Accuracy: 0.9157, Loss: 0.1117
Epoch   8 Batch   82/269 - Train Accuracy: 0.9209, Validation Accuracy: 0.9196, Loss: 0.0908
Epoch   8 Batch   83/269 - Train Accuracy: 0.9093, Validation Accuracy: 0.9201, Loss: 0.1129
Epoch   8 Batch   84/269 - Train Accuracy: 0.9111, Validation Accuracy: 0.9222, Loss: 0.1011
Epoch   8 Batch   85/269 - Train Accuracy: 0.9149, Validation Accuracy: 0.9188, Loss: 0.0978
Epoch   8 Batch   86/269 - Train Accuracy: 0.9029, Validation Accuracy: 0.9147, Loss: 0.0975
Epoch   8 Batch   87/269 - Train Accuracy: 0.9041, Validation Accuracy: 0.9180, Loss: 0.1104
Epoch   8 Batch   88/269 - Train Accuracy: 0.8889, Validation Accuracy: 0.9146, Loss: 0.1067
Epoch   8 Batch   89/269 - Train Accuracy: 0.9132, Validation Accuracy: 0.9158, Loss: 0.1010
Epoch   8 Batch   90/269 - Train Accuracy: 0.9227, Validation Accuracy: 0.9165, Loss: 0.1025
Epoch   8 Batch   91/269 - Train Accuracy: 0.9242, Validation Accuracy: 0.9213, Loss: 0.0951
Epoch   8 Batch   92/269 - Train Accuracy: 0.9286, Validation Accuracy: 0.9259, Loss: 0.0951
Epoch   8 Batch   93/269 - Train Accuracy: 0.9306, Validation Accuracy: 0.9230, Loss: 0.0961
Epoch   8 Batch   94/269 - Train Accuracy: 0.9216, Validation Accuracy: 0.9193, Loss: 0.1150
Epoch   8 Batch   95/269 - Train Accuracy: 0.9227, Validation Accuracy: 0.9193, Loss: 0.0936
Epoch   8 Batch   96/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.9187, Loss: 0.1025
Epoch   8 Batch   97/269 - Train Accuracy: 0.9060, Validation Accuracy: 0.9205, Loss: 0.1011
Epoch   8 Batch   98/269 - Train Accuracy: 0.9157, Validation Accuracy: 0.9227, Loss: 0.1003
Epoch   8 Batch   99/269 - Train Accuracy: 0.9079, Validation Accuracy: 0.9189, Loss: 0.0999
Epoch   8 Batch  100/269 - Train Accuracy: 0.9140, Validation Accuracy: 0.9135, Loss: 0.0971
Epoch   8 Batch  101/269 - Train Accuracy: 0.9042, Validation Accuracy: 0.9240, Loss: 0.1161
Epoch   8 Batch  102/269 - Train Accuracy: 0.9136, Validation Accuracy: 0.9252, Loss: 0.0985
Epoch   8 Batch  103/269 - Train Accuracy: 0.9172, Validation Accuracy: 0.9236, Loss: 0.1054
Epoch   8 Batch  104/269 - Train Accuracy: 0.9147, Validation Accuracy: 0.9192, Loss: 0.0950
Epoch   8 Batch  105/269 - Train Accuracy: 0.9088, Validation Accuracy: 0.9186, Loss: 0.0966
Epoch   8 Batch  106/269 - Train Accuracy: 0.9211, Validation Accuracy: 0.9187, Loss: 0.0916
Epoch   8 Batch  107/269 - Train Accuracy: 0.9169, Validation Accuracy: 0.9230, Loss: 0.0981
Epoch   8 Batch  108/269 - Train Accuracy: 0.9227, Validation Accuracy: 0.9199, Loss: 0.0974
Epoch   8 Batch  109/269 - Train Accuracy: 0.8922, Validation Accuracy: 0.9155, Loss: 0.1049
Epoch   8 Batch  110/269 - Train Accuracy: 0.9122, Validation Accuracy: 0.9211, Loss: 0.0935
Epoch   8 Batch  111/269 - Train Accuracy: 0.9227, Validation Accuracy: 0.9171, Loss: 0.1117
Epoch   8 Batch  112/269 - Train Accuracy: 0.9280, Validation Accuracy: 0.9193, Loss: 0.1006
Epoch   8 Batch  113/269 - Train Accuracy: 0.9126, Validation Accuracy: 0.9167, Loss: 0.0966
Epoch   8 Batch  114/269 - Train Accuracy: 0.9157, Validation Accuracy: 0.9118, Loss: 0.0988
Epoch   8 Batch  115/269 - Train Accuracy: 0.9180, Validation Accuracy: 0.9183, Loss: 0.0980
Epoch   8 Batch  116/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9150, Loss: 0.0999
Epoch   8 Batch  117/269 - Train Accuracy: 0.9126, Validation Accuracy: 0.9123, Loss: 0.0940
Epoch   8 Batch  118/269 - Train Accuracy: 0.9293, Validation Accuracy: 0.9098, Loss: 0.0894
Epoch   8 Batch  119/269 - Train Accuracy: 0.9100, Validation Accuracy: 0.9206, Loss: 0.1083
Epoch   8 Batch  120/269 - Train Accuracy: 0.9176, Validation Accuracy: 0.9157, Loss: 0.0968
Epoch   8 Batch  121/269 - Train Accuracy: 0.9262, Validation Accuracy: 0.9165, Loss: 0.0905
Epoch   8 Batch  122/269 - Train Accuracy: 0.9053, Validation Accuracy: 0.9196, Loss: 0.0963
Epoch   8 Batch  123/269 - Train Accuracy: 0.9224, Validation Accuracy: 0.9154, Loss: 0.1003
Epoch   8 Batch  124/269 - Train Accuracy: 0.9206, Validation Accuracy: 0.9167, Loss: 0.0930
Epoch   8 Batch  125/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9151, Loss: 0.0879
Epoch   8 Batch  126/269 - Train Accuracy: 0.9019, Validation Accuracy: 0.9125, Loss: 0.0964
Epoch   8 Batch  127/269 - Train Accuracy: 0.9087, Validation Accuracy: 0.9128, Loss: 0.0970
Epoch   8 Batch  128/269 - Train Accuracy: 0.9245, Validation Accuracy: 0.9222, Loss: 0.0997
Epoch   8 Batch  129/269 - Train Accuracy: 0.9127, Validation Accuracy: 0.9228, Loss: 0.0990
Epoch   8 Batch  130/269 - Train Accuracy: 0.9144, Validation Accuracy: 0.9242, Loss: 0.1005
Epoch   8 Batch  131/269 - Train Accuracy: 0.8994, Validation Accuracy: 0.9229, Loss: 0.0957
Epoch   8 Batch  132/269 - Train Accuracy: 0.9078, Validation Accuracy: 0.9159, Loss: 0.1020
Epoch   8 Batch  133/269 - Train Accuracy: 0.9240, Validation Accuracy: 0.9164, Loss: 0.0878
Epoch   8 Batch  134/269 - Train Accuracy: 0.9154, Validation Accuracy: 0.9221, Loss: 0.0967
Epoch   8 Batch  135/269 - Train Accuracy: 0.9151, Validation Accuracy: 0.9218, Loss: 0.0985
Epoch   8 Batch  136/269 - Train Accuracy: 0.9032, Validation Accuracy: 0.9242, Loss: 0.1058
Epoch   8 Batch  137/269 - Train Accuracy: 0.9047, Validation Accuracy: 0.9177, Loss: 0.1049
Epoch   8 Batch  138/269 - Train Accuracy: 0.9177, Validation Accuracy: 0.9196, Loss: 0.0956
Epoch   8 Batch  139/269 - Train Accuracy: 0.9130, Validation Accuracy: 0.9214, Loss: 0.0931
Epoch   8 Batch  140/269 - Train Accuracy: 0.9111, Validation Accuracy: 0.9170, Loss: 0.1015
Epoch   8 Batch  141/269 - Train Accuracy: 0.9032, Validation Accuracy: 0.9178, Loss: 0.0999
Epoch   8 Batch  142/269 - Train Accuracy: 0.9077, Validation Accuracy: 0.9230, Loss: 0.0937
Epoch   8 Batch  143/269 - Train Accuracy: 0.9211, Validation Accuracy: 0.9197, Loss: 0.0885
Epoch   8 Batch  144/269 - Train Accuracy: 0.9289, Validation Accuracy: 0.9189, Loss: 0.0836
Epoch   8 Batch  145/269 - Train Accuracy: 0.9145, Validation Accuracy: 0.9229, Loss: 0.0923
Epoch   8 Batch  146/269 - Train Accuracy: 0.9219, Validation Accuracy: 0.9173, Loss: 0.0959
Epoch   8 Batch  147/269 - Train Accuracy: 0.9107, Validation Accuracy: 0.9149, Loss: 0.0986
Epoch   8 Batch  148/269 - Train Accuracy: 0.9249, Validation Accuracy: 0.9191, Loss: 0.0980
Epoch   8 Batch  149/269 - Train Accuracy: 0.9075, Validation Accuracy: 0.9168, Loss: 0.1048
Epoch   8 Batch  150/269 - Train Accuracy: 0.9063, Validation Accuracy: 0.9203, Loss: 0.0960
Epoch   8 Batch  151/269 - Train Accuracy: 0.9110, Validation Accuracy: 0.9160, Loss: 0.0918
Epoch   8 Batch  152/269 - Train Accuracy: 0.9154, Validation Accuracy: 0.9150, Loss: 0.0964
Epoch   8 Batch  153/269 - Train Accuracy: 0.9301, Validation Accuracy: 0.9193, Loss: 0.0902
Epoch   8 Batch  154/269 - Train Accuracy: 0.9313, Validation Accuracy: 0.9237, Loss: 0.0881
Epoch   8 Batch  155/269 - Train Accuracy: 0.9121, Validation Accuracy: 0.9237, Loss: 0.0937
Epoch   8 Batch  156/269 - Train Accuracy: 0.9098, Validation Accuracy: 0.9228, Loss: 0.1003
Epoch   8 Batch  157/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.9210, Loss: 0.0896
Epoch   8 Batch  158/269 - Train Accuracy: 0.9247, Validation Accuracy: 0.9228, Loss: 0.0913
Epoch   8 Batch  159/269 - Train Accuracy: 0.9087, Validation Accuracy: 0.9197, Loss: 0.0972
Epoch   8 Batch  160/269 - Train Accuracy: 0.9146, Validation Accuracy: 0.9188, Loss: 0.0961
Epoch   8 Batch  161/269 - Train Accuracy: 0.9134, Validation Accuracy: 0.9163, Loss: 0.0922
Epoch   8 Batch  162/269 - Train Accuracy: 0.9262, Validation Accuracy: 0.9228, Loss: 0.0946
Epoch   8 Batch  163/269 - Train Accuracy: 0.9197, Validation Accuracy: 0.9187, Loss: 0.0938
Epoch   8 Batch  164/269 - Train Accuracy: 0.9238, Validation Accuracy: 0.9185, Loss: 0.0962
Epoch   8 Batch  165/269 - Train Accuracy: 0.9184, Validation Accuracy: 0.9199, Loss: 0.0931
Epoch   8 Batch  166/269 - Train Accuracy: 0.9205, Validation Accuracy: 0.9145, Loss: 0.0956
Epoch   8 Batch  167/269 - Train Accuracy: 0.9174, Validation Accuracy: 0.9190, Loss: 0.0971
Epoch   8 Batch  168/269 - Train Accuracy: 0.9173, Validation Accuracy: 0.9184, Loss: 0.0952
Epoch   8 Batch  169/269 - Train Accuracy: 0.9164, Validation Accuracy: 0.9189, Loss: 0.0977
Epoch   8 Batch  170/269 - Train Accuracy: 0.9106, Validation Accuracy: 0.9216, Loss: 0.0904
Epoch   8 Batch  171/269 - Train Accuracy: 0.9226, Validation Accuracy: 0.9160, Loss: 0.0952
Epoch   8 Batch  172/269 - Train Accuracy: 0.9086, Validation Accuracy: 0.9211, Loss: 0.1052
Epoch   8 Batch  173/269 - Train Accuracy: 0.9267, Validation Accuracy: 0.9247, Loss: 0.0902
Epoch   8 Batch  174/269 - Train Accuracy: 0.9283, Validation Accuracy: 0.9202, Loss: 0.0943
Epoch   8 Batch  175/269 - Train Accuracy: 0.9066, Validation Accuracy: 0.9183, Loss: 0.1085
Epoch   8 Batch  176/269 - Train Accuracy: 0.9061, Validation Accuracy: 0.9220, Loss: 0.1066
Epoch   8 Batch  177/269 - Train Accuracy: 0.9246, Validation Accuracy: 0.9252, Loss: 0.0897
Epoch   8 Batch  178/269 - Train Accuracy: 0.9295, Validation Accuracy: 0.9189, Loss: 0.0841
Epoch   8 Batch  179/269 - Train Accuracy: 0.9035, Validation Accuracy: 0.9175, Loss: 0.0975
Epoch   8 Batch  180/269 - Train Accuracy: 0.9249, Validation Accuracy: 0.9210, Loss: 0.0941
Epoch   8 Batch  181/269 - Train Accuracy: 0.9129, Validation Accuracy: 0.9225, Loss: 0.1033
Epoch   8 Batch  182/269 - Train Accuracy: 0.9153, Validation Accuracy: 0.9239, Loss: 0.0933
Epoch   8 Batch  183/269 - Train Accuracy: 0.9316, Validation Accuracy: 0.9188, Loss: 0.0788
Epoch   8 Batch  184/269 - Train Accuracy: 0.9111, Validation Accuracy: 0.9243, Loss: 0.0992
Epoch   8 Batch  185/269 - Train Accuracy: 0.9296, Validation Accuracy: 0.9224, Loss: 0.0877
Epoch   8 Batch  186/269 - Train Accuracy: 0.9073, Validation Accuracy: 0.9193, Loss: 0.0878
Epoch   8 Batch  187/269 - Train Accuracy: 0.9147, Validation Accuracy: 0.9244, Loss: 0.0918
Epoch   8 Batch  188/269 - Train Accuracy: 0.9242, Validation Accuracy: 0.9247, Loss: 0.0906
Epoch   8 Batch  189/269 - Train Accuracy: 0.9188, Validation Accuracy: 0.9229, Loss: 0.0877
Epoch   8 Batch  190/269 - Train Accuracy: 0.9222, Validation Accuracy: 0.9229, Loss: 0.0876
Epoch   8 Batch  191/269 - Train Accuracy: 0.9126, Validation Accuracy: 0.9188, Loss: 0.0903
Epoch   8 Batch  192/269 - Train Accuracy: 0.9227, Validation Accuracy: 0.9142, Loss: 0.0928
Epoch   8 Batch  193/269 - Train Accuracy: 0.9277, Validation Accuracy: 0.9128, Loss: 0.0960
Epoch   8 Batch  194/269 - Train Accuracy: 0.9095, Validation Accuracy: 0.9183, Loss: 0.0965
Epoch   8 Batch  195/269 - Train Accuracy: 0.9103, Validation Accuracy: 0.9214, Loss: 0.0933
Epoch   8 Batch  196/269 - Train Accuracy: 0.9139, Validation Accuracy: 0.9244, Loss: 0.0921
Epoch   8 Batch  197/269 - Train Accuracy: 0.9142, Validation Accuracy: 0.9269, Loss: 0.0946
Epoch   8 Batch  198/269 - Train Accuracy: 0.9160, Validation Accuracy: 0.9256, Loss: 0.1010
Epoch   8 Batch  199/269 - Train Accuracy: 0.9211, Validation Accuracy: 0.9299, Loss: 0.0982
Epoch   8 Batch  200/269 - Train Accuracy: 0.9100, Validation Accuracy: 0.9268, Loss: 0.0928
Epoch   8 Batch  201/269 - Train Accuracy: 0.9209, Validation Accuracy: 0.9255, Loss: 0.0964
Epoch   8 Batch  202/269 - Train Accuracy: 0.9103, Validation Accuracy: 0.9205, Loss: 0.0903
Epoch   8 Batch  203/269 - Train Accuracy: 0.9163, Validation Accuracy: 0.9274, Loss: 0.1042
Epoch   8 Batch  204/269 - Train Accuracy: 0.9188, Validation Accuracy: 0.9260, Loss: 0.0981
Epoch   8 Batch  205/269 - Train Accuracy: 0.9169, Validation Accuracy: 0.9255, Loss: 0.0934
Epoch   8 Batch  206/269 - Train Accuracy: 0.9063, Validation Accuracy: 0.9247, Loss: 0.0974
Epoch   8 Batch  207/269 - Train Accuracy: 0.9118, Validation Accuracy: 0.9244, Loss: 0.0924
Epoch   8 Batch  208/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9253, Loss: 0.0937
Epoch   8 Batch  209/269 - Train Accuracy: 0.9335, Validation Accuracy: 0.9256, Loss: 0.0875
Epoch   8 Batch  210/269 - Train Accuracy: 0.9227, Validation Accuracy: 0.9201, Loss: 0.0837
Epoch   8 Batch  211/269 - Train Accuracy: 0.9212, Validation Accuracy: 0.9196, Loss: 0.0980
Epoch   8 Batch  212/269 - Train Accuracy: 0.9244, Validation Accuracy: 0.9278, Loss: 0.0973
Epoch   8 Batch  213/269 - Train Accuracy: 0.9011, Validation Accuracy: 0.9191, Loss: 0.0889
Epoch   8 Batch  214/269 - Train Accuracy: 0.9114, Validation Accuracy: 0.9170, Loss: 0.0932
Epoch   8 Batch  215/269 - Train Accuracy: 0.9298, Validation Accuracy: 0.9276, Loss: 0.0852
Epoch   8 Batch  216/269 - Train Accuracy: 0.9032, Validation Accuracy: 0.9217, Loss: 0.1065
Epoch   8 Batch  217/269 - Train Accuracy: 0.9013, Validation Accuracy: 0.9246, Loss: 0.0939
Epoch   8 Batch  218/269 - Train Accuracy: 0.9310, Validation Accuracy: 0.9264, Loss: 0.0901
Epoch   8 Batch  219/269 - Train Accuracy: 0.9146, Validation Accuracy: 0.9275, Loss: 0.0930
Epoch   8 Batch  220/269 - Train Accuracy: 0.9151, Validation Accuracy: 0.9248, Loss: 0.0889
Epoch   8 Batch  221/269 - Train Accuracy: 0.9168, Validation Accuracy: 0.9221, Loss: 0.0930
Epoch   8 Batch  222/269 - Train Accuracy: 0.9345, Validation Accuracy: 0.9167, Loss: 0.0842
Epoch   8 Batch  223/269 - Train Accuracy: 0.9175, Validation Accuracy: 0.9255, Loss: 0.0876
Epoch   8 Batch  224/269 - Train Accuracy: 0.9269, Validation Accuracy: 0.9245, Loss: 0.1015
Epoch   8 Batch  225/269 - Train Accuracy: 0.9079, Validation Accuracy: 0.9229, Loss: 0.0828
Epoch   8 Batch  226/269 - Train Accuracy: 0.9249, Validation Accuracy: 0.9232, Loss: 0.0944
Epoch   8 Batch  227/269 - Train Accuracy: 0.9316, Validation Accuracy: 0.9255, Loss: 0.0954
Epoch   8 Batch  228/269 - Train Accuracy: 0.9169, Validation Accuracy: 0.9208, Loss: 0.0880
Epoch   8 Batch  229/269 - Train Accuracy: 0.9181, Validation Accuracy: 0.9221, Loss: 0.0910
Epoch   8 Batch  230/269 - Train Accuracy: 0.9287, Validation Accuracy: 0.9213, Loss: 0.0850
Epoch   8 Batch  231/269 - Train Accuracy: 0.9151, Validation Accuracy: 0.9276, Loss: 0.0931
Epoch   8 Batch  232/269 - Train Accuracy: 0.9135, Validation Accuracy: 0.9266, Loss: 0.0874
Epoch   8 Batch  233/269 - Train Accuracy: 0.9338, Validation Accuracy: 0.9235, Loss: 0.0940
Epoch   8 Batch  234/269 - Train Accuracy: 0.9262, Validation Accuracy: 0.9271, Loss: 0.0894
Epoch   8 Batch  235/269 - Train Accuracy: 0.9429, Validation Accuracy: 0.9246, Loss: 0.0806
Epoch   8 Batch  236/269 - Train Accuracy: 0.9050, Validation Accuracy: 0.9198, Loss: 0.0882
Epoch   8 Batch  237/269 - Train Accuracy: 0.9125, Validation Accuracy: 0.9159, Loss: 0.0858
Epoch   8 Batch  238/269 - Train Accuracy: 0.9209, Validation Accuracy: 0.9184, Loss: 0.0883
Epoch   8 Batch  239/269 - Train Accuracy: 0.9296, Validation Accuracy: 0.9211, Loss: 0.0877
Epoch   8 Batch  240/269 - Train Accuracy: 0.9277, Validation Accuracy: 0.9244, Loss: 0.0842
Epoch   8 Batch  241/269 - Train Accuracy: 0.9081, Validation Accuracy: 0.9281, Loss: 0.1014
Epoch   8 Batch  242/269 - Train Accuracy: 0.9402, Validation Accuracy: 0.9284, Loss: 0.0837
Epoch   8 Batch  243/269 - Train Accuracy: 0.9178, Validation Accuracy: 0.9289, Loss: 0.0812
Epoch   8 Batch  244/269 - Train Accuracy: 0.9209, Validation Accuracy: 0.9273, Loss: 0.0915
Epoch   8 Batch  245/269 - Train Accuracy: 0.9110, Validation Accuracy: 0.9268, Loss: 0.0894
Epoch   8 Batch  246/269 - Train Accuracy: 0.9214, Validation Accuracy: 0.9290, Loss: 0.0923
Epoch   8 Batch  247/269 - Train Accuracy: 0.9245, Validation Accuracy: 0.9243, Loss: 0.0868
Epoch   8 Batch  248/269 - Train Accuracy: 0.9362, Validation Accuracy: 0.9247, Loss: 0.0850
Epoch   8 Batch  249/269 - Train Accuracy: 0.9287, Validation Accuracy: 0.9287, Loss: 0.0807
Epoch   8 Batch  250/269 - Train Accuracy: 0.9336, Validation Accuracy: 0.9311, Loss: 0.0870
Epoch   8 Batch  251/269 - Train Accuracy: 0.9518, Validation Accuracy: 0.9191, Loss: 0.0818
Epoch   8 Batch  252/269 - Train Accuracy: 0.9246, Validation Accuracy: 0.9291, Loss: 0.0784
Epoch   8 Batch  253/269 - Train Accuracy: 0.9121, Validation Accuracy: 0.9286, Loss: 0.0912
Epoch   8 Batch  254/269 - Train Accuracy: 0.9184, Validation Accuracy: 0.9302, Loss: 0.0841
Epoch   8 Batch  255/269 - Train Accuracy: 0.9126, Validation Accuracy: 0.9295, Loss: 0.0874
Epoch   8 Batch  256/269 - Train Accuracy: 0.9074, Validation Accuracy: 0.9299, Loss: 0.0862
Epoch   8 Batch  257/269 - Train Accuracy: 0.9039, Validation Accuracy: 0.9260, Loss: 0.0940
Epoch   8 Batch  258/269 - Train Accuracy: 0.9284, Validation Accuracy: 0.9213, Loss: 0.0893
Epoch   8 Batch  259/269 - Train Accuracy: 0.9177, Validation Accuracy: 0.9260, Loss: 0.0930
Epoch   8 Batch  260/269 - Train Accuracy: 0.9171, Validation Accuracy: 0.9249, Loss: 0.0953
Epoch   8 Batch  261/269 - Train Accuracy: 0.9227, Validation Accuracy: 0.9237, Loss: 0.0852
Epoch   8 Batch  262/269 - Train Accuracy: 0.9214, Validation Accuracy: 0.9261, Loss: 0.0858
Epoch   8 Batch  263/269 - Train Accuracy: 0.9175, Validation Accuracy: 0.9194, Loss: 0.0879
Epoch   8 Batch  264/269 - Train Accuracy: 0.8918, Validation Accuracy: 0.9157, Loss: 0.0925
Epoch   8 Batch  265/269 - Train Accuracy: 0.9243, Validation Accuracy: 0.9197, Loss: 0.0892
Epoch   8 Batch  266/269 - Train Accuracy: 0.9299, Validation Accuracy: 0.9265, Loss: 0.0803
Epoch   8 Batch  267/269 - Train Accuracy: 0.9233, Validation Accuracy: 0.9265, Loss: 0.0899
Epoch   9 Batch    1/269 - Train Accuracy: 0.9231, Validation Accuracy: 0.9276, Loss: 0.0872
Epoch   9 Batch    2/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9234, Loss: 0.0888
Epoch   9 Batch    3/269 - Train Accuracy: 0.9316, Validation Accuracy: 0.9251, Loss: 0.0887
Epoch   9 Batch    4/269 - Train Accuracy: 0.9205, Validation Accuracy: 0.9256, Loss: 0.0881
Epoch   9 Batch    5/269 - Train Accuracy: 0.9228, Validation Accuracy: 0.9261, Loss: 0.0838
Epoch   9 Batch    6/269 - Train Accuracy: 0.9341, Validation Accuracy: 0.9262, Loss: 0.0799
Epoch   9 Batch    7/269 - Train Accuracy: 0.9302, Validation Accuracy: 0.9277, Loss: 0.0811
Epoch   9 Batch    8/269 - Train Accuracy: 0.9288, Validation Accuracy: 0.9237, Loss: 0.0908
Epoch   9 Batch    9/269 - Train Accuracy: 0.9281, Validation Accuracy: 0.9237, Loss: 0.0852
Epoch   9 Batch   10/269 - Train Accuracy: 0.9344, Validation Accuracy: 0.9205, Loss: 0.0823
Epoch   9 Batch   11/269 - Train Accuracy: 0.9307, Validation Accuracy: 0.9216, Loss: 0.0917
Epoch   9 Batch   12/269 - Train Accuracy: 0.9148, Validation Accuracy: 0.9207, Loss: 0.0963
Epoch   9 Batch   13/269 - Train Accuracy: 0.9229, Validation Accuracy: 0.9229, Loss: 0.0761
Epoch   9 Batch   14/269 - Train Accuracy: 0.9136, Validation Accuracy: 0.9215, Loss: 0.0851
Epoch   9 Batch   15/269 - Train Accuracy: 0.9279, Validation Accuracy: 0.9218, Loss: 0.0773
Epoch   9 Batch   16/269 - Train Accuracy: 0.9136, Validation Accuracy: 0.9229, Loss: 0.0906
Epoch   9 Batch   17/269 - Train Accuracy: 0.9222, Validation Accuracy: 0.9217, Loss: 0.0790
Epoch   9 Batch   18/269 - Train Accuracy: 0.9099, Validation Accuracy: 0.9279, Loss: 0.0846
Epoch   9 Batch   19/269 - Train Accuracy: 0.9309, Validation Accuracy: 0.9300, Loss: 0.0711
Epoch   9 Batch   20/269 - Train Accuracy: 0.9194, Validation Accuracy: 0.9248, Loss: 0.0787
Epoch   9 Batch   21/269 - Train Accuracy: 0.9040, Validation Accuracy: 0.9260, Loss: 0.0960
Epoch   9 Batch   22/269 - Train Accuracy: 0.9377, Validation Accuracy: 0.9268, Loss: 0.0772
Epoch   9 Batch   23/269 - Train Accuracy: 0.9170, Validation Accuracy: 0.9229, Loss: 0.0891
Epoch   9 Batch   24/269 - Train Accuracy: 0.9279, Validation Accuracy: 0.9258, Loss: 0.0858
Epoch   9 Batch   25/269 - Train Accuracy: 0.9117, Validation Accuracy: 0.9239, Loss: 0.0941
Epoch   9 Batch   26/269 - Train Accuracy: 0.9142, Validation Accuracy: 0.9234, Loss: 0.0786
Epoch   9 Batch   27/269 - Train Accuracy: 0.9163, Validation Accuracy: 0.9247, Loss: 0.0798
Epoch   9 Batch   28/269 - Train Accuracy: 0.8986, Validation Accuracy: 0.9235, Loss: 0.0904
Epoch   9 Batch   29/269 - Train Accuracy: 0.9159, Validation Accuracy: 0.9233, Loss: 0.0897
Epoch   9 Batch   30/269 - Train Accuracy: 0.9209, Validation Accuracy: 0.9263, Loss: 0.0814
Epoch   9 Batch   31/269 - Train Accuracy: 0.9361, Validation Accuracy: 0.9238, Loss: 0.0811
Epoch   9 Batch   32/269 - Train Accuracy: 0.9394, Validation Accuracy: 0.9229, Loss: 0.0783
Epoch   9 Batch   33/269 - Train Accuracy: 0.9196, Validation Accuracy: 0.9268, Loss: 0.0760
Epoch   9 Batch   34/269 - Train Accuracy: 0.9211, Validation Accuracy: 0.9232, Loss: 0.0809
Epoch   9 Batch   35/269 - Train Accuracy: 0.9299, Validation Accuracy: 0.9292, Loss: 0.0937
Epoch   9 Batch   36/269 - Train Accuracy: 0.9240, Validation Accuracy: 0.9299, Loss: 0.0817
Epoch   9 Batch   37/269 - Train Accuracy: 0.9214, Validation Accuracy: 0.9277, Loss: 0.0861
Epoch   9 Batch   38/269 - Train Accuracy: 0.9188, Validation Accuracy: 0.9300, Loss: 0.0816
Epoch   9 Batch   39/269 - Train Accuracy: 0.9125, Validation Accuracy: 0.9244, Loss: 0.0829
Epoch   9 Batch   40/269 - Train Accuracy: 0.9133, Validation Accuracy: 0.9215, Loss: 0.0925
Epoch   9 Batch   41/269 - Train Accuracy: 0.9191, Validation Accuracy: 0.9226, Loss: 0.0895
Epoch   9 Batch   42/269 - Train Accuracy: 0.9378, Validation Accuracy: 0.9241, Loss: 0.0736
Epoch   9 Batch   43/269 - Train Accuracy: 0.9274, Validation Accuracy: 0.9225, Loss: 0.0861
Epoch   9 Batch   44/269 - Train Accuracy: 0.9319, Validation Accuracy: 0.9246, Loss: 0.0829
Epoch   9 Batch   45/269 - Train Accuracy: 0.9161, Validation Accuracy: 0.9231, Loss: 0.0853
Epoch   9 Batch   46/269 - Train Accuracy: 0.9230, Validation Accuracy: 0.9240, Loss: 0.0750
Epoch   9 Batch   47/269 - Train Accuracy: 0.9351, Validation Accuracy: 0.9240, Loss: 0.0742
Epoch   9 Batch   48/269 - Train Accuracy: 0.9249, Validation Accuracy: 0.9260, Loss: 0.0809
Epoch   9 Batch   49/269 - Train Accuracy: 0.9216, Validation Accuracy: 0.9245, Loss: 0.0793
Epoch   9 Batch   50/269 - Train Accuracy: 0.9048, Validation Accuracy: 0.9268, Loss: 0.0876
Epoch   9 Batch   51/269 - Train Accuracy: 0.9232, Validation Accuracy: 0.9286, Loss: 0.0813
Epoch   9 Batch   52/269 - Train Accuracy: 0.9189, Validation Accuracy: 0.9328, Loss: 0.0752
Epoch   9 Batch   53/269 - Train Accuracy: 0.9276, Validation Accuracy: 0.9281, Loss: 0.0893
Epoch   9 Batch   54/269 - Train Accuracy: 0.9444, Validation Accuracy: 0.9284, Loss: 0.0781
Epoch   9 Batch   55/269 - Train Accuracy: 0.9286, Validation Accuracy: 0.9284, Loss: 0.0811
Epoch   9 Batch   56/269 - Train Accuracy: 0.9162, Validation Accuracy: 0.9285, Loss: 0.0887
Epoch   9 Batch   57/269 - Train Accuracy: 0.9271, Validation Accuracy: 0.9283, Loss: 0.0873
Epoch   9 Batch   58/269 - Train Accuracy: 0.9220, Validation Accuracy: 0.9299, Loss: 0.0899
Epoch   9 Batch   59/269 - Train Accuracy: 0.9496, Validation Accuracy: 0.9332, Loss: 0.0683
Epoch   9 Batch   60/269 - Train Accuracy: 0.9260, Validation Accuracy: 0.9326, Loss: 0.0775
Epoch   9 Batch   61/269 - Train Accuracy: 0.9384, Validation Accuracy: 0.9360, Loss: 0.0753
Epoch   9 Batch   62/269 - Train Accuracy: 0.9163, Validation Accuracy: 0.9280, Loss: 0.0852
Epoch   9 Batch   63/269 - Train Accuracy: 0.9160, Validation Accuracy: 0.9287, Loss: 0.0898
Epoch   9 Batch   64/269 - Train Accuracy: 0.9211, Validation Accuracy: 0.9259, Loss: 0.0810
Epoch   9 Batch   65/269 - Train Accuracy: 0.9201, Validation Accuracy: 0.9275, Loss: 0.0777
Epoch   9 Batch   66/269 - Train Accuracy: 0.9197, Validation Accuracy: 0.9334, Loss: 0.0830
Epoch   9 Batch   67/269 - Train Accuracy: 0.9208, Validation Accuracy: 0.9265, Loss: 0.0897
Epoch   9 Batch   68/269 - Train Accuracy: 0.9090, Validation Accuracy: 0.9245, Loss: 0.0919
Epoch   9 Batch   69/269 - Train Accuracy: 0.9183, Validation Accuracy: 0.9267, Loss: 0.1029
Epoch   9 Batch   70/269 - Train Accuracy: 0.9337, Validation Accuracy: 0.9272, Loss: 0.0903
Epoch   9 Batch   71/269 - Train Accuracy: 0.9107, Validation Accuracy: 0.9198, Loss: 0.0903
Epoch   9 Batch   72/269 - Train Accuracy: 0.9120, Validation Accuracy: 0.9166, Loss: 0.0870
Epoch   9 Batch   73/269 - Train Accuracy: 0.9021, Validation Accuracy: 0.9280, Loss: 0.0933
Epoch   9 Batch   74/269 - Train Accuracy: 0.9336, Validation Accuracy: 0.9258, Loss: 0.0788
Epoch   9 Batch   75/269 - Train Accuracy: 0.9260, Validation Accuracy: 0.9277, Loss: 0.0923
Epoch   9 Batch   76/269 - Train Accuracy: 0.9061, Validation Accuracy: 0.9190, Loss: 0.0801
Epoch   9 Batch   77/269 - Train Accuracy: 0.9214, Validation Accuracy: 0.9219, Loss: 0.0818
Epoch   9 Batch   78/269 - Train Accuracy: 0.9249, Validation Accuracy: 0.9277, Loss: 0.0852
Epoch   9 Batch   79/269 - Train Accuracy: 0.9157, Validation Accuracy: 0.9264, Loss: 0.0846
Epoch   9 Batch   80/269 - Train Accuracy: 0.9269, Validation Accuracy: 0.9266, Loss: 0.0814
Epoch   9 Batch   81/269 - Train Accuracy: 0.9060, Validation Accuracy: 0.9198, Loss: 0.0949
Epoch   9 Batch   82/269 - Train Accuracy: 0.9379, Validation Accuracy: 0.9198, Loss: 0.0750
Epoch   9 Batch   83/269 - Train Accuracy: 0.9123, Validation Accuracy: 0.9286, Loss: 0.0909
Epoch   9 Batch   84/269 - Train Accuracy: 0.9251, Validation Accuracy: 0.9299, Loss: 0.0835
Epoch   9 Batch   85/269 - Train Accuracy: 0.9183, Validation Accuracy: 0.9260, Loss: 0.0795
Epoch   9 Batch   86/269 - Train Accuracy: 0.9160, Validation Accuracy: 0.9244, Loss: 0.0806
Epoch   9 Batch   87/269 - Train Accuracy: 0.9128, Validation Accuracy: 0.9280, Loss: 0.0903
Epoch   9 Batch   88/269 - Train Accuracy: 0.9045, Validation Accuracy: 0.9276, Loss: 0.0845
Epoch   9 Batch   89/269 - Train Accuracy: 0.9313, Validation Accuracy: 0.9305, Loss: 0.0800
Epoch   9 Batch   90/269 - Train Accuracy: 0.9285, Validation Accuracy: 0.9211, Loss: 0.0854
Epoch   9 Batch   91/269 - Train Accuracy: 0.9217, Validation Accuracy: 0.9227, Loss: 0.0788
Epoch   9 Batch   92/269 - Train Accuracy: 0.9390, Validation Accuracy: 0.9324, Loss: 0.0754
Epoch   9 Batch   93/269 - Train Accuracy: 0.9379, Validation Accuracy: 0.9255, Loss: 0.0800
Epoch   9 Batch   94/269 - Train Accuracy: 0.9270, Validation Accuracy: 0.9297, Loss: 0.0958
Epoch   9 Batch   95/269 - Train Accuracy: 0.9250, Validation Accuracy: 0.9158, Loss: 0.0823
Epoch   9 Batch   96/269 - Train Accuracy: 0.9006, Validation Accuracy: 0.9125, Loss: 0.0813
Epoch   9 Batch   97/269 - Train Accuracy: 0.9212, Validation Accuracy: 0.9247, Loss: 0.0863
Epoch   9 Batch   98/269 - Train Accuracy: 0.9204, Validation Accuracy: 0.9224, Loss: 0.0830
Epoch   9 Batch   99/269 - Train Accuracy: 0.9216, Validation Accuracy: 0.9292, Loss: 0.0856
Epoch   9 Batch  100/269 - Train Accuracy: 0.9246, Validation Accuracy: 0.9268, Loss: 0.0794
Epoch   9 Batch  101/269 - Train Accuracy: 0.9121, Validation Accuracy: 0.9231, Loss: 0.0946
Epoch   9 Batch  102/269 - Train Accuracy: 0.9221, Validation Accuracy: 0.9309, Loss: 0.0795
Epoch   9 Batch  103/269 - Train Accuracy: 0.9326, Validation Accuracy: 0.9306, Loss: 0.0880
Epoch   9 Batch  104/269 - Train Accuracy: 0.9265, Validation Accuracy: 0.9220, Loss: 0.0800
Epoch   9 Batch  105/269 - Train Accuracy: 0.9051, Validation Accuracy: 0.9227, Loss: 0.0814
Epoch   9 Batch  106/269 - Train Accuracy: 0.9265, Validation Accuracy: 0.9291, Loss: 0.0724
Epoch   9 Batch  107/269 - Train Accuracy: 0.9340, Validation Accuracy: 0.9324, Loss: 0.0799
Epoch   9 Batch  108/269 - Train Accuracy: 0.9316, Validation Accuracy: 0.9301, Loss: 0.0764
Epoch   9 Batch  109/269 - Train Accuracy: 0.9089, Validation Accuracy: 0.9227, Loss: 0.0887
Epoch   9 Batch  110/269 - Train Accuracy: 0.9187, Validation Accuracy: 0.9185, Loss: 0.0793
Epoch   9 Batch  111/269 - Train Accuracy: 0.9276, Validation Accuracy: 0.9199, Loss: 0.0918
Epoch   9 Batch  112/269 - Train Accuracy: 0.9287, Validation Accuracy: 0.9231, Loss: 0.0840
Epoch   9 Batch  113/269 - Train Accuracy: 0.9192, Validation Accuracy: 0.9241, Loss: 0.0749
Epoch   9 Batch  114/269 - Train Accuracy: 0.9328, Validation Accuracy: 0.9249, Loss: 0.0786
Epoch   9 Batch  115/269 - Train Accuracy: 0.9208, Validation Accuracy: 0.9165, Loss: 0.0816
Epoch   9 Batch  116/269 - Train Accuracy: 0.9327, Validation Accuracy: 0.9190, Loss: 0.0831
Epoch   9 Batch  117/269 - Train Accuracy: 0.9242, Validation Accuracy: 0.9235, Loss: 0.0768
Epoch   9 Batch  118/269 - Train Accuracy: 0.9323, Validation Accuracy: 0.9254, Loss: 0.0721
Epoch   9 Batch  119/269 - Train Accuracy: 0.9230, Validation Accuracy: 0.9297, Loss: 0.0867
Epoch   9 Batch  120/269 - Train Accuracy: 0.9272, Validation Accuracy: 0.9285, Loss: 0.0809
Epoch   9 Batch  121/269 - Train Accuracy: 0.9352, Validation Accuracy: 0.9245, Loss: 0.0751
Epoch   9 Batch  122/269 - Train Accuracy: 0.9219, Validation Accuracy: 0.9281, Loss: 0.0777
Epoch   9 Batch  123/269 - Train Accuracy: 0.9230, Validation Accuracy: 0.9267, Loss: 0.0832
Epoch   9 Batch  124/269 - Train Accuracy: 0.9320, Validation Accuracy: 0.9322, Loss: 0.0784
Epoch   9 Batch  125/269 - Train Accuracy: 0.9277, Validation Accuracy: 0.9266, Loss: 0.0756
Epoch   9 Batch  126/269 - Train Accuracy: 0.9121, Validation Accuracy: 0.9229, Loss: 0.0832
Epoch   9 Batch  127/269 - Train Accuracy: 0.9294, Validation Accuracy: 0.9290, Loss: 0.0806
Epoch   9 Batch  128/269 - Train Accuracy: 0.9314, Validation Accuracy: 0.9354, Loss: 0.0831
Epoch   9 Batch  129/269 - Train Accuracy: 0.9216, Validation Accuracy: 0.9325, Loss: 0.0842
Epoch   9 Batch  130/269 - Train Accuracy: 0.9234, Validation Accuracy: 0.9350, Loss: 0.0843
Epoch   9 Batch  131/269 - Train Accuracy: 0.9143, Validation Accuracy: 0.9295, Loss: 0.0812
Epoch   9 Batch  132/269 - Train Accuracy: 0.9222, Validation Accuracy: 0.9286, Loss: 0.0844
Epoch   9 Batch  133/269 - Train Accuracy: 0.9290, Validation Accuracy: 0.9316, Loss: 0.0715
Epoch   9 Batch  134/269 - Train Accuracy: 0.9281, Validation Accuracy: 0.9333, Loss: 0.0778
Epoch   9 Batch  135/269 - Train Accuracy: 0.9343, Validation Accuracy: 0.9308, Loss: 0.0809
Epoch   9 Batch  136/269 - Train Accuracy: 0.9145, Validation Accuracy: 0.9252, Loss: 0.0863
Epoch   9 Batch  137/269 - Train Accuracy: 0.9098, Validation Accuracy: 0.9261, Loss: 0.0865
Epoch   9 Batch  138/269 - Train Accuracy: 0.9264, Validation Accuracy: 0.9243, Loss: 0.0769
Epoch   9 Batch  139/269 - Train Accuracy: 0.9241, Validation Accuracy: 0.9227, Loss: 0.0766
Epoch   9 Batch  140/269 - Train Accuracy: 0.9188, Validation Accuracy: 0.9252, Loss: 0.0827
Epoch   9 Batch  141/269 - Train Accuracy: 0.9107, Validation Accuracy: 0.9251, Loss: 0.0832
Epoch   9 Batch  142/269 - Train Accuracy: 0.9207, Validation Accuracy: 0.9252, Loss: 0.0792
Epoch   9 Batch  143/269 - Train Accuracy: 0.9406, Validation Accuracy: 0.9247, Loss: 0.0752
Epoch   9 Batch  144/269 - Train Accuracy: 0.9353, Validation Accuracy: 0.9237, Loss: 0.0660
Epoch   9 Batch  145/269 - Train Accuracy: 0.9284, Validation Accuracy: 0.9241, Loss: 0.0768
Epoch   9 Batch  146/269 - Train Accuracy: 0.9361, Validation Accuracy: 0.9256, Loss: 0.0791
Epoch   9 Batch  147/269 - Train Accuracy: 0.9257, Validation Accuracy: 0.9291, Loss: 0.0824
Epoch   9 Batch  148/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9331, Loss: 0.0799
Epoch   9 Batch  149/269 - Train Accuracy: 0.9205, Validation Accuracy: 0.9313, Loss: 0.0884
Epoch   9 Batch  150/269 - Train Accuracy: 0.9205, Validation Accuracy: 0.9287, Loss: 0.0759
Epoch   9 Batch  151/269 - Train Accuracy: 0.9252, Validation Accuracy: 0.9249, Loss: 0.0807
Epoch   9 Batch  152/269 - Train Accuracy: 0.9290, Validation Accuracy: 0.9248, Loss: 0.0766
Epoch   9 Batch  153/269 - Train Accuracy: 0.9305, Validation Accuracy: 0.9288, Loss: 0.0755
Epoch   9 Batch  154/269 - Train Accuracy: 0.9311, Validation Accuracy: 0.9316, Loss: 0.0712
Epoch   9 Batch  155/269 - Train Accuracy: 0.9251, Validation Accuracy: 0.9305, Loss: 0.0754
Epoch   9 Batch  156/269 - Train Accuracy: 0.9259, Validation Accuracy: 0.9317, Loss: 0.0776
Epoch   9 Batch  157/269 - Train Accuracy: 0.9086, Validation Accuracy: 0.9297, Loss: 0.0735
Epoch   9 Batch  158/269 - Train Accuracy: 0.9250, Validation Accuracy: 0.9287, Loss: 0.0753
Epoch   9 Batch  159/269 - Train Accuracy: 0.9201, Validation Accuracy: 0.9307, Loss: 0.0810
Epoch   9 Batch  160/269 - Train Accuracy: 0.9237, Validation Accuracy: 0.9308, Loss: 0.0765
Epoch   9 Batch  161/269 - Train Accuracy: 0.9295, Validation Accuracy: 0.9278, Loss: 0.0730
Epoch   9 Batch  162/269 - Train Accuracy: 0.9297, Validation Accuracy: 0.9288, Loss: 0.0760
Epoch   9 Batch  163/269 - Train Accuracy: 0.9362, Validation Accuracy: 0.9275, Loss: 0.0785
Epoch   9 Batch  164/269 - Train Accuracy: 0.9270, Validation Accuracy: 0.9237, Loss: 0.0737
Epoch   9 Batch  165/269 - Train Accuracy: 0.9271, Validation Accuracy: 0.9257, Loss: 0.0774
Epoch   9 Batch  166/269 - Train Accuracy: 0.9306, Validation Accuracy: 0.9265, Loss: 0.0765
Epoch   9 Batch  167/269 - Train Accuracy: 0.9247, Validation Accuracy: 0.9255, Loss: 0.0775
Epoch   9 Batch  168/269 - Train Accuracy: 0.9267, Validation Accuracy: 0.9283, Loss: 0.0791
Epoch   9 Batch  169/269 - Train Accuracy: 0.9251, Validation Accuracy: 0.9301, Loss: 0.0769
Epoch   9 Batch  170/269 - Train Accuracy: 0.9259, Validation Accuracy: 0.9273, Loss: 0.0729
Epoch   9 Batch  171/269 - Train Accuracy: 0.9322, Validation Accuracy: 0.9321, Loss: 0.0794
Epoch   9 Batch  172/269 - Train Accuracy: 0.9119, Validation Accuracy: 0.9290, Loss: 0.0876
Epoch   9 Batch  173/269 - Train Accuracy: 0.9347, Validation Accuracy: 0.9322, Loss: 0.0761
Epoch   9 Batch  174/269 - Train Accuracy: 0.9378, Validation Accuracy: 0.9308, Loss: 0.0767
Epoch   9 Batch  175/269 - Train Accuracy: 0.9193, Validation Accuracy: 0.9306, Loss: 0.0895
Epoch   9 Batch  176/269 - Train Accuracy: 0.9100, Validation Accuracy: 0.9242, Loss: 0.0869
Epoch   9 Batch  177/269 - Train Accuracy: 0.9312, Validation Accuracy: 0.9274, Loss: 0.0747
Epoch   9 Batch  178/269 - Train Accuracy: 0.9405, Validation Accuracy: 0.9252, Loss: 0.0724
Epoch   9 Batch  179/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.9213, Loss: 0.0797
Epoch   9 Batch  180/269 - Train Accuracy: 0.9280, Validation Accuracy: 0.9276, Loss: 0.0735
Epoch   9 Batch  181/269 - Train Accuracy: 0.9170, Validation Accuracy: 0.9311, Loss: 0.0853
Epoch   9 Batch  182/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9258, Loss: 0.0742
Epoch   9 Batch  183/269 - Train Accuracy: 0.9386, Validation Accuracy: 0.9218, Loss: 0.0643
Epoch   9 Batch  184/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9166, Loss: 0.0774
Epoch   9 Batch  185/269 - Train Accuracy: 0.9413, Validation Accuracy: 0.9224, Loss: 0.0786
Epoch   9 Batch  186/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9291, Loss: 0.0711
Epoch   9 Batch  187/269 - Train Accuracy: 0.9272, Validation Accuracy: 0.9275, Loss: 0.0731
Epoch   9 Batch  188/269 - Train Accuracy: 0.9352, Validation Accuracy: 0.9307, Loss: 0.0719
Epoch   9 Batch  189/269 - Train Accuracy: 0.9191, Validation Accuracy: 0.9333, Loss: 0.0697
Epoch   9 Batch  190/269 - Train Accuracy: 0.9280, Validation Accuracy: 0.9287, Loss: 0.0780
Epoch   9 Batch  191/269 - Train Accuracy: 0.9196, Validation Accuracy: 0.9298, Loss: 0.0751
Epoch   9 Batch  192/269 - Train Accuracy: 0.9301, Validation Accuracy: 0.9263, Loss: 0.0787
Epoch   9 Batch  193/269 - Train Accuracy: 0.9344, Validation Accuracy: 0.9273, Loss: 0.0748
Epoch   9 Batch  194/269 - Train Accuracy: 0.9175, Validation Accuracy: 0.9260, Loss: 0.0779
Epoch   9 Batch  195/269 - Train Accuracy: 0.9221, Validation Accuracy: 0.9297, Loss: 0.0807
Epoch   9 Batch  196/269 - Train Accuracy: 0.9123, Validation Accuracy: 0.9262, Loss: 0.0767
Epoch   9 Batch  197/269 - Train Accuracy: 0.9155, Validation Accuracy: 0.9249, Loss: 0.0795
Epoch   9 Batch  198/269 - Train Accuracy: 0.9231, Validation Accuracy: 0.9238, Loss: 0.0827
Epoch   9 Batch  199/269 - Train Accuracy: 0.9222, Validation Accuracy: 0.9238, Loss: 0.0826
Epoch   9 Batch  200/269 - Train Accuracy: 0.9243, Validation Accuracy: 0.9259, Loss: 0.0780
Epoch   9 Batch  201/269 - Train Accuracy: 0.9310, Validation Accuracy: 0.9293, Loss: 0.0768
Epoch   9 Batch  202/269 - Train Accuracy: 0.9244, Validation Accuracy: 0.9270, Loss: 0.0742
Epoch   9 Batch  203/269 - Train Accuracy: 0.9239, Validation Accuracy: 0.9295, Loss: 0.0848
Epoch   9 Batch  204/269 - Train Accuracy: 0.9197, Validation Accuracy: 0.9245, Loss: 0.0779
Epoch   9 Batch  205/269 - Train Accuracy: 0.9275, Validation Accuracy: 0.9245, Loss: 0.0750
Epoch   9 Batch  206/269 - Train Accuracy: 0.9192, Validation Accuracy: 0.9288, Loss: 0.0795
Epoch   9 Batch  207/269 - Train Accuracy: 0.9256, Validation Accuracy: 0.9260, Loss: 0.0763
Epoch   9 Batch  208/269 - Train Accuracy: 0.9279, Validation Accuracy: 0.9303, Loss: 0.0797
Epoch   9 Batch  209/269 - Train Accuracy: 0.9374, Validation Accuracy: 0.9316, Loss: 0.0689
Epoch   9 Batch  210/269 - Train Accuracy: 0.9381, Validation Accuracy: 0.9307, Loss: 0.0693
Epoch   9 Batch  211/269 - Train Accuracy: 0.9321, Validation Accuracy: 0.9333, Loss: 0.0788
Epoch   9 Batch  212/269 - Train Accuracy: 0.9334, Validation Accuracy: 0.9354, Loss: 0.0814
Epoch   9 Batch  213/269 - Train Accuracy: 0.9137, Validation Accuracy: 0.9293, Loss: 0.0737
Epoch   9 Batch  214/269 - Train Accuracy: 0.9296, Validation Accuracy: 0.9299, Loss: 0.0764
Epoch   9 Batch  215/269 - Train Accuracy: 0.9308, Validation Accuracy: 0.9338, Loss: 0.0682
Epoch   9 Batch  216/269 - Train Accuracy: 0.9144, Validation Accuracy: 0.9277, Loss: 0.0891
Epoch   9 Batch  217/269 - Train Accuracy: 0.9151, Validation Accuracy: 0.9269, Loss: 0.0750
Epoch   9 Batch  218/269 - Train Accuracy: 0.9317, Validation Accuracy: 0.9318, Loss: 0.0773
Epoch   9 Batch  219/269 - Train Accuracy: 0.9316, Validation Accuracy: 0.9266, Loss: 0.0800
Epoch   9 Batch  220/269 - Train Accuracy: 0.9279, Validation Accuracy: 0.9285, Loss: 0.0746
Epoch   9 Batch  221/269 - Train Accuracy: 0.9244, Validation Accuracy: 0.9285, Loss: 0.0772
Epoch   9 Batch  222/269 - Train Accuracy: 0.9395, Validation Accuracy: 0.9280, Loss: 0.0673
Epoch   9 Batch  223/269 - Train Accuracy: 0.9255, Validation Accuracy: 0.9319, Loss: 0.0695
Epoch   9 Batch  224/269 - Train Accuracy: 0.9333, Validation Accuracy: 0.9343, Loss: 0.0826
Epoch   9 Batch  225/269 - Train Accuracy: 0.9230, Validation Accuracy: 0.9336, Loss: 0.0722
Epoch   9 Batch  226/269 - Train Accuracy: 0.9315, Validation Accuracy: 0.9340, Loss: 0.0774
Epoch   9 Batch  227/269 - Train Accuracy: 0.9371, Validation Accuracy: 0.9341, Loss: 0.0791
Epoch   9 Batch  228/269 - Train Accuracy: 0.9222, Validation Accuracy: 0.9335, Loss: 0.0719
Epoch   9 Batch  229/269 - Train Accuracy: 0.9240, Validation Accuracy: 0.9362, Loss: 0.0751
Epoch   9 Batch  230/269 - Train Accuracy: 0.9363, Validation Accuracy: 0.9362, Loss: 0.0733
Epoch   9 Batch  231/269 - Train Accuracy: 0.9191, Validation Accuracy: 0.9362, Loss: 0.0800
Epoch   9 Batch  232/269 - Train Accuracy: 0.9222, Validation Accuracy: 0.9338, Loss: 0.0737
Epoch   9 Batch  233/269 - Train Accuracy: 0.9359, Validation Accuracy: 0.9323, Loss: 0.0802
Epoch   9 Batch  234/269 - Train Accuracy: 0.9260, Validation Accuracy: 0.9325, Loss: 0.0746
Epoch   9 Batch  235/269 - Train Accuracy: 0.9523, Validation Accuracy: 0.9307, Loss: 0.0683
Epoch   9 Batch  236/269 - Train Accuracy: 0.9257, Validation Accuracy: 0.9337, Loss: 0.0731
Epoch   9 Batch  237/269 - Train Accuracy: 0.9278, Validation Accuracy: 0.9295, Loss: 0.0743
Epoch   9 Batch  238/269 - Train Accuracy: 0.9242, Validation Accuracy: 0.9179, Loss: 0.0728
Epoch   9 Batch  239/269 - Train Accuracy: 0.9364, Validation Accuracy: 0.9298, Loss: 0.0717
Epoch   9 Batch  240/269 - Train Accuracy: 0.9350, Validation Accuracy: 0.9331, Loss: 0.0674
Epoch   9 Batch  241/269 - Train Accuracy: 0.9197, Validation Accuracy: 0.9342, Loss: 0.0806
Epoch   9 Batch  242/269 - Train Accuracy: 0.9458, Validation Accuracy: 0.9352, Loss: 0.0680
Epoch   9 Batch  243/269 - Train Accuracy: 0.9366, Validation Accuracy: 0.9360, Loss: 0.0665
Epoch   9 Batch  244/269 - Train Accuracy: 0.9290, Validation Accuracy: 0.9328, Loss: 0.0737
Epoch   9 Batch  245/269 - Train Accuracy: 0.9218, Validation Accuracy: 0.9344, Loss: 0.0776
Epoch   9 Batch  246/269 - Train Accuracy: 0.9233, Validation Accuracy: 0.9331, Loss: 0.0779
Epoch   9 Batch  247/269 - Train Accuracy: 0.9350, Validation Accuracy: 0.9309, Loss: 0.0726
Epoch   9 Batch  248/269 - Train Accuracy: 0.9292, Validation Accuracy: 0.9316, Loss: 0.0728
Epoch   9 Batch  249/269 - Train Accuracy: 0.9313, Validation Accuracy: 0.9302, Loss: 0.0689
Epoch   9 Batch  250/269 - Train Accuracy: 0.9344, Validation Accuracy: 0.9281, Loss: 0.0723
Epoch   9 Batch  251/269 - Train Accuracy: 0.9541, Validation Accuracy: 0.9284, Loss: 0.0674
Epoch   9 Batch  252/269 - Train Accuracy: 0.9305, Validation Accuracy: 0.9320, Loss: 0.0668
Epoch   9 Batch  253/269 - Train Accuracy: 0.9134, Validation Accuracy: 0.9331, Loss: 0.0774
Epoch   9 Batch  254/269 - Train Accuracy: 0.9255, Validation Accuracy: 0.9309, Loss: 0.0722
Epoch   9 Batch  255/269 - Train Accuracy: 0.9292, Validation Accuracy: 0.9303, Loss: 0.0744
Epoch   9 Batch  256/269 - Train Accuracy: 0.9192, Validation Accuracy: 0.9329, Loss: 0.0722
Epoch   9 Batch  257/269 - Train Accuracy: 0.9118, Validation Accuracy: 0.9312, Loss: 0.0802
Epoch   9 Batch  258/269 - Train Accuracy: 0.9272, Validation Accuracy: 0.9304, Loss: 0.0742
Epoch   9 Batch  259/269 - Train Accuracy: 0.9252, Validation Accuracy: 0.9355, Loss: 0.0747
Epoch   9 Batch  260/269 - Train Accuracy: 0.9372, Validation Accuracy: 0.9297, Loss: 0.0793
Epoch   9 Batch  261/269 - Train Accuracy: 0.9309, Validation Accuracy: 0.9347, Loss: 0.0745
Epoch   9 Batch  262/269 - Train Accuracy: 0.9299, Validation Accuracy: 0.9350, Loss: 0.0684
Epoch   9 Batch  263/269 - Train Accuracy: 0.9240, Validation Accuracy: 0.9353, Loss: 0.0746
Epoch   9 Batch  264/269 - Train Accuracy: 0.9064, Validation Accuracy: 0.9364, Loss: 0.0800
Epoch   9 Batch  265/269 - Train Accuracy: 0.9346, Validation Accuracy: 0.9312, Loss: 0.0707
Epoch   9 Batch  266/269 - Train Accuracy: 0.9406, Validation Accuracy: 0.9315, Loss: 0.0690
Epoch   9 Batch  267/269 - Train Accuracy: 0.9271, Validation Accuracy: 0.9271, Loss: 0.0766
Model Trained and Saved
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Save-Parameters">Save Parameters<a class="anchor-link" href="#Save-Parameters">&#182;</a></h3><p>Save the <code>batch_size</code> and <code>save_path</code> parameters for inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[35]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Save parameters for checkpoint</span>
<span class="n">helper</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[36]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="p">(</span><span class="n">source_int_to_vocab</span><span class="p">,</span> <span class="n">target_int_to_vocab</span><span class="p">)</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">load_path</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_params</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sentence-to-Sequence">Sentence to Sequence<a class="anchor-link" href="#Sentence-to-Sequence">&#182;</a></h2><p>To feed a sentence into the model for translation, you first need to preprocess it.  Implement the function <code>sentence_to_seq()</code> to preprocess new sentences.</p>
<ul>
<li>Convert the sentence to lowercase</li>
<li>Convert words into ids using <code>vocab_to_int</code><ul>
<li>Convert words not in the vocabulary, to the <code>&lt;UNK&gt;</code> word id.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[39]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sentence_to_seq</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a sentence to a sequence of ids</span>
<span class="sd">    :param sentence: String</span>
<span class="sd">    :param vocab_to_int: Dictionary to go from the words to an id</span>
<span class="sd">    :return: List of word ids</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function </span>
    <span class="n">sentence_int</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab_to_int</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">,</span><span class="n">vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;UNK&gt;&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>

    <span class="k">return</span> <span class="n">sentence_int</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_sentence_to_seq</span><span class="p">(</span><span class="n">sentence_to_seq</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Translate">Translate<a class="anchor-link" href="#Translate">&#182;</a></h2><p>This will translate <code>translate_sentence</code> from English to French.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[41]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">translate_sentence</span> <span class="o">=</span> <span class="s1">&#39;he saw a old yellow truck .&#39;</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">translate_sentence</span> <span class="o">=</span> <span class="n">sentence_to_seq</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">)</span>

<span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Load saved model</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">load_path</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
    <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">load_path</span><span class="p">)</span>

    <span class="n">input_data</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;input:0&#39;</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;predictions:0&#39;</span><span class="p">)</span>
    <span class="n">target_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;target_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;source_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;keep_prob:0&#39;</span><span class="p">)</span>

    <span class="n">translate_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="p">[</span><span class="n">translate_sentence</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">target_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">source_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  English Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">source_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Prediction&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  French Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">target_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">])))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Restoring parameters from checkpoints/dev
Input
  Word Ids:      [186, 146, 164, 171, 42, 68, 126]
  English Words: [&#39;he&#39;, &#39;saw&#39;, &#39;a&#39;, &#39;old&#39;, &#39;yellow&#39;, &#39;truck&#39;, &#39;.&#39;]

Prediction
  Word Ids:      [189, 145, 341, 81, 99, 336, 298, 1]
  French Words: il a vu un camion bleu . &lt;EOS&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Imperfect-Translation">Imperfect Translation<a class="anchor-link" href="#Imperfect-Translation">&#182;</a></h2><p>You might notice that some sentences translate better than others.  Since the dataset you're using only has a vocabulary of 227 English words of the thousands that you use, you're only going to see good results using these words.  For this project, you don't need a perfect translation. However, if you want to create a better translation model, you'll need better data.</p>
<p>You can train on the <a href="http://www.statmt.org/wmt10/training-giga-fren.tar">WMT10 French-English corpus</a>.  This dataset has more vocabulary and richer in topics discussed.  However, this will take you days to train, so make sure you've a GPU and the neural network is performing well on dataset we provided.  Just make sure you play with the WMT10 corpus after you've submitted this project.</p>
<h2 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="#Submitting-This-Project">&#182;</a></h2><p>When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as "dlnd_language_translation.ipynb" and save it as a HTML file under "File" -&gt; "Download as". Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>

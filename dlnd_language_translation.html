<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_language_translation</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Language-Translation">Language Translation<a class="anchor-link" href="#Language-Translation">&#182;</a></h1><p>In this project, youre going to take a peek into the realm of neural network machine translation.  Youll be training a sequence to sequence model on a dataset of English and French sentences that can translate new sentences from English to French.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="#Get-the-Data">&#182;</a></h2><p>Since translating the whole language of English to French will take lots of time to train, we have provided you with a small portion of the English corpus.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">source_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_en&#39;</span>
<span class="n">target_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_fr&#39;</span>
<span class="n">source_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">)</span>
<span class="n">target_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">target_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="#Explore-the-Data">&#182;</a></h2><p>Play around with view_sentence_range to view different parts of the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">view_sentence_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dataset Stats&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Roughly the number of unique words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">({</span><span class="n">word</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">()})))</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of sentences: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average number of words in a sentence: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;English sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;French sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset Stats
Roughly the number of unique words: 227
Number of sentences: 137861
Average number of words in a sentence: 13.225277634719028

English sentences 0 to 10:
new jersey is sometimes quiet during autumn , and it is snowy in april .
the united states is usually chilly during july , and it is usually freezing in november .
california is usually quiet during march , and it is usually hot in june .
the united states is sometimes mild during june , and it is cold in september .
your least liked fruit is the grape , but my least liked is the apple .
his favorite fruit is the orange , but my favorite is the grape .
paris is relaxing during december , but it is usually chilly in july .
new jersey is busy during spring , and it is never hot in march .
our least liked fruit is the lemon , but my least liked is the grape .
the united states is sometimes busy during january , and it is sometimes warm in november .

French sentences 0 to 10:
new jersey est parfois calme pendant l&#39; automne , et il est neigeux en avril .
les tats-unis est gnralement froid en juillet , et il gle habituellement en novembre .
california est gnralement calme en mars , et il est gnralement chaud en juin .
les tats-unis est parfois lgre en juin , et il fait froid en septembre .
votre moins aim fruit est le raisin , mais mon moins aim est la pomme .
son fruit prfr est l&#39;orange , mais mon prfr est le raisin .
paris est relaxant en dcembre , mais il est gnralement froid en juillet .
new jersey est occup au printemps , et il est jamais chaude en mars .
notre fruit est moins aim le citron , mais mon moins aim est le raisin .
les tats-unis est parfois occup en janvier , et il est parfois chaud en novembre .
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocessing-Function">Implement Preprocessing Function<a class="anchor-link" href="#Implement-Preprocessing-Function">&#182;</a></h2><h3 id="Text-to-Word-Ids">Text to Word Ids<a class="anchor-link" href="#Text-to-Word-Ids">&#182;</a></h3><p>As you did with other RNNs, you must turn the text into a number so the computer can understand it. In the function <code>text_to_ids()</code>, you'll turn <code>source_text</code> and <code>target_text</code> from words to ids.  However, you need to add the <code>&lt;EOS&gt;</code> word id at the end of <code>target_text</code>.  This will help the neural network predict when the sentence should end.</p>
<p>You can get the <code>&lt;EOS&gt;</code> word id by doing:</p>
<div class="highlight"><pre><span></span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]</span>
</pre></div>
<p>You can get other word ids using <code>source_vocab_to_int</code> and <code>target_vocab_to_int</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">text_to_ids</span><span class="p">(</span><span class="n">source_text</span><span class="p">,</span> <span class="n">target_text</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert source and target text to proper word ids</span>
<span class="sd">    :param source_text: String that contains all the source text.</span>
<span class="sd">    :param target_text: String that contains all the target text.</span>
<span class="sd">    :param source_vocab_to_int: Dictionary to go from the source words to an id</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: A tuple of lists (source_id_text, target_id_text)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">source_id_text</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)):</span>
        <span class="n">source_id_text</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
            <span class="n">source_id_text</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        
    <span class="n">target_id_text</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)):</span>
        <span class="n">target_id_text</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
            <span class="n">target_id_text</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="n">target_id_text</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">])</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">source_id_text</span><span class="p">,</span> <span class="n">target_id_text</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_text_to_ids</span><span class="p">(</span><span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="#Preprocess-all-the-data-and-save-it">&#182;</a></h3><p>Running the code cell below will preprocess all the data and save it to file.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">,</span> <span class="n">target_path</span><span class="p">,</span> <span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Check-the-Version-of-TensorFlow-and-Access-to-GPU">Check the Version of TensorFlow and Access to GPU<a class="anchor-link" href="#Check-the-Version-of-TensorFlow-and-Access-to-GPU">&#182;</a></h3><p>This will check to make sure you have the correct version of TensorFlow and access to a GPU</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[32]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="k">import</span> <span class="n">LooseVersion</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.layers.core</span> <span class="k">import</span> <span class="n">Dense</span>

<span class="c1"># Check TensorFlow Version</span>
<span class="k">assert</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;1.1&#39;</span><span class="p">),</span> <span class="s1">&#39;Please use TensorFlow version 1.1 or newer&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TensorFlow Version: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>

<span class="c1"># Check for a GPU</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;No GPU found. Please use a GPU to train your neural network.&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Default GPU Device: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow Version: 1.2.1
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:15: UserWarning: No GPU found. Please use a GPU to train your neural network.
  from ipykernel import kernelapp as app
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h2><p>You'll build the components necessary to build a Sequence-to-Sequence model by implementing the following functions below:</p>
<ul>
<li><code>model_inputs</code></li>
<li><code>process_decoder_input</code></li>
<li><code>encoding_layer</code></li>
<li><code>decoding_layer_train</code></li>
<li><code>decoding_layer_infer</code></li>
<li><code>decoding_layer</code></li>
<li><code>seq2seq_model</code></li>
</ul>
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>Implement the <code>model_inputs()</code> function to create TF Placeholders for the Neural Network. It should create the following placeholders:</p>
<ul>
<li>Input text placeholder named "input" using the TF Placeholder name parameter with rank 2.</li>
<li>Targets placeholder with rank 2.</li>
<li>Learning rate placeholder with rank 0.</li>
<li>Keep probability placeholder named "keep_prob" using the TF Placeholder name parameter with rank 0.</li>
<li>Target sequence length placeholder named "target_sequence_length" with rank 1</li>
<li>Max target sequence length tensor named "max_target_len" getting its value from applying tf.reduce_max on the target_sequence_length placeholder. Rank 0.</li>
<li>Source sequence length placeholder named "source_sequence_length" with rank 1</li>
</ul>
<p>Return the placeholders in the following the tuple (input, targets, learning rate, keep probability, target sequence length, max target sequence length, source sequence length)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[35]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_inputs</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create TF Placeholders for input, targets, learning rate, and lengths of source and target sequences.</span>
<span class="sd">    :return: Tuple (input, targets, learning rate, keep probability, target sequence length,</span>
<span class="sd">    max target sequence length, source sequence length)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span> <span class="s2">&quot;input&quot;</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span> <span class="s2">&quot;targets&quot;</span><span class="p">)</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span> <span class="s2">&quot;learning_rate&quot;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span> <span class="s2">&quot;keep_prob&quot;</span><span class="p">)</span>
    <span class="n">target_sequence_lenth</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span> <span class="s2">&quot;target_sequence_length&quot;</span><span class="p">)</span>
    <span class="n">max_target_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">target_sequence_lenth</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span> <span class="s1">&#39;max_target_len&#39;</span><span class="p">)</span>
    <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span> <span class="s2">&quot;source_sequence_length&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_sequence_lenth</span><span class="p">,</span> <span class="n">max_target_len</span><span class="p">,</span> <span class="n">source_sequence_length</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_model_inputs</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>ERROR:tensorflow:==================================
Object was never used (type &lt;class &#39;tensorflow.python.framework.ops.Operation&#39;&gt;):
&lt;tf.Operation &#39;assert_rank_2/Assert/Assert&#39; type=Assert&gt;
If you want to mark it as used call its &#34;mark_used()&#34; method.
It was originally created here:
[&#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/runpy.py&#34;, line 170, in _run_module_as_main\n    &#34;__main__&#34;, mod_spec)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/runpy.py&#34;, line 85, in _run_code\n    exec(code, run_globals)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py&#34;, line 16, in &lt;module&gt;\n    app.launch_new_instance()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py&#34;, line 658, in launch_instance\n    app.start()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py&#34;, line 474, in start\n    ioloop.IOLoop.instance().start()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py&#34;, line 177, in start\n    super(ZMQIOLoop, self).start()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py&#34;, line 887, in start\n    handler_func(fd_obj, events)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py&#34;, line 275, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 440, in _handle_events\n    self._handle_recv()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 472, in _handle_recv\n    self._run_callback(callback, msg)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 414, in _run_callback\n    callback(*args, **kwargs)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py&#34;, line 275, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 228, in dispatch_shell\n    handler(stream, idents, msg)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 390, in execute_request\n    user_expressions, allow_stdin)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py&#34;, line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py&#34;, line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2827, in run_ast_nodes\n    if self.run_code(code, result):&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)&#39;, &#39;File &#34;&lt;ipython-input-35-214c04400709&gt;&#34;, line 22, in &lt;module&gt;\n    tests.test_model_inputs(model_inputs)&#39;, &#39;File &#34;/home/sergiocncruz/Codes/python/udacity/deep_learn/dlnd_language_translation/problem_unittests.py&#34;, line 106, in test_model_inputs\n    assert tf.assert_rank(lr, 0, message=\&#39;Learning Rate has wrong rank\&#39;)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/check_ops.py&#34;, line 617, in assert_rank\n    dynamic_condition, data, summarize)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/check_ops.py&#34;, line 571, in _assert_rank_condition\n    return control_flow_ops.Assert(condition, data, summarize=summarize)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 170, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 139, in _add_should_use_warning\n    wrapped = TFShouldUseWarningWrapper(x)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 96, in __init__\n    stack = [s.strip() for s in traceback.format_stack()]&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/traceback.py&#34;, line 189, in format_stack\n    return format_list(extract_stack(f, limit=limit))&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/traceback.py&#34;, line 201, in extract_stack\n    stack = StackSummary.extract(walk_stack(f), limit=limit)&#39;]
==================================
ERROR:tensorflow:==================================
Object was never used (type &lt;class &#39;tensorflow.python.framework.ops.Operation&#39;&gt;):
&lt;tf.Operation &#39;assert_rank_3/Assert/Assert&#39; type=Assert&gt;
If you want to mark it as used call its &#34;mark_used()&#34; method.
It was originally created here:
[&#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/runpy.py&#34;, line 170, in _run_module_as_main\n    &#34;__main__&#34;, mod_spec)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/runpy.py&#34;, line 85, in _run_code\n    exec(code, run_globals)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py&#34;, line 16, in &lt;module&gt;\n    app.launch_new_instance()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py&#34;, line 658, in launch_instance\n    app.start()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py&#34;, line 474, in start\n    ioloop.IOLoop.instance().start()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py&#34;, line 177, in start\n    super(ZMQIOLoop, self).start()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py&#34;, line 887, in start\n    handler_func(fd_obj, events)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py&#34;, line 275, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 440, in _handle_events\n    self._handle_recv()&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 472, in _handle_recv\n    self._run_callback(callback, msg)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py&#34;, line 414, in _run_callback\n    callback(*args, **kwargs)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py&#34;, line 275, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 228, in dispatch_shell\n    handler(stream, idents, msg)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py&#34;, line 390, in execute_request\n    user_expressions, allow_stdin)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py&#34;, line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py&#34;, line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2827, in run_ast_nodes\n    if self.run_code(code, result):&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py&#34;, line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)&#39;, &#39;File &#34;&lt;ipython-input-35-214c04400709&gt;&#34;, line 22, in &lt;module&gt;\n    tests.test_model_inputs(model_inputs)&#39;, &#39;File &#34;/home/sergiocncruz/Codes/python/udacity/deep_learn/dlnd_language_translation/problem_unittests.py&#34;, line 107, in test_model_inputs\n    assert tf.assert_rank(keep_prob, 0, message=\&#39;Keep Probability has wrong rank\&#39;)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/check_ops.py&#34;, line 617, in assert_rank\n    dynamic_condition, data, summarize)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/check_ops.py&#34;, line 571, in _assert_rank_condition\n    return control_flow_ops.Assert(condition, data, summarize=summarize)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 170, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 139, in _add_should_use_warning\n    wrapped = TFShouldUseWarningWrapper(x)&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py&#34;, line 96, in __init__\n    stack = [s.strip() for s in traceback.format_stack()]&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/traceback.py&#34;, line 189, in format_stack\n    return format_list(extract_stack(f, limit=limit))&#39;, &#39;File &#34;/home/sergiocncruz/anaconda3/lib/python3.5/traceback.py&#34;, line 201, in extract_stack\n    stack = StackSummary.extract(walk_stack(f), limit=limit)&#39;]
==================================
Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Process-Decoder-Input">Process Decoder Input<a class="anchor-link" href="#Process-Decoder-Input">&#182;</a></h3><p>Implement <code>process_decoder_input</code> by removing the last word id from each batch in <code>target_data</code> and concat the GO ID to the begining of each batch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[36]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Preprocess target data for encoding</span>
<span class="sd">    :param target_data: Target Placehoder</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :return: Preprocessed target data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">go</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">preprocessed_target_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">go</span><span class="p">,</span><span class="n">target_data</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">preprocessed_target_data</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_process_encoding_input</span><span class="p">(</span><span class="n">process_decoder_input</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoding">Encoding<a class="anchor-link" href="#Encoding">&#182;</a></h3><p>Implement <code>encoding_layer()</code> to create a Encoder RNN layer:</p>
<ul>
<li>Embed the encoder input using <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence"><code>tf.contrib.layers.embed_sequence</code></a></li>
<li>Construct a <a href="https://github.com/tensorflow/tensorflow/blob/6947f65a374ebf29e74bb71e36fd82760056d82c/tensorflow/docs_src/tutorials/recurrent.md#stacking-multiple-lstms">stacked</a> <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LSTMCell"><code>tf.contrib.rnn.LSTMCell</code></a> wrapped in a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper"><code>tf.contrib.rnn.DropoutWrapper</code></a></li>
<li>Pass cell and embedded input to <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"><code>tf.nn.dynamic_rnn()</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[37]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">imp</span> <span class="k">import</span> <span class="n">reload</span>
<span class="n">reload</span><span class="p">(</span><span class="n">tests</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">encoding_layer</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> 
                   <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> 
                   <span class="n">encoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create encoding layer</span>
<span class="sd">    :param rnn_inputs: Inputs for the RNN</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :param source_sequence_length: a list of the lengths of each sequence in the batch</span>
<span class="sd">    :param source_vocab_size: vocabulary size of source data</span>
<span class="sd">    :param encoding_embedding_size: embedding size of source data</span>
<span class="sd">    :return: tuple (RNN output, RNN state)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="k">def</span> <span class="nf">build_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
        <span class="n">lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span>
        <span class="n">lstm_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">lstm_drop</span>


    <span class="n">stacked_lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">build_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
    <span class="n">embed_encoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">embed_sequence</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">=</span> <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span> <span class="o">=</span> <span class="n">encoding_embedding_size</span><span class="p">)</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">stacked_lstm</span><span class="p">,</span> <span class="n">embed_encoder</span><span class="p">,</span> <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_encoding_layer</span><span class="p">(</span><span class="n">encoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Training">Decoding - Training<a class="anchor-link" href="#Decoding---Training">&#182;</a></h3><p>Create a training decoding layer:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/TrainingHelper"><code>tf.contrib.seq2seq.TrainingHelper</code></a> </li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[38]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> 
                         <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_summary_length</span><span class="p">,</span> 
                         <span class="n">output_layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for training</span>
<span class="sd">    :param encoder_state: Encoder State</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embed_input: Decoder embedded input</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_summary_length: The length of the longest sequence in the batch</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing training logits and sample_id</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">trainig_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">TrainingHelper</span><span class="p">(</span><span class="n">dec_embed_input</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">)</span>
    <span class="n">basic_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span> <span class="n">trainig_helper</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">)</span>
    <span class="n">training_logits</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">basic_decoder</span><span class="p">,</span><span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_summary_length</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">training_logits</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_train</span><span class="p">(</span><span class="n">decoding_layer_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Inference">Decoding - Inference<a class="anchor-link" href="#Decoding---Inference">&#182;</a></h3><p>Create inference decoder:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/GreedyEmbeddingHelper"><code>tf.contrib.seq2seq.GreedyEmbeddingHelper</code></a></li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[39]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_of_sequence_id</span><span class="p">,</span>
                         <span class="n">end_of_sequence_id</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                         <span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for inference</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embeddings: Decoder embeddings</span>
<span class="sd">    :param start_of_sequence_id: GO ID</span>
<span class="sd">    :param end_of_sequence_id: EOS Id</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param vocab_size: Size of decoder/target vocabulary</span>
<span class="sd">    :param decoding_scope: TenorFlow Variable Scope for decoding</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param batch_size: Batch size</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing inference logits and sample_id</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">start_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">([</span><span class="n">start_of_sequence_id</span><span class="p">],</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">])</span>
    <span class="n">embedding_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">GreedyEmbeddingHelper</span><span class="p">(</span>
        <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_ids</span><span class="p">,</span> <span class="n">end_of_sequence_id</span>
    <span class="p">)</span>
    <span class="n">basic_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span>
        <span class="n">dec_cell</span><span class="p">,</span> <span class="n">embedding_helper</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span> <span class="n">output_layer</span>
    <span class="p">)</span>
    <span class="n">training_logits</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span>
        <span class="n">basic_decoder</span><span class="p">,</span><span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_target_sequence_length</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">training_logits</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_infer</span><span class="p">(</span><span class="n">decoding_layer_infer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Decoding-Layer">Build the Decoding Layer<a class="anchor-link" href="#Build-the-Decoding-Layer">&#182;</a></h3><p>Implement <code>decoding_layer()</code> to create a Decoder RNN layer.</p>
<ul>
<li>Embed the target sequences</li>
<li>Construct the decoder LSTM cell (just like you constructed the encoder cell above)</li>
<li>Create an output layer to map the outputs of the decoder to the elements of our vocabulary</li>
<li>Use the your <code>decoding_layer_train(encoder_state, dec_cell, dec_embed_input, target_sequence_length, max_target_sequence_length, output_layer, keep_prob)</code> function to get the training logits.</li>
<li>Use your <code>decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, max_target_sequence_length, vocab_size, output_layer, batch_size, keep_prob)</code> function to get the inference logits.</li>
</ul>
<p>Note: You'll need to use <a href="https://www.tensorflow.org/api_docs/python/tf/variable_scope">tf.variable_scope</a> to share variables between training and inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[40]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span>
                   <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                   <span class="n">rnn_size</span><span class="p">,</span>
                   <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create decoding layer</span>
<span class="sd">    :param dec_input: Decoder input</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param target_vocab_size: Size of target vocabulary</span>
<span class="sd">    :param batch_size: The size of the batch</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :param decoding_embedding_size: Decoding embedding size</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="k">def</span> <span class="nf">build_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
        <span class="n">lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span>
        <span class="n">lstm_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">lstm_drop</span>

    <span class="n">stacked_lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">build_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
    
    <span class="n">dec_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">]))</span>
    <span class="n">dec_embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">)</span>

    <span class="n">dense_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span>
                    <span class="n">target_vocab_size</span><span class="p">,</span>
                    <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span><span class="n">mean</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
                  <span class="p">)</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;decode&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
        <span class="n">trainig_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer_train</span><span class="p">(</span>
            <span class="n">encoder_state</span><span class="p">,</span> 
            <span class="n">stacked_lstm</span><span class="p">,</span> 
            <span class="n">dec_embed_input</span><span class="p">,</span> 
            <span class="n">target_sequence_length</span><span class="p">,</span> 
            <span class="n">max_target_sequence_length</span><span class="p">,</span> 
            <span class="n">dense_layer</span><span class="p">,</span> 
            <span class="n">keep_prob</span>
        <span class="p">)</span>
        <span class="n">scope</span><span class="o">.</span><span class="n">reuse_variables</span><span class="p">()</span>
        <span class="n">inference_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer_infer</span><span class="p">(</span>
            <span class="n">encoder_state</span><span class="p">,</span> 
            <span class="n">stacked_lstm</span><span class="p">,</span> 
            <span class="n">dec_embeddings</span><span class="p">,</span> 
            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">],</span> 
            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">],</span> 
            <span class="n">max_target_sequence_length</span><span class="p">,</span> 
            <span class="n">target_vocab_size</span><span class="p">,</span> 
            <span class="n">dense_layer</span><span class="p">,</span> 
            <span class="n">batch_size</span><span class="p">,</span> 
            <span class="n">keep_prob</span>
        <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">trainig_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer</span><span class="p">(</span><span class="n">decoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h3><p>Apply the functions you implemented above to:</p>
<ul>
<li>Encode the input using your <code>encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob,  source_sequence_length, source_vocab_size, encoding_embedding_size)</code>.</li>
<li>Process target data using your <code>process_decoder_input(target_data, target_vocab_to_int, batch_size)</code> function.</li>
<li>Decode the encoded input using your <code>decoding_layer(dec_input, enc_state, target_sequence_length, max_target_sentence_length, rnn_size, num_layers, target_vocab_to_int, target_vocab_size, batch_size, keep_prob, dec_embedding_size)</code> function.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[41]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">seq2seq_model</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">target_data</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                  <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span>
                  <span class="n">max_target_sentence_length</span><span class="p">,</span>
                  <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                  <span class="n">enc_embedding_size</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">,</span>
                  <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build the Sequence-to-Sequence part of the neural network</span>
<span class="sd">    :param input_data: Input placeholder</span>
<span class="sd">    :param target_data: Target placeholder</span>
<span class="sd">    :param keep_prob: Dropout keep probability placeholder</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :param source_sequence_length: Sequence Lengths of source sequences in the batch</span>
<span class="sd">    :param target_sequence_length: Sequence Lengths of target sequences in the batch</span>
<span class="sd">    :param source_vocab_size: Source vocabulary size</span>
<span class="sd">    :param target_vocab_size: Target vocabulary size</span>
<span class="sd">    :param enc_embedding_size: Decoder embedding size</span>
<span class="sd">    :param dec_embedding_size: Encoder embedding size</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">encoding_layer</span><span class="p">(</span>
                        <span class="n">input_data</span><span class="p">,</span> 
                        <span class="n">rnn_size</span><span class="p">,</span> 
                        <span class="n">num_layers</span><span class="p">,</span> 
                        <span class="n">keep_prob</span><span class="p">,</span> 
                        <span class="n">source_sequence_length</span><span class="p">,</span> 
                        <span class="n">source_vocab_size</span><span class="p">,</span> 
                        <span class="n">enc_embedding_size</span>
                    <span class="p">)</span>
    
    <span class="n">processed_input</span> <span class="o">=</span> <span class="n">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    
    <span class="n">trainig_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer</span><span class="p">(</span>
                                                            <span class="n">processed_input</span><span class="p">,</span> 
                                                            <span class="n">state</span><span class="p">,</span>
                                                            <span class="n">target_sequence_length</span><span class="p">,</span> 
                                                            <span class="n">max_target_sentence_length</span><span class="p">,</span>
                                                            <span class="n">rnn_size</span><span class="p">,</span> 
                                                            <span class="n">num_layers</span><span class="p">,</span> 
                                                            <span class="n">target_vocab_to_int</span><span class="p">,</span> 
                                                            <span class="n">target_vocab_size</span><span class="p">,</span>
                                                            <span class="n">batch_size</span><span class="p">,</span> 
                                                            <span class="n">keep_prob</span><span class="p">,</span> 
                                                            <span class="n">dec_embedding_size</span>
                                                       <span class="p">)</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">trainig_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_seq2seq_model</span><span class="p">(</span><span class="n">seq2seq_model</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Network-Training">Neural Network Training<a class="anchor-link" href="#Neural-Network-Training">&#182;</a></h2><h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>epochs</code> to the number of epochs.</li>
<li>Set <code>batch_size</code> to the batch size.</li>
<li>Set <code>rnn_size</code> to the size of the RNNs.</li>
<li>Set <code>num_layers</code> to the number of layers.</li>
<li>Set <code>encoding_embedding_size</code> to the size of the embedding for the encoder.</li>
<li>Set <code>decoding_embedding_size</code> to the size of the embedding for the decoder.</li>
<li>Set <code>learning_rate</code> to the learning rate.</li>
<li>Set <code>keep_probability</code> to the Dropout keep probability</li>
<li>Set <code>display_step</code> to state how many steps between each debug output statement</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[58]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Number of Epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1"># Batch Size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="c1"># RNN Size</span>
<span class="n">rnn_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># Number of Layers</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Embedding Size</span>
<span class="n">encoding_embedding_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">decoding_embedding_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># Learning Rate</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="c1"># Dropout Keep Probability</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="mf">0.75</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Graph">Build the Graph<a class="anchor-link" href="#Build-the-Graph">&#182;</a></h3><p>Build the graph using the neural network you implemented.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[59]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="s1">&#39;checkpoints/dev&#39;</span>
<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">max_target_sentence_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_int_text</span><span class="p">])</span>

<span class="n">train_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">train_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">input_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">model_inputs</span><span class="p">()</span>

    <span class="c1">#sequence_length = tf.placeholder_with_default(max_target_sentence_length, None, name=&#39;sequence_length&#39;)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

    <span class="n">train_logits</span><span class="p">,</span> <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">seq2seq_model</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                                                   <span class="n">targets</span><span class="p">,</span>
                                                   <span class="n">keep_prob</span><span class="p">,</span>
                                                   <span class="n">batch_size</span><span class="p">,</span>
                                                   <span class="n">source_sequence_length</span><span class="p">,</span>
                                                   <span class="n">target_sequence_length</span><span class="p">,</span>
                                                   <span class="n">max_target_sequence_length</span><span class="p">,</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">),</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">),</span>
                                                   <span class="n">encoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">decoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">rnn_size</span><span class="p">,</span>
                                                   <span class="n">num_layers</span><span class="p">,</span>
                                                   <span class="n">target_vocab_to_int</span><span class="p">)</span>


    <span class="n">training_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">train_logits</span><span class="o">.</span><span class="n">rnn_output</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;logits&#39;</span><span class="p">)</span>
    <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">inference_logits</span><span class="o">.</span><span class="n">sample_id</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">)</span>

    <span class="n">masks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sequence_mask</span><span class="p">(</span><span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;masks&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;optimization&quot;</span><span class="p">):</span>
        <span class="c1"># Loss function</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span>
            <span class="n">training_logits</span><span class="p">,</span>
            <span class="n">targets</span><span class="p">,</span>
            <span class="n">masks</span><span class="p">)</span>

        <span class="c1"># Optimizer</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

        <span class="c1"># Gradient Clipping</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
        <span class="n">capped_gradients</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">gradients</span> <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_gradients</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Batch and pad the source and target sequences</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[60]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">pad_sentence_batch</span><span class="p">(</span><span class="n">sentence_batch</span><span class="p">,</span> <span class="n">pad_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pad sentences with &lt;PAD&gt; so that each sentence of a batch has the same length&quot;&quot;&quot;</span>
    <span class="n">max_sentence</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">+</span> <span class="p">[</span><span class="n">pad_int</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_sentence</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">get_batches</span><span class="p">(</span><span class="n">sources</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Batch targets, sources, and the lengths of their sentences together&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">batch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sources</span><span class="p">)</span><span class="o">//</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">start_i</span> <span class="o">=</span> <span class="n">batch_i</span> <span class="o">*</span> <span class="n">batch_size</span>

        <span class="c1"># Slice the right amount for the batch</span>
        <span class="n">sources_batch</span> <span class="o">=</span> <span class="n">sources</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">targets_batch</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>

        <span class="c1"># Pad</span>
        <span class="n">pad_sources_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">sources_batch</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">))</span>
        <span class="n">pad_targets_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">targets_batch</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">))</span>

        <span class="c1"># Need the lengths for the _lengths parameters</span>
        <span class="n">pad_targets_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">pad_targets_batch</span><span class="p">:</span>
            <span class="n">pad_targets_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">))</span>

        <span class="n">pad_source_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">pad_sources_batch</span><span class="p">:</span>
            <span class="n">pad_source_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">source</span><span class="p">))</span>

        <span class="k">yield</span> <span class="n">pad_sources_batch</span><span class="p">,</span> <span class="n">pad_targets_batch</span><span class="p">,</span> <span class="n">pad_source_lengths</span><span class="p">,</span> <span class="n">pad_targets_lengths</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train">Train<a class="anchor-link" href="#Train">&#182;</a></h3><p>Train the neural network on the preprocessed data. If you have a hard time getting a good loss, check the forms to see if anyone is having the same problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[61]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate accuracy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_seq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">logits</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">))</span>

<span class="c1"># Split data to training and validation sets</span>
<span class="n">train_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">train_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">valid_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="n">valid_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="p">(</span><span class="n">valid_sources_batch</span><span class="p">,</span> <span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">valid_sources_lengths</span><span class="p">,</span> <span class="n">valid_targets_lengths</span> <span class="p">)</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">get_batches</span><span class="p">(</span><span class="n">valid_source</span><span class="p">,</span>
                                                                                                             <span class="n">valid_target</span><span class="p">,</span>
                                                                                                             <span class="n">batch_size</span><span class="p">,</span>
                                                                                                             <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                                                                                                             <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">]))</span>                                                                                                  
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">train_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_i</span><span class="p">,</span> <span class="p">(</span><span class="n">source_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">,</span> <span class="n">sources_lengths</span><span class="p">,</span> <span class="n">targets_lengths</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="n">get_batches</span><span class="p">(</span><span class="n">train_source</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">])):</span>

            <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="p">[</span><span class="n">train_op</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                 <span class="n">targets</span><span class="p">:</span> <span class="n">target_batch</span><span class="p">,</span>
                 <span class="n">lr</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
                 <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                 <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_probability</span><span class="p">})</span>


            <span class="k">if</span> <span class="n">batch_i</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">batch_i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>


                <span class="n">batch_train_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>


                <span class="n">batch_valid_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">valid_sources_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">valid_sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">valid_targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>

                <span class="n">train_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">batch_train_logits</span><span class="p">)</span>

                <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">batch_valid_logits</span><span class="p">)</span>

                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;3}</span><span class="s1"> Batch </span><span class="si">{:&gt;4}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> - Train Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Validation Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Loss: </span><span class="si">{:&gt;6.4f}</span><span class="s1">&#39;</span>
                      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_i</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_int_text</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">valid_acc</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>

    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model Trained and Saved&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch   0 Batch    1/269 - Train Accuracy: 0.2338, Validation Accuracy: 0.3101, Loss: 5.6644
Epoch   0 Batch    2/269 - Train Accuracy: 0.2655, Validation Accuracy: 0.3096, Loss: 5.4059
Epoch   0 Batch    3/269 - Train Accuracy: 0.2444, Validation Accuracy: 0.3096, Loss: 5.2049
Epoch   0 Batch    4/269 - Train Accuracy: 0.2317, Validation Accuracy: 0.3096, Loss: 5.0020
Epoch   0 Batch    5/269 - Train Accuracy: 0.2324, Validation Accuracy: 0.3096, Loss: 4.8104
Epoch   0 Batch    6/269 - Train Accuracy: 0.2785, Validation Accuracy: 0.3096, Loss: 4.4671
Epoch   0 Batch    7/269 - Train Accuracy: 0.2767, Validation Accuracy: 0.3099, Loss: 4.3519
Epoch   0 Batch    8/269 - Train Accuracy: 0.2424, Validation Accuracy: 0.3108, Loss: 4.4426
Epoch   0 Batch    9/269 - Train Accuracy: 0.2797, Validation Accuracy: 0.3220, Loss: 4.2361
Epoch   0 Batch   10/269 - Train Accuracy: 0.2625, Validation Accuracy: 0.3348, Loss: 4.3005
Epoch   0 Batch   11/269 - Train Accuracy: 0.3052, Validation Accuracy: 0.3410, Loss: 4.0329
Epoch   0 Batch   12/269 - Train Accuracy: 0.2791, Validation Accuracy: 0.3421, Loss: 4.0539
Epoch   0 Batch   13/269 - Train Accuracy: 0.3443, Validation Accuracy: 0.3427, Loss: 3.6995
Epoch   0 Batch   14/269 - Train Accuracy: 0.3054, Validation Accuracy: 0.3427, Loss: 3.8143
Epoch   0 Batch   15/269 - Train Accuracy: 0.2961, Validation Accuracy: 0.3427, Loss: 3.7784
Epoch   0 Batch   16/269 - Train Accuracy: 0.3118, Validation Accuracy: 0.3427, Loss: 3.6643
Epoch   0 Batch   17/269 - Train Accuracy: 0.3022, Validation Accuracy: 0.3428, Loss: 3.6154
Epoch   0 Batch   18/269 - Train Accuracy: 0.2712, Validation Accuracy: 0.3428, Loss: 3.7127
Epoch   0 Batch   19/269 - Train Accuracy: 0.3412, Validation Accuracy: 0.3427, Loss: 3.3949
Epoch   0 Batch   20/269 - Train Accuracy: 0.2751, Validation Accuracy: 0.3427, Loss: 3.6045
Epoch   0 Batch   21/269 - Train Accuracy: 0.2912, Validation Accuracy: 0.3563, Loss: 3.5850
Epoch   0 Batch   22/269 - Train Accuracy: 0.3436, Validation Accuracy: 0.3691, Loss: 3.4049
Epoch   0 Batch   23/269 - Train Accuracy: 0.3537, Validation Accuracy: 0.3717, Loss: 3.3603
Epoch   0 Batch   24/269 - Train Accuracy: 0.3064, Validation Accuracy: 0.3723, Loss: 3.4897
Epoch   0 Batch   25/269 - Train Accuracy: 0.3109, Validation Accuracy: 0.3723, Loss: 3.4571
Epoch   0 Batch   26/269 - Train Accuracy: 0.3743, Validation Accuracy: 0.3723, Loss: 3.1456
Epoch   0 Batch   27/269 - Train Accuracy: 0.3419, Validation Accuracy: 0.3742, Loss: 3.2757
Epoch   0 Batch   28/269 - Train Accuracy: 0.2989, Validation Accuracy: 0.3744, Loss: 3.4224
Epoch   0 Batch   29/269 - Train Accuracy: 0.3087, Validation Accuracy: 0.3753, Loss: 3.3557
Epoch   0 Batch   30/269 - Train Accuracy: 0.3383, Validation Accuracy: 0.3752, Loss: 3.1909
Epoch   0 Batch   31/269 - Train Accuracy: 0.3477, Validation Accuracy: 0.3750, Loss: 3.1542
Epoch   0 Batch   32/269 - Train Accuracy: 0.3448, Validation Accuracy: 0.3809, Loss: 3.1590
Epoch   0 Batch   33/269 - Train Accuracy: 0.3541, Validation Accuracy: 0.3823, Loss: 3.0755
Epoch   0 Batch   34/269 - Train Accuracy: 0.3519, Validation Accuracy: 0.3828, Loss: 3.0907
Epoch   0 Batch   35/269 - Train Accuracy: 0.3601, Validation Accuracy: 0.3880, Loss: 3.0686
Epoch   0 Batch   36/269 - Train Accuracy: 0.3588, Validation Accuracy: 0.3882, Loss: 3.0620
Epoch   0 Batch   37/269 - Train Accuracy: 0.3618, Validation Accuracy: 0.3891, Loss: 3.0368
Epoch   0 Batch   38/269 - Train Accuracy: 0.3590, Validation Accuracy: 0.3901, Loss: 3.0350
Epoch   0 Batch   39/269 - Train Accuracy: 0.3583, Validation Accuracy: 0.3903, Loss: 2.9960
Epoch   0 Batch   40/269 - Train Accuracy: 0.3290, Validation Accuracy: 0.3904, Loss: 3.1215
Epoch   0 Batch   41/269 - Train Accuracy: 0.3689, Validation Accuracy: 0.4007, Loss: 2.9886
Epoch   0 Batch   42/269 - Train Accuracy: 0.4070, Validation Accuracy: 0.4112, Loss: 2.8425
Epoch   0 Batch   43/269 - Train Accuracy: 0.3594, Validation Accuracy: 0.4110, Loss: 3.0587
Epoch   0 Batch   44/269 - Train Accuracy: 0.3922, Validation Accuracy: 0.4134, Loss: 2.9316
Epoch   0 Batch   45/269 - Train Accuracy: 0.3534, Validation Accuracy: 0.4127, Loss: 3.0532
Epoch   0 Batch   46/269 - Train Accuracy: 0.3459, Validation Accuracy: 0.4100, Loss: 3.0673
Epoch   0 Batch   47/269 - Train Accuracy: 0.4062, Validation Accuracy: 0.4094, Loss: 2.7612
Epoch   0 Batch   48/269 - Train Accuracy: 0.3904, Validation Accuracy: 0.4173, Loss: 2.8603
Epoch   0 Batch   49/269 - Train Accuracy: 0.3656, Validation Accuracy: 0.4229, Loss: 2.9958
Epoch   0 Batch   50/269 - Train Accuracy: 0.3728, Validation Accuracy: 0.4245, Loss: 2.9811
Epoch   0 Batch   51/269 - Train Accuracy: 0.3996, Validation Accuracy: 0.4323, Loss: 2.8749
Epoch   0 Batch   52/269 - Train Accuracy: 0.3997, Validation Accuracy: 0.4286, Loss: 2.8235
Epoch   0 Batch   53/269 - Train Accuracy: 0.3741, Validation Accuracy: 0.4308, Loss: 2.9463
Epoch   0 Batch   54/269 - Train Accuracy: 0.3812, Validation Accuracy: 0.4345, Loss: 2.9390
Epoch   0 Batch   55/269 - Train Accuracy: 0.4014, Validation Accuracy: 0.4348, Loss: 2.8032
Epoch   0 Batch   56/269 - Train Accuracy: 0.4109, Validation Accuracy: 0.4362, Loss: 2.7870
Epoch   0 Batch   57/269 - Train Accuracy: 0.4077, Validation Accuracy: 0.4359, Loss: 2.7805
Epoch   0 Batch   58/269 - Train Accuracy: 0.4118, Validation Accuracy: 0.4365, Loss: 2.7652
Epoch   0 Batch   59/269 - Train Accuracy: 0.4054, Validation Accuracy: 0.4356, Loss: 2.7476
Epoch   0 Batch   60/269 - Train Accuracy: 0.4287, Validation Accuracy: 0.4462, Loss: 2.6637
Epoch   0 Batch   61/269 - Train Accuracy: 0.4447, Validation Accuracy: 0.4449, Loss: 2.6033
Epoch   0 Batch   62/269 - Train Accuracy: 0.4490, Validation Accuracy: 0.4513, Loss: 2.6292
Epoch   0 Batch   63/269 - Train Accuracy: 0.4163, Validation Accuracy: 0.4464, Loss: 2.7122
Epoch   0 Batch   64/269 - Train Accuracy: 0.4181, Validation Accuracy: 0.4521, Loss: 2.7226
Epoch   0 Batch   65/269 - Train Accuracy: 0.4273, Validation Accuracy: 0.4536, Loss: 2.6748
Epoch   0 Batch   66/269 - Train Accuracy: 0.4419, Validation Accuracy: 0.4513, Loss: 2.6090
Epoch   0 Batch   67/269 - Train Accuracy: 0.4236, Validation Accuracy: 0.4542, Loss: 2.6920
Epoch   0 Batch   68/269 - Train Accuracy: 0.4177, Validation Accuracy: 0.4503, Loss: 2.6637
Epoch   0 Batch   69/269 - Train Accuracy: 0.3884, Validation Accuracy: 0.4521, Loss: 2.8187
Epoch   0 Batch   70/269 - Train Accuracy: 0.4371, Validation Accuracy: 0.4575, Loss: 2.6338
Epoch   0 Batch   71/269 - Train Accuracy: 0.4089, Validation Accuracy: 0.4599, Loss: 2.7710
Epoch   0 Batch   72/269 - Train Accuracy: 0.4565, Validation Accuracy: 0.4632, Loss: 2.5331
Epoch   0 Batch   73/269 - Train Accuracy: 0.4355, Validation Accuracy: 0.4580, Loss: 2.6260
Epoch   0 Batch   74/269 - Train Accuracy: 0.4146, Validation Accuracy: 0.4599, Loss: 2.7058
Epoch   0 Batch   75/269 - Train Accuracy: 0.4205, Validation Accuracy: 0.4468, Loss: 2.5920
Epoch   0 Batch   76/269 - Train Accuracy: 0.4172, Validation Accuracy: 0.4565, Loss: 2.6448
Epoch   0 Batch   77/269 - Train Accuracy: 0.4131, Validation Accuracy: 0.4346, Loss: 2.5910
Epoch   0 Batch   78/269 - Train Accuracy: 0.4348, Validation Accuracy: 0.4659, Loss: 2.6228
Epoch   0 Batch   79/269 - Train Accuracy: 0.4350, Validation Accuracy: 0.4664, Loss: 2.5927
Epoch   0 Batch   80/269 - Train Accuracy: 0.4315, Validation Accuracy: 0.4516, Loss: 2.5046
Epoch   0 Batch   81/269 - Train Accuracy: 0.4378, Validation Accuracy: 0.4635, Loss: 2.5730
Epoch   0 Batch   82/269 - Train Accuracy: 0.4490, Validation Accuracy: 0.4633, Loss: 2.4960
Epoch   0 Batch   83/269 - Train Accuracy: 0.4325, Validation Accuracy: 0.4515, Loss: 2.4997
Epoch   0 Batch   84/269 - Train Accuracy: 0.4385, Validation Accuracy: 0.4634, Loss: 2.5250
Epoch   0 Batch   85/269 - Train Accuracy: 0.4332, Validation Accuracy: 0.4697, Loss: 2.5379
Epoch   0 Batch   86/269 - Train Accuracy: 0.4338, Validation Accuracy: 0.4608, Loss: 2.5369
Epoch   0 Batch   87/269 - Train Accuracy: 0.4074, Validation Accuracy: 0.4724, Loss: 2.6810
Epoch   0 Batch   88/269 - Train Accuracy: 0.4505, Validation Accuracy: 0.4681, Loss: 2.4772
Epoch   0 Batch   89/269 - Train Accuracy: 0.4439, Validation Accuracy: 0.4675, Loss: 2.4681
Epoch   0 Batch   90/269 - Train Accuracy: 0.4063, Validation Accuracy: 0.4630, Loss: 2.6113
Epoch   0 Batch   91/269 - Train Accuracy: 0.4395, Validation Accuracy: 0.4683, Loss: 2.4639
Epoch   0 Batch   92/269 - Train Accuracy: 0.4462, Validation Accuracy: 0.4732, Loss: 2.4701
Epoch   0 Batch   93/269 - Train Accuracy: 0.4605, Validation Accuracy: 0.4632, Loss: 2.3688
Epoch   0 Batch   94/269 - Train Accuracy: 0.4510, Validation Accuracy: 0.4781, Loss: 2.4615
Epoch   0 Batch   95/269 - Train Accuracy: 0.4564, Validation Accuracy: 0.4801, Loss: 2.4443
Epoch   0 Batch   96/269 - Train Accuracy: 0.4402, Validation Accuracy: 0.4682, Loss: 2.4307
Epoch   0 Batch   97/269 - Train Accuracy: 0.4592, Validation Accuracy: 0.4826, Loss: 2.4234
Epoch   0 Batch   98/269 - Train Accuracy: 0.4569, Validation Accuracy: 0.4751, Loss: 2.3777
Epoch   0 Batch   99/269 - Train Accuracy: 0.4226, Validation Accuracy: 0.4755, Loss: 2.5486
Epoch   0 Batch  100/269 - Train Accuracy: 0.4781, Validation Accuracy: 0.4800, Loss: 2.3547
Epoch   0 Batch  101/269 - Train Accuracy: 0.4224, Validation Accuracy: 0.4777, Loss: 2.5113
Epoch   0 Batch  102/269 - Train Accuracy: 0.4547, Validation Accuracy: 0.4801, Loss: 2.3901
Epoch   0 Batch  103/269 - Train Accuracy: 0.4581, Validation Accuracy: 0.4798, Loss: 2.3647
Epoch   0 Batch  104/269 - Train Accuracy: 0.4409, Validation Accuracy: 0.4748, Loss: 2.3775
Epoch   0 Batch  105/269 - Train Accuracy: 0.4461, Validation Accuracy: 0.4776, Loss: 2.3870
Epoch   0 Batch  106/269 - Train Accuracy: 0.4461, Validation Accuracy: 0.4765, Loss: 2.3778
Epoch   0 Batch  107/269 - Train Accuracy: 0.4118, Validation Accuracy: 0.4767, Loss: 2.5049
Epoch   0 Batch  108/269 - Train Accuracy: 0.4501, Validation Accuracy: 0.4792, Loss: 2.3525
Epoch   0 Batch  109/269 - Train Accuracy: 0.4516, Validation Accuracy: 0.4822, Loss: 2.3574
Epoch   0 Batch  110/269 - Train Accuracy: 0.4627, Validation Accuracy: 0.4894, Loss: 2.3454
Epoch   0 Batch  111/269 - Train Accuracy: 0.4169, Validation Accuracy: 0.4756, Loss: 2.4648
Epoch   0 Batch  112/269 - Train Accuracy: 0.4652, Validation Accuracy: 0.4933, Loss: 2.3074
Epoch   0 Batch  113/269 - Train Accuracy: 0.4859, Validation Accuracy: 0.4910, Loss: 2.2084
Epoch   0 Batch  114/269 - Train Accuracy: 0.4583, Validation Accuracy: 0.4886, Loss: 2.3033
Epoch   0 Batch  115/269 - Train Accuracy: 0.4386, Validation Accuracy: 0.4925, Loss: 2.3968
Epoch   0 Batch  116/269 - Train Accuracy: 0.4728, Validation Accuracy: 0.4948, Loss: 2.2928
Epoch   0 Batch  117/269 - Train Accuracy: 0.4621, Validation Accuracy: 0.4951, Loss: 2.3050
Epoch   0 Batch  118/269 - Train Accuracy: 0.4747, Validation Accuracy: 0.4863, Loss: 2.2130
Epoch   0 Batch  119/269 - Train Accuracy: 0.4597, Validation Accuracy: 0.4979, Loss: 2.3623
Epoch   0 Batch  120/269 - Train Accuracy: 0.4506, Validation Accuracy: 0.5011, Loss: 2.3656
Epoch   0 Batch  121/269 - Train Accuracy: 0.4674, Validation Accuracy: 0.4962, Loss: 2.2486
Epoch   0 Batch  122/269 - Train Accuracy: 0.4852, Validation Accuracy: 0.5025, Loss: 2.2169
Epoch   0 Batch  123/269 - Train Accuracy: 0.4510, Validation Accuracy: 0.5018, Loss: 2.3587
Epoch   0 Batch  124/269 - Train Accuracy: 0.4699, Validation Accuracy: 0.4976, Loss: 2.2248
Epoch   0 Batch  125/269 - Train Accuracy: 0.4721, Validation Accuracy: 0.4997, Loss: 2.2061
Epoch   0 Batch  126/269 - Train Accuracy: 0.4886, Validation Accuracy: 0.5023, Loss: 2.1800
Epoch   0 Batch  127/269 - Train Accuracy: 0.4520, Validation Accuracy: 0.5004, Loss: 2.3214
Epoch   0 Batch  128/269 - Train Accuracy: 0.4846, Validation Accuracy: 0.4998, Loss: 2.1774
Epoch   0 Batch  129/269 - Train Accuracy: 0.4772, Validation Accuracy: 0.5059, Loss: 2.2106
Epoch   0 Batch  130/269 - Train Accuracy: 0.4476, Validation Accuracy: 0.5073, Loss: 2.3387
Epoch   0 Batch  131/269 - Train Accuracy: 0.4534, Validation Accuracy: 0.4975, Loss: 2.2646
Epoch   0 Batch  132/269 - Train Accuracy: 0.4783, Validation Accuracy: 0.5069, Loss: 2.1914
Epoch   0 Batch  133/269 - Train Accuracy: 0.4838, Validation Accuracy: 0.5065, Loss: 2.1576
Epoch   0 Batch  134/269 - Train Accuracy: 0.4354, Validation Accuracy: 0.4941, Loss: 2.2378
Epoch   0 Batch  135/269 - Train Accuracy: 0.4456, Validation Accuracy: 0.5039, Loss: 2.3052
Epoch   0 Batch  136/269 - Train Accuracy: 0.4578, Validation Accuracy: 0.5094, Loss: 2.2608
Epoch   0 Batch  137/269 - Train Accuracy: 0.4475, Validation Accuracy: 0.4943, Loss: 2.2308
Epoch   0 Batch  138/269 - Train Accuracy: 0.4697, Validation Accuracy: 0.5077, Loss: 2.1815
Epoch   0 Batch  139/269 - Train Accuracy: 0.4940, Validation Accuracy: 0.5069, Loss: 2.0815
Epoch   0 Batch  140/269 - Train Accuracy: 0.4732, Validation Accuracy: 0.4959, Loss: 2.0954
Epoch   0 Batch  141/269 - Train Accuracy: 0.4754, Validation Accuracy: 0.5072, Loss: 2.1401
Epoch   0 Batch  142/269 - Train Accuracy: 0.4874, Validation Accuracy: 0.5080, Loss: 2.0683
Epoch   0 Batch  143/269 - Train Accuracy: 0.4693, Validation Accuracy: 0.4954, Loss: 2.0903
Epoch   0 Batch  144/269 - Train Accuracy: 0.4888, Validation Accuracy: 0.5097, Loss: 2.0655
Epoch   0 Batch  145/269 - Train Accuracy: 0.4804, Validation Accuracy: 0.5102, Loss: 2.0713
Epoch   0 Batch  146/269 - Train Accuracy: 0.4846, Validation Accuracy: 0.5070, Loss: 2.0339
Epoch   0 Batch  147/269 - Train Accuracy: 0.5122, Validation Accuracy: 0.5112, Loss: 1.9641
Epoch   0 Batch  148/269 - Train Accuracy: 0.4858, Validation Accuracy: 0.5149, Loss: 2.0860
Epoch   0 Batch  149/269 - Train Accuracy: 0.4842, Validation Accuracy: 0.5028, Loss: 2.0252
Epoch   0 Batch  150/269 - Train Accuracy: 0.4886, Validation Accuracy: 0.5134, Loss: 2.0351
Epoch   0 Batch  151/269 - Train Accuracy: 0.5162, Validation Accuracy: 0.5119, Loss: 1.9179
Epoch   0 Batch  152/269 - Train Accuracy: 0.4756, Validation Accuracy: 0.5044, Loss: 2.0156
Epoch   0 Batch  153/269 - Train Accuracy: 0.4976, Validation Accuracy: 0.5132, Loss: 1.9979
Epoch   0 Batch  154/269 - Train Accuracy: 0.4463, Validation Accuracy: 0.5037, Loss: 2.1007
Epoch   0 Batch  155/269 - Train Accuracy: 0.5136, Validation Accuracy: 0.5039, Loss: 1.8754
Epoch   0 Batch  156/269 - Train Accuracy: 0.4735, Validation Accuracy: 0.5127, Loss: 2.0267
Epoch   0 Batch  157/269 - Train Accuracy: 0.4844, Validation Accuracy: 0.5101, Loss: 1.9615
Epoch   0 Batch  158/269 - Train Accuracy: 0.4752, Validation Accuracy: 0.4994, Loss: 1.9425
Epoch   0 Batch  159/269 - Train Accuracy: 0.4929, Validation Accuracy: 0.5097, Loss: 1.9690
Epoch   0 Batch  160/269 - Train Accuracy: 0.4798, Validation Accuracy: 0.4992, Loss: 1.9401
Epoch   0 Batch  161/269 - Train Accuracy: 0.4760, Validation Accuracy: 0.5091, Loss: 1.9550
Epoch   0 Batch  162/269 - Train Accuracy: 0.4914, Validation Accuracy: 0.5140, Loss: 1.9160
Epoch   0 Batch  163/269 - Train Accuracy: 0.4977, Validation Accuracy: 0.5127, Loss: 1.9005
Epoch   0 Batch  164/269 - Train Accuracy: 0.4923, Validation Accuracy: 0.5178, Loss: 1.8993
Epoch   0 Batch  165/269 - Train Accuracy: 0.4570, Validation Accuracy: 0.5169, Loss: 1.9681
Epoch   0 Batch  166/269 - Train Accuracy: 0.5255, Validation Accuracy: 0.5211, Loss: 1.7807
Epoch   0 Batch  167/269 - Train Accuracy: 0.4965, Validation Accuracy: 0.5191, Loss: 1.8629
Epoch   0 Batch  168/269 - Train Accuracy: 0.4896, Validation Accuracy: 0.5203, Loss: 1.8816
Epoch   0 Batch  169/269 - Train Accuracy: 0.4867, Validation Accuracy: 0.5206, Loss: 1.8510
Epoch   0 Batch  170/269 - Train Accuracy: 0.4966, Validation Accuracy: 0.5184, Loss: 1.8444
Epoch   0 Batch  171/269 - Train Accuracy: 0.4771, Validation Accuracy: 0.5191, Loss: 1.9027
Epoch   0 Batch  172/269 - Train Accuracy: 0.4936, Validation Accuracy: 0.5172, Loss: 1.8348
Epoch   0 Batch  173/269 - Train Accuracy: 0.4994, Validation Accuracy: 0.5210, Loss: 1.8163
Epoch   0 Batch  174/269 - Train Accuracy: 0.4882, Validation Accuracy: 0.5194, Loss: 1.8181
Epoch   0 Batch  175/269 - Train Accuracy: 0.4990, Validation Accuracy: 0.5199, Loss: 1.8221
Epoch   0 Batch  176/269 - Train Accuracy: 0.4870, Validation Accuracy: 0.5316, Loss: 1.8777
Epoch   0 Batch  177/269 - Train Accuracy: 0.5186, Validation Accuracy: 0.5289, Loss: 1.7305
Epoch   0 Batch  178/269 - Train Accuracy: 0.4780, Validation Accuracy: 0.5135, Loss: 1.8419
Epoch   0 Batch  179/269 - Train Accuracy: 0.5070, Validation Accuracy: 0.5299, Loss: 1.7750
Epoch   0 Batch  180/269 - Train Accuracy: 0.5080, Validation Accuracy: 0.5334, Loss: 1.7476
Epoch   0 Batch  181/269 - Train Accuracy: 0.4834, Validation Accuracy: 0.5115, Loss: 1.7536
Epoch   0 Batch  182/269 - Train Accuracy: 0.5113, Validation Accuracy: 0.5350, Loss: 1.7612
Epoch   0 Batch  183/269 - Train Accuracy: 0.5760, Validation Accuracy: 0.5386, Loss: 1.5144
Epoch   0 Batch  184/269 - Train Accuracy: 0.4531, Validation Accuracy: 0.5032, Loss: 1.8105
Epoch   0 Batch  185/269 - Train Accuracy: 0.5171, Validation Accuracy: 0.5330, Loss: 1.7124
Epoch   0 Batch  186/269 - Train Accuracy: 0.4838, Validation Accuracy: 0.5350, Loss: 1.7986
Epoch   0 Batch  187/269 - Train Accuracy: 0.4912, Validation Accuracy: 0.5123, Loss: 1.6741
Epoch   0 Batch  188/269 - Train Accuracy: 0.5091, Validation Accuracy: 0.5200, Loss: 1.6636
Epoch   0 Batch  189/269 - Train Accuracy: 0.5120, Validation Accuracy: 0.5297, Loss: 1.6782
Epoch   0 Batch  190/269 - Train Accuracy: 0.4981, Validation Accuracy: 0.5220, Loss: 1.6735
Epoch   0 Batch  191/269 - Train Accuracy: 0.4953, Validation Accuracy: 0.5143, Loss: 1.6848
Epoch   0 Batch  192/269 - Train Accuracy: 0.5040, Validation Accuracy: 0.5297, Loss: 1.6824
Epoch   0 Batch  193/269 - Train Accuracy: 0.4893, Validation Accuracy: 0.5165, Loss: 1.6676
Epoch   0 Batch  194/269 - Train Accuracy: 0.4967, Validation Accuracy: 0.5192, Loss: 1.6719
Epoch   0 Batch  195/269 - Train Accuracy: 0.5028, Validation Accuracy: 0.5365, Loss: 1.6861
Epoch   0 Batch  196/269 - Train Accuracy: 0.4924, Validation Accuracy: 0.5288, Loss: 1.6485
Epoch   0 Batch  197/269 - Train Accuracy: 0.4611, Validation Accuracy: 0.5162, Loss: 1.7183
Epoch   0 Batch  198/269 - Train Accuracy: 0.4887, Validation Accuracy: 0.5403, Loss: 1.7517
Epoch   0 Batch  199/269 - Train Accuracy: 0.4989, Validation Accuracy: 0.5324, Loss: 1.6716
Epoch   0 Batch  200/269 - Train Accuracy: 0.4779, Validation Accuracy: 0.5179, Loss: 1.6856
Epoch   0 Batch  201/269 - Train Accuracy: 0.5154, Validation Accuracy: 0.5330, Loss: 1.6324
Epoch   0 Batch  202/269 - Train Accuracy: 0.4998, Validation Accuracy: 0.5311, Loss: 1.6351
Epoch   0 Batch  203/269 - Train Accuracy: 0.4730, Validation Accuracy: 0.5222, Loss: 1.6785
Epoch   0 Batch  204/269 - Train Accuracy: 0.4743, Validation Accuracy: 0.5289, Loss: 1.6765
Epoch   0 Batch  205/269 - Train Accuracy: 0.5012, Validation Accuracy: 0.5375, Loss: 1.6047
Epoch   0 Batch  206/269 - Train Accuracy: 0.4669, Validation Accuracy: 0.5207, Loss: 1.6982
Epoch   0 Batch  207/269 - Train Accuracy: 0.5328, Validation Accuracy: 0.5370, Loss: 1.5348
Epoch   0 Batch  208/269 - Train Accuracy: 0.4849, Validation Accuracy: 0.5417, Loss: 1.6786
Epoch   0 Batch  209/269 - Train Accuracy: 0.4759, Validation Accuracy: 0.5218, Loss: 1.6408
Epoch   0 Batch  210/269 - Train Accuracy: 0.5165, Validation Accuracy: 0.5382, Loss: 1.5665
Epoch   0 Batch  211/269 - Train Accuracy: 0.5247, Validation Accuracy: 0.5423, Loss: 1.5649
Epoch   0 Batch  212/269 - Train Accuracy: 0.5136, Validation Accuracy: 0.5239, Loss: 1.5363
Epoch   0 Batch  213/269 - Train Accuracy: 0.5136, Validation Accuracy: 0.5328, Loss: 1.5391
Epoch   0 Batch  214/269 - Train Accuracy: 0.5150, Validation Accuracy: 0.5321, Loss: 1.5491
Epoch   0 Batch  215/269 - Train Accuracy: 0.5318, Validation Accuracy: 0.5230, Loss: 1.4568
Epoch   0 Batch  216/269 - Train Accuracy: 0.4685, Validation Accuracy: 0.5272, Loss: 1.6482
Epoch   0 Batch  217/269 - Train Accuracy: 0.4777, Validation Accuracy: 0.5264, Loss: 1.6056
Epoch   0 Batch  218/269 - Train Accuracy: 0.4930, Validation Accuracy: 0.5306, Loss: 1.6041
Epoch   0 Batch  219/269 - Train Accuracy: 0.4834, Validation Accuracy: 0.5262, Loss: 1.5757
Epoch   0 Batch  220/269 - Train Accuracy: 0.5189, Validation Accuracy: 0.5292, Loss: 1.4639
Epoch   0 Batch  221/269 - Train Accuracy: 0.5181, Validation Accuracy: 0.5317, Loss: 1.5049
Epoch   0 Batch  222/269 - Train Accuracy: 0.5172, Validation Accuracy: 0.5338, Loss: 1.4757
Epoch   0 Batch  223/269 - Train Accuracy: 0.5059, Validation Accuracy: 0.5243, Loss: 1.4697
Epoch   0 Batch  224/269 - Train Accuracy: 0.5135, Validation Accuracy: 0.5257, Loss: 1.5093
Epoch   0 Batch  225/269 - Train Accuracy: 0.4960, Validation Accuracy: 0.5349, Loss: 1.5552
Epoch   0 Batch  226/269 - Train Accuracy: 0.5037, Validation Accuracy: 0.5277, Loss: 1.4933
Epoch   0 Batch  227/269 - Train Accuracy: 0.5720, Validation Accuracy: 0.5290, Loss: 1.3017
Epoch   0 Batch  228/269 - Train Accuracy: 0.5054, Validation Accuracy: 0.5338, Loss: 1.4991
Epoch   0 Batch  229/269 - Train Accuracy: 0.5103, Validation Accuracy: 0.5286, Loss: 1.4721
Epoch   0 Batch  230/269 - Train Accuracy: 0.4884, Validation Accuracy: 0.5226, Loss: 1.4893
Epoch   0 Batch  231/269 - Train Accuracy: 0.4756, Validation Accuracy: 0.5217, Loss: 1.5465
Epoch   0 Batch  232/269 - Train Accuracy: 0.4770, Validation Accuracy: 0.5338, Loss: 1.5367
Epoch   0 Batch  233/269 - Train Accuracy: 0.5100, Validation Accuracy: 0.5322, Loss: 1.4672
Epoch   0 Batch  234/269 - Train Accuracy: 0.4941, Validation Accuracy: 0.5249, Loss: 1.4648
Epoch   0 Batch  235/269 - Train Accuracy: 0.5100, Validation Accuracy: 0.5290, Loss: 1.4567
Epoch   0 Batch  236/269 - Train Accuracy: 0.5014, Validation Accuracy: 0.5277, Loss: 1.4391
Epoch   0 Batch  237/269 - Train Accuracy: 0.4951, Validation Accuracy: 0.5236, Loss: 1.4378
Epoch   0 Batch  238/269 - Train Accuracy: 0.5064, Validation Accuracy: 0.5271, Loss: 1.4416
Epoch   0 Batch  239/269 - Train Accuracy: 0.4867, Validation Accuracy: 0.5082, Loss: 1.4173
Epoch   0 Batch  240/269 - Train Accuracy: 0.5406, Validation Accuracy: 0.5259, Loss: 1.3308
Epoch   0 Batch  241/269 - Train Accuracy: 0.5136, Validation Accuracy: 0.5288, Loss: 1.4173
Epoch   0 Batch  242/269 - Train Accuracy: 0.4882, Validation Accuracy: 0.5192, Loss: 1.4167
Epoch   0 Batch  243/269 - Train Accuracy: 0.5223, Validation Accuracy: 0.5263, Loss: 1.3780
Epoch   0 Batch  244/269 - Train Accuracy: 0.5148, Validation Accuracy: 0.5384, Loss: 1.3999
Epoch   0 Batch  245/269 - Train Accuracy: 0.4596, Validation Accuracy: 0.5053, Loss: 1.4766
Epoch   0 Batch  246/269 - Train Accuracy: 0.5078, Validation Accuracy: 0.5377, Loss: 1.4152
Epoch   0 Batch  247/269 - Train Accuracy: 0.4841, Validation Accuracy: 0.5222, Loss: 1.4469
Epoch   0 Batch  248/269 - Train Accuracy: 0.4737, Validation Accuracy: 0.5059, Loss: 1.3873
Epoch   0 Batch  249/269 - Train Accuracy: 0.5365, Validation Accuracy: 0.5293, Loss: 1.3369
Epoch   0 Batch  250/269 - Train Accuracy: 0.4861, Validation Accuracy: 0.5183, Loss: 1.4272
Epoch   0 Batch  251/269 - Train Accuracy: 0.4953, Validation Accuracy: 0.5133, Loss: 1.3685
Epoch   0 Batch  252/269 - Train Accuracy: 0.4980, Validation Accuracy: 0.5303, Loss: 1.3956
Epoch   0 Batch  253/269 - Train Accuracy: 0.4718, Validation Accuracy: 0.5031, Loss: 1.3849
Epoch   0 Batch  254/269 - Train Accuracy: 0.4827, Validation Accuracy: 0.5125, Loss: 1.3477
Epoch   0 Batch  255/269 - Train Accuracy: 0.5320, Validation Accuracy: 0.5266, Loss: 1.3108
Epoch   0 Batch  256/269 - Train Accuracy: 0.4653, Validation Accuracy: 0.5100, Loss: 1.3915
Epoch   0 Batch  257/269 - Train Accuracy: 0.4830, Validation Accuracy: 0.5194, Loss: 1.3694
Epoch   0 Batch  258/269 - Train Accuracy: 0.4936, Validation Accuracy: 0.5296, Loss: 1.3543
Epoch   0 Batch  259/269 - Train Accuracy: 0.5028, Validation Accuracy: 0.5184, Loss: 1.3446
Epoch   0 Batch  260/269 - Train Accuracy: 0.4716, Validation Accuracy: 0.5165, Loss: 1.4052
Epoch   0 Batch  261/269 - Train Accuracy: 0.4732, Validation Accuracy: 0.5336, Loss: 1.4147
Epoch   0 Batch  262/269 - Train Accuracy: 0.5202, Validation Accuracy: 0.5354, Loss: 1.3462
Epoch   0 Batch  263/269 - Train Accuracy: 0.4845, Validation Accuracy: 0.5206, Loss: 1.3811
Epoch   0 Batch  264/269 - Train Accuracy: 0.4952, Validation Accuracy: 0.5344, Loss: 1.3982
Epoch   0 Batch  265/269 - Train Accuracy: 0.4946, Validation Accuracy: 0.5388, Loss: 1.3620
Epoch   0 Batch  266/269 - Train Accuracy: 0.5053, Validation Accuracy: 0.5243, Loss: 1.3042
Epoch   0 Batch  267/269 - Train Accuracy: 0.4927, Validation Accuracy: 0.5241, Loss: 1.3354
Epoch   1 Batch    1/269 - Train Accuracy: 0.4633, Validation Accuracy: 0.5238, Loss: 1.3507
Epoch   1 Batch    2/269 - Train Accuracy: 0.4962, Validation Accuracy: 0.5351, Loss: 1.3266
Epoch   1 Batch    3/269 - Train Accuracy: 0.4971, Validation Accuracy: 0.5362, Loss: 1.3388
Epoch   1 Batch    4/269 - Train Accuracy: 0.4648, Validation Accuracy: 0.5187, Loss: 1.3406
Epoch   1 Batch    5/269 - Train Accuracy: 0.4690, Validation Accuracy: 0.5247, Loss: 1.3478
Epoch   1 Batch    6/269 - Train Accuracy: 0.5334, Validation Accuracy: 0.5401, Loss: 1.2310
Epoch   1 Batch    7/269 - Train Accuracy: 0.5182, Validation Accuracy: 0.5288, Loss: 1.2641
Epoch   1 Batch    8/269 - Train Accuracy: 0.4883, Validation Accuracy: 0.5289, Loss: 1.3270
Epoch   1 Batch    9/269 - Train Accuracy: 0.5050, Validation Accuracy: 0.5372, Loss: 1.2775
Epoch   1 Batch   10/269 - Train Accuracy: 0.4773, Validation Accuracy: 0.5250, Loss: 1.2989
Epoch   1 Batch   11/269 - Train Accuracy: 0.4982, Validation Accuracy: 0.5273, Loss: 1.2725
Epoch   1 Batch   12/269 - Train Accuracy: 0.4856, Validation Accuracy: 0.5356, Loss: 1.3145
Epoch   1 Batch   13/269 - Train Accuracy: 0.5459, Validation Accuracy: 0.5352, Loss: 1.1705
Epoch   1 Batch   14/269 - Train Accuracy: 0.5052, Validation Accuracy: 0.5354, Loss: 1.2475
Epoch   1 Batch   15/269 - Train Accuracy: 0.4907, Validation Accuracy: 0.5288, Loss: 1.2454
Epoch   1 Batch   16/269 - Train Accuracy: 0.5135, Validation Accuracy: 0.5278, Loss: 1.2509
Epoch   1 Batch   17/269 - Train Accuracy: 0.5073, Validation Accuracy: 0.5281, Loss: 1.2174
Epoch   1 Batch   18/269 - Train Accuracy: 0.4806, Validation Accuracy: 0.5271, Loss: 1.2799
Epoch   1 Batch   19/269 - Train Accuracy: 0.5249, Validation Accuracy: 0.5235, Loss: 1.1662
Epoch   1 Batch   20/269 - Train Accuracy: 0.4995, Validation Accuracy: 0.5249, Loss: 1.2687
Epoch   1 Batch   21/269 - Train Accuracy: 0.4868, Validation Accuracy: 0.5283, Loss: 1.2987
Epoch   1 Batch   22/269 - Train Accuracy: 0.5121, Validation Accuracy: 0.5309, Loss: 1.2054
Epoch   1 Batch   23/269 - Train Accuracy: 0.5189, Validation Accuracy: 0.5275, Loss: 1.2220
Epoch   1 Batch   24/269 - Train Accuracy: 0.4821, Validation Accuracy: 0.5226, Loss: 1.2619
Epoch   1 Batch   25/269 - Train Accuracy: 0.4851, Validation Accuracy: 0.5336, Loss: 1.2668
Epoch   1 Batch   26/269 - Train Accuracy: 0.5404, Validation Accuracy: 0.5364, Loss: 1.1374
Epoch   1 Batch   27/269 - Train Accuracy: 0.5089, Validation Accuracy: 0.5336, Loss: 1.2017
Epoch   1 Batch   28/269 - Train Accuracy: 0.4713, Validation Accuracy: 0.5305, Loss: 1.2748
Epoch   1 Batch   29/269 - Train Accuracy: 0.4975, Validation Accuracy: 0.5358, Loss: 1.2370
Epoch   1 Batch   30/269 - Train Accuracy: 0.5179, Validation Accuracy: 0.5365, Loss: 1.1813
Epoch   1 Batch   31/269 - Train Accuracy: 0.5136, Validation Accuracy: 0.5317, Loss: 1.1778
Epoch   1 Batch   32/269 - Train Accuracy: 0.5077, Validation Accuracy: 0.5339, Loss: 1.1848
Epoch   1 Batch   33/269 - Train Accuracy: 0.5253, Validation Accuracy: 0.5385, Loss: 1.1429
Epoch   1 Batch   34/269 - Train Accuracy: 0.5170, Validation Accuracy: 0.5243, Loss: 1.1792
Epoch   1 Batch   35/269 - Train Accuracy: 0.5192, Validation Accuracy: 0.5282, Loss: 1.1667
Epoch   1 Batch   36/269 - Train Accuracy: 0.5028, Validation Accuracy: 0.5229, Loss: 1.1759
Epoch   1 Batch   37/269 - Train Accuracy: 0.4993, Validation Accuracy: 0.5184, Loss: 1.1767
Epoch   1 Batch   38/269 - Train Accuracy: 0.4942, Validation Accuracy: 0.5200, Loss: 1.1740
Epoch   1 Batch   39/269 - Train Accuracy: 0.5189, Validation Accuracy: 0.5281, Loss: 1.1482
Epoch   1 Batch   40/269 - Train Accuracy: 0.4900, Validation Accuracy: 0.5275, Loss: 1.1953
Epoch   1 Batch   41/269 - Train Accuracy: 0.5139, Validation Accuracy: 0.5312, Loss: 1.1575
Epoch   1 Batch   42/269 - Train Accuracy: 0.5404, Validation Accuracy: 0.5389, Loss: 1.0910
Epoch   1 Batch   43/269 - Train Accuracy: 0.5042, Validation Accuracy: 0.5415, Loss: 1.1820
Epoch   1 Batch   44/269 - Train Accuracy: 0.5320, Validation Accuracy: 0.5371, Loss: 1.1484
Epoch   1 Batch   45/269 - Train Accuracy: 0.4917, Validation Accuracy: 0.5302, Loss: 1.1894
Epoch   1 Batch   46/269 - Train Accuracy: 0.4967, Validation Accuracy: 0.5316, Loss: 1.1889
Epoch   1 Batch   47/269 - Train Accuracy: 0.5355, Validation Accuracy: 0.5301, Loss: 1.0703
Epoch   1 Batch   48/269 - Train Accuracy: 0.5108, Validation Accuracy: 0.5300, Loss: 1.1005
Epoch   1 Batch   49/269 - Train Accuracy: 0.5054, Validation Accuracy: 0.5416, Loss: 1.1676
Epoch   1 Batch   50/269 - Train Accuracy: 0.5034, Validation Accuracy: 0.5403, Loss: 1.1718
Epoch   1 Batch   51/269 - Train Accuracy: 0.5015, Validation Accuracy: 0.5368, Loss: 1.1438
Epoch   1 Batch   52/269 - Train Accuracy: 0.5109, Validation Accuracy: 0.5348, Loss: 1.0958
Epoch   1 Batch   53/269 - Train Accuracy: 0.5004, Validation Accuracy: 0.5442, Loss: 1.1708
Epoch   1 Batch   54/269 - Train Accuracy: 0.5074, Validation Accuracy: 0.5418, Loss: 1.1601
Epoch   1 Batch   55/269 - Train Accuracy: 0.5250, Validation Accuracy: 0.5449, Loss: 1.1024
Epoch   1 Batch   56/269 - Train Accuracy: 0.5380, Validation Accuracy: 0.5453, Loss: 1.1038
Epoch   1 Batch   57/269 - Train Accuracy: 0.5322, Validation Accuracy: 0.5456, Loss: 1.1096
Epoch   1 Batch   58/269 - Train Accuracy: 0.5261, Validation Accuracy: 0.5453, Loss: 1.0991
Epoch   1 Batch   59/269 - Train Accuracy: 0.5337, Validation Accuracy: 0.5453, Loss: 1.0723
Epoch   1 Batch   60/269 - Train Accuracy: 0.5392, Validation Accuracy: 0.5472, Loss: 1.0533
Epoch   1 Batch   61/269 - Train Accuracy: 0.5477, Validation Accuracy: 0.5471, Loss: 1.0341
Epoch   1 Batch   62/269 - Train Accuracy: 0.5449, Validation Accuracy: 0.5490, Loss: 1.0566
Epoch   1 Batch   63/269 - Train Accuracy: 0.5235, Validation Accuracy: 0.5509, Loss: 1.0950
Epoch   1 Batch   64/269 - Train Accuracy: 0.5235, Validation Accuracy: 0.5510, Loss: 1.0735
Epoch   1 Batch   65/269 - Train Accuracy: 0.5342, Validation Accuracy: 0.5497, Loss: 1.0731
Epoch   1 Batch   66/269 - Train Accuracy: 0.5423, Validation Accuracy: 0.5497, Loss: 1.0529
Epoch   1 Batch   67/269 - Train Accuracy: 0.5209, Validation Accuracy: 0.5507, Loss: 1.0908
Epoch   1 Batch   68/269 - Train Accuracy: 0.5101, Validation Accuracy: 0.5481, Loss: 1.0813
Epoch   1 Batch   69/269 - Train Accuracy: 0.5051, Validation Accuracy: 0.5466, Loss: 1.1643
Epoch   1 Batch   70/269 - Train Accuracy: 0.5447, Validation Accuracy: 0.5463, Loss: 1.0677
Epoch   1 Batch   71/269 - Train Accuracy: 0.5039, Validation Accuracy: 0.5428, Loss: 1.1175
Epoch   1 Batch   72/269 - Train Accuracy: 0.5349, Validation Accuracy: 0.5410, Loss: 1.0421
Epoch   1 Batch   73/269 - Train Accuracy: 0.5144, Validation Accuracy: 0.5469, Loss: 1.0911
Epoch   1 Batch   74/269 - Train Accuracy: 0.5279, Validation Accuracy: 0.5474, Loss: 1.0908
Epoch   1 Batch   75/269 - Train Accuracy: 0.5229, Validation Accuracy: 0.5487, Loss: 1.0504
Epoch   1 Batch   76/269 - Train Accuracy: 0.5170, Validation Accuracy: 0.5515, Loss: 1.0813
Epoch   1 Batch   77/269 - Train Accuracy: 0.5444, Validation Accuracy: 0.5467, Loss: 1.0435
Epoch   1 Batch   78/269 - Train Accuracy: 0.5166, Validation Accuracy: 0.5429, Loss: 1.0557
Epoch   1 Batch   79/269 - Train Accuracy: 0.5239, Validation Accuracy: 0.5487, Loss: 1.0420
Epoch   1 Batch   80/269 - Train Accuracy: 0.5533, Validation Accuracy: 0.5508, Loss: 1.0227
Epoch   1 Batch   81/269 - Train Accuracy: 0.5220, Validation Accuracy: 0.5435, Loss: 1.0672
Epoch   1 Batch   82/269 - Train Accuracy: 0.5305, Validation Accuracy: 0.5455, Loss: 1.0104
Epoch   1 Batch   83/269 - Train Accuracy: 0.5416, Validation Accuracy: 0.5480, Loss: 1.0195
Epoch   1 Batch   84/269 - Train Accuracy: 0.5258, Validation Accuracy: 0.5437, Loss: 1.0168
Epoch   1 Batch   85/269 - Train Accuracy: 0.5304, Validation Accuracy: 0.5477, Loss: 1.0376
Epoch   1 Batch   86/269 - Train Accuracy: 0.5119, Validation Accuracy: 0.5481, Loss: 1.0385
Epoch   1 Batch   87/269 - Train Accuracy: 0.4909, Validation Accuracy: 0.5520, Loss: 1.1099
Epoch   1 Batch   88/269 - Train Accuracy: 0.5271, Validation Accuracy: 0.5422, Loss: 1.0244
Epoch   1 Batch   89/269 - Train Accuracy: 0.5428, Validation Accuracy: 0.5514, Loss: 1.0205
Epoch   1 Batch   90/269 - Train Accuracy: 0.4923, Validation Accuracy: 0.5551, Loss: 1.0892
Epoch   1 Batch   91/269 - Train Accuracy: 0.5308, Validation Accuracy: 0.5537, Loss: 1.0085
Epoch   1 Batch   92/269 - Train Accuracy: 0.5370, Validation Accuracy: 0.5549, Loss: 1.0151
Epoch   1 Batch   93/269 - Train Accuracy: 0.5565, Validation Accuracy: 0.5559, Loss: 0.9729
Epoch   1 Batch   94/269 - Train Accuracy: 0.5295, Validation Accuracy: 0.5586, Loss: 1.0314
Epoch   1 Batch   95/269 - Train Accuracy: 0.5370, Validation Accuracy: 0.5542, Loss: 1.0180
Epoch   1 Batch   96/269 - Train Accuracy: 0.5418, Validation Accuracy: 0.5552, Loss: 1.0011
Epoch   1 Batch   97/269 - Train Accuracy: 0.5262, Validation Accuracy: 0.5540, Loss: 1.0058
Epoch   1 Batch   98/269 - Train Accuracy: 0.5481, Validation Accuracy: 0.5510, Loss: 0.9926
Epoch   1 Batch   99/269 - Train Accuracy: 0.5123, Validation Accuracy: 0.5481, Loss: 1.0529
Epoch   1 Batch  100/269 - Train Accuracy: 0.5456, Validation Accuracy: 0.5518, Loss: 0.9795
Epoch   1 Batch  101/269 - Train Accuracy: 0.5062, Validation Accuracy: 0.5510, Loss: 1.0494
Epoch   1 Batch  102/269 - Train Accuracy: 0.5285, Validation Accuracy: 0.5533, Loss: 0.9942
Epoch   1 Batch  103/269 - Train Accuracy: 0.5224, Validation Accuracy: 0.5531, Loss: 0.9938
Epoch   1 Batch  104/269 - Train Accuracy: 0.5230, Validation Accuracy: 0.5574, Loss: 0.9934
Epoch   1 Batch  105/269 - Train Accuracy: 0.5286, Validation Accuracy: 0.5563, Loss: 0.9993
Epoch   1 Batch  106/269 - Train Accuracy: 0.5299, Validation Accuracy: 0.5538, Loss: 0.9914
Epoch   1 Batch  107/269 - Train Accuracy: 0.4977, Validation Accuracy: 0.5555, Loss: 1.0371
Epoch   1 Batch  108/269 - Train Accuracy: 0.5244, Validation Accuracy: 0.5467, Loss: 0.9764
Epoch   1 Batch  109/269 - Train Accuracy: 0.5180, Validation Accuracy: 0.5510, Loss: 1.0038
Epoch   1 Batch  110/269 - Train Accuracy: 0.5312, Validation Accuracy: 0.5522, Loss: 0.9784
Epoch   1 Batch  111/269 - Train Accuracy: 0.5059, Validation Accuracy: 0.5498, Loss: 1.0495
Epoch   1 Batch  112/269 - Train Accuracy: 0.5399, Validation Accuracy: 0.5483, Loss: 0.9701
Epoch   1 Batch  113/269 - Train Accuracy: 0.5539, Validation Accuracy: 0.5561, Loss: 0.9306
Epoch   1 Batch  114/269 - Train Accuracy: 0.5266, Validation Accuracy: 0.5545, Loss: 0.9742
Epoch   1 Batch  115/269 - Train Accuracy: 0.5157, Validation Accuracy: 0.5501, Loss: 1.0028
Epoch   1 Batch  116/269 - Train Accuracy: 0.5317, Validation Accuracy: 0.5487, Loss: 0.9780
Epoch   1 Batch  117/269 - Train Accuracy: 0.5284, Validation Accuracy: 0.5474, Loss: 0.9677
Epoch   1 Batch  118/269 - Train Accuracy: 0.5609, Validation Accuracy: 0.5517, Loss: 0.9420
Epoch   1 Batch  119/269 - Train Accuracy: 0.5265, Validation Accuracy: 0.5563, Loss: 1.0179
Epoch   1 Batch  120/269 - Train Accuracy: 0.5136, Validation Accuracy: 0.5521, Loss: 1.0016
Epoch   1 Batch  121/269 - Train Accuracy: 0.5331, Validation Accuracy: 0.5558, Loss: 0.9480
Epoch   1 Batch  122/269 - Train Accuracy: 0.5456, Validation Accuracy: 0.5597, Loss: 0.9494
Epoch   1 Batch  123/269 - Train Accuracy: 0.5107, Validation Accuracy: 0.5575, Loss: 1.0055
Epoch   1 Batch  124/269 - Train Accuracy: 0.5450, Validation Accuracy: 0.5578, Loss: 0.9356
Epoch   1 Batch  125/269 - Train Accuracy: 0.5462, Validation Accuracy: 0.5574, Loss: 0.9308
Epoch   1 Batch  126/269 - Train Accuracy: 0.5500, Validation Accuracy: 0.5637, Loss: 0.9273
Epoch   1 Batch  127/269 - Train Accuracy: 0.5276, Validation Accuracy: 0.5602, Loss: 0.9929
Epoch   1 Batch  128/269 - Train Accuracy: 0.5683, Validation Accuracy: 0.5652, Loss: 0.9379
Epoch   1 Batch  129/269 - Train Accuracy: 0.5311, Validation Accuracy: 0.5628, Loss: 0.9625
Epoch   1 Batch  130/269 - Train Accuracy: 0.5009, Validation Accuracy: 0.5507, Loss: 1.0027
Epoch   1 Batch  131/269 - Train Accuracy: 0.5199, Validation Accuracy: 0.5546, Loss: 0.9694
Epoch   1 Batch  132/269 - Train Accuracy: 0.5419, Validation Accuracy: 0.5554, Loss: 0.9440
Epoch   1 Batch  133/269 - Train Accuracy: 0.5425, Validation Accuracy: 0.5601, Loss: 0.9208
Epoch   1 Batch  134/269 - Train Accuracy: 0.5091, Validation Accuracy: 0.5542, Loss: 0.9717
Epoch   1 Batch  135/269 - Train Accuracy: 0.5062, Validation Accuracy: 0.5520, Loss: 1.0003
Epoch   1 Batch  136/269 - Train Accuracy: 0.5038, Validation Accuracy: 0.5553, Loss: 0.9970
Epoch   1 Batch  137/269 - Train Accuracy: 0.5370, Validation Accuracy: 0.5609, Loss: 0.9760
Epoch   1 Batch  138/269 - Train Accuracy: 0.5437, Validation Accuracy: 0.5579, Loss: 0.9484
Epoch   1 Batch  139/269 - Train Accuracy: 0.5645, Validation Accuracy: 0.5626, Loss: 0.9115
Epoch   1 Batch  140/269 - Train Accuracy: 0.5608, Validation Accuracy: 0.5620, Loss: 0.9313
Epoch   1 Batch  141/269 - Train Accuracy: 0.5420, Validation Accuracy: 0.5568, Loss: 0.9423
Epoch   1 Batch  142/269 - Train Accuracy: 0.5410, Validation Accuracy: 0.5583, Loss: 0.9049
Epoch   1 Batch  143/269 - Train Accuracy: 0.5538, Validation Accuracy: 0.5579, Loss: 0.9195
Epoch   1 Batch  144/269 - Train Accuracy: 0.5456, Validation Accuracy: 0.5627, Loss: 0.9028
Epoch   1 Batch  145/269 - Train Accuracy: 0.5404, Validation Accuracy: 0.5603, Loss: 0.9174
Epoch   1 Batch  146/269 - Train Accuracy: 0.5337, Validation Accuracy: 0.5572, Loss: 0.9088
Epoch   1 Batch  147/269 - Train Accuracy: 0.5713, Validation Accuracy: 0.5597, Loss: 0.8743
Epoch   1 Batch  148/269 - Train Accuracy: 0.5326, Validation Accuracy: 0.5651, Loss: 0.9315
Epoch   1 Batch  149/269 - Train Accuracy: 0.5580, Validation Accuracy: 0.5702, Loss: 0.9173
Epoch   1 Batch  150/269 - Train Accuracy: 0.5494, Validation Accuracy: 0.5646, Loss: 0.9252
Epoch   1 Batch  151/269 - Train Accuracy: 0.5784, Validation Accuracy: 0.5580, Loss: 0.8719
Epoch   1 Batch  152/269 - Train Accuracy: 0.5444, Validation Accuracy: 0.5728, Loss: 0.9132
Epoch   1 Batch  153/269 - Train Accuracy: 0.5605, Validation Accuracy: 0.5725, Loss: 0.8946
Epoch   1 Batch  154/269 - Train Accuracy: 0.5311, Validation Accuracy: 0.5645, Loss: 0.9369
Epoch   1 Batch  155/269 - Train Accuracy: 0.5561, Validation Accuracy: 0.5539, Loss: 0.8478
Epoch   1 Batch  156/269 - Train Accuracy: 0.5363, Validation Accuracy: 0.5666, Loss: 0.9431
Epoch   1 Batch  157/269 - Train Accuracy: 0.5513, Validation Accuracy: 0.5726, Loss: 0.8954
Epoch   1 Batch  158/269 - Train Accuracy: 0.5613, Validation Accuracy: 0.5724, Loss: 0.8902
Epoch   1 Batch  159/269 - Train Accuracy: 0.5495, Validation Accuracy: 0.5606, Loss: 0.8984
Epoch   1 Batch  160/269 - Train Accuracy: 0.5444, Validation Accuracy: 0.5611, Loss: 0.8939
Epoch   1 Batch  161/269 - Train Accuracy: 0.5409, Validation Accuracy: 0.5679, Loss: 0.8965
Epoch   1 Batch  162/269 - Train Accuracy: 0.5489, Validation Accuracy: 0.5695, Loss: 0.8826
Epoch   1 Batch  163/269 - Train Accuracy: 0.5633, Validation Accuracy: 0.5691, Loss: 0.8803
Epoch   1 Batch  164/269 - Train Accuracy: 0.5528, Validation Accuracy: 0.5669, Loss: 0.8801
Epoch   1 Batch  165/269 - Train Accuracy: 0.5297, Validation Accuracy: 0.5711, Loss: 0.9097
Epoch   1 Batch  166/269 - Train Accuracy: 0.5815, Validation Accuracy: 0.5708, Loss: 0.8376
Epoch   1 Batch  167/269 - Train Accuracy: 0.5622, Validation Accuracy: 0.5726, Loss: 0.8792
Epoch   1 Batch  168/269 - Train Accuracy: 0.5419, Validation Accuracy: 0.5739, Loss: 0.8901
Epoch   1 Batch  169/269 - Train Accuracy: 0.5479, Validation Accuracy: 0.5698, Loss: 0.8798
Epoch   1 Batch  170/269 - Train Accuracy: 0.5527, Validation Accuracy: 0.5701, Loss: 0.8761
Epoch   1 Batch  171/269 - Train Accuracy: 0.5465, Validation Accuracy: 0.5732, Loss: 0.9115
Epoch   1 Batch  172/269 - Train Accuracy: 0.5529, Validation Accuracy: 0.5758, Loss: 0.8770
Epoch   1 Batch  173/269 - Train Accuracy: 0.5529, Validation Accuracy: 0.5740, Loss: 0.8585
Epoch   1 Batch  174/269 - Train Accuracy: 0.5492, Validation Accuracy: 0.5700, Loss: 0.8712
Epoch   1 Batch  175/269 - Train Accuracy: 0.5565, Validation Accuracy: 0.5694, Loss: 0.8804
Epoch   1 Batch  176/269 - Train Accuracy: 0.5425, Validation Accuracy: 0.5721, Loss: 0.9127
Epoch   1 Batch  177/269 - Train Accuracy: 0.5656, Validation Accuracy: 0.5704, Loss: 0.8351
Epoch   1 Batch  178/269 - Train Accuracy: 0.5398, Validation Accuracy: 0.5696, Loss: 0.8860
Epoch   1 Batch  179/269 - Train Accuracy: 0.5561, Validation Accuracy: 0.5742, Loss: 0.8741
Epoch   1 Batch  180/269 - Train Accuracy: 0.5585, Validation Accuracy: 0.5726, Loss: 0.8530
Epoch   1 Batch  181/269 - Train Accuracy: 0.5509, Validation Accuracy: 0.5742, Loss: 0.8672
Epoch   1 Batch  182/269 - Train Accuracy: 0.5637, Validation Accuracy: 0.5755, Loss: 0.8631
Epoch   1 Batch  183/269 - Train Accuracy: 0.6279, Validation Accuracy: 0.5724, Loss: 0.7468
Epoch   1 Batch  184/269 - Train Accuracy: 0.5415, Validation Accuracy: 0.5698, Loss: 0.8896
Epoch   1 Batch  185/269 - Train Accuracy: 0.5650, Validation Accuracy: 0.5702, Loss: 0.8495
Epoch   1 Batch  186/269 - Train Accuracy: 0.5410, Validation Accuracy: 0.5795, Loss: 0.8840
Epoch   1 Batch  187/269 - Train Accuracy: 0.5721, Validation Accuracy: 0.5767, Loss: 0.8340
Epoch   1 Batch  188/269 - Train Accuracy: 0.5782, Validation Accuracy: 0.5758, Loss: 0.8280
Epoch   1 Batch  189/269 - Train Accuracy: 0.5754, Validation Accuracy: 0.5759, Loss: 0.8336
Epoch   1 Batch  190/269 - Train Accuracy: 0.5604, Validation Accuracy: 0.5771, Loss: 0.8279
Epoch   1 Batch  191/269 - Train Accuracy: 0.5632, Validation Accuracy: 0.5770, Loss: 0.8338
Epoch   1 Batch  192/269 - Train Accuracy: 0.5702, Validation Accuracy: 0.5768, Loss: 0.8498
Epoch   1 Batch  193/269 - Train Accuracy: 0.5544, Validation Accuracy: 0.5768, Loss: 0.8411
Epoch   1 Batch  194/269 - Train Accuracy: 0.5711, Validation Accuracy: 0.5763, Loss: 0.8510
Epoch   1 Batch  195/269 - Train Accuracy: 0.5533, Validation Accuracy: 0.5803, Loss: 0.8484
Epoch   1 Batch  196/269 - Train Accuracy: 0.5506, Validation Accuracy: 0.5817, Loss: 0.8332
Epoch   1 Batch  197/269 - Train Accuracy: 0.5456, Validation Accuracy: 0.5794, Loss: 0.8732
Epoch   1 Batch  198/269 - Train Accuracy: 0.5516, Validation Accuracy: 0.5859, Loss: 0.8907
Epoch   1 Batch  199/269 - Train Accuracy: 0.5533, Validation Accuracy: 0.5835, Loss: 0.8559
Epoch   1 Batch  200/269 - Train Accuracy: 0.5595, Validation Accuracy: 0.5841, Loss: 0.8593
Epoch   1 Batch  201/269 - Train Accuracy: 0.5738, Validation Accuracy: 0.5846, Loss: 0.8326
Epoch   1 Batch  202/269 - Train Accuracy: 0.5645, Validation Accuracy: 0.5830, Loss: 0.8337
Epoch   1 Batch  203/269 - Train Accuracy: 0.5476, Validation Accuracy: 0.5814, Loss: 0.8801
Epoch   1 Batch  204/269 - Train Accuracy: 0.5515, Validation Accuracy: 0.5835, Loss: 0.8596
Epoch   1 Batch  205/269 - Train Accuracy: 0.5491, Validation Accuracy: 0.5823, Loss: 0.8216
Epoch   1 Batch  206/269 - Train Accuracy: 0.5420, Validation Accuracy: 0.5828, Loss: 0.8763
Epoch   1 Batch  207/269 - Train Accuracy: 0.5860, Validation Accuracy: 0.5805, Loss: 0.8036
Epoch   1 Batch  208/269 - Train Accuracy: 0.5472, Validation Accuracy: 0.5840, Loss: 0.8666
Epoch   1 Batch  209/269 - Train Accuracy: 0.5620, Validation Accuracy: 0.5858, Loss: 0.8397
Epoch   1 Batch  210/269 - Train Accuracy: 0.5857, Validation Accuracy: 0.5877, Loss: 0.8068
Epoch   1 Batch  211/269 - Train Accuracy: 0.5725, Validation Accuracy: 0.5884, Loss: 0.8328
Epoch   1 Batch  212/269 - Train Accuracy: 0.5878, Validation Accuracy: 0.5864, Loss: 0.8078
Epoch   1 Batch  213/269 - Train Accuracy: 0.5732, Validation Accuracy: 0.5782, Loss: 0.8061
Epoch   1 Batch  214/269 - Train Accuracy: 0.5796, Validation Accuracy: 0.5779, Loss: 0.8081
Epoch   1 Batch  215/269 - Train Accuracy: 0.5985, Validation Accuracy: 0.5920, Loss: 0.7641
Epoch   1 Batch  216/269 - Train Accuracy: 0.5357, Validation Accuracy: 0.5895, Loss: 0.8729
Epoch   1 Batch  217/269 - Train Accuracy: 0.5478, Validation Accuracy: 0.5827, Loss: 0.8435
Epoch   1 Batch  218/269 - Train Accuracy: 0.5575, Validation Accuracy: 0.5783, Loss: 0.8481
Epoch   1 Batch  219/269 - Train Accuracy: 0.5687, Validation Accuracy: 0.5822, Loss: 0.8449
Epoch   1 Batch  220/269 - Train Accuracy: 0.5869, Validation Accuracy: 0.5885, Loss: 0.7679
Epoch   1 Batch  221/269 - Train Accuracy: 0.6002, Validation Accuracy: 0.5852, Loss: 0.8001
Epoch   1 Batch  222/269 - Train Accuracy: 0.5926, Validation Accuracy: 0.5859, Loss: 0.7786
Epoch   1 Batch  223/269 - Train Accuracy: 0.5804, Validation Accuracy: 0.5899, Loss: 0.7829
Epoch   1 Batch  224/269 - Train Accuracy: 0.5787, Validation Accuracy: 0.5905, Loss: 0.8190
Epoch   1 Batch  225/269 - Train Accuracy: 0.5744, Validation Accuracy: 0.5883, Loss: 0.8205
Epoch   1 Batch  226/269 - Train Accuracy: 0.5665, Validation Accuracy: 0.5929, Loss: 0.7998
Epoch   1 Batch  227/269 - Train Accuracy: 0.6381, Validation Accuracy: 0.5937, Loss: 0.7015
Epoch   1 Batch  228/269 - Train Accuracy: 0.5751, Validation Accuracy: 0.5969, Loss: 0.8025
Epoch   1 Batch  229/269 - Train Accuracy: 0.5858, Validation Accuracy: 0.5942, Loss: 0.7920
Epoch   1 Batch  230/269 - Train Accuracy: 0.5769, Validation Accuracy: 0.5982, Loss: 0.8009
Epoch   1 Batch  231/269 - Train Accuracy: 0.5562, Validation Accuracy: 0.5951, Loss: 0.8439
Epoch   1 Batch  232/269 - Train Accuracy: 0.5617, Validation Accuracy: 0.5974, Loss: 0.8286
Epoch   1 Batch  233/269 - Train Accuracy: 0.5974, Validation Accuracy: 0.5984, Loss: 0.7980
Epoch   1 Batch  234/269 - Train Accuracy: 0.5871, Validation Accuracy: 0.5966, Loss: 0.7998
Epoch   1 Batch  235/269 - Train Accuracy: 0.5937, Validation Accuracy: 0.5922, Loss: 0.7906
Epoch   1 Batch  236/269 - Train Accuracy: 0.5794, Validation Accuracy: 0.5953, Loss: 0.7863
Epoch   1 Batch  237/269 - Train Accuracy: 0.5802, Validation Accuracy: 0.6026, Loss: 0.7836
Epoch   1 Batch  238/269 - Train Accuracy: 0.6113, Validation Accuracy: 0.6003, Loss: 0.7819
Epoch   1 Batch  239/269 - Train Accuracy: 0.5970, Validation Accuracy: 0.6000, Loss: 0.7758
Epoch   1 Batch  240/269 - Train Accuracy: 0.6090, Validation Accuracy: 0.5952, Loss: 0.7212
Epoch   1 Batch  241/269 - Train Accuracy: 0.5880, Validation Accuracy: 0.6004, Loss: 0.7961
Epoch   1 Batch  242/269 - Train Accuracy: 0.5792, Validation Accuracy: 0.5982, Loss: 0.7850
Epoch   1 Batch  243/269 - Train Accuracy: 0.6115, Validation Accuracy: 0.6016, Loss: 0.7630
Epoch   1 Batch  244/269 - Train Accuracy: 0.5811, Validation Accuracy: 0.5970, Loss: 0.7751
Epoch   1 Batch  245/269 - Train Accuracy: 0.5841, Validation Accuracy: 0.6041, Loss: 0.8287
Epoch   1 Batch  246/269 - Train Accuracy: 0.5821, Validation Accuracy: 0.6056, Loss: 0.7906
Epoch   1 Batch  247/269 - Train Accuracy: 0.5782, Validation Accuracy: 0.5986, Loss: 0.8088
Epoch   1 Batch  248/269 - Train Accuracy: 0.5766, Validation Accuracy: 0.5975, Loss: 0.7735
Epoch   1 Batch  249/269 - Train Accuracy: 0.6172, Validation Accuracy: 0.6008, Loss: 0.7445
Epoch   1 Batch  250/269 - Train Accuracy: 0.5719, Validation Accuracy: 0.6016, Loss: 0.7975
Epoch   1 Batch  251/269 - Train Accuracy: 0.6057, Validation Accuracy: 0.6001, Loss: 0.7597
Epoch   1 Batch  252/269 - Train Accuracy: 0.5923, Validation Accuracy: 0.5991, Loss: 0.7824
Epoch   1 Batch  253/269 - Train Accuracy: 0.5756, Validation Accuracy: 0.5973, Loss: 0.7836
Epoch   1 Batch  254/269 - Train Accuracy: 0.5846, Validation Accuracy: 0.5940, Loss: 0.7683
Epoch   1 Batch  255/269 - Train Accuracy: 0.6122, Validation Accuracy: 0.5985, Loss: 0.7363
Epoch   1 Batch  256/269 - Train Accuracy: 0.5733, Validation Accuracy: 0.6001, Loss: 0.7807
Epoch   1 Batch  257/269 - Train Accuracy: 0.5684, Validation Accuracy: 0.5988, Loss: 0.7760
Epoch   1 Batch  258/269 - Train Accuracy: 0.5770, Validation Accuracy: 0.5989, Loss: 0.7775
Epoch   1 Batch  259/269 - Train Accuracy: 0.6096, Validation Accuracy: 0.6024, Loss: 0.7614
Epoch   1 Batch  260/269 - Train Accuracy: 0.5786, Validation Accuracy: 0.6021, Loss: 0.8047
Epoch   1 Batch  261/269 - Train Accuracy: 0.5597, Validation Accuracy: 0.6035, Loss: 0.8127
Epoch   1 Batch  262/269 - Train Accuracy: 0.5972, Validation Accuracy: 0.5999, Loss: 0.7671
Epoch   1 Batch  263/269 - Train Accuracy: 0.5816, Validation Accuracy: 0.6000, Loss: 0.7873
Epoch   1 Batch  264/269 - Train Accuracy: 0.5641, Validation Accuracy: 0.5985, Loss: 0.8016
Epoch   1 Batch  265/269 - Train Accuracy: 0.5657, Validation Accuracy: 0.5968, Loss: 0.7865
Epoch   1 Batch  266/269 - Train Accuracy: 0.5950, Validation Accuracy: 0.5994, Loss: 0.7556
Epoch   1 Batch  267/269 - Train Accuracy: 0.5911, Validation Accuracy: 0.6014, Loss: 0.7741
Epoch   2 Batch    1/269 - Train Accuracy: 0.5785, Validation Accuracy: 0.6025, Loss: 0.7783
Epoch   2 Batch    2/269 - Train Accuracy: 0.5803, Validation Accuracy: 0.6049, Loss: 0.7700
Epoch   2 Batch    3/269 - Train Accuracy: 0.5778, Validation Accuracy: 0.5983, Loss: 0.7780
Epoch   2 Batch    4/269 - Train Accuracy: 0.5596, Validation Accuracy: 0.5994, Loss: 0.7916
Epoch   2 Batch    5/269 - Train Accuracy: 0.5666, Validation Accuracy: 0.5993, Loss: 0.7884
Epoch   2 Batch    6/269 - Train Accuracy: 0.5954, Validation Accuracy: 0.6002, Loss: 0.7302
Epoch   2 Batch    7/269 - Train Accuracy: 0.5922, Validation Accuracy: 0.6009, Loss: 0.7388
Epoch   2 Batch    8/269 - Train Accuracy: 0.5720, Validation Accuracy: 0.6064, Loss: 0.7900
Epoch   2 Batch    9/269 - Train Accuracy: 0.5853, Validation Accuracy: 0.6073, Loss: 0.7635
Epoch   2 Batch   10/269 - Train Accuracy: 0.5809, Validation Accuracy: 0.6028, Loss: 0.7748
Epoch   2 Batch   11/269 - Train Accuracy: 0.5827, Validation Accuracy: 0.5985, Loss: 0.7635
Epoch   2 Batch   12/269 - Train Accuracy: 0.5684, Validation Accuracy: 0.6065, Loss: 0.7859
Epoch   2 Batch   13/269 - Train Accuracy: 0.6246, Validation Accuracy: 0.6053, Loss: 0.6979
Epoch   2 Batch   14/269 - Train Accuracy: 0.5939, Validation Accuracy: 0.6021, Loss: 0.7457
Epoch   2 Batch   15/269 - Train Accuracy: 0.5847, Validation Accuracy: 0.6053, Loss: 0.7407
Epoch   2 Batch   16/269 - Train Accuracy: 0.5958, Validation Accuracy: 0.6008, Loss: 0.7456
Epoch   2 Batch   17/269 - Train Accuracy: 0.5907, Validation Accuracy: 0.6033, Loss: 0.7327
Epoch   2 Batch   18/269 - Train Accuracy: 0.5723, Validation Accuracy: 0.6100, Loss: 0.7638
Epoch   2 Batch   19/269 - Train Accuracy: 0.6251, Validation Accuracy: 0.6094, Loss: 0.7008
Epoch   2 Batch   20/269 - Train Accuracy: 0.5946, Validation Accuracy: 0.6096, Loss: 0.7607
Epoch   2 Batch   21/269 - Train Accuracy: 0.5796, Validation Accuracy: 0.6092, Loss: 0.7903
Epoch   2 Batch   22/269 - Train Accuracy: 0.6052, Validation Accuracy: 0.6101, Loss: 0.7275
Epoch   2 Batch   23/269 - Train Accuracy: 0.6124, Validation Accuracy: 0.6089, Loss: 0.7361
Epoch   2 Batch   24/269 - Train Accuracy: 0.5922, Validation Accuracy: 0.6055, Loss: 0.7718
Epoch   2 Batch   25/269 - Train Accuracy: 0.5700, Validation Accuracy: 0.6089, Loss: 0.7821
Epoch   2 Batch   26/269 - Train Accuracy: 0.6262, Validation Accuracy: 0.6080, Loss: 0.6903
Epoch   2 Batch   27/269 - Train Accuracy: 0.5864, Validation Accuracy: 0.6057, Loss: 0.7297
Epoch   2 Batch   28/269 - Train Accuracy: 0.5581, Validation Accuracy: 0.6088, Loss: 0.7901
Epoch   2 Batch   29/269 - Train Accuracy: 0.5933, Validation Accuracy: 0.6102, Loss: 0.7608
Epoch   2 Batch   30/269 - Train Accuracy: 0.5984, Validation Accuracy: 0.6070, Loss: 0.7251
Epoch   2 Batch   31/269 - Train Accuracy: 0.6054, Validation Accuracy: 0.6076, Loss: 0.7169
Epoch   2 Batch   32/269 - Train Accuracy: 0.5967, Validation Accuracy: 0.6120, Loss: 0.7237
Epoch   2 Batch   33/269 - Train Accuracy: 0.6111, Validation Accuracy: 0.6094, Loss: 0.7106
Epoch   2 Batch   34/269 - Train Accuracy: 0.6028, Validation Accuracy: 0.6062, Loss: 0.7257
Epoch   2 Batch   35/269 - Train Accuracy: 0.6054, Validation Accuracy: 0.6096, Loss: 0.7395
Epoch   2 Batch   36/269 - Train Accuracy: 0.5993, Validation Accuracy: 0.6101, Loss: 0.7280
Epoch   2 Batch   37/269 - Train Accuracy: 0.6022, Validation Accuracy: 0.6060, Loss: 0.7247
Epoch   2 Batch   38/269 - Train Accuracy: 0.5942, Validation Accuracy: 0.6019, Loss: 0.7271
Epoch   2 Batch   39/269 - Train Accuracy: 0.6020, Validation Accuracy: 0.6064, Loss: 0.7221
Epoch   2 Batch   40/269 - Train Accuracy: 0.5847, Validation Accuracy: 0.6114, Loss: 0.7599
Epoch   2 Batch   41/269 - Train Accuracy: 0.5915, Validation Accuracy: 0.6073, Loss: 0.7384
Epoch   2 Batch   42/269 - Train Accuracy: 0.6222, Validation Accuracy: 0.6015, Loss: 0.6873
Epoch   2 Batch   43/269 - Train Accuracy: 0.5901, Validation Accuracy: 0.6090, Loss: 0.7463
Epoch   2 Batch   44/269 - Train Accuracy: 0.6075, Validation Accuracy: 0.6120, Loss: 0.7230
Epoch   2 Batch   45/269 - Train Accuracy: 0.5788, Validation Accuracy: 0.6100, Loss: 0.7557
Epoch   2 Batch   46/269 - Train Accuracy: 0.5822, Validation Accuracy: 0.6034, Loss: 0.7501
Epoch   2 Batch   47/269 - Train Accuracy: 0.6221, Validation Accuracy: 0.6031, Loss: 0.6718
Epoch   2 Batch   48/269 - Train Accuracy: 0.5979, Validation Accuracy: 0.6117, Loss: 0.6960
Epoch   2 Batch   49/269 - Train Accuracy: 0.5828, Validation Accuracy: 0.6118, Loss: 0.7383
Epoch   2 Batch   50/269 - Train Accuracy: 0.5854, Validation Accuracy: 0.6060, Loss: 0.7425
Epoch   2 Batch   51/269 - Train Accuracy: 0.5928, Validation Accuracy: 0.6044, Loss: 0.7233
Epoch   2 Batch   52/269 - Train Accuracy: 0.5994, Validation Accuracy: 0.6100, Loss: 0.7001
Epoch   2 Batch   53/269 - Train Accuracy: 0.5821, Validation Accuracy: 0.6120, Loss: 0.7485
Epoch   2 Batch   54/269 - Train Accuracy: 0.5883, Validation Accuracy: 0.6098, Loss: 0.7317
Epoch   2 Batch   55/269 - Train Accuracy: 0.6057, Validation Accuracy: 0.5995, Loss: 0.7024
Epoch   2 Batch   56/269 - Train Accuracy: 0.6089, Validation Accuracy: 0.6080, Loss: 0.7155
Epoch   2 Batch   57/269 - Train Accuracy: 0.6104, Validation Accuracy: 0.6126, Loss: 0.7249
Epoch   2 Batch   58/269 - Train Accuracy: 0.6128, Validation Accuracy: 0.6138, Loss: 0.7013
Epoch   2 Batch   59/269 - Train Accuracy: 0.6130, Validation Accuracy: 0.6064, Loss: 0.6828
Epoch   2 Batch   60/269 - Train Accuracy: 0.6037, Validation Accuracy: 0.6039, Loss: 0.6779
Epoch   2 Batch   61/269 - Train Accuracy: 0.6197, Validation Accuracy: 0.6079, Loss: 0.6608
Epoch   2 Batch   62/269 - Train Accuracy: 0.6118, Validation Accuracy: 0.6146, Loss: 0.6840
Epoch   2 Batch   63/269 - Train Accuracy: 0.5974, Validation Accuracy: 0.6139, Loss: 0.7135
Epoch   2 Batch   64/269 - Train Accuracy: 0.5884, Validation Accuracy: 0.6108, Loss: 0.6991
Epoch   2 Batch   65/269 - Train Accuracy: 0.5976, Validation Accuracy: 0.6141, Loss: 0.6985
Epoch   2 Batch   66/269 - Train Accuracy: 0.6202, Validation Accuracy: 0.6114, Loss: 0.6805
Epoch   2 Batch   67/269 - Train Accuracy: 0.5898, Validation Accuracy: 0.6078, Loss: 0.7148
Epoch   2 Batch   68/269 - Train Accuracy: 0.5827, Validation Accuracy: 0.6060, Loss: 0.7085
Epoch   2 Batch   69/269 - Train Accuracy: 0.5806, Validation Accuracy: 0.6074, Loss: 0.7662
Epoch   2 Batch   70/269 - Train Accuracy: 0.6183, Validation Accuracy: 0.6116, Loss: 0.7043
Epoch   2 Batch   71/269 - Train Accuracy: 0.5917, Validation Accuracy: 0.6125, Loss: 0.7351
Epoch   2 Batch   72/269 - Train Accuracy: 0.6122, Validation Accuracy: 0.6123, Loss: 0.6907
Epoch   2 Batch   73/269 - Train Accuracy: 0.6038, Validation Accuracy: 0.6135, Loss: 0.7143
Epoch   2 Batch   74/269 - Train Accuracy: 0.6067, Validation Accuracy: 0.6117, Loss: 0.7097
Epoch   2 Batch   75/269 - Train Accuracy: 0.5970, Validation Accuracy: 0.6096, Loss: 0.6929
Epoch   2 Batch   76/269 - Train Accuracy: 0.5822, Validation Accuracy: 0.6079, Loss: 0.7129
Epoch   2 Batch   77/269 - Train Accuracy: 0.6227, Validation Accuracy: 0.6063, Loss: 0.6908
Epoch   2 Batch   78/269 - Train Accuracy: 0.6025, Validation Accuracy: 0.6079, Loss: 0.6910
Epoch   2 Batch   79/269 - Train Accuracy: 0.6086, Validation Accuracy: 0.6136, Loss: 0.6945
Epoch   2 Batch   80/269 - Train Accuracy: 0.6162, Validation Accuracy: 0.6117, Loss: 0.6820
Epoch   2 Batch   81/269 - Train Accuracy: 0.6056, Validation Accuracy: 0.6120, Loss: 0.7070
Epoch   2 Batch   82/269 - Train Accuracy: 0.6216, Validation Accuracy: 0.6116, Loss: 0.6662
Epoch   2 Batch   83/269 - Train Accuracy: 0.6055, Validation Accuracy: 0.6129, Loss: 0.6947
Epoch   2 Batch   84/269 - Train Accuracy: 0.6164, Validation Accuracy: 0.6141, Loss: 0.6764
Epoch   2 Batch   85/269 - Train Accuracy: 0.6064, Validation Accuracy: 0.6128, Loss: 0.6894
Epoch   2 Batch   86/269 - Train Accuracy: 0.5848, Validation Accuracy: 0.6162, Loss: 0.6852
Epoch   2 Batch   87/269 - Train Accuracy: 0.5877, Validation Accuracy: 0.6141, Loss: 0.7295
Epoch   2 Batch   88/269 - Train Accuracy: 0.6050, Validation Accuracy: 0.6100, Loss: 0.6865
Epoch   2 Batch   89/269 - Train Accuracy: 0.6257, Validation Accuracy: 0.6124, Loss: 0.6845
Epoch   2 Batch   90/269 - Train Accuracy: 0.5761, Validation Accuracy: 0.6123, Loss: 0.7342
Epoch   2 Batch   91/269 - Train Accuracy: 0.6084, Validation Accuracy: 0.6153, Loss: 0.6653
Epoch   2 Batch   92/269 - Train Accuracy: 0.5977, Validation Accuracy: 0.6127, Loss: 0.6800
Epoch   2 Batch   93/269 - Train Accuracy: 0.6197, Validation Accuracy: 0.6151, Loss: 0.6578
Epoch   2 Batch   94/269 - Train Accuracy: 0.6070, Validation Accuracy: 0.6154, Loss: 0.6967
Epoch   2 Batch   95/269 - Train Accuracy: 0.6045, Validation Accuracy: 0.6142, Loss: 0.6901
Epoch   2 Batch   96/269 - Train Accuracy: 0.6103, Validation Accuracy: 0.6143, Loss: 0.6840
Epoch   2 Batch   97/269 - Train Accuracy: 0.5919, Validation Accuracy: 0.6129, Loss: 0.6827
Epoch   2 Batch   98/269 - Train Accuracy: 0.6129, Validation Accuracy: 0.6135, Loss: 0.6854
Epoch   2 Batch   99/269 - Train Accuracy: 0.5958, Validation Accuracy: 0.6076, Loss: 0.7074
Epoch   2 Batch  100/269 - Train Accuracy: 0.6185, Validation Accuracy: 0.6078, Loss: 0.6720
Epoch   2 Batch  101/269 - Train Accuracy: 0.5766, Validation Accuracy: 0.6145, Loss: 0.7149
Epoch   2 Batch  102/269 - Train Accuracy: 0.6120, Validation Accuracy: 0.6175, Loss: 0.6802
Epoch   2 Batch  103/269 - Train Accuracy: 0.6018, Validation Accuracy: 0.6142, Loss: 0.6680
Epoch   2 Batch  104/269 - Train Accuracy: 0.5981, Validation Accuracy: 0.6088, Loss: 0.6743
Epoch   2 Batch  105/269 - Train Accuracy: 0.6039, Validation Accuracy: 0.6128, Loss: 0.6946
Epoch   2 Batch  106/269 - Train Accuracy: 0.6084, Validation Accuracy: 0.6164, Loss: 0.6712
Epoch   2 Batch  107/269 - Train Accuracy: 0.5801, Validation Accuracy: 0.6158, Loss: 0.7133
Epoch   2 Batch  108/269 - Train Accuracy: 0.6122, Validation Accuracy: 0.6158, Loss: 0.6756
Epoch   2 Batch  109/269 - Train Accuracy: 0.5867, Validation Accuracy: 0.6150, Loss: 0.6794
Epoch   2 Batch  110/269 - Train Accuracy: 0.6027, Validation Accuracy: 0.6146, Loss: 0.6700
Epoch   2 Batch  111/269 - Train Accuracy: 0.5747, Validation Accuracy: 0.6141, Loss: 0.7121
Epoch   2 Batch  112/269 - Train Accuracy: 0.6141, Validation Accuracy: 0.6146, Loss: 0.6691
Epoch   2 Batch  113/269 - Train Accuracy: 0.6123, Validation Accuracy: 0.6124, Loss: 0.6480
Epoch   2 Batch  114/269 - Train Accuracy: 0.6028, Validation Accuracy: 0.6143, Loss: 0.6684
Epoch   2 Batch  115/269 - Train Accuracy: 0.5978, Validation Accuracy: 0.6130, Loss: 0.6923
Epoch   2 Batch  116/269 - Train Accuracy: 0.6044, Validation Accuracy: 0.6140, Loss: 0.6751
Epoch   2 Batch  117/269 - Train Accuracy: 0.6047, Validation Accuracy: 0.6145, Loss: 0.6666
Epoch   2 Batch  118/269 - Train Accuracy: 0.6274, Validation Accuracy: 0.6148, Loss: 0.6512
Epoch   2 Batch  119/269 - Train Accuracy: 0.5980, Validation Accuracy: 0.6176, Loss: 0.6992
Epoch   2 Batch  120/269 - Train Accuracy: 0.6021, Validation Accuracy: 0.6151, Loss: 0.6935
Epoch   2 Batch  121/269 - Train Accuracy: 0.6079, Validation Accuracy: 0.6207, Loss: 0.6605
Epoch   2 Batch  122/269 - Train Accuracy: 0.6200, Validation Accuracy: 0.6205, Loss: 0.6550
Epoch   2 Batch  123/269 - Train Accuracy: 0.5973, Validation Accuracy: 0.6211, Loss: 0.7007
Epoch   2 Batch  124/269 - Train Accuracy: 0.6092, Validation Accuracy: 0.6218, Loss: 0.6540
Epoch   2 Batch  125/269 - Train Accuracy: 0.6158, Validation Accuracy: 0.6192, Loss: 0.6511
Epoch   2 Batch  126/269 - Train Accuracy: 0.6142, Validation Accuracy: 0.6162, Loss: 0.6522
Epoch   2 Batch  127/269 - Train Accuracy: 0.5985, Validation Accuracy: 0.6192, Loss: 0.6932
Epoch   2 Batch  128/269 - Train Accuracy: 0.6253, Validation Accuracy: 0.6202, Loss: 0.6574
Epoch   2 Batch  129/269 - Train Accuracy: 0.6033, Validation Accuracy: 0.6171, Loss: 0.6650
Epoch   2 Batch  130/269 - Train Accuracy: 0.5881, Validation Accuracy: 0.6183, Loss: 0.6913
Epoch   2 Batch  131/269 - Train Accuracy: 0.5966, Validation Accuracy: 0.6192, Loss: 0.6823
Epoch   2 Batch  132/269 - Train Accuracy: 0.6091, Validation Accuracy: 0.6203, Loss: 0.6708
Epoch   2 Batch  133/269 - Train Accuracy: 0.6262, Validation Accuracy: 0.6238, Loss: 0.6407
Epoch   2 Batch  134/269 - Train Accuracy: 0.5967, Validation Accuracy: 0.6202, Loss: 0.6768
Epoch   2 Batch  135/269 - Train Accuracy: 0.5921, Validation Accuracy: 0.6203, Loss: 0.7100
Epoch   2 Batch  136/269 - Train Accuracy: 0.5888, Validation Accuracy: 0.6263, Loss: 0.7079
Epoch   2 Batch  137/269 - Train Accuracy: 0.6075, Validation Accuracy: 0.6244, Loss: 0.6951
Epoch   2 Batch  138/269 - Train Accuracy: 0.6009, Validation Accuracy: 0.6181, Loss: 0.6768
Epoch   2 Batch  139/269 - Train Accuracy: 0.6317, Validation Accuracy: 0.6193, Loss: 0.6437
Epoch   2 Batch  140/269 - Train Accuracy: 0.6184, Validation Accuracy: 0.6196, Loss: 0.6676
Epoch   2 Batch  141/269 - Train Accuracy: 0.6141, Validation Accuracy: 0.6212, Loss: 0.6693
Epoch   2 Batch  142/269 - Train Accuracy: 0.6137, Validation Accuracy: 0.6216, Loss: 0.6394
Epoch   2 Batch  143/269 - Train Accuracy: 0.6080, Validation Accuracy: 0.6207, Loss: 0.6532
Epoch   2 Batch  144/269 - Train Accuracy: 0.6183, Validation Accuracy: 0.6259, Loss: 0.6334
Epoch   2 Batch  145/269 - Train Accuracy: 0.6108, Validation Accuracy: 0.6185, Loss: 0.6439
Epoch   2 Batch  146/269 - Train Accuracy: 0.6069, Validation Accuracy: 0.6161, Loss: 0.6367
Epoch   2 Batch  147/269 - Train Accuracy: 0.6322, Validation Accuracy: 0.6224, Loss: 0.6232
Epoch   2 Batch  148/269 - Train Accuracy: 0.6149, Validation Accuracy: 0.6235, Loss: 0.6529
Epoch   2 Batch  149/269 - Train Accuracy: 0.6261, Validation Accuracy: 0.6276, Loss: 0.6564
Epoch   2 Batch  150/269 - Train Accuracy: 0.6272, Validation Accuracy: 0.6309, Loss: 0.6609
Epoch   2 Batch  151/269 - Train Accuracy: 0.6472, Validation Accuracy: 0.6281, Loss: 0.6257
Epoch   2 Batch  152/269 - Train Accuracy: 0.6091, Validation Accuracy: 0.6254, Loss: 0.6546
Epoch   2 Batch  153/269 - Train Accuracy: 0.6160, Validation Accuracy: 0.6269, Loss: 0.6416
Epoch   2 Batch  154/269 - Train Accuracy: 0.5984, Validation Accuracy: 0.6298, Loss: 0.6684
Epoch   2 Batch  155/269 - Train Accuracy: 0.6505, Validation Accuracy: 0.6291, Loss: 0.6107
Epoch   2 Batch  156/269 - Train Accuracy: 0.6055, Validation Accuracy: 0.6305, Loss: 0.6807
Epoch   2 Batch  157/269 - Train Accuracy: 0.6190, Validation Accuracy: 0.6328, Loss: 0.6505
Epoch   2 Batch  158/269 - Train Accuracy: 0.6134, Validation Accuracy: 0.6207, Loss: 0.6454
Epoch   2 Batch  159/269 - Train Accuracy: 0.6180, Validation Accuracy: 0.6279, Loss: 0.6535
Epoch   2 Batch  160/269 - Train Accuracy: 0.6250, Validation Accuracy: 0.6341, Loss: 0.6425
Epoch   2 Batch  161/269 - Train Accuracy: 0.6153, Validation Accuracy: 0.6321, Loss: 0.6472
Epoch   2 Batch  162/269 - Train Accuracy: 0.6121, Validation Accuracy: 0.6327, Loss: 0.6416
Epoch   2 Batch  163/269 - Train Accuracy: 0.6193, Validation Accuracy: 0.6311, Loss: 0.6474
Epoch   2 Batch  164/269 - Train Accuracy: 0.6307, Validation Accuracy: 0.6286, Loss: 0.6351
Epoch   2 Batch  165/269 - Train Accuracy: 0.6005, Validation Accuracy: 0.6352, Loss: 0.6684
Epoch   2 Batch  166/269 - Train Accuracy: 0.6358, Validation Accuracy: 0.6354, Loss: 0.6064
Epoch   2 Batch  167/269 - Train Accuracy: 0.6285, Validation Accuracy: 0.6346, Loss: 0.6411
Epoch   2 Batch  168/269 - Train Accuracy: 0.6150, Validation Accuracy: 0.6278, Loss: 0.6416
Epoch   2 Batch  169/269 - Train Accuracy: 0.6203, Validation Accuracy: 0.6256, Loss: 0.6452
Epoch   2 Batch  170/269 - Train Accuracy: 0.6175, Validation Accuracy: 0.6272, Loss: 0.6362
Epoch   2 Batch  171/269 - Train Accuracy: 0.6146, Validation Accuracy: 0.6297, Loss: 0.6663
Epoch   2 Batch  172/269 - Train Accuracy: 0.6140, Validation Accuracy: 0.6311, Loss: 0.6462
Epoch   2 Batch  173/269 - Train Accuracy: 0.6243, Validation Accuracy: 0.6315, Loss: 0.6265
Epoch   2 Batch  174/269 - Train Accuracy: 0.6101, Validation Accuracy: 0.6310, Loss: 0.6371
Epoch   2 Batch  175/269 - Train Accuracy: 0.6178, Validation Accuracy: 0.6262, Loss: 0.6460
Epoch   2 Batch  176/269 - Train Accuracy: 0.6057, Validation Accuracy: 0.6296, Loss: 0.6776
Epoch   2 Batch  177/269 - Train Accuracy: 0.6433, Validation Accuracy: 0.6333, Loss: 0.6087
Epoch   2 Batch  178/269 - Train Accuracy: 0.6124, Validation Accuracy: 0.6348, Loss: 0.6543
Epoch   2 Batch  179/269 - Train Accuracy: 0.6283, Validation Accuracy: 0.6344, Loss: 0.6366
Epoch   2 Batch  180/269 - Train Accuracy: 0.6297, Validation Accuracy: 0.6386, Loss: 0.6326
Epoch   2 Batch  181/269 - Train Accuracy: 0.6053, Validation Accuracy: 0.6350, Loss: 0.6331
Epoch   2 Batch  182/269 - Train Accuracy: 0.6212, Validation Accuracy: 0.6286, Loss: 0.6331
Epoch   2 Batch  183/269 - Train Accuracy: 0.6773, Validation Accuracy: 0.6309, Loss: 0.5544
Epoch   2 Batch  184/269 - Train Accuracy: 0.6044, Validation Accuracy: 0.6374, Loss: 0.6576
Epoch   2 Batch  185/269 - Train Accuracy: 0.6385, Validation Accuracy: 0.6425, Loss: 0.6269
Epoch   2 Batch  186/269 - Train Accuracy: 0.6019, Validation Accuracy: 0.6422, Loss: 0.6523
Epoch   2 Batch  187/269 - Train Accuracy: 0.6215, Validation Accuracy: 0.6407, Loss: 0.6219
Epoch   2 Batch  188/269 - Train Accuracy: 0.6318, Validation Accuracy: 0.6347, Loss: 0.6164
Epoch   2 Batch  189/269 - Train Accuracy: 0.6220, Validation Accuracy: 0.6339, Loss: 0.6108
Epoch   2 Batch  190/269 - Train Accuracy: 0.6259, Validation Accuracy: 0.6376, Loss: 0.6129
Epoch   2 Batch  191/269 - Train Accuracy: 0.6391, Validation Accuracy: 0.6394, Loss: 0.6213
Epoch   2 Batch  192/269 - Train Accuracy: 0.6315, Validation Accuracy: 0.6397, Loss: 0.6245
Epoch   2 Batch  193/269 - Train Accuracy: 0.6305, Validation Accuracy: 0.6402, Loss: 0.6236
Epoch   2 Batch  194/269 - Train Accuracy: 0.6452, Validation Accuracy: 0.6361, Loss: 0.6285
Epoch   2 Batch  195/269 - Train Accuracy: 0.6168, Validation Accuracy: 0.6384, Loss: 0.6225
Epoch   2 Batch  196/269 - Train Accuracy: 0.6067, Validation Accuracy: 0.6379, Loss: 0.6250
Epoch   2 Batch  197/269 - Train Accuracy: 0.5990, Validation Accuracy: 0.6398, Loss: 0.6510
Epoch   2 Batch  198/269 - Train Accuracy: 0.6146, Validation Accuracy: 0.6419, Loss: 0.6624
Epoch   2 Batch  199/269 - Train Accuracy: 0.6187, Validation Accuracy: 0.6404, Loss: 0.6341
Epoch   2 Batch  200/269 - Train Accuracy: 0.6293, Validation Accuracy: 0.6444, Loss: 0.6391
Epoch   2 Batch  201/269 - Train Accuracy: 0.6211, Validation Accuracy: 0.6433, Loss: 0.6226
Epoch   2 Batch  202/269 - Train Accuracy: 0.6220, Validation Accuracy: 0.6426, Loss: 0.6127
Epoch   2 Batch  203/269 - Train Accuracy: 0.6081, Validation Accuracy: 0.6374, Loss: 0.6592
Epoch   2 Batch  204/269 - Train Accuracy: 0.6093, Validation Accuracy: 0.6350, Loss: 0.6494
Epoch   2 Batch  205/269 - Train Accuracy: 0.6173, Validation Accuracy: 0.6419, Loss: 0.6124
Epoch   2 Batch  206/269 - Train Accuracy: 0.6162, Validation Accuracy: 0.6414, Loss: 0.6403
Epoch   2 Batch  207/269 - Train Accuracy: 0.6465, Validation Accuracy: 0.6411, Loss: 0.6034
Epoch   2 Batch  208/269 - Train Accuracy: 0.6244, Validation Accuracy: 0.6437, Loss: 0.6399
Epoch   2 Batch  209/269 - Train Accuracy: 0.6293, Validation Accuracy: 0.6403, Loss: 0.6259
Epoch   2 Batch  210/269 - Train Accuracy: 0.6372, Validation Accuracy: 0.6374, Loss: 0.6057
Epoch   2 Batch  211/269 - Train Accuracy: 0.6257, Validation Accuracy: 0.6445, Loss: 0.6209
Epoch   2 Batch  212/269 - Train Accuracy: 0.6481, Validation Accuracy: 0.6457, Loss: 0.6082
Epoch   2 Batch  213/269 - Train Accuracy: 0.6220, Validation Accuracy: 0.6393, Loss: 0.6152
Epoch   2 Batch  214/269 - Train Accuracy: 0.6477, Validation Accuracy: 0.6426, Loss: 0.6189
Epoch   2 Batch  215/269 - Train Accuracy: 0.6611, Validation Accuracy: 0.6469, Loss: 0.5764
Epoch   2 Batch  216/269 - Train Accuracy: 0.5974, Validation Accuracy: 0.6401, Loss: 0.6563
Epoch   2 Batch  217/269 - Train Accuracy: 0.5970, Validation Accuracy: 0.6363, Loss: 0.6425
Epoch   2 Batch  218/269 - Train Accuracy: 0.6110, Validation Accuracy: 0.6437, Loss: 0.6343
Epoch   2 Batch  219/269 - Train Accuracy: 0.6303, Validation Accuracy: 0.6449, Loss: 0.6412
Epoch   2 Batch  220/269 - Train Accuracy: 0.6361, Validation Accuracy: 0.6455, Loss: 0.5834
Epoch   2 Batch  221/269 - Train Accuracy: 0.6557, Validation Accuracy: 0.6394, Loss: 0.6115
Epoch   2 Batch  222/269 - Train Accuracy: 0.6496, Validation Accuracy: 0.6441, Loss: 0.5933
Epoch   2 Batch  223/269 - Train Accuracy: 0.6271, Validation Accuracy: 0.6435, Loss: 0.5960
Epoch   2 Batch  224/269 - Train Accuracy: 0.6340, Validation Accuracy: 0.6388, Loss: 0.6308
Epoch   2 Batch  225/269 - Train Accuracy: 0.6154, Validation Accuracy: 0.6341, Loss: 0.6110
Epoch   2 Batch  226/269 - Train Accuracy: 0.6356, Validation Accuracy: 0.6501, Loss: 0.6066
Epoch   2 Batch  227/269 - Train Accuracy: 0.6885, Validation Accuracy: 0.6495, Loss: 0.5378
Epoch   2 Batch  228/269 - Train Accuracy: 0.6282, Validation Accuracy: 0.6498, Loss: 0.6079
Epoch   2 Batch  229/269 - Train Accuracy: 0.6349, Validation Accuracy: 0.6457, Loss: 0.5959
Epoch   2 Batch  230/269 - Train Accuracy: 0.6251, Validation Accuracy: 0.6469, Loss: 0.6112
Epoch   2 Batch  231/269 - Train Accuracy: 0.6090, Validation Accuracy: 0.6516, Loss: 0.6455
Epoch   2 Batch  232/269 - Train Accuracy: 0.6029, Validation Accuracy: 0.6449, Loss: 0.6370
Epoch   2 Batch  233/269 - Train Accuracy: 0.6396, Validation Accuracy: 0.6473, Loss: 0.6120
Epoch   2 Batch  234/269 - Train Accuracy: 0.6470, Validation Accuracy: 0.6515, Loss: 0.6004
Epoch   2 Batch  235/269 - Train Accuracy: 0.6385, Validation Accuracy: 0.6500, Loss: 0.5910
Epoch   2 Batch  236/269 - Train Accuracy: 0.6233, Validation Accuracy: 0.6464, Loss: 0.5872
Epoch   2 Batch  237/269 - Train Accuracy: 0.6178, Validation Accuracy: 0.6437, Loss: 0.5979
Epoch   2 Batch  238/269 - Train Accuracy: 0.6541, Validation Accuracy: 0.6528, Loss: 0.5894
Epoch   2 Batch  239/269 - Train Accuracy: 0.6488, Validation Accuracy: 0.6544, Loss: 0.5949
Epoch   2 Batch  240/269 - Train Accuracy: 0.6658, Validation Accuracy: 0.6515, Loss: 0.5449
Epoch   2 Batch  241/269 - Train Accuracy: 0.6287, Validation Accuracy: 0.6438, Loss: 0.5956
Epoch   2 Batch  242/269 - Train Accuracy: 0.6180, Validation Accuracy: 0.6469, Loss: 0.5996
Epoch   2 Batch  243/269 - Train Accuracy: 0.6556, Validation Accuracy: 0.6494, Loss: 0.5769
Epoch   2 Batch  244/269 - Train Accuracy: 0.6288, Validation Accuracy: 0.6499, Loss: 0.6014
Epoch   2 Batch  245/269 - Train Accuracy: 0.6102, Validation Accuracy: 0.6507, Loss: 0.6267
Epoch   2 Batch  246/269 - Train Accuracy: 0.6215, Validation Accuracy: 0.6528, Loss: 0.5982
Epoch   2 Batch  247/269 - Train Accuracy: 0.6245, Validation Accuracy: 0.6520, Loss: 0.6168
Epoch   2 Batch  248/269 - Train Accuracy: 0.6269, Validation Accuracy: 0.6523, Loss: 0.5876
Epoch   2 Batch  249/269 - Train Accuracy: 0.6620, Validation Accuracy: 0.6483, Loss: 0.5659
Epoch   2 Batch  250/269 - Train Accuracy: 0.6249, Validation Accuracy: 0.6491, Loss: 0.6040
Epoch   2 Batch  251/269 - Train Accuracy: 0.6512, Validation Accuracy: 0.6507, Loss: 0.5798
Epoch   2 Batch  252/269 - Train Accuracy: 0.6348, Validation Accuracy: 0.6494, Loss: 0.6033
Epoch   2 Batch  253/269 - Train Accuracy: 0.6303, Validation Accuracy: 0.6462, Loss: 0.6012
Epoch   2 Batch  254/269 - Train Accuracy: 0.6407, Validation Accuracy: 0.6454, Loss: 0.5896
Epoch   2 Batch  255/269 - Train Accuracy: 0.6570, Validation Accuracy: 0.6528, Loss: 0.5674
Epoch   2 Batch  256/269 - Train Accuracy: 0.6281, Validation Accuracy: 0.6497, Loss: 0.6008
Epoch   2 Batch  257/269 - Train Accuracy: 0.6122, Validation Accuracy: 0.6499, Loss: 0.6007
Epoch   2 Batch  258/269 - Train Accuracy: 0.6330, Validation Accuracy: 0.6451, Loss: 0.5932
Epoch   2 Batch  259/269 - Train Accuracy: 0.6416, Validation Accuracy: 0.6483, Loss: 0.5830
Epoch   2 Batch  260/269 - Train Accuracy: 0.6271, Validation Accuracy: 0.6501, Loss: 0.6105
Epoch   2 Batch  261/269 - Train Accuracy: 0.6118, Validation Accuracy: 0.6516, Loss: 0.6242
Epoch   2 Batch  262/269 - Train Accuracy: 0.6398, Validation Accuracy: 0.6498, Loss: 0.5894
Epoch   2 Batch  263/269 - Train Accuracy: 0.6297, Validation Accuracy: 0.6514, Loss: 0.6061
Epoch   2 Batch  264/269 - Train Accuracy: 0.6178, Validation Accuracy: 0.6525, Loss: 0.6107
Epoch   2 Batch  265/269 - Train Accuracy: 0.6203, Validation Accuracy: 0.6507, Loss: 0.6028
Epoch   2 Batch  266/269 - Train Accuracy: 0.6531, Validation Accuracy: 0.6520, Loss: 0.5742
Epoch   2 Batch  267/269 - Train Accuracy: 0.6369, Validation Accuracy: 0.6561, Loss: 0.5918
Epoch   3 Batch    1/269 - Train Accuracy: 0.6213, Validation Accuracy: 0.6572, Loss: 0.6008
Epoch   3 Batch    2/269 - Train Accuracy: 0.6243, Validation Accuracy: 0.6576, Loss: 0.5901
Epoch   3 Batch    3/269 - Train Accuracy: 0.6320, Validation Accuracy: 0.6551, Loss: 0.5936
Epoch   3 Batch    4/269 - Train Accuracy: 0.6135, Validation Accuracy: 0.6570, Loss: 0.6136
Epoch   3 Batch    5/269 - Train Accuracy: 0.6056, Validation Accuracy: 0.6594, Loss: 0.6056
Epoch   3 Batch    6/269 - Train Accuracy: 0.6382, Validation Accuracy: 0.6582, Loss: 0.5664
Epoch   3 Batch    7/269 - Train Accuracy: 0.6397, Validation Accuracy: 0.6554, Loss: 0.5738
Epoch   3 Batch    8/269 - Train Accuracy: 0.6231, Validation Accuracy: 0.6571, Loss: 0.6052
Epoch   3 Batch    9/269 - Train Accuracy: 0.6305, Validation Accuracy: 0.6586, Loss: 0.5947
Epoch   3 Batch   10/269 - Train Accuracy: 0.6334, Validation Accuracy: 0.6564, Loss: 0.5953
Epoch   3 Batch   11/269 - Train Accuracy: 0.6430, Validation Accuracy: 0.6570, Loss: 0.5900
Epoch   3 Batch   12/269 - Train Accuracy: 0.6203, Validation Accuracy: 0.6578, Loss: 0.6108
Epoch   3 Batch   13/269 - Train Accuracy: 0.6691, Validation Accuracy: 0.6556, Loss: 0.5363
Epoch   3 Batch   14/269 - Train Accuracy: 0.6315, Validation Accuracy: 0.6559, Loss: 0.5750
Epoch   3 Batch   15/269 - Train Accuracy: 0.6292, Validation Accuracy: 0.6578, Loss: 0.5673
Epoch   3 Batch   16/269 - Train Accuracy: 0.6593, Validation Accuracy: 0.6578, Loss: 0.5706
Epoch   3 Batch   17/269 - Train Accuracy: 0.6430, Validation Accuracy: 0.6529, Loss: 0.5646
Epoch   3 Batch   18/269 - Train Accuracy: 0.6305, Validation Accuracy: 0.6582, Loss: 0.5917
Epoch   3 Batch   19/269 - Train Accuracy: 0.6685, Validation Accuracy: 0.6563, Loss: 0.5407
Epoch   3 Batch   20/269 - Train Accuracy: 0.6371, Validation Accuracy: 0.6539, Loss: 0.5858
Epoch   3 Batch   21/269 - Train Accuracy: 0.6303, Validation Accuracy: 0.6578, Loss: 0.6109
Epoch   3 Batch   22/269 - Train Accuracy: 0.6494, Validation Accuracy: 0.6568, Loss: 0.5574
Epoch   3 Batch   23/269 - Train Accuracy: 0.6505, Validation Accuracy: 0.6569, Loss: 0.5587
Epoch   3 Batch   24/269 - Train Accuracy: 0.6271, Validation Accuracy: 0.6579, Loss: 0.6016
Epoch   3 Batch   25/269 - Train Accuracy: 0.6119, Validation Accuracy: 0.6562, Loss: 0.6109
Epoch   3 Batch   26/269 - Train Accuracy: 0.6563, Validation Accuracy: 0.6571, Loss: 0.5342
Epoch   3 Batch   27/269 - Train Accuracy: 0.6234, Validation Accuracy: 0.6585, Loss: 0.5652
Epoch   3 Batch   28/269 - Train Accuracy: 0.5922, Validation Accuracy: 0.6551, Loss: 0.6178
Epoch   3 Batch   29/269 - Train Accuracy: 0.6408, Validation Accuracy: 0.6555, Loss: 0.5966
Epoch   3 Batch   30/269 - Train Accuracy: 0.6472, Validation Accuracy: 0.6552, Loss: 0.5648
Epoch   3 Batch   31/269 - Train Accuracy: 0.6420, Validation Accuracy: 0.6533, Loss: 0.5563
Epoch   3 Batch   32/269 - Train Accuracy: 0.6376, Validation Accuracy: 0.6541, Loss: 0.5631
Epoch   3 Batch   33/269 - Train Accuracy: 0.6556, Validation Accuracy: 0.6562, Loss: 0.5523
Epoch   3 Batch   34/269 - Train Accuracy: 0.6449, Validation Accuracy: 0.6583, Loss: 0.5579
Epoch   3 Batch   35/269 - Train Accuracy: 0.6380, Validation Accuracy: 0.6573, Loss: 0.5826
Epoch   3 Batch   36/269 - Train Accuracy: 0.6371, Validation Accuracy: 0.6590, Loss: 0.5601
Epoch   3 Batch   37/269 - Train Accuracy: 0.6451, Validation Accuracy: 0.6586, Loss: 0.5615
Epoch   3 Batch   38/269 - Train Accuracy: 0.6437, Validation Accuracy: 0.6556, Loss: 0.5595
Epoch   3 Batch   39/269 - Train Accuracy: 0.6442, Validation Accuracy: 0.6593, Loss: 0.5646
Epoch   3 Batch   40/269 - Train Accuracy: 0.6275, Validation Accuracy: 0.6586, Loss: 0.5838
Epoch   3 Batch   41/269 - Train Accuracy: 0.6393, Validation Accuracy: 0.6538, Loss: 0.5698
Epoch   3 Batch   42/269 - Train Accuracy: 0.6642, Validation Accuracy: 0.6575, Loss: 0.5383
Epoch   3 Batch   43/269 - Train Accuracy: 0.6390, Validation Accuracy: 0.6604, Loss: 0.5742
Epoch   3 Batch   44/269 - Train Accuracy: 0.6422, Validation Accuracy: 0.6611, Loss: 0.5629
Epoch   3 Batch   45/269 - Train Accuracy: 0.6392, Validation Accuracy: 0.6610, Loss: 0.5824
Epoch   3 Batch   46/269 - Train Accuracy: 0.6395, Validation Accuracy: 0.6583, Loss: 0.5800
Epoch   3 Batch   47/269 - Train Accuracy: 0.6692, Validation Accuracy: 0.6591, Loss: 0.5262
Epoch   3 Batch   48/269 - Train Accuracy: 0.6544, Validation Accuracy: 0.6636, Loss: 0.5409
Epoch   3 Batch   49/269 - Train Accuracy: 0.6325, Validation Accuracy: 0.6610, Loss: 0.5704
Epoch   3 Batch   50/269 - Train Accuracy: 0.6404, Validation Accuracy: 0.6607, Loss: 0.5762
Epoch   3 Batch   51/269 - Train Accuracy: 0.6388, Validation Accuracy: 0.6590, Loss: 0.5602
Epoch   3 Batch   52/269 - Train Accuracy: 0.6468, Validation Accuracy: 0.6575, Loss: 0.5378
Epoch   3 Batch   53/269 - Train Accuracy: 0.6281, Validation Accuracy: 0.6535, Loss: 0.5874
Epoch   3 Batch   54/269 - Train Accuracy: 0.6566, Validation Accuracy: 0.6540, Loss: 0.5750
Epoch   3 Batch   55/269 - Train Accuracy: 0.6589, Validation Accuracy: 0.6568, Loss: 0.5466
Epoch   3 Batch   56/269 - Train Accuracy: 0.6457, Validation Accuracy: 0.6539, Loss: 0.5515
Epoch   3 Batch   57/269 - Train Accuracy: 0.6444, Validation Accuracy: 0.6547, Loss: 0.5676
Epoch   3 Batch   58/269 - Train Accuracy: 0.6467, Validation Accuracy: 0.6562, Loss: 0.5490
Epoch   3 Batch   59/269 - Train Accuracy: 0.6577, Validation Accuracy: 0.6569, Loss: 0.5328
Epoch   3 Batch   60/269 - Train Accuracy: 0.6525, Validation Accuracy: 0.6607, Loss: 0.5277
Epoch   3 Batch   61/269 - Train Accuracy: 0.6676, Validation Accuracy: 0.6630, Loss: 0.5129
Epoch   3 Batch   62/269 - Train Accuracy: 0.6620, Validation Accuracy: 0.6624, Loss: 0.5333
Epoch   3 Batch   63/269 - Train Accuracy: 0.6459, Validation Accuracy: 0.6613, Loss: 0.5639
Epoch   3 Batch   64/269 - Train Accuracy: 0.6484, Validation Accuracy: 0.6594, Loss: 0.5458
Epoch   3 Batch   65/269 - Train Accuracy: 0.6443, Validation Accuracy: 0.6567, Loss: 0.5469
Epoch   3 Batch   66/269 - Train Accuracy: 0.6386, Validation Accuracy: 0.6589, Loss: 0.5327
Epoch   3 Batch   67/269 - Train Accuracy: 0.6361, Validation Accuracy: 0.6589, Loss: 0.5587
Epoch   3 Batch   68/269 - Train Accuracy: 0.6282, Validation Accuracy: 0.6531, Loss: 0.5520
Epoch   3 Batch   69/269 - Train Accuracy: 0.6123, Validation Accuracy: 0.6534, Loss: 0.6026
Epoch   3 Batch   70/269 - Train Accuracy: 0.6557, Validation Accuracy: 0.6578, Loss: 0.5486
Epoch   3 Batch   71/269 - Train Accuracy: 0.6372, Validation Accuracy: 0.6506, Loss: 0.5783
Epoch   3 Batch   72/269 - Train Accuracy: 0.6465, Validation Accuracy: 0.6501, Loss: 0.5413
Epoch   3 Batch   73/269 - Train Accuracy: 0.6399, Validation Accuracy: 0.6516, Loss: 0.5602
Epoch   3 Batch   74/269 - Train Accuracy: 0.6542, Validation Accuracy: 0.6524, Loss: 0.5565
Epoch   3 Batch   75/269 - Train Accuracy: 0.6503, Validation Accuracy: 0.6544, Loss: 0.5378
Epoch   3 Batch   76/269 - Train Accuracy: 0.6376, Validation Accuracy: 0.6539, Loss: 0.5556
Epoch   3 Batch   77/269 - Train Accuracy: 0.6623, Validation Accuracy: 0.6506, Loss: 0.5427
Epoch   3 Batch   78/269 - Train Accuracy: 0.6538, Validation Accuracy: 0.6524, Loss: 0.5380
Epoch   3 Batch   79/269 - Train Accuracy: 0.6499, Validation Accuracy: 0.6578, Loss: 0.5406
Epoch   3 Batch   80/269 - Train Accuracy: 0.6696, Validation Accuracy: 0.6594, Loss: 0.5264
Epoch   3 Batch   81/269 - Train Accuracy: 0.6577, Validation Accuracy: 0.6595, Loss: 0.5519
Epoch   3 Batch   82/269 - Train Accuracy: 0.6719, Validation Accuracy: 0.6618, Loss: 0.5193
Epoch   3 Batch   83/269 - Train Accuracy: 0.6495, Validation Accuracy: 0.6581, Loss: 0.5439
Epoch   3 Batch   84/269 - Train Accuracy: 0.6560, Validation Accuracy: 0.6622, Loss: 0.5275
Epoch   3 Batch   85/269 - Train Accuracy: 0.6441, Validation Accuracy: 0.6584, Loss: 0.5359
Epoch   3 Batch   86/269 - Train Accuracy: 0.6372, Validation Accuracy: 0.6599, Loss: 0.5314
Epoch   3 Batch   87/269 - Train Accuracy: 0.6224, Validation Accuracy: 0.6596, Loss: 0.5705
Epoch   3 Batch   88/269 - Train Accuracy: 0.6421, Validation Accuracy: 0.6587, Loss: 0.5375
Epoch   3 Batch   89/269 - Train Accuracy: 0.6642, Validation Accuracy: 0.6570, Loss: 0.5368
Epoch   3 Batch   90/269 - Train Accuracy: 0.6162, Validation Accuracy: 0.6570, Loss: 0.5710
Epoch   3 Batch   91/269 - Train Accuracy: 0.6611, Validation Accuracy: 0.6588, Loss: 0.5141
Epoch   3 Batch   92/269 - Train Accuracy: 0.6430, Validation Accuracy: 0.6579, Loss: 0.5310
Epoch   3 Batch   93/269 - Train Accuracy: 0.6689, Validation Accuracy: 0.6616, Loss: 0.5140
Epoch   3 Batch   94/269 - Train Accuracy: 0.6508, Validation Accuracy: 0.6586, Loss: 0.5502
Epoch   3 Batch   95/269 - Train Accuracy: 0.6469, Validation Accuracy: 0.6650, Loss: 0.5383
Epoch   3 Batch   96/269 - Train Accuracy: 0.6477, Validation Accuracy: 0.6555, Loss: 0.5362
Epoch   3 Batch   97/269 - Train Accuracy: 0.6496, Validation Accuracy: 0.6506, Loss: 0.5348
Epoch   3 Batch   98/269 - Train Accuracy: 0.6565, Validation Accuracy: 0.6594, Loss: 0.5361
Epoch   3 Batch   99/269 - Train Accuracy: 0.6456, Validation Accuracy: 0.6607, Loss: 0.5517
Epoch   3 Batch  100/269 - Train Accuracy: 0.6792, Validation Accuracy: 0.6614, Loss: 0.5446
Epoch   3 Batch  101/269 - Train Accuracy: 0.6260, Validation Accuracy: 0.6652, Loss: 0.5605
Epoch   3 Batch  102/269 - Train Accuracy: 0.6439, Validation Accuracy: 0.6579, Loss: 0.5350
Epoch   3 Batch  103/269 - Train Accuracy: 0.6512, Validation Accuracy: 0.6545, Loss: 0.5341
Epoch   3 Batch  104/269 - Train Accuracy: 0.6456, Validation Accuracy: 0.6599, Loss: 0.5371
Epoch   3 Batch  105/269 - Train Accuracy: 0.6398, Validation Accuracy: 0.6636, Loss: 0.5587
Epoch   3 Batch  106/269 - Train Accuracy: 0.6413, Validation Accuracy: 0.6568, Loss: 0.5235
Epoch   3 Batch  107/269 - Train Accuracy: 0.6266, Validation Accuracy: 0.6553, Loss: 0.5710
Epoch   3 Batch  108/269 - Train Accuracy: 0.6524, Validation Accuracy: 0.6600, Loss: 0.5320
Epoch   3 Batch  109/269 - Train Accuracy: 0.6347, Validation Accuracy: 0.6630, Loss: 0.5428
Epoch   3 Batch  110/269 - Train Accuracy: 0.6506, Validation Accuracy: 0.6600, Loss: 0.5183
Epoch   3 Batch  111/269 - Train Accuracy: 0.6311, Validation Accuracy: 0.6614, Loss: 0.5642
Epoch   3 Batch  112/269 - Train Accuracy: 0.6527, Validation Accuracy: 0.6586, Loss: 0.5269
Epoch   3 Batch  113/269 - Train Accuracy: 0.6555, Validation Accuracy: 0.6566, Loss: 0.5127
Epoch   3 Batch  114/269 - Train Accuracy: 0.6537, Validation Accuracy: 0.6537, Loss: 0.5244
Epoch   3 Batch  115/269 - Train Accuracy: 0.6451, Validation Accuracy: 0.6585, Loss: 0.5548
Epoch   3 Batch  116/269 - Train Accuracy: 0.6540, Validation Accuracy: 0.6660, Loss: 0.5343
Epoch   3 Batch  117/269 - Train Accuracy: 0.6498, Validation Accuracy: 0.6582, Loss: 0.5282
Epoch   3 Batch  118/269 - Train Accuracy: 0.6656, Validation Accuracy: 0.6595, Loss: 0.5165
Epoch   3 Batch  119/269 - Train Accuracy: 0.6523, Validation Accuracy: 0.6657, Loss: 0.5494
Epoch   3 Batch  120/269 - Train Accuracy: 0.6504, Validation Accuracy: 0.6627, Loss: 0.5420
Epoch   3 Batch  121/269 - Train Accuracy: 0.6497, Validation Accuracy: 0.6689, Loss: 0.5215
Epoch   3 Batch  122/269 - Train Accuracy: 0.6652, Validation Accuracy: 0.6669, Loss: 0.5171
Epoch   3 Batch  123/269 - Train Accuracy: 0.6423, Validation Accuracy: 0.6642, Loss: 0.5446
Epoch   3 Batch  124/269 - Train Accuracy: 0.6478, Validation Accuracy: 0.6658, Loss: 0.5121
Epoch   3 Batch  125/269 - Train Accuracy: 0.6576, Validation Accuracy: 0.6697, Loss: 0.5107
Epoch   3 Batch  126/269 - Train Accuracy: 0.6580, Validation Accuracy: 0.6706, Loss: 0.5169
Epoch   3 Batch  127/269 - Train Accuracy: 0.6446, Validation Accuracy: 0.6697, Loss: 0.5374
Epoch   3 Batch  128/269 - Train Accuracy: 0.6743, Validation Accuracy: 0.6730, Loss: 0.5245
Epoch   3 Batch  129/269 - Train Accuracy: 0.6498, Validation Accuracy: 0.6713, Loss: 0.5172
Epoch   3 Batch  130/269 - Train Accuracy: 0.6329, Validation Accuracy: 0.6689, Loss: 0.5392
Epoch   3 Batch  131/269 - Train Accuracy: 0.6517, Validation Accuracy: 0.6739, Loss: 0.5330
Epoch   3 Batch  132/269 - Train Accuracy: 0.6649, Validation Accuracy: 0.6705, Loss: 0.5285
Epoch   3 Batch  133/269 - Train Accuracy: 0.6630, Validation Accuracy: 0.6655, Loss: 0.5053
Epoch   3 Batch  134/269 - Train Accuracy: 0.6366, Validation Accuracy: 0.6647, Loss: 0.5283
Epoch   3 Batch  135/269 - Train Accuracy: 0.6362, Validation Accuracy: 0.6695, Loss: 0.5551
Epoch   3 Batch  136/269 - Train Accuracy: 0.6415, Validation Accuracy: 0.6630, Loss: 0.5459
Epoch   3 Batch  137/269 - Train Accuracy: 0.6481, Validation Accuracy: 0.6604, Loss: 0.5481
Epoch   3 Batch  138/269 - Train Accuracy: 0.6565, Validation Accuracy: 0.6687, Loss: 0.5276
Epoch   3 Batch  139/269 - Train Accuracy: 0.6780, Validation Accuracy: 0.6773, Loss: 0.4988
Epoch   3 Batch  140/269 - Train Accuracy: 0.6716, Validation Accuracy: 0.6770, Loss: 0.5195
Epoch   3 Batch  141/269 - Train Accuracy: 0.6633, Validation Accuracy: 0.6737, Loss: 0.5282
Epoch   3 Batch  142/269 - Train Accuracy: 0.6636, Validation Accuracy: 0.6783, Loss: 0.5012
Epoch   3 Batch  143/269 - Train Accuracy: 0.6647, Validation Accuracy: 0.6750, Loss: 0.5096
Epoch   3 Batch  144/269 - Train Accuracy: 0.6787, Validation Accuracy: 0.6764, Loss: 0.4920
Epoch   3 Batch  145/269 - Train Accuracy: 0.6708, Validation Accuracy: 0.6743, Loss: 0.4997
Epoch   3 Batch  146/269 - Train Accuracy: 0.6754, Validation Accuracy: 0.6828, Loss: 0.5015
Epoch   3 Batch  147/269 - Train Accuracy: 0.6871, Validation Accuracy: 0.6809, Loss: 0.4843
Epoch   3 Batch  148/269 - Train Accuracy: 0.6715, Validation Accuracy: 0.6829, Loss: 0.5125
Epoch   3 Batch  149/269 - Train Accuracy: 0.6632, Validation Accuracy: 0.6742, Loss: 0.5143
Epoch   3 Batch  150/269 - Train Accuracy: 0.6818, Validation Accuracy: 0.6787, Loss: 0.5064
Epoch   3 Batch  151/269 - Train Accuracy: 0.6853, Validation Accuracy: 0.6713, Loss: 0.4860
Epoch   3 Batch  152/269 - Train Accuracy: 0.6663, Validation Accuracy: 0.6790, Loss: 0.5139
Epoch   3 Batch  153/269 - Train Accuracy: 0.6749, Validation Accuracy: 0.6801, Loss: 0.4948
Epoch   3 Batch  154/269 - Train Accuracy: 0.6590, Validation Accuracy: 0.6740, Loss: 0.5180
Epoch   3 Batch  155/269 - Train Accuracy: 0.6942, Validation Accuracy: 0.6732, Loss: 0.4780
Epoch   3 Batch  156/269 - Train Accuracy: 0.6537, Validation Accuracy: 0.6810, Loss: 0.5286
Epoch   3 Batch  157/269 - Train Accuracy: 0.6636, Validation Accuracy: 0.6799, Loss: 0.5044
Epoch   3 Batch  158/269 - Train Accuracy: 0.6699, Validation Accuracy: 0.6758, Loss: 0.5018
Epoch   3 Batch  159/269 - Train Accuracy: 0.6666, Validation Accuracy: 0.6781, Loss: 0.5071
Epoch   3 Batch  160/269 - Train Accuracy: 0.6746, Validation Accuracy: 0.6808, Loss: 0.4966
Epoch   3 Batch  161/269 - Train Accuracy: 0.6727, Validation Accuracy: 0.6821, Loss: 0.5105
Epoch   3 Batch  162/269 - Train Accuracy: 0.6748, Validation Accuracy: 0.6813, Loss: 0.4942
Epoch   3 Batch  163/269 - Train Accuracy: 0.6777, Validation Accuracy: 0.6806, Loss: 0.4975
Epoch   3 Batch  164/269 - Train Accuracy: 0.6789, Validation Accuracy: 0.6821, Loss: 0.4970
Epoch   3 Batch  165/269 - Train Accuracy: 0.6662, Validation Accuracy: 0.6847, Loss: 0.5141
Epoch   3 Batch  166/269 - Train Accuracy: 0.6849, Validation Accuracy: 0.6837, Loss: 0.4721
Epoch   3 Batch  167/269 - Train Accuracy: 0.6782, Validation Accuracy: 0.6824, Loss: 0.4979
Epoch   3 Batch  168/269 - Train Accuracy: 0.6514, Validation Accuracy: 0.6757, Loss: 0.5081
Epoch   3 Batch  169/269 - Train Accuracy: 0.6711, Validation Accuracy: 0.6860, Loss: 0.5072
Epoch   3 Batch  170/269 - Train Accuracy: 0.6758, Validation Accuracy: 0.6869, Loss: 0.4961
Epoch   3 Batch  171/269 - Train Accuracy: 0.6839, Validation Accuracy: 0.6888, Loss: 0.5143
Epoch   3 Batch  172/269 - Train Accuracy: 0.6718, Validation Accuracy: 0.6929, Loss: 0.5029
Epoch   3 Batch  173/269 - Train Accuracy: 0.6784, Validation Accuracy: 0.6809, Loss: 0.4843
Epoch   3 Batch  174/269 - Train Accuracy: 0.6670, Validation Accuracy: 0.6834, Loss: 0.4972
Epoch   3 Batch  175/269 - Train Accuracy: 0.6835, Validation Accuracy: 0.6870, Loss: 0.5089
Epoch   3 Batch  176/269 - Train Accuracy: 0.6711, Validation Accuracy: 0.6894, Loss: 0.5261
Epoch   3 Batch  177/269 - Train Accuracy: 0.6876, Validation Accuracy: 0.6895, Loss: 0.4659
Epoch   3 Batch  178/269 - Train Accuracy: 0.6674, Validation Accuracy: 0.6829, Loss: 0.4986
Epoch   3 Batch  179/269 - Train Accuracy: 0.6716, Validation Accuracy: 0.6854, Loss: 0.4907
Epoch   3 Batch  180/269 - Train Accuracy: 0.6738, Validation Accuracy: 0.6837, Loss: 0.4907
Epoch   3 Batch  181/269 - Train Accuracy: 0.6767, Validation Accuracy: 0.6925, Loss: 0.4908
Epoch   3 Batch  182/269 - Train Accuracy: 0.6878, Validation Accuracy: 0.6838, Loss: 0.4998
Epoch   3 Batch  183/269 - Train Accuracy: 0.7167, Validation Accuracy: 0.6776, Loss: 0.4294
Epoch   3 Batch  184/269 - Train Accuracy: 0.6598, Validation Accuracy: 0.6844, Loss: 0.5109
Epoch   3 Batch  185/269 - Train Accuracy: 0.6813, Validation Accuracy: 0.6862, Loss: 0.4853
Epoch   3 Batch  186/269 - Train Accuracy: 0.6670, Validation Accuracy: 0.6844, Loss: 0.5037
Epoch   3 Batch  187/269 - Train Accuracy: 0.6944, Validation Accuracy: 0.6779, Loss: 0.4805
Epoch   3 Batch  188/269 - Train Accuracy: 0.6939, Validation Accuracy: 0.6831, Loss: 0.4700
Epoch   3 Batch  189/269 - Train Accuracy: 0.6702, Validation Accuracy: 0.6818, Loss: 0.4763
Epoch   3 Batch  190/269 - Train Accuracy: 0.6818, Validation Accuracy: 0.6887, Loss: 0.4777
Epoch   3 Batch  191/269 - Train Accuracy: 0.6868, Validation Accuracy: 0.6884, Loss: 0.4843
Epoch   3 Batch  192/269 - Train Accuracy: 0.6874, Validation Accuracy: 0.6872, Loss: 0.4854
Epoch   3 Batch  193/269 - Train Accuracy: 0.6841, Validation Accuracy: 0.6936, Loss: 0.4785
Epoch   3 Batch  194/269 - Train Accuracy: 0.6956, Validation Accuracy: 0.6959, Loss: 0.4851
Epoch   3 Batch  195/269 - Train Accuracy: 0.6893, Validation Accuracy: 0.6939, Loss: 0.4816
Epoch   3 Batch  196/269 - Train Accuracy: 0.6682, Validation Accuracy: 0.6943, Loss: 0.4773
Epoch   3 Batch  197/269 - Train Accuracy: 0.6830, Validation Accuracy: 0.6930, Loss: 0.5048
Epoch   3 Batch  198/269 - Train Accuracy: 0.6776, Validation Accuracy: 0.6896, Loss: 0.5074
Epoch   3 Batch  199/269 - Train Accuracy: 0.6684, Validation Accuracy: 0.6916, Loss: 0.4979
Epoch   3 Batch  200/269 - Train Accuracy: 0.6799, Validation Accuracy: 0.6891, Loss: 0.4956
Epoch   3 Batch  201/269 - Train Accuracy: 0.6902, Validation Accuracy: 0.7047, Loss: 0.4843
Epoch   3 Batch  202/269 - Train Accuracy: 0.6793, Validation Accuracy: 0.6972, Loss: 0.4773
Epoch   3 Batch  203/269 - Train Accuracy: 0.6752, Validation Accuracy: 0.6991, Loss: 0.5144
Epoch   3 Batch  204/269 - Train Accuracy: 0.6786, Validation Accuracy: 0.7020, Loss: 0.5009
Epoch   3 Batch  205/269 - Train Accuracy: 0.6784, Validation Accuracy: 0.6942, Loss: 0.4740
Epoch   3 Batch  206/269 - Train Accuracy: 0.6809, Validation Accuracy: 0.6985, Loss: 0.4969
Epoch   3 Batch  207/269 - Train Accuracy: 0.6946, Validation Accuracy: 0.6962, Loss: 0.4628
Epoch   3 Batch  208/269 - Train Accuracy: 0.6805, Validation Accuracy: 0.6911, Loss: 0.4926
Epoch   3 Batch  209/269 - Train Accuracy: 0.6907, Validation Accuracy: 0.6937, Loss: 0.4845
Epoch   3 Batch  210/269 - Train Accuracy: 0.6964, Validation Accuracy: 0.6941, Loss: 0.4662
Epoch   3 Batch  211/269 - Train Accuracy: 0.6789, Validation Accuracy: 0.6982, Loss: 0.4782
Epoch   3 Batch  212/269 - Train Accuracy: 0.7037, Validation Accuracy: 0.6984, Loss: 0.4663
Epoch   3 Batch  213/269 - Train Accuracy: 0.6965, Validation Accuracy: 0.6984, Loss: 0.4772
Epoch   3 Batch  214/269 - Train Accuracy: 0.7032, Validation Accuracy: 0.6989, Loss: 0.4739
Epoch   3 Batch  215/269 - Train Accuracy: 0.7172, Validation Accuracy: 0.6927, Loss: 0.4479
Epoch   3 Batch  216/269 - Train Accuracy: 0.6651, Validation Accuracy: 0.6910, Loss: 0.5074
Epoch   3 Batch  217/269 - Train Accuracy: 0.6743, Validation Accuracy: 0.6946, Loss: 0.4877
Epoch   3 Batch  218/269 - Train Accuracy: 0.6832, Validation Accuracy: 0.6993, Loss: 0.4924
Epoch   3 Batch  219/269 - Train Accuracy: 0.6935, Validation Accuracy: 0.6963, Loss: 0.4879
Epoch   3 Batch  220/269 - Train Accuracy: 0.6914, Validation Accuracy: 0.7011, Loss: 0.4489
Epoch   3 Batch  221/269 - Train Accuracy: 0.7135, Validation Accuracy: 0.7029, Loss: 0.4705
Epoch   3 Batch  222/269 - Train Accuracy: 0.7208, Validation Accuracy: 0.7014, Loss: 0.4500
Epoch   3 Batch  223/269 - Train Accuracy: 0.6880, Validation Accuracy: 0.7006, Loss: 0.4608
Epoch   3 Batch  224/269 - Train Accuracy: 0.6991, Validation Accuracy: 0.6950, Loss: 0.4801
Epoch   3 Batch  225/269 - Train Accuracy: 0.6802, Validation Accuracy: 0.6952, Loss: 0.4743
Epoch   3 Batch  226/269 - Train Accuracy: 0.7080, Validation Accuracy: 0.7009, Loss: 0.4705
Epoch   3 Batch  227/269 - Train Accuracy: 0.7387, Validation Accuracy: 0.7030, Loss: 0.4219
Epoch   3 Batch  228/269 - Train Accuracy: 0.6988, Validation Accuracy: 0.7066, Loss: 0.4619
Epoch   3 Batch  229/269 - Train Accuracy: 0.7046, Validation Accuracy: 0.7002, Loss: 0.4592
Epoch   3 Batch  230/269 - Train Accuracy: 0.7009, Validation Accuracy: 0.7018, Loss: 0.4672
Epoch   3 Batch  231/269 - Train Accuracy: 0.6759, Validation Accuracy: 0.7052, Loss: 0.4967
Epoch   3 Batch  232/269 - Train Accuracy: 0.6788, Validation Accuracy: 0.7041, Loss: 0.4954
Epoch   3 Batch  233/269 - Train Accuracy: 0.7037, Validation Accuracy: 0.7027, Loss: 0.4682
Epoch   3 Batch  234/269 - Train Accuracy: 0.7071, Validation Accuracy: 0.7058, Loss: 0.4594
Epoch   3 Batch  235/269 - Train Accuracy: 0.7104, Validation Accuracy: 0.7060, Loss: 0.4524
Epoch   3 Batch  236/269 - Train Accuracy: 0.7014, Validation Accuracy: 0.7045, Loss: 0.4504
Epoch   3 Batch  237/269 - Train Accuracy: 0.6868, Validation Accuracy: 0.7089, Loss: 0.4619
Epoch   3 Batch  238/269 - Train Accuracy: 0.7217, Validation Accuracy: 0.7053, Loss: 0.4520
Epoch   3 Batch  239/269 - Train Accuracy: 0.6914, Validation Accuracy: 0.7043, Loss: 0.4589
Epoch   3 Batch  240/269 - Train Accuracy: 0.7269, Validation Accuracy: 0.7078, Loss: 0.4198
Epoch   3 Batch  241/269 - Train Accuracy: 0.7069, Validation Accuracy: 0.6929, Loss: 0.4610
Epoch   3 Batch  242/269 - Train Accuracy: 0.7038, Validation Accuracy: 0.7104, Loss: 0.4513
Epoch   3 Batch  243/269 - Train Accuracy: 0.7032, Validation Accuracy: 0.6998, Loss: 0.4434
Epoch   3 Batch  244/269 - Train Accuracy: 0.6901, Validation Accuracy: 0.6985, Loss: 0.4617
Epoch   3 Batch  245/269 - Train Accuracy: 0.6788, Validation Accuracy: 0.7000, Loss: 0.4871
Epoch   3 Batch  246/269 - Train Accuracy: 0.6855, Validation Accuracy: 0.7119, Loss: 0.4581
Epoch   3 Batch  247/269 - Train Accuracy: 0.6894, Validation Accuracy: 0.7133, Loss: 0.4757
Epoch   3 Batch  248/269 - Train Accuracy: 0.7044, Validation Accuracy: 0.7114, Loss: 0.4476
Epoch   3 Batch  249/269 - Train Accuracy: 0.7218, Validation Accuracy: 0.7148, Loss: 0.4334
Epoch   3 Batch  250/269 - Train Accuracy: 0.7012, Validation Accuracy: 0.7112, Loss: 0.4657
Epoch   3 Batch  251/269 - Train Accuracy: 0.7226, Validation Accuracy: 0.7077, Loss: 0.4409
Epoch   3 Batch  252/269 - Train Accuracy: 0.6892, Validation Accuracy: 0.7030, Loss: 0.4600
Epoch   3 Batch  253/269 - Train Accuracy: 0.6868, Validation Accuracy: 0.7036, Loss: 0.4612
Epoch   3 Batch  254/269 - Train Accuracy: 0.7108, Validation Accuracy: 0.7090, Loss: 0.4504
Epoch   3 Batch  255/269 - Train Accuracy: 0.7156, Validation Accuracy: 0.7085, Loss: 0.4484
Epoch   3 Batch  256/269 - Train Accuracy: 0.6815, Validation Accuracy: 0.7074, Loss: 0.4699
Epoch   3 Batch  257/269 - Train Accuracy: 0.6818, Validation Accuracy: 0.7102, Loss: 0.4638
Epoch   3 Batch  258/269 - Train Accuracy: 0.6898, Validation Accuracy: 0.7020, Loss: 0.4595
Epoch   3 Batch  259/269 - Train Accuracy: 0.6994, Validation Accuracy: 0.7051, Loss: 0.4566
Epoch   3 Batch  260/269 - Train Accuracy: 0.6940, Validation Accuracy: 0.7044, Loss: 0.4693
Epoch   3 Batch  261/269 - Train Accuracy: 0.6697, Validation Accuracy: 0.7030, Loss: 0.4805
Epoch   3 Batch  262/269 - Train Accuracy: 0.6974, Validation Accuracy: 0.7063, Loss: 0.4525
Epoch   3 Batch  263/269 - Train Accuracy: 0.7034, Validation Accuracy: 0.7091, Loss: 0.4697
Epoch   3 Batch  264/269 - Train Accuracy: 0.6944, Validation Accuracy: 0.6993, Loss: 0.4732
Epoch   3 Batch  265/269 - Train Accuracy: 0.6915, Validation Accuracy: 0.7047, Loss: 0.4640
Epoch   3 Batch  266/269 - Train Accuracy: 0.7099, Validation Accuracy: 0.7095, Loss: 0.4469
Epoch   3 Batch  267/269 - Train Accuracy: 0.6975, Validation Accuracy: 0.6936, Loss: 0.4565
Epoch   4 Batch    1/269 - Train Accuracy: 0.6937, Validation Accuracy: 0.7104, Loss: 0.4664
Epoch   4 Batch    2/269 - Train Accuracy: 0.6821, Validation Accuracy: 0.7058, Loss: 0.4495
Epoch   4 Batch    3/269 - Train Accuracy: 0.7122, Validation Accuracy: 0.7113, Loss: 0.4628
Epoch   4 Batch    4/269 - Train Accuracy: 0.6873, Validation Accuracy: 0.7062, Loss: 0.4596
Epoch   4 Batch    5/269 - Train Accuracy: 0.6720, Validation Accuracy: 0.7122, Loss: 0.4627
Epoch   4 Batch    6/269 - Train Accuracy: 0.7219, Validation Accuracy: 0.7111, Loss: 0.4301
Epoch   4 Batch    7/269 - Train Accuracy: 0.7134, Validation Accuracy: 0.7117, Loss: 0.4363
Epoch   4 Batch    8/269 - Train Accuracy: 0.6969, Validation Accuracy: 0.6996, Loss: 0.4653
Epoch   4 Batch    9/269 - Train Accuracy: 0.7134, Validation Accuracy: 0.7104, Loss: 0.4574
Epoch   4 Batch   10/269 - Train Accuracy: 0.7072, Validation Accuracy: 0.7207, Loss: 0.4540
Epoch   4 Batch   11/269 - Train Accuracy: 0.7103, Validation Accuracy: 0.7055, Loss: 0.4472
Epoch   4 Batch   12/269 - Train Accuracy: 0.6877, Validation Accuracy: 0.7129, Loss: 0.4697
Epoch   4 Batch   13/269 - Train Accuracy: 0.7181, Validation Accuracy: 0.7195, Loss: 0.4127
Epoch   4 Batch   14/269 - Train Accuracy: 0.7008, Validation Accuracy: 0.7151, Loss: 0.4373
Epoch   4 Batch   15/269 - Train Accuracy: 0.6860, Validation Accuracy: 0.7117, Loss: 0.4290
Epoch   4 Batch   16/269 - Train Accuracy: 0.7209, Validation Accuracy: 0.7095, Loss: 0.4417
Epoch   4 Batch   17/269 - Train Accuracy: 0.6996, Validation Accuracy: 0.7055, Loss: 0.4285
Epoch   4 Batch   18/269 - Train Accuracy: 0.7062, Validation Accuracy: 0.7100, Loss: 0.4524
Epoch   4 Batch   19/269 - Train Accuracy: 0.7205, Validation Accuracy: 0.7162, Loss: 0.4132
Epoch   4 Batch   20/269 - Train Accuracy: 0.7019, Validation Accuracy: 0.7016, Loss: 0.4466
Epoch   4 Batch   21/269 - Train Accuracy: 0.6813, Validation Accuracy: 0.7115, Loss: 0.4650
Epoch   4 Batch   22/269 - Train Accuracy: 0.7157, Validation Accuracy: 0.7224, Loss: 0.4314
Epoch   4 Batch   23/269 - Train Accuracy: 0.7145, Validation Accuracy: 0.7200, Loss: 0.4280
Epoch   4 Batch   24/269 - Train Accuracy: 0.6990, Validation Accuracy: 0.7218, Loss: 0.4566
Epoch   4 Batch   25/269 - Train Accuracy: 0.6982, Validation Accuracy: 0.7167, Loss: 0.4618
Epoch   4 Batch   26/269 - Train Accuracy: 0.7271, Validation Accuracy: 0.7156, Loss: 0.4079
Epoch   4 Batch   27/269 - Train Accuracy: 0.7071, Validation Accuracy: 0.7182, Loss: 0.4266
Epoch   4 Batch   28/269 - Train Accuracy: 0.6678, Validation Accuracy: 0.7222, Loss: 0.4686
Epoch   4 Batch   29/269 - Train Accuracy: 0.7122, Validation Accuracy: 0.7186, Loss: 0.4508
Epoch   4 Batch   30/269 - Train Accuracy: 0.7085, Validation Accuracy: 0.7156, Loss: 0.4274
Epoch   4 Batch   31/269 - Train Accuracy: 0.7115, Validation Accuracy: 0.7128, Loss: 0.4214
Epoch   4 Batch   32/269 - Train Accuracy: 0.7123, Validation Accuracy: 0.7206, Loss: 0.4287
Epoch   4 Batch   33/269 - Train Accuracy: 0.7375, Validation Accuracy: 0.7251, Loss: 0.4159
Epoch   4 Batch   34/269 - Train Accuracy: 0.7181, Validation Accuracy: 0.7225, Loss: 0.4306
Epoch   4 Batch   35/269 - Train Accuracy: 0.7198, Validation Accuracy: 0.7168, Loss: 0.4392
Epoch   4 Batch   36/269 - Train Accuracy: 0.7068, Validation Accuracy: 0.7300, Loss: 0.4316
Epoch   4 Batch   37/269 - Train Accuracy: 0.7236, Validation Accuracy: 0.7217, Loss: 0.4281
Epoch   4 Batch   38/269 - Train Accuracy: 0.7263, Validation Accuracy: 0.7152, Loss: 0.4262
Epoch   4 Batch   39/269 - Train Accuracy: 0.7109, Validation Accuracy: 0.7164, Loss: 0.4240
Epoch   4 Batch   40/269 - Train Accuracy: 0.6911, Validation Accuracy: 0.7116, Loss: 0.4474
Epoch   4 Batch   41/269 - Train Accuracy: 0.7222, Validation Accuracy: 0.7221, Loss: 0.4328
Epoch   4 Batch   42/269 - Train Accuracy: 0.7423, Validation Accuracy: 0.7244, Loss: 0.4071
Epoch   4 Batch   43/269 - Train Accuracy: 0.7189, Validation Accuracy: 0.7145, Loss: 0.4375
Epoch   4 Batch   44/269 - Train Accuracy: 0.7047, Validation Accuracy: 0.7236, Loss: 0.4261
Epoch   4 Batch   45/269 - Train Accuracy: 0.7015, Validation Accuracy: 0.7229, Loss: 0.4404
Epoch   4 Batch   46/269 - Train Accuracy: 0.7073, Validation Accuracy: 0.7144, Loss: 0.4466
Epoch   4 Batch   47/269 - Train Accuracy: 0.7308, Validation Accuracy: 0.7154, Loss: 0.3944
Epoch   4 Batch   48/269 - Train Accuracy: 0.7231, Validation Accuracy: 0.7229, Loss: 0.4096
Epoch   4 Batch   49/269 - Train Accuracy: 0.7164, Validation Accuracy: 0.7170, Loss: 0.4283
Epoch   4 Batch   50/269 - Train Accuracy: 0.6989, Validation Accuracy: 0.7199, Loss: 0.4379
Epoch   4 Batch   51/269 - Train Accuracy: 0.7185, Validation Accuracy: 0.7200, Loss: 0.4182
Epoch   4 Batch   52/269 - Train Accuracy: 0.6961, Validation Accuracy: 0.7195, Loss: 0.4081
Epoch   4 Batch   53/269 - Train Accuracy: 0.7096, Validation Accuracy: 0.7140, Loss: 0.4440
Epoch   4 Batch   54/269 - Train Accuracy: 0.7221, Validation Accuracy: 0.7222, Loss: 0.4330
Epoch   4 Batch   55/269 - Train Accuracy: 0.7320, Validation Accuracy: 0.7276, Loss: 0.4106
Epoch   4 Batch   56/269 - Train Accuracy: 0.7300, Validation Accuracy: 0.7176, Loss: 0.4193
Epoch   4 Batch   57/269 - Train Accuracy: 0.7065, Validation Accuracy: 0.7207, Loss: 0.4320
Epoch   4 Batch   58/269 - Train Accuracy: 0.7303, Validation Accuracy: 0.7282, Loss: 0.4174
Epoch   4 Batch   59/269 - Train Accuracy: 0.7380, Validation Accuracy: 0.7201, Loss: 0.3974
Epoch   4 Batch   60/269 - Train Accuracy: 0.7373, Validation Accuracy: 0.7327, Loss: 0.3966
Epoch   4 Batch   61/269 - Train Accuracy: 0.7293, Validation Accuracy: 0.7278, Loss: 0.3899
Epoch   4 Batch   62/269 - Train Accuracy: 0.7287, Validation Accuracy: 0.7210, Loss: 0.4071
Epoch   4 Batch   63/269 - Train Accuracy: 0.7204, Validation Accuracy: 0.7301, Loss: 0.4301
Epoch   4 Batch   64/269 - Train Accuracy: 0.7216, Validation Accuracy: 0.7241, Loss: 0.4188
Epoch   4 Batch   65/269 - Train Accuracy: 0.7214, Validation Accuracy: 0.7249, Loss: 0.4220
Epoch   4 Batch   66/269 - Train Accuracy: 0.7215, Validation Accuracy: 0.7260, Loss: 0.4061
Epoch   4 Batch   67/269 - Train Accuracy: 0.7198, Validation Accuracy: 0.7328, Loss: 0.4317
Epoch   4 Batch   68/269 - Train Accuracy: 0.7127, Validation Accuracy: 0.7281, Loss: 0.4203
Epoch   4 Batch   69/269 - Train Accuracy: 0.6891, Validation Accuracy: 0.7222, Loss: 0.4604
Epoch   4 Batch   70/269 - Train Accuracy: 0.7193, Validation Accuracy: 0.7092, Loss: 0.4129
Epoch   4 Batch   71/269 - Train Accuracy: 0.7131, Validation Accuracy: 0.7217, Loss: 0.4412
Epoch   4 Batch   72/269 - Train Accuracy: 0.7228, Validation Accuracy: 0.7251, Loss: 0.4116
Epoch   4 Batch   73/269 - Train Accuracy: 0.7174, Validation Accuracy: 0.7227, Loss: 0.4239
Epoch   4 Batch   74/269 - Train Accuracy: 0.7223, Validation Accuracy: 0.7228, Loss: 0.4206
Epoch   4 Batch   75/269 - Train Accuracy: 0.7347, Validation Accuracy: 0.7300, Loss: 0.4113
Epoch   4 Batch   76/269 - Train Accuracy: 0.7084, Validation Accuracy: 0.7290, Loss: 0.4156
Epoch   4 Batch   77/269 - Train Accuracy: 0.7360, Validation Accuracy: 0.7308, Loss: 0.4126
Epoch   4 Batch   78/269 - Train Accuracy: 0.7370, Validation Accuracy: 0.7307, Loss: 0.4065
Epoch   4 Batch   79/269 - Train Accuracy: 0.7192, Validation Accuracy: 0.7240, Loss: 0.4104
Epoch   4 Batch   80/269 - Train Accuracy: 0.7343, Validation Accuracy: 0.7265, Loss: 0.4008
Epoch   4 Batch   81/269 - Train Accuracy: 0.7216, Validation Accuracy: 0.7286, Loss: 0.4237
Epoch   4 Batch   82/269 - Train Accuracy: 0.7563, Validation Accuracy: 0.7305, Loss: 0.3898
Epoch   4 Batch   83/269 - Train Accuracy: 0.7250, Validation Accuracy: 0.7336, Loss: 0.4123
Epoch   4 Batch   84/269 - Train Accuracy: 0.7234, Validation Accuracy: 0.7304, Loss: 0.3985
Epoch   4 Batch   85/269 - Train Accuracy: 0.7288, Validation Accuracy: 0.7362, Loss: 0.4011
Epoch   4 Batch   86/269 - Train Accuracy: 0.7287, Validation Accuracy: 0.7395, Loss: 0.4035
Epoch   4 Batch   87/269 - Train Accuracy: 0.7165, Validation Accuracy: 0.7356, Loss: 0.4325
Epoch   4 Batch   88/269 - Train Accuracy: 0.7096, Validation Accuracy: 0.7324, Loss: 0.4051
Epoch   4 Batch   89/269 - Train Accuracy: 0.7306, Validation Accuracy: 0.7258, Loss: 0.4081
Epoch   4 Batch   90/269 - Train Accuracy: 0.6866, Validation Accuracy: 0.7230, Loss: 0.4330
Epoch   4 Batch   91/269 - Train Accuracy: 0.7498, Validation Accuracy: 0.7291, Loss: 0.4051
Epoch   4 Batch   92/269 - Train Accuracy: 0.7430, Validation Accuracy: 0.7389, Loss: 0.3998
Epoch   4 Batch   93/269 - Train Accuracy: 0.7178, Validation Accuracy: 0.7293, Loss: 0.3870
Epoch   4 Batch   94/269 - Train Accuracy: 0.7323, Validation Accuracy: 0.7275, Loss: 0.4175
Epoch   4 Batch   95/269 - Train Accuracy: 0.7306, Validation Accuracy: 0.7346, Loss: 0.4012
Epoch   4 Batch   96/269 - Train Accuracy: 0.7192, Validation Accuracy: 0.7338, Loss: 0.3992
Epoch   4 Batch   97/269 - Train Accuracy: 0.7310, Validation Accuracy: 0.7422, Loss: 0.4024
Epoch   4 Batch   98/269 - Train Accuracy: 0.7294, Validation Accuracy: 0.7409, Loss: 0.4016
Epoch   4 Batch   99/269 - Train Accuracy: 0.7203, Validation Accuracy: 0.7332, Loss: 0.4157
Epoch   4 Batch  100/269 - Train Accuracy: 0.7504, Validation Accuracy: 0.7364, Loss: 0.4013
Epoch   4 Batch  101/269 - Train Accuracy: 0.7137, Validation Accuracy: 0.7434, Loss: 0.4230
Epoch   4 Batch  102/269 - Train Accuracy: 0.7196, Validation Accuracy: 0.7289, Loss: 0.3951
Epoch   4 Batch  103/269 - Train Accuracy: 0.7389, Validation Accuracy: 0.7304, Loss: 0.3964
Epoch   4 Batch  104/269 - Train Accuracy: 0.7250, Validation Accuracy: 0.7414, Loss: 0.3971
Epoch   4 Batch  105/269 - Train Accuracy: 0.7118, Validation Accuracy: 0.7376, Loss: 0.3963
Epoch   4 Batch  106/269 - Train Accuracy: 0.7336, Validation Accuracy: 0.7313, Loss: 0.3924
Epoch   4 Batch  107/269 - Train Accuracy: 0.7271, Validation Accuracy: 0.7336, Loss: 0.4248
Epoch   4 Batch  108/269 - Train Accuracy: 0.7323, Validation Accuracy: 0.7276, Loss: 0.4029
Epoch   4 Batch  109/269 - Train Accuracy: 0.7094, Validation Accuracy: 0.7392, Loss: 0.4035
Epoch   4 Batch  110/269 - Train Accuracy: 0.7431, Validation Accuracy: 0.7399, Loss: 0.3879
Epoch   4 Batch  111/269 - Train Accuracy: 0.7193, Validation Accuracy: 0.7390, Loss: 0.4242
Epoch   4 Batch  112/269 - Train Accuracy: 0.7317, Validation Accuracy: 0.7362, Loss: 0.3919
Epoch   4 Batch  113/269 - Train Accuracy: 0.7397, Validation Accuracy: 0.7432, Loss: 0.3821
Epoch   4 Batch  114/269 - Train Accuracy: 0.7442, Validation Accuracy: 0.7463, Loss: 0.3919
Epoch   4 Batch  115/269 - Train Accuracy: 0.7098, Validation Accuracy: 0.7402, Loss: 0.4106
Epoch   4 Batch  116/269 - Train Accuracy: 0.7453, Validation Accuracy: 0.7361, Loss: 0.4010
Epoch   4 Batch  117/269 - Train Accuracy: 0.7237, Validation Accuracy: 0.7331, Loss: 0.3961
Epoch   4 Batch  118/269 - Train Accuracy: 0.7589, Validation Accuracy: 0.7432, Loss: 0.3845
Epoch   4 Batch  119/269 - Train Accuracy: 0.7485, Validation Accuracy: 0.7430, Loss: 0.4091
Epoch   4 Batch  120/269 - Train Accuracy: 0.7319, Validation Accuracy: 0.7463, Loss: 0.4062
Epoch   4 Batch  121/269 - Train Accuracy: 0.7274, Validation Accuracy: 0.7364, Loss: 0.3858
Epoch   4 Batch  122/269 - Train Accuracy: 0.7493, Validation Accuracy: 0.7369, Loss: 0.3855
Epoch   4 Batch  123/269 - Train Accuracy: 0.7398, Validation Accuracy: 0.7385, Loss: 0.4221
Epoch   4 Batch  124/269 - Train Accuracy: 0.7239, Validation Accuracy: 0.7325, Loss: 0.3950
Epoch   4 Batch  125/269 - Train Accuracy: 0.7405, Validation Accuracy: 0.7453, Loss: 0.3932
Epoch   4 Batch  126/269 - Train Accuracy: 0.7149, Validation Accuracy: 0.7394, Loss: 0.3850
Epoch   4 Batch  127/269 - Train Accuracy: 0.7208, Validation Accuracy: 0.7368, Loss: 0.4073
Epoch   4 Batch  128/269 - Train Accuracy: 0.7526, Validation Accuracy: 0.7381, Loss: 0.3944
Epoch   4 Batch  129/269 - Train Accuracy: 0.7311, Validation Accuracy: 0.7358, Loss: 0.3883
Epoch   4 Batch  130/269 - Train Accuracy: 0.7076, Validation Accuracy: 0.7338, Loss: 0.4112
Epoch   4 Batch  131/269 - Train Accuracy: 0.7238, Validation Accuracy: 0.7460, Loss: 0.4084
Epoch   4 Batch  132/269 - Train Accuracy: 0.7334, Validation Accuracy: 0.7367, Loss: 0.4023
Epoch   4 Batch  133/269 - Train Accuracy: 0.7507, Validation Accuracy: 0.7360, Loss: 0.3837
Epoch   4 Batch  134/269 - Train Accuracy: 0.7276, Validation Accuracy: 0.7419, Loss: 0.4031
Epoch   4 Batch  135/269 - Train Accuracy: 0.7171, Validation Accuracy: 0.7363, Loss: 0.4186
Epoch   4 Batch  136/269 - Train Accuracy: 0.7206, Validation Accuracy: 0.7474, Loss: 0.4159
Epoch   4 Batch  137/269 - Train Accuracy: 0.7251, Validation Accuracy: 0.7441, Loss: 0.4136
Epoch   4 Batch  138/269 - Train Accuracy: 0.7380, Validation Accuracy: 0.7430, Loss: 0.3955
Epoch   4 Batch  139/269 - Train Accuracy: 0.7549, Validation Accuracy: 0.7480, Loss: 0.3758
Epoch   4 Batch  140/269 - Train Accuracy: 0.7369, Validation Accuracy: 0.7409, Loss: 0.3956
Epoch   4 Batch  141/269 - Train Accuracy: 0.7347, Validation Accuracy: 0.7499, Loss: 0.3979
Epoch   4 Batch  142/269 - Train Accuracy: 0.7435, Validation Accuracy: 0.7539, Loss: 0.3823
Epoch   4 Batch  143/269 - Train Accuracy: 0.7378, Validation Accuracy: 0.7406, Loss: 0.3814
Epoch   4 Batch  144/269 - Train Accuracy: 0.7479, Validation Accuracy: 0.7372, Loss: 0.3716
Epoch   4 Batch  145/269 - Train Accuracy: 0.7461, Validation Accuracy: 0.7516, Loss: 0.3752
Epoch   4 Batch  146/269 - Train Accuracy: 0.7340, Validation Accuracy: 0.7385, Loss: 0.3750
Epoch   4 Batch  147/269 - Train Accuracy: 0.7582, Validation Accuracy: 0.7463, Loss: 0.3710
Epoch   4 Batch  148/269 - Train Accuracy: 0.7330, Validation Accuracy: 0.7482, Loss: 0.3855
Epoch   4 Batch  149/269 - Train Accuracy: 0.7229, Validation Accuracy: 0.7388, Loss: 0.3869
Epoch   4 Batch  150/269 - Train Accuracy: 0.7514, Validation Accuracy: 0.7507, Loss: 0.3848
Epoch   4 Batch  151/269 - Train Accuracy: 0.7635, Validation Accuracy: 0.7451, Loss: 0.3664
Epoch   4 Batch  152/269 - Train Accuracy: 0.7377, Validation Accuracy: 0.7474, Loss: 0.3828
Epoch   4 Batch  153/269 - Train Accuracy: 0.7442, Validation Accuracy: 0.7512, Loss: 0.3741
Epoch   4 Batch  154/269 - Train Accuracy: 0.7484, Validation Accuracy: 0.7444, Loss: 0.3873
Epoch   4 Batch  155/269 - Train Accuracy: 0.7472, Validation Accuracy: 0.7389, Loss: 0.3648
Epoch   4 Batch  156/269 - Train Accuracy: 0.7142, Validation Accuracy: 0.7406, Loss: 0.3903
Epoch   4 Batch  157/269 - Train Accuracy: 0.7366, Validation Accuracy: 0.7469, Loss: 0.3702
Epoch   4 Batch  158/269 - Train Accuracy: 0.7404, Validation Accuracy: 0.7455, Loss: 0.3740
Epoch   4 Batch  159/269 - Train Accuracy: 0.7498, Validation Accuracy: 0.7405, Loss: 0.3766
Epoch   4 Batch  160/269 - Train Accuracy: 0.7546, Validation Accuracy: 0.7473, Loss: 0.3791
Epoch   4 Batch  161/269 - Train Accuracy: 0.7350, Validation Accuracy: 0.7447, Loss: 0.3744
Epoch   4 Batch  162/269 - Train Accuracy: 0.7568, Validation Accuracy: 0.7450, Loss: 0.3682
Epoch   4 Batch  163/269 - Train Accuracy: 0.7495, Validation Accuracy: 0.7498, Loss: 0.3713
Epoch   4 Batch  164/269 - Train Accuracy: 0.7501, Validation Accuracy: 0.7386, Loss: 0.3780
Epoch   4 Batch  165/269 - Train Accuracy: 0.7414, Validation Accuracy: 0.7503, Loss: 0.3835
Epoch   4 Batch  166/269 - Train Accuracy: 0.7515, Validation Accuracy: 0.7478, Loss: 0.3596
Epoch   4 Batch  167/269 - Train Accuracy: 0.7511, Validation Accuracy: 0.7509, Loss: 0.3726
Epoch   4 Batch  168/269 - Train Accuracy: 0.7209, Validation Accuracy: 0.7457, Loss: 0.3743
Epoch   4 Batch  169/269 - Train Accuracy: 0.7410, Validation Accuracy: 0.7532, Loss: 0.3760
Epoch   4 Batch  170/269 - Train Accuracy: 0.7425, Validation Accuracy: 0.7506, Loss: 0.3730
Epoch   4 Batch  171/269 - Train Accuracy: 0.7602, Validation Accuracy: 0.7514, Loss: 0.3783
Epoch   4 Batch  172/269 - Train Accuracy: 0.7525, Validation Accuracy: 0.7479, Loss: 0.3780
Epoch   4 Batch  173/269 - Train Accuracy: 0.7670, Validation Accuracy: 0.7441, Loss: 0.3623
Epoch   4 Batch  174/269 - Train Accuracy: 0.7491, Validation Accuracy: 0.7483, Loss: 0.3648
Epoch   4 Batch  175/269 - Train Accuracy: 0.7418, Validation Accuracy: 0.7464, Loss: 0.3868
Epoch   4 Batch  176/269 - Train Accuracy: 0.7333, Validation Accuracy: 0.7474, Loss: 0.3962
Epoch   4 Batch  177/269 - Train Accuracy: 0.7611, Validation Accuracy: 0.7422, Loss: 0.3640
Epoch   4 Batch  178/269 - Train Accuracy: 0.7568, Validation Accuracy: 0.7533, Loss: 0.3810
Epoch   4 Batch  179/269 - Train Accuracy: 0.7421, Validation Accuracy: 0.7448, Loss: 0.3737
Epoch   4 Batch  180/269 - Train Accuracy: 0.7485, Validation Accuracy: 0.7456, Loss: 0.3703
Epoch   4 Batch  181/269 - Train Accuracy: 0.7259, Validation Accuracy: 0.7327, Loss: 0.3646
Epoch   4 Batch  182/269 - Train Accuracy: 0.7285, Validation Accuracy: 0.7312, Loss: 0.3732
Epoch   4 Batch  183/269 - Train Accuracy: 0.7746, Validation Accuracy: 0.7429, Loss: 0.3353
Epoch   4 Batch  184/269 - Train Accuracy: 0.7294, Validation Accuracy: 0.7409, Loss: 0.3747
Epoch   4 Batch  185/269 - Train Accuracy: 0.7528, Validation Accuracy: 0.7415, Loss: 0.3677
Epoch   4 Batch  186/269 - Train Accuracy: 0.7378, Validation Accuracy: 0.7519, Loss: 0.3769
Epoch   4 Batch  187/269 - Train Accuracy: 0.7727, Validation Accuracy: 0.7541, Loss: 0.3589
Epoch   4 Batch  188/269 - Train Accuracy: 0.7554, Validation Accuracy: 0.7520, Loss: 0.3528
Epoch   4 Batch  189/269 - Train Accuracy: 0.7433, Validation Accuracy: 0.7459, Loss: 0.3562
Epoch   4 Batch  190/269 - Train Accuracy: 0.7493, Validation Accuracy: 0.7576, Loss: 0.3618
Epoch   4 Batch  191/269 - Train Accuracy: 0.7524, Validation Accuracy: 0.7575, Loss: 0.3607
Epoch   4 Batch  192/269 - Train Accuracy: 0.7623, Validation Accuracy: 0.7518, Loss: 0.3622
Epoch   4 Batch  193/269 - Train Accuracy: 0.7706, Validation Accuracy: 0.7523, Loss: 0.3584
Epoch   4 Batch  194/269 - Train Accuracy: 0.7664, Validation Accuracy: 0.7541, Loss: 0.3676
Epoch   4 Batch  195/269 - Train Accuracy: 0.7494, Validation Accuracy: 0.7534, Loss: 0.3566
Epoch   4 Batch  196/269 - Train Accuracy: 0.7561, Validation Accuracy: 0.7591, Loss: 0.3637
Epoch   4 Batch  197/269 - Train Accuracy: 0.7500, Validation Accuracy: 0.7556, Loss: 0.3736
Epoch   4 Batch  198/269 - Train Accuracy: 0.7434, Validation Accuracy: 0.7539, Loss: 0.3811
Epoch   4 Batch  199/269 - Train Accuracy: 0.7474, Validation Accuracy: 0.7567, Loss: 0.3754
Epoch   4 Batch  200/269 - Train Accuracy: 0.7381, Validation Accuracy: 0.7518, Loss: 0.3702
Epoch   4 Batch  201/269 - Train Accuracy: 0.7533, Validation Accuracy: 0.7543, Loss: 0.3604
Epoch   4 Batch  202/269 - Train Accuracy: 0.7484, Validation Accuracy: 0.7536, Loss: 0.3594
Epoch   4 Batch  203/269 - Train Accuracy: 0.7438, Validation Accuracy: 0.7568, Loss: 0.3858
Epoch   4 Batch  204/269 - Train Accuracy: 0.7604, Validation Accuracy: 0.7586, Loss: 0.3805
Epoch   4 Batch  205/269 - Train Accuracy: 0.7555, Validation Accuracy: 0.7490, Loss: 0.3558
Epoch   4 Batch  206/269 - Train Accuracy: 0.7456, Validation Accuracy: 0.7652, Loss: 0.3830
Epoch   4 Batch  207/269 - Train Accuracy: 0.7535, Validation Accuracy: 0.7619, Loss: 0.3448
Epoch   4 Batch  208/269 - Train Accuracy: 0.7532, Validation Accuracy: 0.7646, Loss: 0.3690
Epoch   4 Batch  209/269 - Train Accuracy: 0.7705, Validation Accuracy: 0.7534, Loss: 0.3618
Epoch   4 Batch  210/269 - Train Accuracy: 0.7626, Validation Accuracy: 0.7528, Loss: 0.3514
Epoch   4 Batch  211/269 - Train Accuracy: 0.7676, Validation Accuracy: 0.7675, Loss: 0.3644
Epoch   4 Batch  212/269 - Train Accuracy: 0.7529, Validation Accuracy: 0.7574, Loss: 0.3535
Epoch   4 Batch  213/269 - Train Accuracy: 0.7523, Validation Accuracy: 0.7554, Loss: 0.3603
Epoch   4 Batch  214/269 - Train Accuracy: 0.7631, Validation Accuracy: 0.7575, Loss: 0.3650
Epoch   4 Batch  215/269 - Train Accuracy: 0.7783, Validation Accuracy: 0.7594, Loss: 0.3465
Epoch   4 Batch  216/269 - Train Accuracy: 0.7171, Validation Accuracy: 0.7496, Loss: 0.3884
Epoch   4 Batch  217/269 - Train Accuracy: 0.7386, Validation Accuracy: 0.7501, Loss: 0.3816
Epoch   4 Batch  218/269 - Train Accuracy: 0.7604, Validation Accuracy: 0.7623, Loss: 0.4014
Epoch   4 Batch  219/269 - Train Accuracy: 0.7399, Validation Accuracy: 0.7460, Loss: 0.3682
Epoch   4 Batch  220/269 - Train Accuracy: 0.7573, Validation Accuracy: 0.7664, Loss: 0.3826
Epoch   4 Batch  221/269 - Train Accuracy: 0.7551, Validation Accuracy: 0.7419, Loss: 0.3643
Epoch   4 Batch  222/269 - Train Accuracy: 0.7826, Validation Accuracy: 0.7637, Loss: 0.3722
Epoch   4 Batch  223/269 - Train Accuracy: 0.7332, Validation Accuracy: 0.7447, Loss: 0.3483
Epoch   4 Batch  224/269 - Train Accuracy: 0.7706, Validation Accuracy: 0.7686, Loss: 0.3902
Epoch   4 Batch  225/269 - Train Accuracy: 0.7360, Validation Accuracy: 0.7477, Loss: 0.3551
Epoch   4 Batch  226/269 - Train Accuracy: 0.7693, Validation Accuracy: 0.7604, Loss: 0.3662
Epoch   4 Batch  227/269 - Train Accuracy: 0.7730, Validation Accuracy: 0.7559, Loss: 0.3237
Epoch   4 Batch  228/269 - Train Accuracy: 0.7370, Validation Accuracy: 0.7568, Loss: 0.3548
Epoch   4 Batch  229/269 - Train Accuracy: 0.7620, Validation Accuracy: 0.7671, Loss: 0.3559
Epoch   4 Batch  230/269 - Train Accuracy: 0.7575, Validation Accuracy: 0.7619, Loss: 0.3511
Epoch   4 Batch  231/269 - Train Accuracy: 0.7528, Validation Accuracy: 0.7560, Loss: 0.3816
Epoch   4 Batch  232/269 - Train Accuracy: 0.7353, Validation Accuracy: 0.7533, Loss: 0.3741
Epoch   4 Batch  233/269 - Train Accuracy: 0.7560, Validation Accuracy: 0.7534, Loss: 0.3616
Epoch   4 Batch  234/269 - Train Accuracy: 0.7691, Validation Accuracy: 0.7699, Loss: 0.3549
Epoch   4 Batch  235/269 - Train Accuracy: 0.7728, Validation Accuracy: 0.7618, Loss: 0.3384
Epoch   4 Batch  236/269 - Train Accuracy: 0.7642, Validation Accuracy: 0.7698, Loss: 0.3459
Epoch   4 Batch  237/269 - Train Accuracy: 0.7556, Validation Accuracy: 0.7670, Loss: 0.3459
Epoch   4 Batch  238/269 - Train Accuracy: 0.7684, Validation Accuracy: 0.7736, Loss: 0.3491
Epoch   4 Batch  239/269 - Train Accuracy: 0.7746, Validation Accuracy: 0.7704, Loss: 0.3416
Epoch   4 Batch  240/269 - Train Accuracy: 0.7862, Validation Accuracy: 0.7682, Loss: 0.3171
Epoch   4 Batch  241/269 - Train Accuracy: 0.7616, Validation Accuracy: 0.7693, Loss: 0.3597
Epoch   4 Batch  242/269 - Train Accuracy: 0.7583, Validation Accuracy: 0.7625, Loss: 0.3415
Epoch   4 Batch  243/269 - Train Accuracy: 0.7667, Validation Accuracy: 0.7621, Loss: 0.3350
Epoch   4 Batch  244/269 - Train Accuracy: 0.7659, Validation Accuracy: 0.7638, Loss: 0.3475
Epoch   4 Batch  245/269 - Train Accuracy: 0.7573, Validation Accuracy: 0.7647, Loss: 0.3655
Epoch   4 Batch  246/269 - Train Accuracy: 0.7503, Validation Accuracy: 0.7731, Loss: 0.3447
Epoch   4 Batch  247/269 - Train Accuracy: 0.7556, Validation Accuracy: 0.7707, Loss: 0.3542
Epoch   4 Batch  248/269 - Train Accuracy: 0.7629, Validation Accuracy: 0.7626, Loss: 0.3360
Epoch   4 Batch  249/269 - Train Accuracy: 0.7808, Validation Accuracy: 0.7607, Loss: 0.3249
Epoch   4 Batch  250/269 - Train Accuracy: 0.7775, Validation Accuracy: 0.7679, Loss: 0.3479
Epoch   4 Batch  251/269 - Train Accuracy: 0.7786, Validation Accuracy: 0.7819, Loss: 0.3330
Epoch   4 Batch  252/269 - Train Accuracy: 0.7607, Validation Accuracy: 0.7702, Loss: 0.3445
Epoch   4 Batch  253/269 - Train Accuracy: 0.7611, Validation Accuracy: 0.7725, Loss: 0.3480
Epoch   4 Batch  254/269 - Train Accuracy: 0.7854, Validation Accuracy: 0.7732, Loss: 0.3371
Epoch   4 Batch  255/269 - Train Accuracy: 0.7807, Validation Accuracy: 0.7746, Loss: 0.3296
Epoch   4 Batch  256/269 - Train Accuracy: 0.7713, Validation Accuracy: 0.7845, Loss: 0.3512
Epoch   4 Batch  257/269 - Train Accuracy: 0.7549, Validation Accuracy: 0.7756, Loss: 0.3483
Epoch   4 Batch  258/269 - Train Accuracy: 0.7761, Validation Accuracy: 0.7757, Loss: 0.3485
Epoch   4 Batch  259/269 - Train Accuracy: 0.7736, Validation Accuracy: 0.7737, Loss: 0.3367
Epoch   4 Batch  260/269 - Train Accuracy: 0.7584, Validation Accuracy: 0.7726, Loss: 0.3506
Epoch   4 Batch  261/269 - Train Accuracy: 0.7373, Validation Accuracy: 0.7798, Loss: 0.3615
Epoch   4 Batch  262/269 - Train Accuracy: 0.7741, Validation Accuracy: 0.7763, Loss: 0.3371
Epoch   4 Batch  263/269 - Train Accuracy: 0.7629, Validation Accuracy: 0.7715, Loss: 0.3468
Epoch   4 Batch  264/269 - Train Accuracy: 0.7685, Validation Accuracy: 0.7784, Loss: 0.3546
Epoch   4 Batch  265/269 - Train Accuracy: 0.7681, Validation Accuracy: 0.7695, Loss: 0.3396
Epoch   4 Batch  266/269 - Train Accuracy: 0.7739, Validation Accuracy: 0.7796, Loss: 0.3317
Epoch   4 Batch  267/269 - Train Accuracy: 0.7838, Validation Accuracy: 0.7803, Loss: 0.3404
Epoch   5 Batch    1/269 - Train Accuracy: 0.7696, Validation Accuracy: 0.7703, Loss: 0.3417
Epoch   5 Batch    2/269 - Train Accuracy: 0.7640, Validation Accuracy: 0.7691, Loss: 0.3437
Epoch   5 Batch    3/269 - Train Accuracy: 0.7901, Validation Accuracy: 0.7801, Loss: 0.3388
Epoch   5 Batch    4/269 - Train Accuracy: 0.7585, Validation Accuracy: 0.7792, Loss: 0.3580
Epoch   5 Batch    5/269 - Train Accuracy: 0.7633, Validation Accuracy: 0.7851, Loss: 0.3479
Epoch   5 Batch    6/269 - Train Accuracy: 0.7889, Validation Accuracy: 0.7815, Loss: 0.3167
Epoch   5 Batch    7/269 - Train Accuracy: 0.7732, Validation Accuracy: 0.7757, Loss: 0.3278
Epoch   5 Batch    8/269 - Train Accuracy: 0.7706, Validation Accuracy: 0.7797, Loss: 0.3456
Epoch   5 Batch    9/269 - Train Accuracy: 0.7865, Validation Accuracy: 0.7821, Loss: 0.3427
Epoch   5 Batch   10/269 - Train Accuracy: 0.7912, Validation Accuracy: 0.7872, Loss: 0.3416
Epoch   5 Batch   11/269 - Train Accuracy: 0.7810, Validation Accuracy: 0.7822, Loss: 0.3385
Epoch   5 Batch   12/269 - Train Accuracy: 0.7617, Validation Accuracy: 0.7845, Loss: 0.3511
Epoch   5 Batch   13/269 - Train Accuracy: 0.7820, Validation Accuracy: 0.7902, Loss: 0.3039
Epoch   5 Batch   14/269 - Train Accuracy: 0.7870, Validation Accuracy: 0.7892, Loss: 0.3260
Epoch   5 Batch   15/269 - Train Accuracy: 0.7797, Validation Accuracy: 0.7867, Loss: 0.3184
Epoch   5 Batch   16/269 - Train Accuracy: 0.7810, Validation Accuracy: 0.7879, Loss: 0.3341
Epoch   5 Batch   17/269 - Train Accuracy: 0.7882, Validation Accuracy: 0.7849, Loss: 0.3199
Epoch   5 Batch   18/269 - Train Accuracy: 0.7717, Validation Accuracy: 0.7884, Loss: 0.3330
Epoch   5 Batch   19/269 - Train Accuracy: 0.7869, Validation Accuracy: 0.7851, Loss: 0.3025
Epoch   5 Batch   20/269 - Train Accuracy: 0.7891, Validation Accuracy: 0.7815, Loss: 0.3304
Epoch   5 Batch   21/269 - Train Accuracy: 0.7664, Validation Accuracy: 0.7924, Loss: 0.3525
Epoch   5 Batch   22/269 - Train Accuracy: 0.7877, Validation Accuracy: 0.7842, Loss: 0.3188
Epoch   5 Batch   23/269 - Train Accuracy: 0.7786, Validation Accuracy: 0.7820, Loss: 0.3170
Epoch   5 Batch   24/269 - Train Accuracy: 0.7736, Validation Accuracy: 0.7901, Loss: 0.3414
Epoch   5 Batch   25/269 - Train Accuracy: 0.7757, Validation Accuracy: 0.7910, Loss: 0.3468
Epoch   5 Batch   26/269 - Train Accuracy: 0.8034, Validation Accuracy: 0.7960, Loss: 0.2978
Epoch   5 Batch   27/269 - Train Accuracy: 0.7801, Validation Accuracy: 0.7947, Loss: 0.3162
Epoch   5 Batch   28/269 - Train Accuracy: 0.7523, Validation Accuracy: 0.7984, Loss: 0.3486
Epoch   5 Batch   29/269 - Train Accuracy: 0.8025, Validation Accuracy: 0.7977, Loss: 0.3306
Epoch   5 Batch   30/269 - Train Accuracy: 0.7845, Validation Accuracy: 0.7893, Loss: 0.3182
Epoch   5 Batch   31/269 - Train Accuracy: 0.8023, Validation Accuracy: 0.7878, Loss: 0.3136
Epoch   5 Batch   32/269 - Train Accuracy: 0.7805, Validation Accuracy: 0.7979, Loss: 0.3133
Epoch   5 Batch   33/269 - Train Accuracy: 0.8146, Validation Accuracy: 0.7909, Loss: 0.3084
Epoch   5 Batch   34/269 - Train Accuracy: 0.8024, Validation Accuracy: 0.7961, Loss: 0.3155
Epoch   5 Batch   35/269 - Train Accuracy: 0.8015, Validation Accuracy: 0.7943, Loss: 0.3264
Epoch   5 Batch   36/269 - Train Accuracy: 0.7666, Validation Accuracy: 0.7892, Loss: 0.3164
Epoch   5 Batch   37/269 - Train Accuracy: 0.7911, Validation Accuracy: 0.7908, Loss: 0.3195
Epoch   5 Batch   38/269 - Train Accuracy: 0.7861, Validation Accuracy: 0.7936, Loss: 0.3154
Epoch   5 Batch   39/269 - Train Accuracy: 0.7923, Validation Accuracy: 0.7907, Loss: 0.3140
Epoch   5 Batch   40/269 - Train Accuracy: 0.7803, Validation Accuracy: 0.8010, Loss: 0.3329
Epoch   5 Batch   41/269 - Train Accuracy: 0.7889, Validation Accuracy: 0.7957, Loss: 0.3230
Epoch   5 Batch   42/269 - Train Accuracy: 0.8051, Validation Accuracy: 0.7994, Loss: 0.3029
Epoch   5 Batch   43/269 - Train Accuracy: 0.8057, Validation Accuracy: 0.7997, Loss: 0.3179
Epoch   5 Batch   44/269 - Train Accuracy: 0.7862, Validation Accuracy: 0.7977, Loss: 0.3162
Epoch   5 Batch   45/269 - Train Accuracy: 0.7891, Validation Accuracy: 0.8023, Loss: 0.3309
Epoch   5 Batch   46/269 - Train Accuracy: 0.7949, Validation Accuracy: 0.7961, Loss: 0.3313
Epoch   5 Batch   47/269 - Train Accuracy: 0.8040, Validation Accuracy: 0.8018, Loss: 0.2941
Epoch   5 Batch   48/269 - Train Accuracy: 0.8072, Validation Accuracy: 0.8025, Loss: 0.3066
Epoch   5 Batch   49/269 - Train Accuracy: 0.7849, Validation Accuracy: 0.7970, Loss: 0.3113
Epoch   5 Batch   50/269 - Train Accuracy: 0.7688, Validation Accuracy: 0.7947, Loss: 0.3270
Epoch   5 Batch   51/269 - Train Accuracy: 0.7933, Validation Accuracy: 0.7922, Loss: 0.3125
Epoch   5 Batch   52/269 - Train Accuracy: 0.7836, Validation Accuracy: 0.7885, Loss: 0.3021
Epoch   5 Batch   53/269 - Train Accuracy: 0.7972, Validation Accuracy: 0.7916, Loss: 0.3359
Epoch   5 Batch   54/269 - Train Accuracy: 0.7996, Validation Accuracy: 0.8017, Loss: 0.3172
Epoch   5 Batch   55/269 - Train Accuracy: 0.8124, Validation Accuracy: 0.7919, Loss: 0.3071
Epoch   5 Batch   56/269 - Train Accuracy: 0.7896, Validation Accuracy: 0.7936, Loss: 0.3164
Epoch   5 Batch   57/269 - Train Accuracy: 0.7884, Validation Accuracy: 0.7966, Loss: 0.3187
Epoch   5 Batch   58/269 - Train Accuracy: 0.7891, Validation Accuracy: 0.8001, Loss: 0.3097
Epoch   5 Batch   59/269 - Train Accuracy: 0.8237, Validation Accuracy: 0.8049, Loss: 0.2898
Epoch   5 Batch   60/269 - Train Accuracy: 0.7915, Validation Accuracy: 0.8008, Loss: 0.2973
Epoch   5 Batch   61/269 - Train Accuracy: 0.8185, Validation Accuracy: 0.8054, Loss: 0.2918
Epoch   5 Batch   62/269 - Train Accuracy: 0.8071, Validation Accuracy: 0.8033, Loss: 0.3010
Epoch   5 Batch   63/269 - Train Accuracy: 0.7960, Validation Accuracy: 0.7995, Loss: 0.3204
Epoch   5 Batch   64/269 - Train Accuracy: 0.8142, Validation Accuracy: 0.8082, Loss: 0.3055
Epoch   5 Batch   65/269 - Train Accuracy: 0.8001, Validation Accuracy: 0.8109, Loss: 0.3051
Epoch   5 Batch   66/269 - Train Accuracy: 0.8034, Validation Accuracy: 0.8105, Loss: 0.3038
Epoch   5 Batch   67/269 - Train Accuracy: 0.8053, Validation Accuracy: 0.8092, Loss: 0.3172
Epoch   5 Batch   68/269 - Train Accuracy: 0.7903, Validation Accuracy: 0.7985, Loss: 0.3099
Epoch   5 Batch   69/269 - Train Accuracy: 0.7856, Validation Accuracy: 0.8059, Loss: 0.3441
Epoch   5 Batch   70/269 - Train Accuracy: 0.8032, Validation Accuracy: 0.7997, Loss: 0.3111
Epoch   5 Batch   71/269 - Train Accuracy: 0.7779, Validation Accuracy: 0.7955, Loss: 0.3287
Epoch   5 Batch   72/269 - Train Accuracy: 0.8004, Validation Accuracy: 0.8068, Loss: 0.3162
Epoch   5 Batch   73/269 - Train Accuracy: 0.7839, Validation Accuracy: 0.7992, Loss: 0.3143
Epoch   5 Batch   74/269 - Train Accuracy: 0.8082, Validation Accuracy: 0.8022, Loss: 0.3146
Epoch   5 Batch   75/269 - Train Accuracy: 0.7975, Validation Accuracy: 0.7855, Loss: 0.3023
Epoch   5 Batch   76/269 - Train Accuracy: 0.7830, Validation Accuracy: 0.7971, Loss: 0.3096
Epoch   5 Batch   77/269 - Train Accuracy: 0.7996, Validation Accuracy: 0.7923, Loss: 0.3042
Epoch   5 Batch   78/269 - Train Accuracy: 0.8121, Validation Accuracy: 0.7889, Loss: 0.3040
Epoch   5 Batch   79/269 - Train Accuracy: 0.7999, Validation Accuracy: 0.8054, Loss: 0.3103
Epoch   5 Batch   80/269 - Train Accuracy: 0.8077, Validation Accuracy: 0.8012, Loss: 0.2956
Epoch   5 Batch   81/269 - Train Accuracy: 0.7947, Validation Accuracy: 0.8037, Loss: 0.3220
Epoch   5 Batch   82/269 - Train Accuracy: 0.8212, Validation Accuracy: 0.7920, Loss: 0.2877
Epoch   5 Batch   83/269 - Train Accuracy: 0.7953, Validation Accuracy: 0.8025, Loss: 0.3157
Epoch   5 Batch   84/269 - Train Accuracy: 0.8036, Validation Accuracy: 0.8072, Loss: 0.2972
Epoch   5 Batch   85/269 - Train Accuracy: 0.7964, Validation Accuracy: 0.7939, Loss: 0.3034
Epoch   5 Batch   86/269 - Train Accuracy: 0.8092, Validation Accuracy: 0.8112, Loss: 0.3055
Epoch   5 Batch   87/269 - Train Accuracy: 0.7847, Validation Accuracy: 0.8001, Loss: 0.3239
Epoch   5 Batch   88/269 - Train Accuracy: 0.7906, Validation Accuracy: 0.8033, Loss: 0.3092
Epoch   5 Batch   89/269 - Train Accuracy: 0.8109, Validation Accuracy: 0.7973, Loss: 0.2989
Epoch   5 Batch   90/269 - Train Accuracy: 0.7815, Validation Accuracy: 0.8077, Loss: 0.3187
Epoch   5 Batch   91/269 - Train Accuracy: 0.8322, Validation Accuracy: 0.8094, Loss: 0.2907
Epoch   5 Batch   92/269 - Train Accuracy: 0.8109, Validation Accuracy: 0.7975, Loss: 0.2894
Epoch   5 Batch   93/269 - Train Accuracy: 0.8162, Validation Accuracy: 0.8073, Loss: 0.2881
Epoch   5 Batch   94/269 - Train Accuracy: 0.8118, Validation Accuracy: 0.8064, Loss: 0.3089
Epoch   5 Batch   95/269 - Train Accuracy: 0.8130, Validation Accuracy: 0.8113, Loss: 0.3011
Epoch   5 Batch   96/269 - Train Accuracy: 0.7883, Validation Accuracy: 0.8128, Loss: 0.2958
Epoch   5 Batch   97/269 - Train Accuracy: 0.8146, Validation Accuracy: 0.8113, Loss: 0.2989
Epoch   5 Batch   98/269 - Train Accuracy: 0.8129, Validation Accuracy: 0.8155, Loss: 0.3010
Epoch   5 Batch   99/269 - Train Accuracy: 0.8082, Validation Accuracy: 0.8140, Loss: 0.3007
Epoch   5 Batch  100/269 - Train Accuracy: 0.8317, Validation Accuracy: 0.8159, Loss: 0.2949
Epoch   5 Batch  101/269 - Train Accuracy: 0.7899, Validation Accuracy: 0.8161, Loss: 0.3132
Epoch   5 Batch  102/269 - Train Accuracy: 0.8090, Validation Accuracy: 0.8150, Loss: 0.2950
Epoch   5 Batch  103/269 - Train Accuracy: 0.8331, Validation Accuracy: 0.8097, Loss: 0.2957
Epoch   5 Batch  104/269 - Train Accuracy: 0.8110, Validation Accuracy: 0.8060, Loss: 0.2890
Epoch   5 Batch  105/269 - Train Accuracy: 0.8158, Validation Accuracy: 0.8140, Loss: 0.2969
Epoch   5 Batch  106/269 - Train Accuracy: 0.8073, Validation Accuracy: 0.8173, Loss: 0.2892
Epoch   5 Batch  107/269 - Train Accuracy: 0.8002, Validation Accuracy: 0.8029, Loss: 0.3035
Epoch   5 Batch  108/269 - Train Accuracy: 0.8120, Validation Accuracy: 0.8169, Loss: 0.3058
Epoch   5 Batch  109/269 - Train Accuracy: 0.7973, Validation Accuracy: 0.8143, Loss: 0.3062
Epoch   5 Batch  110/269 - Train Accuracy: 0.7969, Validation Accuracy: 0.8016, Loss: 0.2867
Epoch   5 Batch  111/269 - Train Accuracy: 0.8195, Validation Accuracy: 0.8092, Loss: 0.3145
Epoch   5 Batch  112/269 - Train Accuracy: 0.8190, Validation Accuracy: 0.8136, Loss: 0.2934
Epoch   5 Batch  113/269 - Train Accuracy: 0.8073, Validation Accuracy: 0.8219, Loss: 0.2785
Epoch   5 Batch  114/269 - Train Accuracy: 0.8147, Validation Accuracy: 0.8202, Loss: 0.2924
Epoch   5 Batch  115/269 - Train Accuracy: 0.8005, Validation Accuracy: 0.8125, Loss: 0.3028
Epoch   5 Batch  116/269 - Train Accuracy: 0.8304, Validation Accuracy: 0.8120, Loss: 0.3032
Epoch   5 Batch  117/269 - Train Accuracy: 0.7989, Validation Accuracy: 0.8114, Loss: 0.2877
Epoch   5 Batch  118/269 - Train Accuracy: 0.8150, Validation Accuracy: 0.8145, Loss: 0.2806
Epoch   5 Batch  119/269 - Train Accuracy: 0.8120, Validation Accuracy: 0.8147, Loss: 0.3056
Epoch   5 Batch  120/269 - Train Accuracy: 0.8037, Validation Accuracy: 0.8209, Loss: 0.2966
Epoch   5 Batch  121/269 - Train Accuracy: 0.8189, Validation Accuracy: 0.8221, Loss: 0.2850
Epoch   5 Batch  122/269 - Train Accuracy: 0.8071, Validation Accuracy: 0.8221, Loss: 0.2832
Epoch   5 Batch  123/269 - Train Accuracy: 0.8178, Validation Accuracy: 0.8228, Loss: 0.3061
Epoch   5 Batch  124/269 - Train Accuracy: 0.8121, Validation Accuracy: 0.8231, Loss: 0.2809
Epoch   5 Batch  125/269 - Train Accuracy: 0.8157, Validation Accuracy: 0.8090, Loss: 0.2771
Epoch   5 Batch  126/269 - Train Accuracy: 0.8100, Validation Accuracy: 0.8121, Loss: 0.2867
Epoch   5 Batch  127/269 - Train Accuracy: 0.8043, Validation Accuracy: 0.8182, Loss: 0.2948
Epoch   5 Batch  128/269 - Train Accuracy: 0.8281, Validation Accuracy: 0.8229, Loss: 0.2871
Epoch   5 Batch  129/269 - Train Accuracy: 0.7971, Validation Accuracy: 0.8089, Loss: 0.2850
Epoch   5 Batch  130/269 - Train Accuracy: 0.8027, Validation Accuracy: 0.8187, Loss: 0.2990
Epoch   5 Batch  131/269 - Train Accuracy: 0.7913, Validation Accuracy: 0.8137, Loss: 0.2910
Epoch   5 Batch  132/269 - Train Accuracy: 0.8048, Validation Accuracy: 0.8212, Loss: 0.3024
Epoch   5 Batch  133/269 - Train Accuracy: 0.8320, Validation Accuracy: 0.8145, Loss: 0.2802
Epoch   5 Batch  134/269 - Train Accuracy: 0.8010, Validation Accuracy: 0.8257, Loss: 0.2940
Epoch   5 Batch  135/269 - Train Accuracy: 0.8201, Validation Accuracy: 0.8180, Loss: 0.3087
Epoch   5 Batch  136/269 - Train Accuracy: 0.7902, Validation Accuracy: 0.8100, Loss: 0.3053
Epoch   5 Batch  137/269 - Train Accuracy: 0.8097, Validation Accuracy: 0.8194, Loss: 0.3112
Epoch   5 Batch  138/269 - Train Accuracy: 0.8217, Validation Accuracy: 0.8241, Loss: 0.2848
Epoch   5 Batch  139/269 - Train Accuracy: 0.8209, Validation Accuracy: 0.8171, Loss: 0.2769
Epoch   5 Batch  140/269 - Train Accuracy: 0.8109, Validation Accuracy: 0.8151, Loss: 0.2931
Epoch   5 Batch  141/269 - Train Accuracy: 0.8189, Validation Accuracy: 0.8238, Loss: 0.2923
Epoch   5 Batch  142/269 - Train Accuracy: 0.8197, Validation Accuracy: 0.8193, Loss: 0.2724
Epoch   5 Batch  143/269 - Train Accuracy: 0.8298, Validation Accuracy: 0.8240, Loss: 0.2796
Epoch   5 Batch  144/269 - Train Accuracy: 0.8307, Validation Accuracy: 0.8149, Loss: 0.2704
Epoch   5 Batch  145/269 - Train Accuracy: 0.8306, Validation Accuracy: 0.8250, Loss: 0.2754
Epoch   5 Batch  146/269 - Train Accuracy: 0.8200, Validation Accuracy: 0.8208, Loss: 0.2754
Epoch   5 Batch  147/269 - Train Accuracy: 0.8219, Validation Accuracy: 0.8175, Loss: 0.2717
Epoch   5 Batch  148/269 - Train Accuracy: 0.8005, Validation Accuracy: 0.8160, Loss: 0.2800
Epoch   5 Batch  149/269 - Train Accuracy: 0.8113, Validation Accuracy: 0.8309, Loss: 0.2855
Epoch   5 Batch  150/269 - Train Accuracy: 0.8187, Validation Accuracy: 0.8289, Loss: 0.2800
Epoch   5 Batch  151/269 - Train Accuracy: 0.8153, Validation Accuracy: 0.8224, Loss: 0.2686
Epoch   5 Batch  152/269 - Train Accuracy: 0.8254, Validation Accuracy: 0.8264, Loss: 0.2812
Epoch   5 Batch  153/269 - Train Accuracy: 0.8236, Validation Accuracy: 0.8279, Loss: 0.2745
Epoch   5 Batch  154/269 - Train Accuracy: 0.8349, Validation Accuracy: 0.8268, Loss: 0.2821
Epoch   5 Batch  155/269 - Train Accuracy: 0.8119, Validation Accuracy: 0.8301, Loss: 0.2634
Epoch   5 Batch  156/269 - Train Accuracy: 0.8151, Validation Accuracy: 0.8288, Loss: 0.2863
Epoch   5 Batch  157/269 - Train Accuracy: 0.8163, Validation Accuracy: 0.8303, Loss: 0.2723
Epoch   5 Batch  158/269 - Train Accuracy: 0.8320, Validation Accuracy: 0.8262, Loss: 0.2755
Epoch   5 Batch  159/269 - Train Accuracy: 0.8120, Validation Accuracy: 0.8293, Loss: 0.2781
Epoch   5 Batch  160/269 - Train Accuracy: 0.8415, Validation Accuracy: 0.8291, Loss: 0.2731
Epoch   5 Batch  161/269 - Train Accuracy: 0.8123, Validation Accuracy: 0.8368, Loss: 0.2718
Epoch   5 Batch  162/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8365, Loss: 0.2673
Epoch   5 Batch  163/269 - Train Accuracy: 0.8340, Validation Accuracy: 0.8315, Loss: 0.2727
Epoch   5 Batch  164/269 - Train Accuracy: 0.8386, Validation Accuracy: 0.8398, Loss: 0.2826
Epoch   5 Batch  165/269 - Train Accuracy: 0.8423, Validation Accuracy: 0.8404, Loss: 0.2709
Epoch   5 Batch  166/269 - Train Accuracy: 0.8373, Validation Accuracy: 0.8296, Loss: 0.2580
Epoch   5 Batch  167/269 - Train Accuracy: 0.8294, Validation Accuracy: 0.8405, Loss: 0.2698
Epoch   5 Batch  168/269 - Train Accuracy: 0.8289, Validation Accuracy: 0.8420, Loss: 0.2721
Epoch   5 Batch  169/269 - Train Accuracy: 0.8193, Validation Accuracy: 0.8366, Loss: 0.2731
Epoch   5 Batch  170/269 - Train Accuracy: 0.8332, Validation Accuracy: 0.8381, Loss: 0.2666
Epoch   5 Batch  171/269 - Train Accuracy: 0.8487, Validation Accuracy: 0.8385, Loss: 0.2733
Epoch   5 Batch  172/269 - Train Accuracy: 0.8376, Validation Accuracy: 0.8327, Loss: 0.2755
Epoch   5 Batch  173/269 - Train Accuracy: 0.8361, Validation Accuracy: 0.8256, Loss: 0.2596
Epoch   5 Batch  174/269 - Train Accuracy: 0.8417, Validation Accuracy: 0.8295, Loss: 0.2679
Epoch   5 Batch  175/269 - Train Accuracy: 0.8303, Validation Accuracy: 0.8343, Loss: 0.2867
Epoch   5 Batch  176/269 - Train Accuracy: 0.8337, Validation Accuracy: 0.8322, Loss: 0.2803
Epoch   5 Batch  177/269 - Train Accuracy: 0.8347, Validation Accuracy: 0.8329, Loss: 0.2570
Epoch   5 Batch  178/269 - Train Accuracy: 0.8390, Validation Accuracy: 0.8386, Loss: 0.2692
Epoch   5 Batch  179/269 - Train Accuracy: 0.8235, Validation Accuracy: 0.8381, Loss: 0.2655
Epoch   5 Batch  180/269 - Train Accuracy: 0.8298, Validation Accuracy: 0.8342, Loss: 0.2581
Epoch   5 Batch  181/269 - Train Accuracy: 0.8217, Validation Accuracy: 0.8263, Loss: 0.2644
Epoch   5 Batch  182/269 - Train Accuracy: 0.8305, Validation Accuracy: 0.8320, Loss: 0.2736
Epoch   5 Batch  183/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8307, Loss: 0.2326
Epoch   5 Batch  184/269 - Train Accuracy: 0.8293, Validation Accuracy: 0.8342, Loss: 0.2694
Epoch   5 Batch  185/269 - Train Accuracy: 0.8407, Validation Accuracy: 0.8371, Loss: 0.2599
Epoch   5 Batch  186/269 - Train Accuracy: 0.8360, Validation Accuracy: 0.8403, Loss: 0.2655
Epoch   5 Batch  187/269 - Train Accuracy: 0.8317, Validation Accuracy: 0.8396, Loss: 0.2573
Epoch   5 Batch  188/269 - Train Accuracy: 0.8476, Validation Accuracy: 0.8402, Loss: 0.2534
Epoch   5 Batch  189/269 - Train Accuracy: 0.8313, Validation Accuracy: 0.8379, Loss: 0.2562
Epoch   5 Batch  190/269 - Train Accuracy: 0.8424, Validation Accuracy: 0.8407, Loss: 0.2529
Epoch   5 Batch  191/269 - Train Accuracy: 0.8224, Validation Accuracy: 0.8390, Loss: 0.2593
Epoch   5 Batch  192/269 - Train Accuracy: 0.8459, Validation Accuracy: 0.8445, Loss: 0.2569
Epoch   5 Batch  193/269 - Train Accuracy: 0.8499, Validation Accuracy: 0.8347, Loss: 0.2602
Epoch   5 Batch  194/269 - Train Accuracy: 0.8377, Validation Accuracy: 0.8410, Loss: 0.2641
Epoch   5 Batch  195/269 - Train Accuracy: 0.8282, Validation Accuracy: 0.8406, Loss: 0.2605
Epoch   5 Batch  196/269 - Train Accuracy: 0.8266, Validation Accuracy: 0.8426, Loss: 0.2616
Epoch   5 Batch  197/269 - Train Accuracy: 0.8218, Validation Accuracy: 0.8355, Loss: 0.2788
Epoch   5 Batch  198/269 - Train Accuracy: 0.8320, Validation Accuracy: 0.8379, Loss: 0.2801
Epoch   5 Batch  199/269 - Train Accuracy: 0.8378, Validation Accuracy: 0.8358, Loss: 0.2680
Epoch   5 Batch  200/269 - Train Accuracy: 0.8291, Validation Accuracy: 0.8368, Loss: 0.2682
Epoch   5 Batch  201/269 - Train Accuracy: 0.8282, Validation Accuracy: 0.8310, Loss: 0.2595
Epoch   5 Batch  202/269 - Train Accuracy: 0.8048, Validation Accuracy: 0.8392, Loss: 0.2662
Epoch   5 Batch  203/269 - Train Accuracy: 0.8348, Validation Accuracy: 0.8456, Loss: 0.2800
Epoch   5 Batch  204/269 - Train Accuracy: 0.8357, Validation Accuracy: 0.8363, Loss: 0.2750
Epoch   5 Batch  205/269 - Train Accuracy: 0.8268, Validation Accuracy: 0.8355, Loss: 0.2623
Epoch   5 Batch  206/269 - Train Accuracy: 0.8265, Validation Accuracy: 0.8368, Loss: 0.2815
Epoch   5 Batch  207/269 - Train Accuracy: 0.8438, Validation Accuracy: 0.8406, Loss: 0.2492
Epoch   5 Batch  208/269 - Train Accuracy: 0.8296, Validation Accuracy: 0.8398, Loss: 0.2685
Epoch   5 Batch  209/269 - Train Accuracy: 0.8376, Validation Accuracy: 0.8327, Loss: 0.2573
Epoch   5 Batch  210/269 - Train Accuracy: 0.8459, Validation Accuracy: 0.8417, Loss: 0.2561
Epoch   5 Batch  211/269 - Train Accuracy: 0.8411, Validation Accuracy: 0.8442, Loss: 0.2546
Epoch   5 Batch  212/269 - Train Accuracy: 0.8291, Validation Accuracy: 0.8392, Loss: 0.2530
Epoch   5 Batch  213/269 - Train Accuracy: 0.8486, Validation Accuracy: 0.8500, Loss: 0.2537
Epoch   5 Batch  214/269 - Train Accuracy: 0.8288, Validation Accuracy: 0.8461, Loss: 0.2525
Epoch   5 Batch  215/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8456, Loss: 0.2450
Epoch   5 Batch  216/269 - Train Accuracy: 0.8090, Validation Accuracy: 0.8430, Loss: 0.2835
Epoch   5 Batch  217/269 - Train Accuracy: 0.8353, Validation Accuracy: 0.8450, Loss: 0.2618
Epoch   5 Batch  218/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8438, Loss: 0.2614
Epoch   5 Batch  219/269 - Train Accuracy: 0.8354, Validation Accuracy: 0.8423, Loss: 0.2666
Epoch   5 Batch  220/269 - Train Accuracy: 0.8431, Validation Accuracy: 0.8427, Loss: 0.2418
Epoch   5 Batch  221/269 - Train Accuracy: 0.8473, Validation Accuracy: 0.8415, Loss: 0.2558
Epoch   5 Batch  222/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8446, Loss: 0.2404
Epoch   5 Batch  223/269 - Train Accuracy: 0.8335, Validation Accuracy: 0.8475, Loss: 0.2363
Epoch   5 Batch  224/269 - Train Accuracy: 0.8409, Validation Accuracy: 0.8517, Loss: 0.2597
Epoch   5 Batch  225/269 - Train Accuracy: 0.8363, Validation Accuracy: 0.8509, Loss: 0.2529
Epoch   5 Batch  226/269 - Train Accuracy: 0.8508, Validation Accuracy: 0.8408, Loss: 0.2505
Epoch   5 Batch  227/269 - Train Accuracy: 0.8542, Validation Accuracy: 0.8462, Loss: 0.2353
Epoch   5 Batch  228/269 - Train Accuracy: 0.8355, Validation Accuracy: 0.8490, Loss: 0.2433
Epoch   5 Batch  229/269 - Train Accuracy: 0.8424, Validation Accuracy: 0.8536, Loss: 0.2473
Epoch   5 Batch  230/269 - Train Accuracy: 0.8294, Validation Accuracy: 0.8438, Loss: 0.2445
Epoch   5 Batch  231/269 - Train Accuracy: 0.8457, Validation Accuracy: 0.8528, Loss: 0.2613
Epoch   5 Batch  232/269 - Train Accuracy: 0.8427, Validation Accuracy: 0.8469, Loss: 0.2633
Epoch   5 Batch  233/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8538, Loss: 0.2580
Epoch   5 Batch  234/269 - Train Accuracy: 0.8385, Validation Accuracy: 0.8428, Loss: 0.2476
Epoch   5 Batch  235/269 - Train Accuracy: 0.8439, Validation Accuracy: 0.8533, Loss: 0.2396
Epoch   5 Batch  236/269 - Train Accuracy: 0.8310, Validation Accuracy: 0.8536, Loss: 0.2430
Epoch   5 Batch  237/269 - Train Accuracy: 0.8393, Validation Accuracy: 0.8475, Loss: 0.2459
Epoch   5 Batch  238/269 - Train Accuracy: 0.8403, Validation Accuracy: 0.8460, Loss: 0.2485
Epoch   5 Batch  239/269 - Train Accuracy: 0.8502, Validation Accuracy: 0.8531, Loss: 0.2431
Epoch   5 Batch  240/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8492, Loss: 0.2244
Epoch   5 Batch  241/269 - Train Accuracy: 0.8418, Validation Accuracy: 0.8393, Loss: 0.2618
Epoch   5 Batch  242/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8382, Loss: 0.2444
Epoch   5 Batch  243/269 - Train Accuracy: 0.8606, Validation Accuracy: 0.8512, Loss: 0.2353
Epoch   5 Batch  244/269 - Train Accuracy: 0.8483, Validation Accuracy: 0.8500, Loss: 0.2483
Epoch   5 Batch  245/269 - Train Accuracy: 0.8282, Validation Accuracy: 0.8450, Loss: 0.2605
Epoch   5 Batch  246/269 - Train Accuracy: 0.8282, Validation Accuracy: 0.8505, Loss: 0.2488
Epoch   5 Batch  247/269 - Train Accuracy: 0.8440, Validation Accuracy: 0.8516, Loss: 0.2530
Epoch   5 Batch  248/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8471, Loss: 0.2324
Epoch   5 Batch  249/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8533, Loss: 0.2299
Epoch   5 Batch  250/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8468, Loss: 0.2416
Epoch   5 Batch  251/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8509, Loss: 0.2368
Epoch   5 Batch  252/269 - Train Accuracy: 0.8415, Validation Accuracy: 0.8430, Loss: 0.2376
Epoch   5 Batch  253/269 - Train Accuracy: 0.8324, Validation Accuracy: 0.8482, Loss: 0.2504
Epoch   5 Batch  254/269 - Train Accuracy: 0.8518, Validation Accuracy: 0.8514, Loss: 0.2401
Epoch   5 Batch  255/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8502, Loss: 0.2381
Epoch   5 Batch  256/269 - Train Accuracy: 0.8371, Validation Accuracy: 0.8504, Loss: 0.2428
Epoch   5 Batch  257/269 - Train Accuracy: 0.8358, Validation Accuracy: 0.8536, Loss: 0.2498
Epoch   5 Batch  258/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8552, Loss: 0.2482
Epoch   5 Batch  259/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8522, Loss: 0.2400
Epoch   5 Batch  260/269 - Train Accuracy: 0.8372, Validation Accuracy: 0.8565, Loss: 0.2525
Epoch   5 Batch  261/269 - Train Accuracy: 0.8487, Validation Accuracy: 0.8600, Loss: 0.2418
Epoch   5 Batch  262/269 - Train Accuracy: 0.8354, Validation Accuracy: 0.8594, Loss: 0.2376
Epoch   5 Batch  263/269 - Train Accuracy: 0.8486, Validation Accuracy: 0.8515, Loss: 0.2452
Epoch   5 Batch  264/269 - Train Accuracy: 0.8303, Validation Accuracy: 0.8576, Loss: 0.2541
Epoch   5 Batch  265/269 - Train Accuracy: 0.8526, Validation Accuracy: 0.8548, Loss: 0.2418
Epoch   5 Batch  266/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8508, Loss: 0.2309
Epoch   5 Batch  267/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8521, Loss: 0.2439
Epoch   6 Batch    1/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8519, Loss: 0.2414
Epoch   6 Batch    2/269 - Train Accuracy: 0.8403, Validation Accuracy: 0.8486, Loss: 0.2437
Epoch   6 Batch    3/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8556, Loss: 0.2391
Epoch   6 Batch    4/269 - Train Accuracy: 0.8302, Validation Accuracy: 0.8534, Loss: 0.2474
Epoch   6 Batch    5/269 - Train Accuracy: 0.8371, Validation Accuracy: 0.8485, Loss: 0.2389
Epoch   6 Batch    6/269 - Train Accuracy: 0.8741, Validation Accuracy: 0.8532, Loss: 0.2248
Epoch   6 Batch    7/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8468, Loss: 0.2228
Epoch   6 Batch    8/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8530, Loss: 0.2447
Epoch   6 Batch    9/269 - Train Accuracy: 0.8404, Validation Accuracy: 0.8550, Loss: 0.2395
Epoch   6 Batch   10/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8572, Loss: 0.2383
Epoch   6 Batch   11/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8589, Loss: 0.2377
Epoch   6 Batch   12/269 - Train Accuracy: 0.8375, Validation Accuracy: 0.8430, Loss: 0.2515
Epoch   6 Batch   13/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8589, Loss: 0.2145
Epoch   6 Batch   14/269 - Train Accuracy: 0.8458, Validation Accuracy: 0.8532, Loss: 0.2267
Epoch   6 Batch   15/269 - Train Accuracy: 0.8519, Validation Accuracy: 0.8557, Loss: 0.2171
Epoch   6 Batch   16/269 - Train Accuracy: 0.8414, Validation Accuracy: 0.8500, Loss: 0.2340
Epoch   6 Batch   17/269 - Train Accuracy: 0.8484, Validation Accuracy: 0.8611, Loss: 0.2177
Epoch   6 Batch   18/269 - Train Accuracy: 0.8467, Validation Accuracy: 0.8565, Loss: 0.2330
Epoch   6 Batch   19/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8552, Loss: 0.2147
Epoch   6 Batch   20/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8576, Loss: 0.2330
Epoch   6 Batch   21/269 - Train Accuracy: 0.8343, Validation Accuracy: 0.8595, Loss: 0.2514
Epoch   6 Batch   22/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8590, Loss: 0.2271
Epoch   6 Batch   23/269 - Train Accuracy: 0.8513, Validation Accuracy: 0.8560, Loss: 0.2255
Epoch   6 Batch   24/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8557, Loss: 0.2372
Epoch   6 Batch   25/269 - Train Accuracy: 0.8413, Validation Accuracy: 0.8527, Loss: 0.2480
Epoch   6 Batch   26/269 - Train Accuracy: 0.8678, Validation Accuracy: 0.8556, Loss: 0.2092
Epoch   6 Batch   27/269 - Train Accuracy: 0.8458, Validation Accuracy: 0.8523, Loss: 0.2234
Epoch   6 Batch   28/269 - Train Accuracy: 0.8133, Validation Accuracy: 0.8483, Loss: 0.2473
Epoch   6 Batch   29/269 - Train Accuracy: 0.8625, Validation Accuracy: 0.8544, Loss: 0.2347
Epoch   6 Batch   30/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8546, Loss: 0.2199
Epoch   6 Batch   31/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8549, Loss: 0.2166
Epoch   6 Batch   32/269 - Train Accuracy: 0.8534, Validation Accuracy: 0.8539, Loss: 0.2192
Epoch   6 Batch   33/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8600, Loss: 0.2100
Epoch   6 Batch   34/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8634, Loss: 0.2215
Epoch   6 Batch   35/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8608, Loss: 0.2351
Epoch   6 Batch   36/269 - Train Accuracy: 0.8490, Validation Accuracy: 0.8587, Loss: 0.2214
Epoch   6 Batch   37/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8615, Loss: 0.2277
Epoch   6 Batch   38/269 - Train Accuracy: 0.8500, Validation Accuracy: 0.8572, Loss: 0.2236
Epoch   6 Batch   39/269 - Train Accuracy: 0.8514, Validation Accuracy: 0.8528, Loss: 0.2199
Epoch   6 Batch   40/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8530, Loss: 0.2246
Epoch   6 Batch   41/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8535, Loss: 0.2268
Epoch   6 Batch   42/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8582, Loss: 0.2117
Epoch   6 Batch   43/269 - Train Accuracy: 0.8474, Validation Accuracy: 0.8543, Loss: 0.2272
Epoch   6 Batch   44/269 - Train Accuracy: 0.8548, Validation Accuracy: 0.8545, Loss: 0.2238
Epoch   6 Batch   45/269 - Train Accuracy: 0.8505, Validation Accuracy: 0.8587, Loss: 0.2284
Epoch   6 Batch   46/269 - Train Accuracy: 0.8634, Validation Accuracy: 0.8564, Loss: 0.2227
Epoch   6 Batch   47/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8558, Loss: 0.2047
Epoch   6 Batch   48/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8612, Loss: 0.2156
Epoch   6 Batch   49/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8643, Loss: 0.2161
Epoch   6 Batch   50/269 - Train Accuracy: 0.8368, Validation Accuracy: 0.8542, Loss: 0.2274
Epoch   6 Batch   51/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8579, Loss: 0.2110
Epoch   6 Batch   52/269 - Train Accuracy: 0.8514, Validation Accuracy: 0.8571, Loss: 0.2071
Epoch   6 Batch   53/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8571, Loss: 0.2304
Epoch   6 Batch   54/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8594, Loss: 0.2173
Epoch   6 Batch   55/269 - Train Accuracy: 0.8774, Validation Accuracy: 0.8610, Loss: 0.2074
Epoch   6 Batch   56/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8643, Loss: 0.2197
Epoch   6 Batch   57/269 - Train Accuracy: 0.8527, Validation Accuracy: 0.8659, Loss: 0.2286
Epoch   6 Batch   58/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8619, Loss: 0.2148
Epoch   6 Batch   59/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8635, Loss: 0.2020
Epoch   6 Batch   60/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8662, Loss: 0.2035
Epoch   6 Batch   61/269 - Train Accuracy: 0.8809, Validation Accuracy: 0.8703, Loss: 0.1996
Epoch   6 Batch   62/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8744, Loss: 0.2112
Epoch   6 Batch   63/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8715, Loss: 0.2196
Epoch   6 Batch   64/269 - Train Accuracy: 0.8665, Validation Accuracy: 0.8691, Loss: 0.1986
Epoch   6 Batch   65/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8623, Loss: 0.2115
Epoch   6 Batch   66/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8670, Loss: 0.2083
Epoch   6 Batch   67/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8646, Loss: 0.2196
Epoch   6 Batch   68/269 - Train Accuracy: 0.8483, Validation Accuracy: 0.8597, Loss: 0.2160
Epoch   6 Batch   69/269 - Train Accuracy: 0.8467, Validation Accuracy: 0.8643, Loss: 0.2376
Epoch   6 Batch   70/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8665, Loss: 0.2168
Epoch   6 Batch   71/269 - Train Accuracy: 0.8482, Validation Accuracy: 0.8556, Loss: 0.2306
Epoch   6 Batch   72/269 - Train Accuracy: 0.8625, Validation Accuracy: 0.8596, Loss: 0.2184
Epoch   6 Batch   73/269 - Train Accuracy: 0.8541, Validation Accuracy: 0.8596, Loss: 0.2244
Epoch   6 Batch   74/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8704, Loss: 0.2102
Epoch   6 Batch   75/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8562, Loss: 0.2131
Epoch   6 Batch   76/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8652, Loss: 0.2155
Epoch   6 Batch   77/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8627, Loss: 0.2072
Epoch   6 Batch   78/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8600, Loss: 0.2113
Epoch   6 Batch   79/269 - Train Accuracy: 0.8499, Validation Accuracy: 0.8616, Loss: 0.2086
Epoch   6 Batch   80/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8680, Loss: 0.2084
Epoch   6 Batch   81/269 - Train Accuracy: 0.8524, Validation Accuracy: 0.8722, Loss: 0.2196
Epoch   6 Batch   82/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.8589, Loss: 0.1972
Epoch   6 Batch   83/269 - Train Accuracy: 0.8559, Validation Accuracy: 0.8640, Loss: 0.2196
Epoch   6 Batch   84/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8525, Loss: 0.2116
Epoch   6 Batch   85/269 - Train Accuracy: 0.8566, Validation Accuracy: 0.8541, Loss: 0.2247
Epoch   6 Batch   86/269 - Train Accuracy: 0.8545, Validation Accuracy: 0.8626, Loss: 0.2188
Epoch   6 Batch   87/269 - Train Accuracy: 0.8496, Validation Accuracy: 0.8637, Loss: 0.2224
Epoch   6 Batch   88/269 - Train Accuracy: 0.8334, Validation Accuracy: 0.8534, Loss: 0.2162
Epoch   6 Batch   89/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8688, Loss: 0.2195
Epoch   6 Batch   90/269 - Train Accuracy: 0.8509, Validation Accuracy: 0.8675, Loss: 0.2183
Epoch   6 Batch   91/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8596, Loss: 0.2083
Epoch   6 Batch   92/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8626, Loss: 0.2069
Epoch   6 Batch   93/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8618, Loss: 0.1948
Epoch   6 Batch   94/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8659, Loss: 0.2249
Epoch   6 Batch   95/269 - Train Accuracy: 0.8723, Validation Accuracy: 0.8515, Loss: 0.2037
Epoch   6 Batch   96/269 - Train Accuracy: 0.8571, Validation Accuracy: 0.8676, Loss: 0.2142
Epoch   6 Batch   97/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8691, Loss: 0.2038
Epoch   6 Batch   98/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8691, Loss: 0.2108
Epoch   6 Batch   99/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8635, Loss: 0.2089
Epoch   6 Batch  100/269 - Train Accuracy: 0.8784, Validation Accuracy: 0.8660, Loss: 0.2093
Epoch   6 Batch  101/269 - Train Accuracy: 0.8536, Validation Accuracy: 0.8585, Loss: 0.2247
Epoch   6 Batch  102/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8698, Loss: 0.2043
Epoch   6 Batch  103/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8693, Loss: 0.2113
Epoch   6 Batch  104/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8629, Loss: 0.2013
Epoch   6 Batch  105/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8586, Loss: 0.2006
Epoch   6 Batch  106/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8682, Loss: 0.1962
Epoch   6 Batch  107/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8693, Loss: 0.2120
Epoch   6 Batch  108/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8588, Loss: 0.2032
Epoch   6 Batch  109/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8668, Loss: 0.2078
Epoch   6 Batch  110/269 - Train Accuracy: 0.8765, Validation Accuracy: 0.8729, Loss: 0.1947
Epoch   6 Batch  111/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8698, Loss: 0.2163
Epoch   6 Batch  112/269 - Train Accuracy: 0.8548, Validation Accuracy: 0.8635, Loss: 0.2034
Epoch   6 Batch  113/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8713, Loss: 0.1935
Epoch   6 Batch  114/269 - Train Accuracy: 0.8712, Validation Accuracy: 0.8699, Loss: 0.1983
Epoch   6 Batch  115/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8661, Loss: 0.2082
Epoch   6 Batch  116/269 - Train Accuracy: 0.8851, Validation Accuracy: 0.8580, Loss: 0.2030
Epoch   6 Batch  117/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8736, Loss: 0.2030
Epoch   6 Batch  118/269 - Train Accuracy: 0.8788, Validation Accuracy: 0.8676, Loss: 0.1895
Epoch   6 Batch  119/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8713, Loss: 0.2116
Epoch   6 Batch  120/269 - Train Accuracy: 0.8739, Validation Accuracy: 0.8690, Loss: 0.1996
Epoch   6 Batch  121/269 - Train Accuracy: 0.8799, Validation Accuracy: 0.8744, Loss: 0.1899
Epoch   6 Batch  122/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8752, Loss: 0.1970
Epoch   6 Batch  123/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8721, Loss: 0.2111
Epoch   6 Batch  124/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8708, Loss: 0.1841
Epoch   6 Batch  125/269 - Train Accuracy: 0.8824, Validation Accuracy: 0.8688, Loss: 0.1875
Epoch   6 Batch  126/269 - Train Accuracy: 0.8525, Validation Accuracy: 0.8740, Loss: 0.1980
Epoch   6 Batch  127/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8690, Loss: 0.2050
Epoch   6 Batch  128/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8651, Loss: 0.1991
Epoch   6 Batch  129/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8677, Loss: 0.2026
Epoch   6 Batch  130/269 - Train Accuracy: 0.8796, Validation Accuracy: 0.8762, Loss: 0.2038
Epoch   6 Batch  131/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8722, Loss: 0.1979
Epoch   6 Batch  132/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8612, Loss: 0.2042
Epoch   6 Batch  133/269 - Train Accuracy: 0.8808, Validation Accuracy: 0.8601, Loss: 0.1886
Epoch   6 Batch  134/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8706, Loss: 0.2005
Epoch   6 Batch  135/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8724, Loss: 0.2107
Epoch   6 Batch  136/269 - Train Accuracy: 0.8467, Validation Accuracy: 0.8623, Loss: 0.2083
Epoch   6 Batch  137/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8668, Loss: 0.2092
Epoch   6 Batch  138/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8743, Loss: 0.1922
Epoch   6 Batch  139/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8715, Loss: 0.1887
Epoch   6 Batch  140/269 - Train Accuracy: 0.8712, Validation Accuracy: 0.8596, Loss: 0.2013
Epoch   6 Batch  141/269 - Train Accuracy: 0.8723, Validation Accuracy: 0.8691, Loss: 0.2042
Epoch   6 Batch  142/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8743, Loss: 0.1862
Epoch   6 Batch  143/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8688, Loss: 0.1880
Epoch   6 Batch  144/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8642, Loss: 0.1777
Epoch   6 Batch  145/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8664, Loss: 0.1912
Epoch   6 Batch  146/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8728, Loss: 0.1885
Epoch   6 Batch  147/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8768, Loss: 0.1864
Epoch   6 Batch  148/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8698, Loss: 0.1929
Epoch   6 Batch  149/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8635, Loss: 0.1982
Epoch   6 Batch  150/269 - Train Accuracy: 0.8665, Validation Accuracy: 0.8725, Loss: 0.1883
Epoch   6 Batch  151/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8771, Loss: 0.1918
Epoch   6 Batch  152/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8661, Loss: 0.1920
Epoch   6 Batch  153/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8753, Loss: 0.1918
Epoch   6 Batch  154/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8739, Loss: 0.1851
Epoch   6 Batch  155/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8730, Loss: 0.1844
Epoch   6 Batch  156/269 - Train Accuracy: 0.8657, Validation Accuracy: 0.8751, Loss: 0.1934
Epoch   6 Batch  157/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8735, Loss: 0.1807
Epoch   6 Batch  158/269 - Train Accuracy: 0.8814, Validation Accuracy: 0.8804, Loss: 0.1870
Epoch   6 Batch  159/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8833, Loss: 0.1821
Epoch   6 Batch  160/269 - Train Accuracy: 0.8885, Validation Accuracy: 0.8814, Loss: 0.1922
Epoch   6 Batch  161/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8782, Loss: 0.1893
Epoch   6 Batch  162/269 - Train Accuracy: 0.8935, Validation Accuracy: 0.8781, Loss: 0.1786
Epoch   6 Batch  163/269 - Train Accuracy: 0.8983, Validation Accuracy: 0.8815, Loss: 0.1856
Epoch   6 Batch  164/269 - Train Accuracy: 0.8853, Validation Accuracy: 0.8765, Loss: 0.1852
Epoch   6 Batch  165/269 - Train Accuracy: 0.8857, Validation Accuracy: 0.8842, Loss: 0.1820
Epoch   6 Batch  166/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8845, Loss: 0.1803
Epoch   6 Batch  167/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8748, Loss: 0.1796
Epoch   6 Batch  168/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.8746, Loss: 0.1924
Epoch   6 Batch  169/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8835, Loss: 0.1912
Epoch   6 Batch  170/269 - Train Accuracy: 0.8739, Validation Accuracy: 0.8828, Loss: 0.1850
Epoch   6 Batch  171/269 - Train Accuracy: 0.8917, Validation Accuracy: 0.8794, Loss: 0.1879
Epoch   6 Batch  172/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8695, Loss: 0.1911
Epoch   6 Batch  173/269 - Train Accuracy: 0.8904, Validation Accuracy: 0.8814, Loss: 0.1783
Epoch   6 Batch  174/269 - Train Accuracy: 0.8796, Validation Accuracy: 0.8786, Loss: 0.1795
Epoch   6 Batch  175/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8759, Loss: 0.1999
Epoch   6 Batch  176/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8730, Loss: 0.1949
Epoch   6 Batch  177/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8825, Loss: 0.1768
Epoch   6 Batch  178/269 - Train Accuracy: 0.8814, Validation Accuracy: 0.8786, Loss: 0.1772
Epoch   6 Batch  179/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8754, Loss: 0.1868
Epoch   6 Batch  180/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8691, Loss: 0.1799
Epoch   6 Batch  181/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8637, Loss: 0.1876
Epoch   6 Batch  182/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8691, Loss: 0.1880
Epoch   6 Batch  183/269 - Train Accuracy: 0.9044, Validation Accuracy: 0.8760, Loss: 0.1668
Epoch   6 Batch  184/269 - Train Accuracy: 0.8712, Validation Accuracy: 0.8639, Loss: 0.1859
Epoch   6 Batch  185/269 - Train Accuracy: 0.8919, Validation Accuracy: 0.8753, Loss: 0.1837
Epoch   6 Batch  186/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8831, Loss: 0.1818
Epoch   6 Batch  187/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8841, Loss: 0.1785
Epoch   6 Batch  188/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.8797, Loss: 0.1672
Epoch   6 Batch  189/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8874, Loss: 0.1736
Epoch   6 Batch  190/269 - Train Accuracy: 0.8889, Validation Accuracy: 0.8865, Loss: 0.1751
Epoch   6 Batch  191/269 - Train Accuracy: 0.8668, Validation Accuracy: 0.8785, Loss: 0.1749
Epoch   6 Batch  192/269 - Train Accuracy: 0.8882, Validation Accuracy: 0.8786, Loss: 0.1826
Epoch   6 Batch  193/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8722, Loss: 0.1781
Epoch   6 Batch  194/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8786, Loss: 0.1891
Epoch   6 Batch  195/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8759, Loss: 0.1797
Epoch   6 Batch  196/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8797, Loss: 0.1833
Epoch   6 Batch  197/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8765, Loss: 0.1917
Epoch   6 Batch  198/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8823, Loss: 0.1907
Epoch   6 Batch  199/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8878, Loss: 0.1902
Epoch   6 Batch  200/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8872, Loss: 0.1889
Epoch   6 Batch  201/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8836, Loss: 0.1832
Epoch   6 Batch  202/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8726, Loss: 0.1785
Epoch   6 Batch  203/269 - Train Accuracy: 0.8755, Validation Accuracy: 0.8770, Loss: 0.1968
Epoch   6 Batch  204/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8790, Loss: 0.1894
Epoch   6 Batch  205/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8826, Loss: 0.1804
Epoch   6 Batch  206/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8788, Loss: 0.1883
Epoch   6 Batch  207/269 - Train Accuracy: 0.8678, Validation Accuracy: 0.8801, Loss: 0.1746
Epoch   6 Batch  208/269 - Train Accuracy: 0.8769, Validation Accuracy: 0.8896, Loss: 0.1906
Epoch   6 Batch  209/269 - Train Accuracy: 0.8856, Validation Accuracy: 0.8850, Loss: 0.1726
Epoch   6 Batch  210/269 - Train Accuracy: 0.8821, Validation Accuracy: 0.8837, Loss: 0.1726
Epoch   6 Batch  211/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8777, Loss: 0.1865
Epoch   6 Batch  212/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8796, Loss: 0.1815
Epoch   6 Batch  213/269 - Train Accuracy: 0.8816, Validation Accuracy: 0.8833, Loss: 0.1739
Epoch   6 Batch  214/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8825, Loss: 0.1791
Epoch   6 Batch  215/269 - Train Accuracy: 0.9015, Validation Accuracy: 0.8858, Loss: 0.1660
Epoch   6 Batch  216/269 - Train Accuracy: 0.8581, Validation Accuracy: 0.8872, Loss: 0.1994
Epoch   6 Batch  217/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8849, Loss: 0.1836
Epoch   6 Batch  218/269 - Train Accuracy: 0.8921, Validation Accuracy: 0.8830, Loss: 0.1781
Epoch   6 Batch  219/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8818, Loss: 0.1848
Epoch   6 Batch  220/269 - Train Accuracy: 0.8924, Validation Accuracy: 0.8886, Loss: 0.1670
Epoch   6 Batch  221/269 - Train Accuracy: 0.8908, Validation Accuracy: 0.8856, Loss: 0.1792
Epoch   6 Batch  222/269 - Train Accuracy: 0.9018, Validation Accuracy: 0.8832, Loss: 0.1671
Epoch   6 Batch  223/269 - Train Accuracy: 0.8808, Validation Accuracy: 0.8813, Loss: 0.1636
Epoch   6 Batch  224/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8760, Loss: 0.1821
Epoch   6 Batch  225/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8792, Loss: 0.1653
Epoch   6 Batch  226/269 - Train Accuracy: 0.8938, Validation Accuracy: 0.8797, Loss: 0.1736
Epoch   6 Batch  227/269 - Train Accuracy: 0.8892, Validation Accuracy: 0.8845, Loss: 0.1635
Epoch   6 Batch  228/269 - Train Accuracy: 0.8829, Validation Accuracy: 0.8828, Loss: 0.1704
Epoch   6 Batch  229/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8891, Loss: 0.1737
Epoch   6 Batch  230/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8865, Loss: 0.1715
Epoch   6 Batch  231/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8848, Loss: 0.1876
Epoch   6 Batch  232/269 - Train Accuracy: 0.8779, Validation Accuracy: 0.8856, Loss: 0.1760
Epoch   6 Batch  233/269 - Train Accuracy: 0.8947, Validation Accuracy: 0.8803, Loss: 0.1766
Epoch   6 Batch  234/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.8756, Loss: 0.1673
Epoch   6 Batch  235/269 - Train Accuracy: 0.8913, Validation Accuracy: 0.8851, Loss: 0.1622
Epoch   6 Batch  236/269 - Train Accuracy: 0.8693, Validation Accuracy: 0.8840, Loss: 0.1691
Epoch   6 Batch  237/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8786, Loss: 0.1706
Epoch   6 Batch  238/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8778, Loss: 0.1682
Epoch   6 Batch  239/269 - Train Accuracy: 0.8875, Validation Accuracy: 0.8849, Loss: 0.1644
Epoch   6 Batch  240/269 - Train Accuracy: 0.8929, Validation Accuracy: 0.8873, Loss: 0.1543
Epoch   6 Batch  241/269 - Train Accuracy: 0.8843, Validation Accuracy: 0.8841, Loss: 0.1788
Epoch   6 Batch  242/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8859, Loss: 0.1625
Epoch   6 Batch  243/269 - Train Accuracy: 0.9004, Validation Accuracy: 0.8848, Loss: 0.1581
Epoch   6 Batch  244/269 - Train Accuracy: 0.8842, Validation Accuracy: 0.8905, Loss: 0.1676
Epoch   6 Batch  245/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8830, Loss: 0.1787
Epoch   6 Batch  246/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8823, Loss: 0.1673
Epoch   6 Batch  247/269 - Train Accuracy: 0.8907, Validation Accuracy: 0.8858, Loss: 0.1678
Epoch   6 Batch  248/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.8820, Loss: 0.1576
Epoch   6 Batch  249/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.8810, Loss: 0.1597
Epoch   6 Batch  250/269 - Train Accuracy: 0.8921, Validation Accuracy: 0.8835, Loss: 0.1677
Epoch   6 Batch  251/269 - Train Accuracy: 0.9043, Validation Accuracy: 0.8852, Loss: 0.1593
Epoch   6 Batch  252/269 - Train Accuracy: 0.8870, Validation Accuracy: 0.8857, Loss: 0.1569
Epoch   6 Batch  253/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8857, Loss: 0.1718
Epoch   6 Batch  254/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8834, Loss: 0.1636
Epoch   6 Batch  255/269 - Train Accuracy: 0.8946, Validation Accuracy: 0.8838, Loss: 0.1639
Epoch   6 Batch  256/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8817, Loss: 0.1674
Epoch   6 Batch  257/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8849, Loss: 0.1723
Epoch   6 Batch  258/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8794, Loss: 0.1713
Epoch   6 Batch  259/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8888, Loss: 0.1731
Epoch   6 Batch  260/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8877, Loss: 0.1754
Epoch   6 Batch  261/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8779, Loss: 0.1711
Epoch   6 Batch  262/269 - Train Accuracy: 0.8852, Validation Accuracy: 0.8880, Loss: 0.1684
Epoch   6 Batch  263/269 - Train Accuracy: 0.8878, Validation Accuracy: 0.8883, Loss: 0.1720
Epoch   6 Batch  264/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8784, Loss: 0.1743
Epoch   6 Batch  265/269 - Train Accuracy: 0.8899, Validation Accuracy: 0.8860, Loss: 0.1685
Epoch   6 Batch  266/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8889, Loss: 0.1545
Epoch   6 Batch  267/269 - Train Accuracy: 0.8971, Validation Accuracy: 0.8846, Loss: 0.1725
Epoch   7 Batch    1/269 - Train Accuracy: 0.8914, Validation Accuracy: 0.8862, Loss: 0.1671
Epoch   7 Batch    2/269 - Train Accuracy: 0.8817, Validation Accuracy: 0.8841, Loss: 0.1651
Epoch   7 Batch    3/269 - Train Accuracy: 0.8910, Validation Accuracy: 0.8842, Loss: 0.1621
Epoch   7 Batch    4/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8830, Loss: 0.1681
Epoch   7 Batch    5/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8868, Loss: 0.1661
Epoch   7 Batch    6/269 - Train Accuracy: 0.9002, Validation Accuracy: 0.8770, Loss: 0.1505
Epoch   7 Batch    7/269 - Train Accuracy: 0.8905, Validation Accuracy: 0.8771, Loss: 0.1523
Epoch   7 Batch    8/269 - Train Accuracy: 0.8917, Validation Accuracy: 0.8825, Loss: 0.1707
Epoch   7 Batch    9/269 - Train Accuracy: 0.8878, Validation Accuracy: 0.8810, Loss: 0.1696
Epoch   7 Batch   10/269 - Train Accuracy: 0.8898, Validation Accuracy: 0.8850, Loss: 0.1631
Epoch   7 Batch   11/269 - Train Accuracy: 0.8934, Validation Accuracy: 0.8866, Loss: 0.1694
Epoch   7 Batch   12/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8790, Loss: 0.1746
Epoch   7 Batch   13/269 - Train Accuracy: 0.8847, Validation Accuracy: 0.8917, Loss: 0.1420
Epoch   7 Batch   14/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8926, Loss: 0.1590
Epoch   7 Batch   15/269 - Train Accuracy: 0.8868, Validation Accuracy: 0.8933, Loss: 0.1487
Epoch   7 Batch   16/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8912, Loss: 0.1673
Epoch   7 Batch   17/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.8939, Loss: 0.1477
Epoch   7 Batch   18/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8933, Loss: 0.1623
Epoch   7 Batch   19/269 - Train Accuracy: 0.9052, Validation Accuracy: 0.8925, Loss: 0.1465
Epoch   7 Batch   20/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.8849, Loss: 0.1595
Epoch   7 Batch   21/269 - Train Accuracy: 0.8684, Validation Accuracy: 0.8923, Loss: 0.1770
Epoch   7 Batch   22/269 - Train Accuracy: 0.8994, Validation Accuracy: 0.8890, Loss: 0.1522
Epoch   7 Batch   23/269 - Train Accuracy: 0.8881, Validation Accuracy: 0.8900, Loss: 0.1625
Epoch   7 Batch   24/269 - Train Accuracy: 0.8807, Validation Accuracy: 0.8877, Loss: 0.1605
Epoch   7 Batch   25/269 - Train Accuracy: 0.8807, Validation Accuracy: 0.8876, Loss: 0.1647
Epoch   7 Batch   26/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.8898, Loss: 0.1459
Epoch   7 Batch   27/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8885, Loss: 0.1552
Epoch   7 Batch   28/269 - Train Accuracy: 0.8591, Validation Accuracy: 0.8891, Loss: 0.1724
Epoch   7 Batch   29/269 - Train Accuracy: 0.9006, Validation Accuracy: 0.8894, Loss: 0.1612
Epoch   7 Batch   30/269 - Train Accuracy: 0.8964, Validation Accuracy: 0.8891, Loss: 0.1493
Epoch   7 Batch   31/269 - Train Accuracy: 0.8862, Validation Accuracy: 0.8862, Loss: 0.1499
Epoch   7 Batch   32/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8851, Loss: 0.1514
Epoch   7 Batch   33/269 - Train Accuracy: 0.8924, Validation Accuracy: 0.8836, Loss: 0.1472
Epoch   7 Batch   34/269 - Train Accuracy: 0.8986, Validation Accuracy: 0.8877, Loss: 0.1534
Epoch   7 Batch   35/269 - Train Accuracy: 0.8943, Validation Accuracy: 0.8904, Loss: 0.1624
Epoch   7 Batch   36/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.8845, Loss: 0.1489
Epoch   7 Batch   37/269 - Train Accuracy: 0.8817, Validation Accuracy: 0.8915, Loss: 0.1594
Epoch   7 Batch   38/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8889, Loss: 0.1509
Epoch   7 Batch   39/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.8894, Loss: 0.1482
Epoch   7 Batch   40/269 - Train Accuracy: 0.8782, Validation Accuracy: 0.8944, Loss: 0.1551
Epoch   7 Batch   41/269 - Train Accuracy: 0.8859, Validation Accuracy: 0.8956, Loss: 0.1536
Epoch   7 Batch   42/269 - Train Accuracy: 0.9100, Validation Accuracy: 0.8961, Loss: 0.1405
Epoch   7 Batch   43/269 - Train Accuracy: 0.8834, Validation Accuracy: 0.8940, Loss: 0.1600
Epoch   7 Batch   44/269 - Train Accuracy: 0.8860, Validation Accuracy: 0.8990, Loss: 0.1556
Epoch   7 Batch   45/269 - Train Accuracy: 0.8901, Validation Accuracy: 0.8959, Loss: 0.1545
Epoch   7 Batch   46/269 - Train Accuracy: 0.9015, Validation Accuracy: 0.8888, Loss: 0.1516
Epoch   7 Batch   47/269 - Train Accuracy: 0.8968, Validation Accuracy: 0.8875, Loss: 0.1413
Epoch   7 Batch   48/269 - Train Accuracy: 0.8909, Validation Accuracy: 0.8856, Loss: 0.1453
Epoch   7 Batch   49/269 - Train Accuracy: 0.8905, Validation Accuracy: 0.8956, Loss: 0.1468
Epoch   7 Batch   50/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8964, Loss: 0.1616
Epoch   7 Batch   51/269 - Train Accuracy: 0.8982, Validation Accuracy: 0.8929, Loss: 0.1424
Epoch   7 Batch   52/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.8964, Loss: 0.1390
Epoch   7 Batch   53/269 - Train Accuracy: 0.8871, Validation Accuracy: 0.8947, Loss: 0.1624
Epoch   7 Batch   54/269 - Train Accuracy: 0.8991, Validation Accuracy: 0.8989, Loss: 0.1546
Epoch   7 Batch   55/269 - Train Accuracy: 0.9027, Validation Accuracy: 0.8887, Loss: 0.1457
Epoch   7 Batch   56/269 - Train Accuracy: 0.8901, Validation Accuracy: 0.8953, Loss: 0.1502
Epoch   7 Batch   57/269 - Train Accuracy: 0.8846, Validation Accuracy: 0.8988, Loss: 0.1587
Epoch   7 Batch   58/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8930, Loss: 0.1476
Epoch   7 Batch   59/269 - Train Accuracy: 0.9071, Validation Accuracy: 0.8928, Loss: 0.1397
Epoch   7 Batch   60/269 - Train Accuracy: 0.8889, Validation Accuracy: 0.8971, Loss: 0.1351
Epoch   7 Batch   61/269 - Train Accuracy: 0.9099, Validation Accuracy: 0.8954, Loss: 0.1392
Epoch   7 Batch   62/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.8964, Loss: 0.1471
Epoch   7 Batch   63/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.8975, Loss: 0.1556
Epoch   7 Batch   64/269 - Train Accuracy: 0.9040, Validation Accuracy: 0.8921, Loss: 0.1386
Epoch   7 Batch   65/269 - Train Accuracy: 0.8879, Validation Accuracy: 0.8927, Loss: 0.1388
Epoch   7 Batch   66/269 - Train Accuracy: 0.8901, Validation Accuracy: 0.8932, Loss: 0.1459
Epoch   7 Batch   67/269 - Train Accuracy: 0.8834, Validation Accuracy: 0.8934, Loss: 0.1562
Epoch   7 Batch   68/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8904, Loss: 0.1514
Epoch   7 Batch   69/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8960, Loss: 0.1698
Epoch   7 Batch   70/269 - Train Accuracy: 0.8934, Validation Accuracy: 0.8991, Loss: 0.1526
Epoch   7 Batch   71/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8894, Loss: 0.1601
Epoch   7 Batch   72/269 - Train Accuracy: 0.8904, Validation Accuracy: 0.9023, Loss: 0.1547
Epoch   7 Batch   73/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8959, Loss: 0.1581
Epoch   7 Batch   74/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.8935, Loss: 0.1467
Epoch   7 Batch   75/269 - Train Accuracy: 0.9026, Validation Accuracy: 0.8889, Loss: 0.1518
Epoch   7 Batch   76/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.8966, Loss: 0.1442
Epoch   7 Batch   77/269 - Train Accuracy: 0.8922, Validation Accuracy: 0.8936, Loss: 0.1418
Epoch   7 Batch   78/269 - Train Accuracy: 0.8997, Validation Accuracy: 0.8959, Loss: 0.1476
Epoch   7 Batch   79/269 - Train Accuracy: 0.8825, Validation Accuracy: 0.8972, Loss: 0.1448
Epoch   7 Batch   80/269 - Train Accuracy: 0.9058, Validation Accuracy: 0.8993, Loss: 0.1402
Epoch   7 Batch   81/269 - Train Accuracy: 0.8841, Validation Accuracy: 0.9044, Loss: 0.1583
Epoch   7 Batch   82/269 - Train Accuracy: 0.9144, Validation Accuracy: 0.9034, Loss: 0.1340
Epoch   7 Batch   83/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8980, Loss: 0.1528
Epoch   7 Batch   84/269 - Train Accuracy: 0.9070, Validation Accuracy: 0.9016, Loss: 0.1380
Epoch   7 Batch   85/269 - Train Accuracy: 0.8951, Validation Accuracy: 0.8982, Loss: 0.1439
Epoch   7 Batch   86/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8989, Loss: 0.1396
Epoch   7 Batch   87/269 - Train Accuracy: 0.8841, Validation Accuracy: 0.8971, Loss: 0.1484
Epoch   7 Batch   88/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8997, Loss: 0.1480
Epoch   7 Batch   89/269 - Train Accuracy: 0.9083, Validation Accuracy: 0.8994, Loss: 0.1401
Epoch   7 Batch   90/269 - Train Accuracy: 0.8922, Validation Accuracy: 0.8966, Loss: 0.1526
Epoch   7 Batch   91/269 - Train Accuracy: 0.9055, Validation Accuracy: 0.8922, Loss: 0.1356
Epoch   7 Batch   92/269 - Train Accuracy: 0.9031, Validation Accuracy: 0.8981, Loss: 0.1360
Epoch   7 Batch   93/269 - Train Accuracy: 0.9015, Validation Accuracy: 0.8983, Loss: 0.1346
Epoch   7 Batch   94/269 - Train Accuracy: 0.8964, Validation Accuracy: 0.8947, Loss: 0.1604
Epoch   7 Batch   95/269 - Train Accuracy: 0.8956, Validation Accuracy: 0.8900, Loss: 0.1375
Epoch   7 Batch   96/269 - Train Accuracy: 0.8750, Validation Accuracy: 0.8989, Loss: 0.1473
Epoch   7 Batch   97/269 - Train Accuracy: 0.8926, Validation Accuracy: 0.8977, Loss: 0.1413
Epoch   7 Batch   98/269 - Train Accuracy: 0.9045, Validation Accuracy: 0.8960, Loss: 0.1376
Epoch   7 Batch   99/269 - Train Accuracy: 0.8946, Validation Accuracy: 0.8857, Loss: 0.1399
Epoch   7 Batch  100/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.8852, Loss: 0.1408
Epoch   7 Batch  101/269 - Train Accuracy: 0.8954, Validation Accuracy: 0.8991, Loss: 0.1592
Epoch   7 Batch  102/269 - Train Accuracy: 0.8966, Validation Accuracy: 0.9014, Loss: 0.1396
Epoch   7 Batch  103/269 - Train Accuracy: 0.9009, Validation Accuracy: 0.8979, Loss: 0.1472
Epoch   7 Batch  104/269 - Train Accuracy: 0.8912, Validation Accuracy: 0.8949, Loss: 0.1360
Epoch   7 Batch  105/269 - Train Accuracy: 0.8891, Validation Accuracy: 0.9026, Loss: 0.1405
Epoch   7 Batch  106/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8933, Loss: 0.1338
Epoch   7 Batch  107/269 - Train Accuracy: 0.8907, Validation Accuracy: 0.8864, Loss: 0.1447
Epoch   7 Batch  108/269 - Train Accuracy: 0.9076, Validation Accuracy: 0.8970, Loss: 0.1397
Epoch   7 Batch  109/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.9032, Loss: 0.1417
Epoch   7 Batch  110/269 - Train Accuracy: 0.8984, Validation Accuracy: 0.8999, Loss: 0.1359
Epoch   7 Batch  111/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.8920, Loss: 0.1504
Epoch   7 Batch  112/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.8910, Loss: 0.1375
Epoch   7 Batch  113/269 - Train Accuracy: 0.8920, Validation Accuracy: 0.9024, Loss: 0.1291
Epoch   7 Batch  114/269 - Train Accuracy: 0.9013, Validation Accuracy: 0.8964, Loss: 0.1416
Epoch   7 Batch  115/269 - Train Accuracy: 0.8838, Validation Accuracy: 0.8904, Loss: 0.1452
Epoch   7 Batch  116/269 - Train Accuracy: 0.9152, Validation Accuracy: 0.8859, Loss: 0.1464
Epoch   7 Batch  117/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.8983, Loss: 0.1356
Epoch   7 Batch  118/269 - Train Accuracy: 0.9024, Validation Accuracy: 0.8999, Loss: 0.1336
Epoch   7 Batch  119/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.9016, Loss: 0.1535
Epoch   7 Batch  120/269 - Train Accuracy: 0.9022, Validation Accuracy: 0.9004, Loss: 0.1423
Epoch   7 Batch  121/269 - Train Accuracy: 0.9032, Validation Accuracy: 0.9032, Loss: 0.1299
Epoch   7 Batch  122/269 - Train Accuracy: 0.8885, Validation Accuracy: 0.9029, Loss: 0.1348
Epoch   7 Batch  123/269 - Train Accuracy: 0.9032, Validation Accuracy: 0.8979, Loss: 0.1420
Epoch   7 Batch  124/269 - Train Accuracy: 0.8982, Validation Accuracy: 0.8926, Loss: 0.1248
Epoch   7 Batch  125/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.8979, Loss: 0.1266
Epoch   7 Batch  126/269 - Train Accuracy: 0.8844, Validation Accuracy: 0.9047, Loss: 0.1342
Epoch   7 Batch  127/269 - Train Accuracy: 0.8895, Validation Accuracy: 0.9049, Loss: 0.1413
Epoch   7 Batch  128/269 - Train Accuracy: 0.8908, Validation Accuracy: 0.8927, Loss: 0.1357
Epoch   7 Batch  129/269 - Train Accuracy: 0.8873, Validation Accuracy: 0.9005, Loss: 0.1440
Epoch   7 Batch  130/269 - Train Accuracy: 0.8992, Validation Accuracy: 0.9016, Loss: 0.1449
Epoch   7 Batch  131/269 - Train Accuracy: 0.8807, Validation Accuracy: 0.8961, Loss: 0.1377
Epoch   7 Batch  132/269 - Train Accuracy: 0.8883, Validation Accuracy: 0.8990, Loss: 0.1485
Epoch   7 Batch  133/269 - Train Accuracy: 0.9040, Validation Accuracy: 0.9017, Loss: 0.1290
Epoch   7 Batch  134/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8933, Loss: 0.1399
Epoch   7 Batch  135/269 - Train Accuracy: 0.8913, Validation Accuracy: 0.9048, Loss: 0.1481
Epoch   7 Batch  136/269 - Train Accuracy: 0.8799, Validation Accuracy: 0.9060, Loss: 0.1490
Epoch   7 Batch  137/269 - Train Accuracy: 0.8845, Validation Accuracy: 0.8936, Loss: 0.1505
Epoch   7 Batch  138/269 - Train Accuracy: 0.8920, Validation Accuracy: 0.8978, Loss: 0.1373
Epoch   7 Batch  139/269 - Train Accuracy: 0.8978, Validation Accuracy: 0.8957, Loss: 0.1265
Epoch   7 Batch  140/269 - Train Accuracy: 0.9020, Validation Accuracy: 0.8940, Loss: 0.1466
Epoch   7 Batch  141/269 - Train Accuracy: 0.8950, Validation Accuracy: 0.8901, Loss: 0.1510
Epoch   7 Batch  142/269 - Train Accuracy: 0.8983, Validation Accuracy: 0.8944, Loss: 0.1313
Epoch   7 Batch  143/269 - Train Accuracy: 0.9034, Validation Accuracy: 0.9045, Loss: 0.1369
Epoch   7 Batch  144/269 - Train Accuracy: 0.9043, Validation Accuracy: 0.9083, Loss: 0.1316
Epoch   7 Batch  145/269 - Train Accuracy: 0.8948, Validation Accuracy: 0.9023, Loss: 0.1297
Epoch   7 Batch  146/269 - Train Accuracy: 0.8921, Validation Accuracy: 0.9069, Loss: 0.1425
Epoch   7 Batch  147/269 - Train Accuracy: 0.8967, Validation Accuracy: 0.8988, Loss: 0.1324
Epoch   7 Batch  148/269 - Train Accuracy: 0.8947, Validation Accuracy: 0.9017, Loss: 0.1388
Epoch   7 Batch  149/269 - Train Accuracy: 0.8858, Validation Accuracy: 0.9017, Loss: 0.1457
Epoch   7 Batch  150/269 - Train Accuracy: 0.8924, Validation Accuracy: 0.8893, Loss: 0.1375
Epoch   7 Batch  151/269 - Train Accuracy: 0.8923, Validation Accuracy: 0.8988, Loss: 0.1396
Epoch   7 Batch  152/269 - Train Accuracy: 0.9010, Validation Accuracy: 0.9054, Loss: 0.1340
Epoch   7 Batch  153/269 - Train Accuracy: 0.9136, Validation Accuracy: 0.9021, Loss: 0.1373
Epoch   7 Batch  154/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.8932, Loss: 0.1285
Epoch   7 Batch  155/269 - Train Accuracy: 0.8921, Validation Accuracy: 0.8974, Loss: 0.1283
Epoch   7 Batch  156/269 - Train Accuracy: 0.8924, Validation Accuracy: 0.9008, Loss: 0.1407
Epoch   7 Batch  157/269 - Train Accuracy: 0.8858, Validation Accuracy: 0.8999, Loss: 0.1273
Epoch   7 Batch  158/269 - Train Accuracy: 0.9040, Validation Accuracy: 0.9031, Loss: 0.1289
Epoch   7 Batch  159/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.9078, Loss: 0.1368
Epoch   7 Batch  160/269 - Train Accuracy: 0.9043, Validation Accuracy: 0.8947, Loss: 0.1332
Epoch   7 Batch  161/269 - Train Accuracy: 0.8954, Validation Accuracy: 0.8909, Loss: 0.1287
Epoch   7 Batch  162/269 - Train Accuracy: 0.9179, Validation Accuracy: 0.9071, Loss: 0.1281
Epoch   7 Batch  163/269 - Train Accuracy: 0.9058, Validation Accuracy: 0.8937, Loss: 0.1295
Epoch   7 Batch  164/269 - Train Accuracy: 0.9076, Validation Accuracy: 0.9032, Loss: 0.1310
Epoch   7 Batch  165/269 - Train Accuracy: 0.8976, Validation Accuracy: 0.8865, Loss: 0.1289
Epoch   7 Batch  166/269 - Train Accuracy: 0.9017, Validation Accuracy: 0.9039, Loss: 0.1323
Epoch   7 Batch  167/269 - Train Accuracy: 0.9028, Validation Accuracy: 0.9044, Loss: 0.1275
Epoch   7 Batch  168/269 - Train Accuracy: 0.8932, Validation Accuracy: 0.8886, Loss: 0.1360
Epoch   7 Batch  169/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.9014, Loss: 0.1346
Epoch   7 Batch  170/269 - Train Accuracy: 0.9010, Validation Accuracy: 0.9046, Loss: 0.1265
Epoch   7 Batch  171/269 - Train Accuracy: 0.9164, Validation Accuracy: 0.9018, Loss: 0.1316
Epoch   7 Batch  172/269 - Train Accuracy: 0.8978, Validation Accuracy: 0.9014, Loss: 0.1410
Epoch   7 Batch  173/269 - Train Accuracy: 0.9078, Validation Accuracy: 0.9001, Loss: 0.1268
Epoch   7 Batch  174/269 - Train Accuracy: 0.9051, Validation Accuracy: 0.8959, Loss: 0.1328
Epoch   7 Batch  175/269 - Train Accuracy: 0.8938, Validation Accuracy: 0.9127, Loss: 0.1413
Epoch   7 Batch  176/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.9012, Loss: 0.1362
Epoch   7 Batch  177/269 - Train Accuracy: 0.8994, Validation Accuracy: 0.9082, Loss: 0.1275
Epoch   7 Batch  178/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9055, Loss: 0.1325
Epoch   7 Batch  179/269 - Train Accuracy: 0.8943, Validation Accuracy: 0.9034, Loss: 0.1302
Epoch   7 Batch  180/269 - Train Accuracy: 0.9111, Validation Accuracy: 0.9076, Loss: 0.1264
Epoch   7 Batch  181/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.8961, Loss: 0.1352
Epoch   7 Batch  182/269 - Train Accuracy: 0.9038, Validation Accuracy: 0.9023, Loss: 0.1297
Epoch   7 Batch  183/269 - Train Accuracy: 0.9216, Validation Accuracy: 0.9097, Loss: 0.1079
Epoch   7 Batch  184/269 - Train Accuracy: 0.9007, Validation Accuracy: 0.9070, Loss: 0.1292
Epoch   7 Batch  185/269 - Train Accuracy: 0.9148, Validation Accuracy: 0.9026, Loss: 0.1253
Epoch   7 Batch  186/269 - Train Accuracy: 0.9064, Validation Accuracy: 0.9083, Loss: 0.1271
Epoch   7 Batch  187/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.9108, Loss: 0.1231
Epoch   7 Batch  188/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.9110, Loss: 0.1153
Epoch   7 Batch  189/269 - Train Accuracy: 0.9037, Validation Accuracy: 0.9093, Loss: 0.1218
Epoch   7 Batch  190/269 - Train Accuracy: 0.8998, Validation Accuracy: 0.9023, Loss: 0.1233
Epoch   7 Batch  191/269 - Train Accuracy: 0.8943, Validation Accuracy: 0.8953, Loss: 0.1271
Epoch   7 Batch  192/269 - Train Accuracy: 0.9067, Validation Accuracy: 0.9038, Loss: 0.1269
Epoch   7 Batch  193/269 - Train Accuracy: 0.9129, Validation Accuracy: 0.9036, Loss: 0.1246
Epoch   7 Batch  194/269 - Train Accuracy: 0.8914, Validation Accuracy: 0.9065, Loss: 0.1296
Epoch   7 Batch  195/269 - Train Accuracy: 0.8980, Validation Accuracy: 0.9102, Loss: 0.1256
Epoch   7 Batch  196/269 - Train Accuracy: 0.8970, Validation Accuracy: 0.9049, Loss: 0.1220
Epoch   7 Batch  197/269 - Train Accuracy: 0.8968, Validation Accuracy: 0.9071, Loss: 0.1334
Epoch   7 Batch  198/269 - Train Accuracy: 0.8938, Validation Accuracy: 0.9092, Loss: 0.1307
Epoch   7 Batch  199/269 - Train Accuracy: 0.8985, Validation Accuracy: 0.9012, Loss: 0.1304
Epoch   7 Batch  200/269 - Train Accuracy: 0.9053, Validation Accuracy: 0.9018, Loss: 0.1290
Epoch   7 Batch  201/269 - Train Accuracy: 0.8875, Validation Accuracy: 0.9056, Loss: 0.1267
Epoch   7 Batch  202/269 - Train Accuracy: 0.8968, Validation Accuracy: 0.9086, Loss: 0.1282
Epoch   7 Batch  203/269 - Train Accuracy: 0.8942, Validation Accuracy: 0.9015, Loss: 0.1421
Epoch   7 Batch  204/269 - Train Accuracy: 0.9006, Validation Accuracy: 0.9091, Loss: 0.1340
Epoch   7 Batch  205/269 - Train Accuracy: 0.9003, Validation Accuracy: 0.9064, Loss: 0.1291
Epoch   7 Batch  206/269 - Train Accuracy: 0.8938, Validation Accuracy: 0.9073, Loss: 0.1418
Epoch   7 Batch  207/269 - Train Accuracy: 0.8972, Validation Accuracy: 0.9094, Loss: 0.1247
Epoch   7 Batch  208/269 - Train Accuracy: 0.8898, Validation Accuracy: 0.9057, Loss: 0.1295
Epoch   7 Batch  209/269 - Train Accuracy: 0.9135, Validation Accuracy: 0.9080, Loss: 0.1239
Epoch   7 Batch  210/269 - Train Accuracy: 0.9089, Validation Accuracy: 0.9033, Loss: 0.1234
Epoch   7 Batch  211/269 - Train Accuracy: 0.9112, Validation Accuracy: 0.9125, Loss: 0.1262
Epoch   7 Batch  212/269 - Train Accuracy: 0.9055, Validation Accuracy: 0.9109, Loss: 0.1299
Epoch   7 Batch  213/269 - Train Accuracy: 0.8977, Validation Accuracy: 0.9057, Loss: 0.1233
Epoch   7 Batch  214/269 - Train Accuracy: 0.8995, Validation Accuracy: 0.9099, Loss: 0.1287
Epoch   7 Batch  215/269 - Train Accuracy: 0.9185, Validation Accuracy: 0.9102, Loss: 0.1162
Epoch   7 Batch  216/269 - Train Accuracy: 0.8774, Validation Accuracy: 0.9013, Loss: 0.1447
Epoch   7 Batch  217/269 - Train Accuracy: 0.8809, Validation Accuracy: 0.8965, Loss: 0.1252
Epoch   7 Batch  218/269 - Train Accuracy: 0.9115, Validation Accuracy: 0.9016, Loss: 0.1270
Epoch   7 Batch  219/269 - Train Accuracy: 0.8972, Validation Accuracy: 0.9110, Loss: 0.1289
Epoch   7 Batch  220/269 - Train Accuracy: 0.9078, Validation Accuracy: 0.9006, Loss: 0.1205
Epoch   7 Batch  221/269 - Train Accuracy: 0.9091, Validation Accuracy: 0.8979, Loss: 0.1286
Epoch   7 Batch  222/269 - Train Accuracy: 0.9299, Validation Accuracy: 0.9096, Loss: 0.1203
Epoch   7 Batch  223/269 - Train Accuracy: 0.8990, Validation Accuracy: 0.9114, Loss: 0.1151
Epoch   7 Batch  224/269 - Train Accuracy: 0.8965, Validation Accuracy: 0.9029, Loss: 0.1328
Epoch   7 Batch  225/269 - Train Accuracy: 0.8943, Validation Accuracy: 0.9006, Loss: 0.1231
Epoch   7 Batch  226/269 - Train Accuracy: 0.9062, Validation Accuracy: 0.9065, Loss: 0.1234
Epoch   7 Batch  227/269 - Train Accuracy: 0.9161, Validation Accuracy: 0.9044, Loss: 0.1230
Epoch   7 Batch  228/269 - Train Accuracy: 0.9007, Validation Accuracy: 0.8943, Loss: 0.1220
Epoch   7 Batch  229/269 - Train Accuracy: 0.8918, Validation Accuracy: 0.8975, Loss: 0.1230
Epoch   7 Batch  230/269 - Train Accuracy: 0.9110, Validation Accuracy: 0.9018, Loss: 0.1197
Epoch   7 Batch  231/269 - Train Accuracy: 0.8940, Validation Accuracy: 0.9021, Loss: 0.1319
Epoch   7 Batch  232/269 - Train Accuracy: 0.9046, Validation Accuracy: 0.9039, Loss: 0.1221
Epoch   7 Batch  233/269 - Train Accuracy: 0.9222, Validation Accuracy: 0.9060, Loss: 0.1253
Epoch   7 Batch  234/269 - Train Accuracy: 0.9063, Validation Accuracy: 0.8979, Loss: 0.1241
Epoch   7 Batch  235/269 - Train Accuracy: 0.9169, Validation Accuracy: 0.8978, Loss: 0.1133
Epoch   7 Batch  236/269 - Train Accuracy: 0.8988, Validation Accuracy: 0.9052, Loss: 0.1190
Epoch   7 Batch  237/269 - Train Accuracy: 0.9034, Validation Accuracy: 0.9055, Loss: 0.1163
Epoch   7 Batch  238/269 - Train Accuracy: 0.9014, Validation Accuracy: 0.9038, Loss: 0.1201
Epoch   7 Batch  239/269 - Train Accuracy: 0.8987, Validation Accuracy: 0.9047, Loss: 0.1158
Epoch   7 Batch  240/269 - Train Accuracy: 0.9137, Validation Accuracy: 0.9105, Loss: 0.1150
Epoch   7 Batch  241/269 - Train Accuracy: 0.9001, Validation Accuracy: 0.9083, Loss: 0.1334
Epoch   7 Batch  242/269 - Train Accuracy: 0.9181, Validation Accuracy: 0.9017, Loss: 0.1135
Epoch   7 Batch  243/269 - Train Accuracy: 0.9097, Validation Accuracy: 0.9112, Loss: 0.1125
Epoch   7 Batch  244/269 - Train Accuracy: 0.9055, Validation Accuracy: 0.9062, Loss: 0.1195
Epoch   7 Batch  245/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.9094, Loss: 0.1258
Epoch   7 Batch  246/269 - Train Accuracy: 0.8935, Validation Accuracy: 0.9107, Loss: 0.1237
Epoch   7 Batch  247/269 - Train Accuracy: 0.9147, Validation Accuracy: 0.9118, Loss: 0.1189
Epoch   7 Batch  248/269 - Train Accuracy: 0.9057, Validation Accuracy: 0.9071, Loss: 0.1132
Epoch   7 Batch  249/269 - Train Accuracy: 0.9177, Validation Accuracy: 0.9120, Loss: 0.1118
Epoch   7 Batch  250/269 - Train Accuracy: 0.9238, Validation Accuracy: 0.9102, Loss: 0.1196
Epoch   7 Batch  251/269 - Train Accuracy: 0.9360, Validation Accuracy: 0.9127, Loss: 0.1155
Epoch   7 Batch  252/269 - Train Accuracy: 0.9118, Validation Accuracy: 0.9018, Loss: 0.1115
Epoch   7 Batch  253/269 - Train Accuracy: 0.8978, Validation Accuracy: 0.9108, Loss: 0.1266
Epoch   7 Batch  254/269 - Train Accuracy: 0.9089, Validation Accuracy: 0.9088, Loss: 0.1162
Epoch   7 Batch  255/269 - Train Accuracy: 0.8960, Validation Accuracy: 0.9071, Loss: 0.1157
Epoch   7 Batch  256/269 - Train Accuracy: 0.8906, Validation Accuracy: 0.9092, Loss: 0.1197
Epoch   7 Batch  257/269 - Train Accuracy: 0.8873, Validation Accuracy: 0.9106, Loss: 0.1257
Epoch   7 Batch  258/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.8975, Loss: 0.1250
Epoch   7 Batch  259/269 - Train Accuracy: 0.8990, Validation Accuracy: 0.9009, Loss: 0.1236
Epoch   7 Batch  260/269 - Train Accuracy: 0.9027, Validation Accuracy: 0.9140, Loss: 0.1235
Epoch   7 Batch  261/269 - Train Accuracy: 0.9100, Validation Accuracy: 0.9098, Loss: 0.1184
Epoch   7 Batch  262/269 - Train Accuracy: 0.9088, Validation Accuracy: 0.9023, Loss: 0.1196
Epoch   7 Batch  263/269 - Train Accuracy: 0.9040, Validation Accuracy: 0.9044, Loss: 0.1252
Epoch   7 Batch  264/269 - Train Accuracy: 0.8838, Validation Accuracy: 0.9133, Loss: 0.1218
Epoch   7 Batch  265/269 - Train Accuracy: 0.9031, Validation Accuracy: 0.9042, Loss: 0.1177
Epoch   7 Batch  266/269 - Train Accuracy: 0.9091, Validation Accuracy: 0.9017, Loss: 0.1105
Epoch   7 Batch  267/269 - Train Accuracy: 0.9194, Validation Accuracy: 0.9102, Loss: 0.1264
Epoch   8 Batch    1/269 - Train Accuracy: 0.9087, Validation Accuracy: 0.9075, Loss: 0.1159
Epoch   8 Batch    2/269 - Train Accuracy: 0.9010, Validation Accuracy: 0.9091, Loss: 0.1168
Epoch   8 Batch    3/269 - Train Accuracy: 0.9144, Validation Accuracy: 0.9113, Loss: 0.1188
Epoch   8 Batch    4/269 - Train Accuracy: 0.8934, Validation Accuracy: 0.9106, Loss: 0.1214
Epoch   8 Batch    5/269 - Train Accuracy: 0.9043, Validation Accuracy: 0.9074, Loss: 0.1180
Epoch   8 Batch    6/269 - Train Accuracy: 0.9217, Validation Accuracy: 0.9051, Loss: 0.1080
Epoch   8 Batch    7/269 - Train Accuracy: 0.9058, Validation Accuracy: 0.9055, Loss: 0.1102
Epoch   8 Batch    8/269 - Train Accuracy: 0.9148, Validation Accuracy: 0.9100, Loss: 0.1209
Epoch   8 Batch    9/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.9126, Loss: 0.1206
Epoch   8 Batch   10/269 - Train Accuracy: 0.9040, Validation Accuracy: 0.9116, Loss: 0.1125
Epoch   8 Batch   11/269 - Train Accuracy: 0.9166, Validation Accuracy: 0.9078, Loss: 0.1243
Epoch   8 Batch   12/269 - Train Accuracy: 0.8905, Validation Accuracy: 0.8986, Loss: 0.1308
Epoch   8 Batch   13/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.8991, Loss: 0.1049
Epoch   8 Batch   14/269 - Train Accuracy: 0.9019, Validation Accuracy: 0.9069, Loss: 0.1132
Epoch   8 Batch   15/269 - Train Accuracy: 0.9086, Validation Accuracy: 0.9123, Loss: 0.1040
Epoch   8 Batch   16/269 - Train Accuracy: 0.9022, Validation Accuracy: 0.9086, Loss: 0.1218
Epoch   8 Batch   17/269 - Train Accuracy: 0.9128, Validation Accuracy: 0.9081, Loss: 0.1036
Epoch   8 Batch   18/269 - Train Accuracy: 0.9046, Validation Accuracy: 0.9229, Loss: 0.1172
Epoch   8 Batch   19/269 - Train Accuracy: 0.9157, Validation Accuracy: 0.9152, Loss: 0.1026
Epoch   8 Batch   20/269 - Train Accuracy: 0.9118, Validation Accuracy: 0.9011, Loss: 0.1126
Epoch   8 Batch   21/269 - Train Accuracy: 0.8911, Validation Accuracy: 0.9141, Loss: 0.1309
Epoch   8 Batch   22/269 - Train Accuracy: 0.9163, Validation Accuracy: 0.9107, Loss: 0.1108
Epoch   8 Batch   23/269 - Train Accuracy: 0.9080, Validation Accuracy: 0.9223, Loss: 0.1169
Epoch   8 Batch   24/269 - Train Accuracy: 0.8986, Validation Accuracy: 0.9128, Loss: 0.1115
Epoch   8 Batch   25/269 - Train Accuracy: 0.9025, Validation Accuracy: 0.9083, Loss: 0.1213
Epoch   8 Batch   26/269 - Train Accuracy: 0.9087, Validation Accuracy: 0.9201, Loss: 0.0995
Epoch   8 Batch   27/269 - Train Accuracy: 0.8928, Validation Accuracy: 0.9152, Loss: 0.1098
Epoch   8 Batch   28/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.9075, Loss: 0.1212
Epoch   8 Batch   29/269 - Train Accuracy: 0.9146, Validation Accuracy: 0.9154, Loss: 0.1118
Epoch   8 Batch   30/269 - Train Accuracy: 0.9247, Validation Accuracy: 0.9181, Loss: 0.1115
Epoch   8 Batch   31/269 - Train Accuracy: 0.9106, Validation Accuracy: 0.9138, Loss: 0.1065
Epoch   8 Batch   32/269 - Train Accuracy: 0.9096, Validation Accuracy: 0.9093, Loss: 0.1092
Epoch   8 Batch   33/269 - Train Accuracy: 0.9134, Validation Accuracy: 0.9070, Loss: 0.1039
Epoch   8 Batch   34/269 - Train Accuracy: 0.9158, Validation Accuracy: 0.9115, Loss: 0.1122
Epoch   8 Batch   35/269 - Train Accuracy: 0.9138, Validation Accuracy: 0.9142, Loss: 0.1177
Epoch   8 Batch   36/269 - Train Accuracy: 0.8973, Validation Accuracy: 0.9169, Loss: 0.1142
Epoch   8 Batch   37/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.9091, Loss: 0.1133
Epoch   8 Batch   38/269 - Train Accuracy: 0.9029, Validation Accuracy: 0.9008, Loss: 0.1144
Epoch   8 Batch   39/269 - Train Accuracy: 0.9089, Validation Accuracy: 0.9141, Loss: 0.1113
Epoch   8 Batch   40/269 - Train Accuracy: 0.9132, Validation Accuracy: 0.9060, Loss: 0.1190
Epoch   8 Batch   41/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.9018, Loss: 0.1253
Epoch   8 Batch   42/269 - Train Accuracy: 0.9229, Validation Accuracy: 0.8974, Loss: 0.1035
Epoch   8 Batch   43/269 - Train Accuracy: 0.8976, Validation Accuracy: 0.9126, Loss: 0.1207
Epoch   8 Batch   44/269 - Train Accuracy: 0.9184, Validation Accuracy: 0.9150, Loss: 0.1227
Epoch   8 Batch   45/269 - Train Accuracy: 0.8963, Validation Accuracy: 0.8996, Loss: 0.1156
Epoch   8 Batch   46/269 - Train Accuracy: 0.9183, Validation Accuracy: 0.9014, Loss: 0.1169
Epoch   8 Batch   47/269 - Train Accuracy: 0.9144, Validation Accuracy: 0.9111, Loss: 0.0995
Epoch   8 Batch   48/269 - Train Accuracy: 0.9046, Validation Accuracy: 0.9055, Loss: 0.1099
Epoch   8 Batch   49/269 - Train Accuracy: 0.9114, Validation Accuracy: 0.9052, Loss: 0.1116
Epoch   8 Batch   50/269 - Train Accuracy: 0.8840, Validation Accuracy: 0.9146, Loss: 0.1199
Epoch   8 Batch   51/269 - Train Accuracy: 0.9209, Validation Accuracy: 0.9143, Loss: 0.1129
Epoch   8 Batch   52/269 - Train Accuracy: 0.9063, Validation Accuracy: 0.9056, Loss: 0.1003
Epoch   8 Batch   53/269 - Train Accuracy: 0.9039, Validation Accuracy: 0.9097, Loss: 0.1189
Epoch   8 Batch   54/269 - Train Accuracy: 0.9134, Validation Accuracy: 0.9141, Loss: 0.1097
Epoch   8 Batch   55/269 - Train Accuracy: 0.9104, Validation Accuracy: 0.9102, Loss: 0.1090
Epoch   8 Batch   56/269 - Train Accuracy: 0.9146, Validation Accuracy: 0.9075, Loss: 0.1169
Epoch   8 Batch   57/269 - Train Accuracy: 0.8982, Validation Accuracy: 0.9137, Loss: 0.1199
Epoch   8 Batch   58/269 - Train Accuracy: 0.9079, Validation Accuracy: 0.9101, Loss: 0.1102
Epoch   8 Batch   59/269 - Train Accuracy: 0.9261, Validation Accuracy: 0.9062, Loss: 0.1002
Epoch   8 Batch   60/269 - Train Accuracy: 0.9105, Validation Accuracy: 0.9079, Loss: 0.0990
Epoch   8 Batch   61/269 - Train Accuracy: 0.9283, Validation Accuracy: 0.9110, Loss: 0.1027
Epoch   8 Batch   62/269 - Train Accuracy: 0.8992, Validation Accuracy: 0.9083, Loss: 0.1069
Epoch   8 Batch   63/269 - Train Accuracy: 0.9129, Validation Accuracy: 0.9091, Loss: 0.1124
Epoch   8 Batch   64/269 - Train Accuracy: 0.9219, Validation Accuracy: 0.9091, Loss: 0.1033
Epoch   8 Batch   65/269 - Train Accuracy: 0.9104, Validation Accuracy: 0.9077, Loss: 0.1075
Epoch   8 Batch   66/269 - Train Accuracy: 0.9110, Validation Accuracy: 0.9075, Loss: 0.1103
Epoch   8 Batch   67/269 - Train Accuracy: 0.9074, Validation Accuracy: 0.9133, Loss: 0.1184
Epoch   8 Batch   68/269 - Train Accuracy: 0.8991, Validation Accuracy: 0.9136, Loss: 0.1161
Epoch   8 Batch   69/269 - Train Accuracy: 0.9006, Validation Accuracy: 0.9137, Loss: 0.1267
Epoch   8 Batch   70/269 - Train Accuracy: 0.9200, Validation Accuracy: 0.9138, Loss: 0.1138
Epoch   8 Batch   71/269 - Train Accuracy: 0.9017, Validation Accuracy: 0.9141, Loss: 0.1208
Epoch   8 Batch   72/269 - Train Accuracy: 0.9054, Validation Accuracy: 0.9110, Loss: 0.1163
Epoch   8 Batch   73/269 - Train Accuracy: 0.9002, Validation Accuracy: 0.9211, Loss: 0.1194
Epoch   8 Batch   74/269 - Train Accuracy: 0.9200, Validation Accuracy: 0.9157, Loss: 0.1033
Epoch   8 Batch   75/269 - Train Accuracy: 0.9169, Validation Accuracy: 0.9112, Loss: 0.1154
Epoch   8 Batch   76/269 - Train Accuracy: 0.9075, Validation Accuracy: 0.9032, Loss: 0.1083
Epoch   8 Batch   77/269 - Train Accuracy: 0.9062, Validation Accuracy: 0.9181, Loss: 0.1119
Epoch   8 Batch   78/269 - Train Accuracy: 0.9137, Validation Accuracy: 0.9165, Loss: 0.1108
Epoch   8 Batch   79/269 - Train Accuracy: 0.9038, Validation Accuracy: 0.9078, Loss: 0.1100
Epoch   8 Batch   80/269 - Train Accuracy: 0.9109, Validation Accuracy: 0.9006, Loss: 0.1022
Epoch   8 Batch   81/269 - Train Accuracy: 0.9051, Validation Accuracy: 0.9194, Loss: 0.1210
Epoch   8 Batch   82/269 - Train Accuracy: 0.9205, Validation Accuracy: 0.9174, Loss: 0.1003
Epoch   8 Batch   83/269 - Train Accuracy: 0.8948, Validation Accuracy: 0.9196, Loss: 0.1180
Epoch   8 Batch   84/269 - Train Accuracy: 0.9222, Validation Accuracy: 0.9074, Loss: 0.1059
Epoch   8 Batch   85/269 - Train Accuracy: 0.9150, Validation Accuracy: 0.9112, Loss: 0.1083
Epoch   8 Batch   86/269 - Train Accuracy: 0.9042, Validation Accuracy: 0.9169, Loss: 0.1093
Epoch   8 Batch   87/269 - Train Accuracy: 0.8990, Validation Accuracy: 0.9134, Loss: 0.1168
Epoch   8 Batch   88/269 - Train Accuracy: 0.8935, Validation Accuracy: 0.9107, Loss: 0.1090
Epoch   8 Batch   89/269 - Train Accuracy: 0.9171, Validation Accuracy: 0.9129, Loss: 0.1085
Epoch   8 Batch   90/269 - Train Accuracy: 0.9137, Validation Accuracy: 0.9119, Loss: 0.1131
Epoch   8 Batch   91/269 - Train Accuracy: 0.9199, Validation Accuracy: 0.8996, Loss: 0.1053
Epoch   8 Batch   92/269 - Train Accuracy: 0.9196, Validation Accuracy: 0.8988, Loss: 0.0988
Epoch   8 Batch   93/269 - Train Accuracy: 0.9157, Validation Accuracy: 0.9129, Loss: 0.1040
Epoch   8 Batch   94/269 - Train Accuracy: 0.9090, Validation Accuracy: 0.9141, Loss: 0.1176
Epoch   8 Batch   95/269 - Train Accuracy: 0.9119, Validation Accuracy: 0.9142, Loss: 0.1080
Epoch   8 Batch   96/269 - Train Accuracy: 0.8918, Validation Accuracy: 0.8981, Loss: 0.1063
Epoch   8 Batch   97/269 - Train Accuracy: 0.9088, Validation Accuracy: 0.9064, Loss: 0.1058
Epoch   8 Batch   98/269 - Train Accuracy: 0.9145, Validation Accuracy: 0.9110, Loss: 0.1063
Epoch   8 Batch   99/269 - Train Accuracy: 0.9085, Validation Accuracy: 0.9096, Loss: 0.1053
Epoch   8 Batch  100/269 - Train Accuracy: 0.9170, Validation Accuracy: 0.9070, Loss: 0.1048
Epoch   8 Batch  101/269 - Train Accuracy: 0.9103, Validation Accuracy: 0.9100, Loss: 0.1209
Epoch   8 Batch  102/269 - Train Accuracy: 0.9118, Validation Accuracy: 0.9163, Loss: 0.1017
Epoch   8 Batch  103/269 - Train Accuracy: 0.9164, Validation Accuracy: 0.9139, Loss: 0.1085
Epoch   8 Batch  104/269 - Train Accuracy: 0.9154, Validation Accuracy: 0.9048, Loss: 0.1012
Epoch   8 Batch  105/269 - Train Accuracy: 0.9070, Validation Accuracy: 0.9039, Loss: 0.1115
Epoch   8 Batch  106/269 - Train Accuracy: 0.9203, Validation Accuracy: 0.9175, Loss: 0.0965
Epoch   8 Batch  107/269 - Train Accuracy: 0.9184, Validation Accuracy: 0.9157, Loss: 0.1116
Epoch   8 Batch  108/269 - Train Accuracy: 0.9296, Validation Accuracy: 0.9154, Loss: 0.1014
Epoch   8 Batch  109/269 - Train Accuracy: 0.8932, Validation Accuracy: 0.9071, Loss: 0.1099
Epoch   8 Batch  110/269 - Train Accuracy: 0.9066, Validation Accuracy: 0.9113, Loss: 0.0977
Epoch   8 Batch  111/269 - Train Accuracy: 0.9104, Validation Accuracy: 0.9141, Loss: 0.1134
Epoch   8 Batch  112/269 - Train Accuracy: 0.9164, Validation Accuracy: 0.9107, Loss: 0.1078
Epoch   8 Batch  113/269 - Train Accuracy: 0.9057, Validation Accuracy: 0.9169, Loss: 0.1040
Epoch   8 Batch  114/269 - Train Accuracy: 0.9141, Validation Accuracy: 0.9082, Loss: 0.1081
Epoch   8 Batch  115/269 - Train Accuracy: 0.9099, Validation Accuracy: 0.9179, Loss: 0.1046
Epoch   8 Batch  116/269 - Train Accuracy: 0.9265, Validation Accuracy: 0.9126, Loss: 0.1094
Epoch   8 Batch  117/269 - Train Accuracy: 0.9154, Validation Accuracy: 0.9205, Loss: 0.1016
Epoch   8 Batch  118/269 - Train Accuracy: 0.9246, Validation Accuracy: 0.9157, Loss: 0.0945
Epoch   8 Batch  119/269 - Train Accuracy: 0.8985, Validation Accuracy: 0.9149, Loss: 0.1062
Epoch   8 Batch  120/269 - Train Accuracy: 0.9227, Validation Accuracy: 0.9168, Loss: 0.1054
Epoch   8 Batch  121/269 - Train Accuracy: 0.9158, Validation Accuracy: 0.9180, Loss: 0.0983
Epoch   8 Batch  122/269 - Train Accuracy: 0.9119, Validation Accuracy: 0.9117, Loss: 0.1024
Epoch   8 Batch  123/269 - Train Accuracy: 0.9107, Validation Accuracy: 0.9143, Loss: 0.1085
Epoch   8 Batch  124/269 - Train Accuracy: 0.9149, Validation Accuracy: 0.9180, Loss: 0.0948
Epoch   8 Batch  125/269 - Train Accuracy: 0.9192, Validation Accuracy: 0.9192, Loss: 0.0961
Epoch   8 Batch  126/269 - Train Accuracy: 0.9011, Validation Accuracy: 0.9083, Loss: 0.1049
Epoch   8 Batch  127/269 - Train Accuracy: 0.9051, Validation Accuracy: 0.9072, Loss: 0.1063
Epoch   8 Batch  128/269 - Train Accuracy: 0.9161, Validation Accuracy: 0.9197, Loss: 0.1039
Epoch   8 Batch  129/269 - Train Accuracy: 0.8970, Validation Accuracy: 0.9165, Loss: 0.1062
Epoch   8 Batch  130/269 - Train Accuracy: 0.9198, Validation Accuracy: 0.9048, Loss: 0.1060
Epoch   8 Batch  131/269 - Train Accuracy: 0.8937, Validation Accuracy: 0.9082, Loss: 0.1015
Epoch   8 Batch  132/269 - Train Accuracy: 0.8969, Validation Accuracy: 0.9189, Loss: 0.1073
Epoch   8 Batch  133/269 - Train Accuracy: 0.9237, Validation Accuracy: 0.9170, Loss: 0.0949
Epoch   8 Batch  134/269 - Train Accuracy: 0.8953, Validation Accuracy: 0.9094, Loss: 0.1052
Epoch   8 Batch  135/269 - Train Accuracy: 0.9114, Validation Accuracy: 0.9126, Loss: 0.1102
Epoch   8 Batch  136/269 - Train Accuracy: 0.8966, Validation Accuracy: 0.9182, Loss: 0.1099
Epoch   8 Batch  137/269 - Train Accuracy: 0.9111, Validation Accuracy: 0.9167, Loss: 0.1124
Epoch   8 Batch  138/269 - Train Accuracy: 0.9088, Validation Accuracy: 0.9181, Loss: 0.0965
Epoch   8 Batch  139/269 - Train Accuracy: 0.9193, Validation Accuracy: 0.9191, Loss: 0.1032
Epoch   8 Batch  140/269 - Train Accuracy: 0.9129, Validation Accuracy: 0.9128, Loss: 0.1116
Epoch   8 Batch  141/269 - Train Accuracy: 0.9104, Validation Accuracy: 0.9097, Loss: 0.1122
Epoch   8 Batch  142/269 - Train Accuracy: 0.9181, Validation Accuracy: 0.9148, Loss: 0.1039
Epoch   8 Batch  143/269 - Train Accuracy: 0.9230, Validation Accuracy: 0.9182, Loss: 0.0973
Epoch   8 Batch  144/269 - Train Accuracy: 0.9147, Validation Accuracy: 0.9171, Loss: 0.0922
Epoch   8 Batch  145/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.9226, Loss: 0.0967
Epoch   8 Batch  146/269 - Train Accuracy: 0.9185, Validation Accuracy: 0.9231, Loss: 0.1016
Epoch   8 Batch  147/269 - Train Accuracy: 0.9178, Validation Accuracy: 0.9164, Loss: 0.1021
Epoch   8 Batch  148/269 - Train Accuracy: 0.9143, Validation Accuracy: 0.9187, Loss: 0.1055
Epoch   8 Batch  149/269 - Train Accuracy: 0.9017, Validation Accuracy: 0.9123, Loss: 0.1147
Epoch   8 Batch  150/269 - Train Accuracy: 0.9079, Validation Accuracy: 0.9169, Loss: 0.1024
Epoch   8 Batch  151/269 - Train Accuracy: 0.9152, Validation Accuracy: 0.9185, Loss: 0.1073
Epoch   8 Batch  152/269 - Train Accuracy: 0.9029, Validation Accuracy: 0.9215, Loss: 0.1026
Epoch   8 Batch  153/269 - Train Accuracy: 0.9258, Validation Accuracy: 0.9118, Loss: 0.0992
Epoch   8 Batch  154/269 - Train Accuracy: 0.9226, Validation Accuracy: 0.9109, Loss: 0.0996
Epoch   8 Batch  155/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.9145, Loss: 0.0980
Epoch   8 Batch  156/269 - Train Accuracy: 0.9060, Validation Accuracy: 0.9105, Loss: 0.1082
Epoch   8 Batch  157/269 - Train Accuracy: 0.9024, Validation Accuracy: 0.9126, Loss: 0.0985
Epoch   8 Batch  158/269 - Train Accuracy: 0.9212, Validation Accuracy: 0.9177, Loss: 0.1002
Epoch   8 Batch  159/269 - Train Accuracy: 0.8994, Validation Accuracy: 0.9119, Loss: 0.1030
Epoch   8 Batch  160/269 - Train Accuracy: 0.9125, Validation Accuracy: 0.9164, Loss: 0.0987
Epoch   8 Batch  161/269 - Train Accuracy: 0.9155, Validation Accuracy: 0.9176, Loss: 0.0996
Epoch   8 Batch  162/269 - Train Accuracy: 0.9230, Validation Accuracy: 0.9150, Loss: 0.0983
Epoch   8 Batch  163/269 - Train Accuracy: 0.9269, Validation Accuracy: 0.9195, Loss: 0.0989
Epoch   8 Batch  164/269 - Train Accuracy: 0.9288, Validation Accuracy: 0.9173, Loss: 0.1025
Epoch   8 Batch  165/269 - Train Accuracy: 0.9118, Validation Accuracy: 0.9094, Loss: 0.0979
Epoch   8 Batch  166/269 - Train Accuracy: 0.9160, Validation Accuracy: 0.9192, Loss: 0.0974
Epoch   8 Batch  167/269 - Train Accuracy: 0.9219, Validation Accuracy: 0.9232, Loss: 0.0965
Epoch   8 Batch  168/269 - Train Accuracy: 0.9172, Validation Accuracy: 0.9179, Loss: 0.1079
Epoch   8 Batch  169/269 - Train Accuracy: 0.9062, Validation Accuracy: 0.9088, Loss: 0.1016
Epoch   8 Batch  170/269 - Train Accuracy: 0.9035, Validation Accuracy: 0.9122, Loss: 0.0975
Epoch   8 Batch  171/269 - Train Accuracy: 0.9285, Validation Accuracy: 0.9244, Loss: 0.1004
Epoch   8 Batch  172/269 - Train Accuracy: 0.9102, Validation Accuracy: 0.9207, Loss: 0.1103
Epoch   8 Batch  173/269 - Train Accuracy: 0.9194, Validation Accuracy: 0.9094, Loss: 0.0977
Epoch   8 Batch  174/269 - Train Accuracy: 0.9303, Validation Accuracy: 0.9198, Loss: 0.0988
Epoch   8 Batch  175/269 - Train Accuracy: 0.9090, Validation Accuracy: 0.9239, Loss: 0.1118
Epoch   8 Batch  176/269 - Train Accuracy: 0.9094, Validation Accuracy: 0.9237, Loss: 0.1090
Epoch   8 Batch  177/269 - Train Accuracy: 0.9237, Validation Accuracy: 0.9213, Loss: 0.0959
Epoch   8 Batch  178/269 - Train Accuracy: 0.9177, Validation Accuracy: 0.9187, Loss: 0.0967
Epoch   8 Batch  179/269 - Train Accuracy: 0.9016, Validation Accuracy: 0.9191, Loss: 0.0986
Epoch   8 Batch  180/269 - Train Accuracy: 0.9187, Validation Accuracy: 0.9090, Loss: 0.0985
Epoch   8 Batch  181/269 - Train Accuracy: 0.9066, Validation Accuracy: 0.9039, Loss: 0.1065
Epoch   8 Batch  182/269 - Train Accuracy: 0.9185, Validation Accuracy: 0.9244, Loss: 0.1012
Epoch   8 Batch  183/269 - Train Accuracy: 0.9204, Validation Accuracy: 0.9177, Loss: 0.0872
Epoch   8 Batch  184/269 - Train Accuracy: 0.9104, Validation Accuracy: 0.9125, Loss: 0.1027
Epoch   8 Batch  185/269 - Train Accuracy: 0.9155, Validation Accuracy: 0.9050, Loss: 0.1058
Epoch   8 Batch  186/269 - Train Accuracy: 0.9214, Validation Accuracy: 0.9244, Loss: 0.0977
Epoch   8 Batch  187/269 - Train Accuracy: 0.9236, Validation Accuracy: 0.9217, Loss: 0.1003
Epoch   8 Batch  188/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9110, Loss: 0.0915
Epoch   8 Batch  189/269 - Train Accuracy: 0.9101, Validation Accuracy: 0.9071, Loss: 0.0967
Epoch   8 Batch  190/269 - Train Accuracy: 0.9132, Validation Accuracy: 0.9232, Loss: 0.0965
Epoch   8 Batch  191/269 - Train Accuracy: 0.9142, Validation Accuracy: 0.9216, Loss: 0.0950
Epoch   8 Batch  192/269 - Train Accuracy: 0.9187, Validation Accuracy: 0.9260, Loss: 0.1015
Epoch   8 Batch  193/269 - Train Accuracy: 0.9169, Validation Accuracy: 0.9165, Loss: 0.0986
Epoch   8 Batch  194/269 - Train Accuracy: 0.9092, Validation Accuracy: 0.9233, Loss: 0.1065
Epoch   8 Batch  195/269 - Train Accuracy: 0.9101, Validation Accuracy: 0.9200, Loss: 0.1003
Epoch   8 Batch  196/269 - Train Accuracy: 0.9004, Validation Accuracy: 0.9199, Loss: 0.1010
Epoch   8 Batch  197/269 - Train Accuracy: 0.9026, Validation Accuracy: 0.9215, Loss: 0.1102
Epoch   8 Batch  198/269 - Train Accuracy: 0.9048, Validation Accuracy: 0.9213, Loss: 0.1029
Epoch   8 Batch  199/269 - Train Accuracy: 0.9090, Validation Accuracy: 0.9215, Loss: 0.1065
Epoch   8 Batch  200/269 - Train Accuracy: 0.9044, Validation Accuracy: 0.9108, Loss: 0.1007
Epoch   8 Batch  201/269 - Train Accuracy: 0.9006, Validation Accuracy: 0.9137, Loss: 0.0996
Epoch   8 Batch  202/269 - Train Accuracy: 0.9090, Validation Accuracy: 0.9240, Loss: 0.1030
Epoch   8 Batch  203/269 - Train Accuracy: 0.9143, Validation Accuracy: 0.9190, Loss: 0.1134
Epoch   8 Batch  204/269 - Train Accuracy: 0.9100, Validation Accuracy: 0.9212, Loss: 0.1071
Epoch   8 Batch  205/269 - Train Accuracy: 0.9077, Validation Accuracy: 0.9152, Loss: 0.0948
Epoch   8 Batch  206/269 - Train Accuracy: 0.9071, Validation Accuracy: 0.9157, Loss: 0.1088
Epoch   8 Batch  207/269 - Train Accuracy: 0.9099, Validation Accuracy: 0.9197, Loss: 0.0935
Epoch   8 Batch  208/269 - Train Accuracy: 0.9159, Validation Accuracy: 0.9194, Loss: 0.1056
Epoch   8 Batch  209/269 - Train Accuracy: 0.9237, Validation Accuracy: 0.9166, Loss: 0.0941
Epoch   8 Batch  210/269 - Train Accuracy: 0.9165, Validation Accuracy: 0.9130, Loss: 0.0992
Epoch   8 Batch  211/269 - Train Accuracy: 0.9263, Validation Accuracy: 0.9237, Loss: 0.1060
Epoch   8 Batch  212/269 - Train Accuracy: 0.9137, Validation Accuracy: 0.9200, Loss: 0.1047
Epoch   8 Batch  213/269 - Train Accuracy: 0.9047, Validation Accuracy: 0.9090, Loss: 0.0995
Epoch   8 Batch  214/269 - Train Accuracy: 0.9075, Validation Accuracy: 0.9161, Loss: 0.1044
Epoch   8 Batch  215/269 - Train Accuracy: 0.9305, Validation Accuracy: 0.9148, Loss: 0.0957
Epoch   8 Batch  216/269 - Train Accuracy: 0.8974, Validation Accuracy: 0.9235, Loss: 0.1137
Epoch   8 Batch  217/269 - Train Accuracy: 0.8943, Validation Accuracy: 0.9100, Loss: 0.1026
Epoch   8 Batch  218/269 - Train Accuracy: 0.9278, Validation Accuracy: 0.9073, Loss: 0.1021
Epoch   8 Batch  219/269 - Train Accuracy: 0.9108, Validation Accuracy: 0.9212, Loss: 0.1098
Epoch   8 Batch  220/269 - Train Accuracy: 0.9167, Validation Accuracy: 0.9207, Loss: 0.0923
Epoch   8 Batch  221/269 - Train Accuracy: 0.9166, Validation Accuracy: 0.9158, Loss: 0.1078
Epoch   8 Batch  222/269 - Train Accuracy: 0.9249, Validation Accuracy: 0.9062, Loss: 0.0894
Epoch   8 Batch  223/269 - Train Accuracy: 0.9115, Validation Accuracy: 0.9195, Loss: 0.0883
Epoch   8 Batch  224/269 - Train Accuracy: 0.9140, Validation Accuracy: 0.9240, Loss: 0.1064
Epoch   8 Batch  225/269 - Train Accuracy: 0.9086, Validation Accuracy: 0.9220, Loss: 0.0920
Epoch   8 Batch  226/269 - Train Accuracy: 0.9120, Validation Accuracy: 0.9183, Loss: 0.0975
Epoch   8 Batch  227/269 - Train Accuracy: 0.9150, Validation Accuracy: 0.9140, Loss: 0.1023
Epoch   8 Batch  228/269 - Train Accuracy: 0.9205, Validation Accuracy: 0.9212, Loss: 0.0930
Epoch   8 Batch  229/269 - Train Accuracy: 0.9114, Validation Accuracy: 0.9304, Loss: 0.0947
Epoch   8 Batch  230/269 - Train Accuracy: 0.9221, Validation Accuracy: 0.9277, Loss: 0.0986
Epoch   8 Batch  231/269 - Train Accuracy: 0.9038, Validation Accuracy: 0.9218, Loss: 0.1007
Epoch   8 Batch  232/269 - Train Accuracy: 0.9081, Validation Accuracy: 0.9199, Loss: 0.0986
Epoch   8 Batch  233/269 - Train Accuracy: 0.9268, Validation Accuracy: 0.9255, Loss: 0.1011
Epoch   8 Batch  234/269 - Train Accuracy: 0.9175, Validation Accuracy: 0.9187, Loss: 0.0932
Epoch   8 Batch  235/269 - Train Accuracy: 0.9394, Validation Accuracy: 0.9094, Loss: 0.0850
Epoch   8 Batch  236/269 - Train Accuracy: 0.9084, Validation Accuracy: 0.9148, Loss: 0.0915
Epoch   8 Batch  237/269 - Train Accuracy: 0.9185, Validation Accuracy: 0.9144, Loss: 0.0923
Epoch   8 Batch  238/269 - Train Accuracy: 0.9163, Validation Accuracy: 0.9078, Loss: 0.0935
Epoch   8 Batch  239/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.9084, Loss: 0.0903
Epoch   8 Batch  240/269 - Train Accuracy: 0.9203, Validation Accuracy: 0.9108, Loss: 0.0896
Epoch   8 Batch  241/269 - Train Accuracy: 0.9118, Validation Accuracy: 0.9147, Loss: 0.1066
Epoch   8 Batch  242/269 - Train Accuracy: 0.9298, Validation Accuracy: 0.9137, Loss: 0.0847
Epoch   8 Batch  243/269 - Train Accuracy: 0.9211, Validation Accuracy: 0.9186, Loss: 0.0864
Epoch   8 Batch  244/269 - Train Accuracy: 0.9058, Validation Accuracy: 0.9177, Loss: 0.0970
Epoch   8 Batch  245/269 - Train Accuracy: 0.9057, Validation Accuracy: 0.9166, Loss: 0.0969
Epoch   8 Batch  246/269 - Train Accuracy: 0.9020, Validation Accuracy: 0.9249, Loss: 0.0977
Epoch   8 Batch  247/269 - Train Accuracy: 0.9228, Validation Accuracy: 0.9265, Loss: 0.0931
Epoch   8 Batch  248/269 - Train Accuracy: 0.9150, Validation Accuracy: 0.9165, Loss: 0.0918
Epoch   8 Batch  249/269 - Train Accuracy: 0.9234, Validation Accuracy: 0.9188, Loss: 0.0867
Epoch   8 Batch  250/269 - Train Accuracy: 0.9258, Validation Accuracy: 0.9275, Loss: 0.0981
Epoch   8 Batch  251/269 - Train Accuracy: 0.9453, Validation Accuracy: 0.9293, Loss: 0.0891
Epoch   8 Batch  252/269 - Train Accuracy: 0.9165, Validation Accuracy: 0.9199, Loss: 0.0836
Epoch   8 Batch  253/269 - Train Accuracy: 0.8977, Validation Accuracy: 0.9277, Loss: 0.1020
Epoch   8 Batch  254/269 - Train Accuracy: 0.9136, Validation Accuracy: 0.9223, Loss: 0.0898
Epoch   8 Batch  255/269 - Train Accuracy: 0.9153, Validation Accuracy: 0.9173, Loss: 0.0946
Epoch   8 Batch  256/269 - Train Accuracy: 0.8994, Validation Accuracy: 0.9151, Loss: 0.0940
Epoch   8 Batch  257/269 - Train Accuracy: 0.8916, Validation Accuracy: 0.9165, Loss: 0.1016
Epoch   8 Batch  258/269 - Train Accuracy: 0.9141, Validation Accuracy: 0.9142, Loss: 0.1002
Epoch   8 Batch  259/269 - Train Accuracy: 0.9089, Validation Accuracy: 0.9100, Loss: 0.0984
Epoch   8 Batch  260/269 - Train Accuracy: 0.8997, Validation Accuracy: 0.9138, Loss: 0.0986
Epoch   8 Batch  261/269 - Train Accuracy: 0.9226, Validation Accuracy: 0.9220, Loss: 0.0962
Epoch   8 Batch  262/269 - Train Accuracy: 0.9202, Validation Accuracy: 0.9259, Loss: 0.0940
Epoch   8 Batch  263/269 - Train Accuracy: 0.9079, Validation Accuracy: 0.9189, Loss: 0.0949
Epoch   8 Batch  264/269 - Train Accuracy: 0.8884, Validation Accuracy: 0.9167, Loss: 0.1041
Epoch   8 Batch  265/269 - Train Accuracy: 0.9177, Validation Accuracy: 0.9190, Loss: 0.0960
Epoch   8 Batch  266/269 - Train Accuracy: 0.9194, Validation Accuracy: 0.9213, Loss: 0.0858
Epoch   8 Batch  267/269 - Train Accuracy: 0.9228, Validation Accuracy: 0.9248, Loss: 0.0997
Epoch   9 Batch    1/269 - Train Accuracy: 0.9162, Validation Accuracy: 0.9260, Loss: 0.0941
Epoch   9 Batch    2/269 - Train Accuracy: 0.9116, Validation Accuracy: 0.9276, Loss: 0.0952
Epoch   9 Batch    3/269 - Train Accuracy: 0.9270, Validation Accuracy: 0.9268, Loss: 0.0898
Epoch   9 Batch    4/269 - Train Accuracy: 0.9055, Validation Accuracy: 0.9292, Loss: 0.0953
Epoch   9 Batch    5/269 - Train Accuracy: 0.9133, Validation Accuracy: 0.9160, Loss: 0.0912
Epoch   9 Batch    6/269 - Train Accuracy: 0.9368, Validation Accuracy: 0.9157, Loss: 0.0853
Epoch   9 Batch    7/269 - Train Accuracy: 0.9216, Validation Accuracy: 0.9261, Loss: 0.0860
Epoch   9 Batch    8/269 - Train Accuracy: 0.9355, Validation Accuracy: 0.9252, Loss: 0.0978
Epoch   9 Batch    9/269 - Train Accuracy: 0.9163, Validation Accuracy: 0.9208, Loss: 0.0968
Epoch   9 Batch   10/269 - Train Accuracy: 0.9109, Validation Accuracy: 0.9181, Loss: 0.0870
Epoch   9 Batch   11/269 - Train Accuracy: 0.9205, Validation Accuracy: 0.9193, Loss: 0.0998
Epoch   9 Batch   12/269 - Train Accuracy: 0.9055, Validation Accuracy: 0.9153, Loss: 0.1008
Epoch   9 Batch   13/269 - Train Accuracy: 0.9183, Validation Accuracy: 0.9161, Loss: 0.0815
Epoch   9 Batch   14/269 - Train Accuracy: 0.9099, Validation Accuracy: 0.9161, Loss: 0.0840
Epoch   9 Batch   15/269 - Train Accuracy: 0.9264, Validation Accuracy: 0.9204, Loss: 0.0792
Epoch   9 Batch   16/269 - Train Accuracy: 0.9129, Validation Accuracy: 0.9202, Loss: 0.0975
Epoch   9 Batch   17/269 - Train Accuracy: 0.9239, Validation Accuracy: 0.9148, Loss: 0.0823
Epoch   9 Batch   18/269 - Train Accuracy: 0.9154, Validation Accuracy: 0.9120, Loss: 0.0884
Epoch   9 Batch   19/269 - Train Accuracy: 0.9294, Validation Accuracy: 0.9190, Loss: 0.0840
Epoch   9 Batch   20/269 - Train Accuracy: 0.9259, Validation Accuracy: 0.9263, Loss: 0.0922
Epoch   9 Batch   21/269 - Train Accuracy: 0.8994, Validation Accuracy: 0.9261, Loss: 0.1035
Epoch   9 Batch   22/269 - Train Accuracy: 0.9386, Validation Accuracy: 0.9187, Loss: 0.0849
Epoch   9 Batch   23/269 - Train Accuracy: 0.9162, Validation Accuracy: 0.9270, Loss: 0.0934
Epoch   9 Batch   24/269 - Train Accuracy: 0.9093, Validation Accuracy: 0.9309, Loss: 0.0892
Epoch   9 Batch   25/269 - Train Accuracy: 0.9146, Validation Accuracy: 0.9230, Loss: 0.0996
Epoch   9 Batch   26/269 - Train Accuracy: 0.9142, Validation Accuracy: 0.9205, Loss: 0.0819
Epoch   9 Batch   27/269 - Train Accuracy: 0.9090, Validation Accuracy: 0.9228, Loss: 0.0883
Epoch   9 Batch   28/269 - Train Accuracy: 0.9058, Validation Accuracy: 0.9177, Loss: 0.1026
Epoch   9 Batch   29/269 - Train Accuracy: 0.9186, Validation Accuracy: 0.9182, Loss: 0.0958
Epoch   9 Batch   30/269 - Train Accuracy: 0.9353, Validation Accuracy: 0.9206, Loss: 0.0881
Epoch   9 Batch   31/269 - Train Accuracy: 0.9176, Validation Accuracy: 0.9226, Loss: 0.0878
Epoch   9 Batch   32/269 - Train Accuracy: 0.9189, Validation Accuracy: 0.9169, Loss: 0.0891
Epoch   9 Batch   33/269 - Train Accuracy: 0.9192, Validation Accuracy: 0.9157, Loss: 0.0835
Epoch   9 Batch   34/269 - Train Accuracy: 0.9238, Validation Accuracy: 0.9181, Loss: 0.0905
Epoch   9 Batch   35/269 - Train Accuracy: 0.9171, Validation Accuracy: 0.9204, Loss: 0.0990
Epoch   9 Batch   36/269 - Train Accuracy: 0.9016, Validation Accuracy: 0.9189, Loss: 0.0934
Epoch   9 Batch   37/269 - Train Accuracy: 0.9161, Validation Accuracy: 0.9218, Loss: 0.0897
Epoch   9 Batch   38/269 - Train Accuracy: 0.9146, Validation Accuracy: 0.9248, Loss: 0.0880
Epoch   9 Batch   39/269 - Train Accuracy: 0.9178, Validation Accuracy: 0.9280, Loss: 0.0868
Epoch   9 Batch   40/269 - Train Accuracy: 0.9104, Validation Accuracy: 0.9197, Loss: 0.0948
Epoch   9 Batch   41/269 - Train Accuracy: 0.9168, Validation Accuracy: 0.9236, Loss: 0.0912
Epoch   9 Batch   42/269 - Train Accuracy: 0.9342, Validation Accuracy: 0.9259, Loss: 0.0820
Epoch   9 Batch   43/269 - Train Accuracy: 0.9247, Validation Accuracy: 0.9245, Loss: 0.0931
Epoch   9 Batch   44/269 - Train Accuracy: 0.9184, Validation Accuracy: 0.9227, Loss: 0.0951
Epoch   9 Batch   45/269 - Train Accuracy: 0.9153, Validation Accuracy: 0.9234, Loss: 0.0907
Epoch   9 Batch   46/269 - Train Accuracy: 0.9164, Validation Accuracy: 0.9270, Loss: 0.0876
Epoch   9 Batch   47/269 - Train Accuracy: 0.9281, Validation Accuracy: 0.9260, Loss: 0.0818
Epoch   9 Batch   48/269 - Train Accuracy: 0.9277, Validation Accuracy: 0.9244, Loss: 0.0868
Epoch   9 Batch   49/269 - Train Accuracy: 0.9244, Validation Accuracy: 0.9192, Loss: 0.0839
Epoch   9 Batch   50/269 - Train Accuracy: 0.8979, Validation Accuracy: 0.9265, Loss: 0.0973
Epoch   9 Batch   51/269 - Train Accuracy: 0.9187, Validation Accuracy: 0.9306, Loss: 0.0867
Epoch   9 Batch   52/269 - Train Accuracy: 0.9166, Validation Accuracy: 0.9205, Loss: 0.0787
Epoch   9 Batch   53/269 - Train Accuracy: 0.9187, Validation Accuracy: 0.9239, Loss: 0.0938
Epoch   9 Batch   54/269 - Train Accuracy: 0.9256, Validation Accuracy: 0.9293, Loss: 0.0818
Epoch   9 Batch   55/269 - Train Accuracy: 0.9159, Validation Accuracy: 0.9296, Loss: 0.0804
Epoch   9 Batch   56/269 - Train Accuracy: 0.9155, Validation Accuracy: 0.9238, Loss: 0.0952
Epoch   9 Batch   57/269 - Train Accuracy: 0.9103, Validation Accuracy: 0.9204, Loss: 0.0958
Epoch   9 Batch   58/269 - Train Accuracy: 0.9222, Validation Accuracy: 0.9240, Loss: 0.0904
Epoch   9 Batch   59/269 - Train Accuracy: 0.9388, Validation Accuracy: 0.9252, Loss: 0.0778
Epoch   9 Batch   60/269 - Train Accuracy: 0.9192, Validation Accuracy: 0.9252, Loss: 0.0813
Epoch   9 Batch   61/269 - Train Accuracy: 0.9207, Validation Accuracy: 0.9151, Loss: 0.0799
Epoch   9 Batch   62/269 - Train Accuracy: 0.9116, Validation Accuracy: 0.9213, Loss: 0.0938
Epoch   9 Batch   63/269 - Train Accuracy: 0.9181, Validation Accuracy: 0.9347, Loss: 0.0945
Epoch   9 Batch   64/269 - Train Accuracy: 0.9277, Validation Accuracy: 0.9251, Loss: 0.0846
Epoch   9 Batch   65/269 - Train Accuracy: 0.9310, Validation Accuracy: 0.9272, Loss: 0.0843
Epoch   9 Batch   66/269 - Train Accuracy: 0.9167, Validation Accuracy: 0.9270, Loss: 0.0935
Epoch   9 Batch   67/269 - Train Accuracy: 0.9119, Validation Accuracy: 0.9288, Loss: 0.0947
Epoch   9 Batch   68/269 - Train Accuracy: 0.9084, Validation Accuracy: 0.9276, Loss: 0.0980
Epoch   9 Batch   69/269 - Train Accuracy: 0.9046, Validation Accuracy: 0.9286, Loss: 0.1077
Epoch   9 Batch   70/269 - Train Accuracy: 0.9272, Validation Accuracy: 0.9233, Loss: 0.0917
Epoch   9 Batch   71/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9225, Loss: 0.0948
Epoch   9 Batch   72/269 - Train Accuracy: 0.9173, Validation Accuracy: 0.9240, Loss: 0.0953
Epoch   9 Batch   73/269 - Train Accuracy: 0.9058, Validation Accuracy: 0.9250, Loss: 0.0982
Epoch   9 Batch   74/269 - Train Accuracy: 0.9312, Validation Accuracy: 0.9233, Loss: 0.0849
Epoch   9 Batch   75/269 - Train Accuracy: 0.9258, Validation Accuracy: 0.9247, Loss: 0.0950
Epoch   9 Batch   76/269 - Train Accuracy: 0.9260, Validation Accuracy: 0.9266, Loss: 0.0889
Epoch   9 Batch   77/269 - Train Accuracy: 0.9203, Validation Accuracy: 0.9322, Loss: 0.0899
Epoch   9 Batch   78/269 - Train Accuracy: 0.9208, Validation Accuracy: 0.9324, Loss: 0.0916
Epoch   9 Batch   79/269 - Train Accuracy: 0.9147, Validation Accuracy: 0.9257, Loss: 0.0870
Epoch   9 Batch   80/269 - Train Accuracy: 0.9181, Validation Accuracy: 0.9225, Loss: 0.0827
Epoch   9 Batch   81/269 - Train Accuracy: 0.9018, Validation Accuracy: 0.9184, Loss: 0.1012
Epoch   9 Batch   82/269 - Train Accuracy: 0.9309, Validation Accuracy: 0.9166, Loss: 0.0785
Epoch   9 Batch   83/269 - Train Accuracy: 0.9076, Validation Accuracy: 0.9235, Loss: 0.0980
Epoch   9 Batch   84/269 - Train Accuracy: 0.9305, Validation Accuracy: 0.9215, Loss: 0.0876
Epoch   9 Batch   85/269 - Train Accuracy: 0.9282, Validation Accuracy: 0.9228, Loss: 0.0891
Epoch   9 Batch   86/269 - Train Accuracy: 0.9108, Validation Accuracy: 0.9201, Loss: 0.0870
Epoch   9 Batch   87/269 - Train Accuracy: 0.9163, Validation Accuracy: 0.9224, Loss: 0.0964
Epoch   9 Batch   88/269 - Train Accuracy: 0.9097, Validation Accuracy: 0.9253, Loss: 0.0868
Epoch   9 Batch   89/269 - Train Accuracy: 0.9289, Validation Accuracy: 0.9241, Loss: 0.0860
Epoch   9 Batch   90/269 - Train Accuracy: 0.9214, Validation Accuracy: 0.9202, Loss: 0.0920
Epoch   9 Batch   91/269 - Train Accuracy: 0.9283, Validation Accuracy: 0.9133, Loss: 0.0825
Epoch   9 Batch   92/269 - Train Accuracy: 0.9273, Validation Accuracy: 0.9229, Loss: 0.0820
Epoch   9 Batch   93/269 - Train Accuracy: 0.9317, Validation Accuracy: 0.9279, Loss: 0.0825
Epoch   9 Batch   94/269 - Train Accuracy: 0.9174, Validation Accuracy: 0.9229, Loss: 0.1021
Epoch   9 Batch   95/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9221, Loss: 0.0881
Epoch   9 Batch   96/269 - Train Accuracy: 0.9025, Validation Accuracy: 0.9142, Loss: 0.0888
Epoch   9 Batch   97/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9230, Loss: 0.0875
Epoch   9 Batch   98/269 - Train Accuracy: 0.9243, Validation Accuracy: 0.9229, Loss: 0.0888
Epoch   9 Batch   99/269 - Train Accuracy: 0.9217, Validation Accuracy: 0.9238, Loss: 0.0785
Epoch   9 Batch  100/269 - Train Accuracy: 0.9267, Validation Accuracy: 0.9231, Loss: 0.0886
Epoch   9 Batch  101/269 - Train Accuracy: 0.9108, Validation Accuracy: 0.9178, Loss: 0.0980
Epoch   9 Batch  102/269 - Train Accuracy: 0.9129, Validation Accuracy: 0.9231, Loss: 0.0843
Epoch   9 Batch  103/269 - Train Accuracy: 0.9310, Validation Accuracy: 0.9216, Loss: 0.0928
Epoch   9 Batch  104/269 - Train Accuracy: 0.9220, Validation Accuracy: 0.9300, Loss: 0.0849
Epoch   9 Batch  105/269 - Train Accuracy: 0.9129, Validation Accuracy: 0.9346, Loss: 0.0875
Epoch   9 Batch  106/269 - Train Accuracy: 0.9215, Validation Accuracy: 0.9237, Loss: 0.0792
Epoch   9 Batch  107/269 - Train Accuracy: 0.9303, Validation Accuracy: 0.9207, Loss: 0.0865
Epoch   9 Batch  108/269 - Train Accuracy: 0.9314, Validation Accuracy: 0.9172, Loss: 0.0856
Epoch   9 Batch  109/269 - Train Accuracy: 0.9071, Validation Accuracy: 0.9228, Loss: 0.0934
Epoch   9 Batch  110/269 - Train Accuracy: 0.9213, Validation Accuracy: 0.9162, Loss: 0.0811
Epoch   9 Batch  111/269 - Train Accuracy: 0.9210, Validation Accuracy: 0.9152, Loss: 0.0906
Epoch   9 Batch  112/269 - Train Accuracy: 0.9187, Validation Accuracy: 0.9167, Loss: 0.0904
Epoch   9 Batch  113/269 - Train Accuracy: 0.9197, Validation Accuracy: 0.9216, Loss: 0.0824
Epoch   9 Batch  114/269 - Train Accuracy: 0.9250, Validation Accuracy: 0.9279, Loss: 0.0873
Epoch   9 Batch  115/269 - Train Accuracy: 0.9155, Validation Accuracy: 0.9263, Loss: 0.0888
Epoch   9 Batch  116/269 - Train Accuracy: 0.9327, Validation Accuracy: 0.9247, Loss: 0.0881
Epoch   9 Batch  117/269 - Train Accuracy: 0.9300, Validation Accuracy: 0.9285, Loss: 0.0800
Epoch   9 Batch  118/269 - Train Accuracy: 0.9300, Validation Accuracy: 0.9313, Loss: 0.0761
Epoch   9 Batch  119/269 - Train Accuracy: 0.9062, Validation Accuracy: 0.9276, Loss: 0.0905
Epoch   9 Batch  120/269 - Train Accuracy: 0.9290, Validation Accuracy: 0.9290, Loss: 0.0873
Epoch   9 Batch  121/269 - Train Accuracy: 0.9249, Validation Accuracy: 0.9289, Loss: 0.0790
Epoch   9 Batch  122/269 - Train Accuracy: 0.9180, Validation Accuracy: 0.9249, Loss: 0.0854
Epoch   9 Batch  123/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9244, Loss: 0.0871
Epoch   9 Batch  124/269 - Train Accuracy: 0.9263, Validation Accuracy: 0.9233, Loss: 0.0801
Epoch   9 Batch  125/269 - Train Accuracy: 0.9309, Validation Accuracy: 0.9283, Loss: 0.0769
Epoch   9 Batch  126/269 - Train Accuracy: 0.9095, Validation Accuracy: 0.9293, Loss: 0.0888
Epoch   9 Batch  127/269 - Train Accuracy: 0.9260, Validation Accuracy: 0.9221, Loss: 0.0840
Epoch   9 Batch  128/269 - Train Accuracy: 0.9254, Validation Accuracy: 0.9258, Loss: 0.0897
Epoch   9 Batch  129/269 - Train Accuracy: 0.9057, Validation Accuracy: 0.9292, Loss: 0.0843
Epoch   9 Batch  130/269 - Train Accuracy: 0.9292, Validation Accuracy: 0.9298, Loss: 0.0878
Epoch   9 Batch  131/269 - Train Accuracy: 0.9107, Validation Accuracy: 0.9300, Loss: 0.0855
Epoch   9 Batch  132/269 - Train Accuracy: 0.9106, Validation Accuracy: 0.9344, Loss: 0.0866
Epoch   9 Batch  133/269 - Train Accuracy: 0.9304, Validation Accuracy: 0.9355, Loss: 0.0780
Epoch   9 Batch  134/269 - Train Accuracy: 0.9150, Validation Accuracy: 0.9345, Loss: 0.0875
Epoch   9 Batch  135/269 - Train Accuracy: 0.9190, Validation Accuracy: 0.9339, Loss: 0.0867
Epoch   9 Batch  136/269 - Train Accuracy: 0.9009, Validation Accuracy: 0.9234, Loss: 0.0912
Epoch   9 Batch  137/269 - Train Accuracy: 0.9173, Validation Accuracy: 0.9235, Loss: 0.0956
Epoch   9 Batch  138/269 - Train Accuracy: 0.9151, Validation Accuracy: 0.9292, Loss: 0.0810
Epoch   9 Batch  139/269 - Train Accuracy: 0.9219, Validation Accuracy: 0.9293, Loss: 0.0753
Epoch   9 Batch  140/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9234, Loss: 0.0936
Epoch   9 Batch  141/269 - Train Accuracy: 0.9178, Validation Accuracy: 0.9206, Loss: 0.0884
Epoch   9 Batch  142/269 - Train Accuracy: 0.9220, Validation Accuracy: 0.9206, Loss: 0.0828
Epoch   9 Batch  143/269 - Train Accuracy: 0.9334, Validation Accuracy: 0.9287, Loss: 0.0772
Epoch   9 Batch  144/269 - Train Accuracy: 0.9246, Validation Accuracy: 0.9300, Loss: 0.0715
Epoch   9 Batch  145/269 - Train Accuracy: 0.9315, Validation Accuracy: 0.9317, Loss: 0.0783
Epoch   9 Batch  146/269 - Train Accuracy: 0.9289, Validation Accuracy: 0.9319, Loss: 0.0799
Epoch   9 Batch  147/269 - Train Accuracy: 0.9166, Validation Accuracy: 0.9297, Loss: 0.0912
Epoch   9 Batch  148/269 - Train Accuracy: 0.9261, Validation Accuracy: 0.9347, Loss: 0.0859
Epoch   9 Batch  149/269 - Train Accuracy: 0.9077, Validation Accuracy: 0.9289, Loss: 0.0934
Epoch   9 Batch  150/269 - Train Accuracy: 0.9187, Validation Accuracy: 0.9241, Loss: 0.0860
Epoch   9 Batch  151/269 - Train Accuracy: 0.9207, Validation Accuracy: 0.9239, Loss: 0.0891
Epoch   9 Batch  152/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9331, Loss: 0.0864
Epoch   9 Batch  153/269 - Train Accuracy: 0.9330, Validation Accuracy: 0.9266, Loss: 0.0818
Epoch   9 Batch  154/269 - Train Accuracy: 0.9407, Validation Accuracy: 0.9290, Loss: 0.0790
Epoch   9 Batch  155/269 - Train Accuracy: 0.9142, Validation Accuracy: 0.9352, Loss: 0.0790
Epoch   9 Batch  156/269 - Train Accuracy: 0.9241, Validation Accuracy: 0.9292, Loss: 0.0863
Epoch   9 Batch  157/269 - Train Accuracy: 0.9091, Validation Accuracy: 0.9190, Loss: 0.0774
Epoch   9 Batch  158/269 - Train Accuracy: 0.9304, Validation Accuracy: 0.9259, Loss: 0.0809
Epoch   9 Batch  159/269 - Train Accuracy: 0.9149, Validation Accuracy: 0.9318, Loss: 0.0837
Epoch   9 Batch  160/269 - Train Accuracy: 0.9163, Validation Accuracy: 0.9354, Loss: 0.0846
Epoch   9 Batch  161/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9232, Loss: 0.0817
Epoch   9 Batch  162/269 - Train Accuracy: 0.9325, Validation Accuracy: 0.9283, Loss: 0.0813
Epoch   9 Batch  163/269 - Train Accuracy: 0.9367, Validation Accuracy: 0.9295, Loss: 0.0836
Epoch   9 Batch  164/269 - Train Accuracy: 0.9281, Validation Accuracy: 0.9292, Loss: 0.0826
Epoch   9 Batch  165/269 - Train Accuracy: 0.9253, Validation Accuracy: 0.9283, Loss: 0.0796
Epoch   9 Batch  166/269 - Train Accuracy: 0.9315, Validation Accuracy: 0.9232, Loss: 0.0798
Epoch   9 Batch  167/269 - Train Accuracy: 0.9351, Validation Accuracy: 0.9314, Loss: 0.0837
Epoch   9 Batch  168/269 - Train Accuracy: 0.9284, Validation Accuracy: 0.9307, Loss: 0.0875
Epoch   9 Batch  169/269 - Train Accuracy: 0.9206, Validation Accuracy: 0.9263, Loss: 0.0839
Epoch   9 Batch  170/269 - Train Accuracy: 0.9035, Validation Accuracy: 0.9250, Loss: 0.0771
Epoch   9 Batch  171/269 - Train Accuracy: 0.9349, Validation Accuracy: 0.9383, Loss: 0.0825
Epoch   9 Batch  172/269 - Train Accuracy: 0.9249, Validation Accuracy: 0.9348, Loss: 0.0878
Epoch   9 Batch  173/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9276, Loss: 0.0831
Epoch   9 Batch  174/269 - Train Accuracy: 0.9270, Validation Accuracy: 0.9149, Loss: 0.0834
Epoch   9 Batch  175/269 - Train Accuracy: 0.9038, Validation Accuracy: 0.9209, Loss: 0.0966
Epoch   9 Batch  176/269 - Train Accuracy: 0.9103, Validation Accuracy: 0.9255, Loss: 0.0928
Epoch   9 Batch  177/269 - Train Accuracy: 0.9276, Validation Accuracy: 0.9246, Loss: 0.0791
Epoch   9 Batch  178/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9210, Loss: 0.0817
Epoch   9 Batch  179/269 - Train Accuracy: 0.9104, Validation Accuracy: 0.9240, Loss: 0.0835
Epoch   9 Batch  180/269 - Train Accuracy: 0.9265, Validation Accuracy: 0.9300, Loss: 0.0773
Epoch   9 Batch  181/269 - Train Accuracy: 0.9061, Validation Accuracy: 0.9268, Loss: 0.0878
Epoch   9 Batch  182/269 - Train Accuracy: 0.9139, Validation Accuracy: 0.9213, Loss: 0.0820
Epoch   9 Batch  183/269 - Train Accuracy: 0.9319, Validation Accuracy: 0.9307, Loss: 0.0715
Epoch   9 Batch  184/269 - Train Accuracy: 0.9235, Validation Accuracy: 0.9285, Loss: 0.0807
Epoch   9 Batch  185/269 - Train Accuracy: 0.9291, Validation Accuracy: 0.9267, Loss: 0.0833
Epoch   9 Batch  186/269 - Train Accuracy: 0.9243, Validation Accuracy: 0.9217, Loss: 0.0812
Epoch   9 Batch  187/269 - Train Accuracy: 0.9282, Validation Accuracy: 0.9285, Loss: 0.0801
Epoch   9 Batch  188/269 - Train Accuracy: 0.9337, Validation Accuracy: 0.9280, Loss: 0.0759
Epoch   9 Batch  189/269 - Train Accuracy: 0.9271, Validation Accuracy: 0.9263, Loss: 0.0756
Epoch   9 Batch  190/269 - Train Accuracy: 0.9267, Validation Accuracy: 0.9320, Loss: 0.0804
Epoch   9 Batch  191/269 - Train Accuracy: 0.9126, Validation Accuracy: 0.9242, Loss: 0.0808
Epoch   9 Batch  192/269 - Train Accuracy: 0.9226, Validation Accuracy: 0.9313, Loss: 0.0852
Epoch   9 Batch  193/269 - Train Accuracy: 0.9363, Validation Accuracy: 0.9318, Loss: 0.0788
Epoch   9 Batch  194/269 - Train Accuracy: 0.9247, Validation Accuracy: 0.9316, Loss: 0.0816
Epoch   9 Batch  195/269 - Train Accuracy: 0.9227, Validation Accuracy: 0.9290, Loss: 0.0807
Epoch   9 Batch  196/269 - Train Accuracy: 0.9069, Validation Accuracy: 0.9240, Loss: 0.0787
Epoch   9 Batch  197/269 - Train Accuracy: 0.9121, Validation Accuracy: 0.9253, Loss: 0.0896
Epoch   9 Batch  198/269 - Train Accuracy: 0.9205, Validation Accuracy: 0.9303, Loss: 0.0841
Epoch   9 Batch  199/269 - Train Accuracy: 0.9114, Validation Accuracy: 0.9302, Loss: 0.0884
Epoch   9 Batch  200/269 - Train Accuracy: 0.9115, Validation Accuracy: 0.9214, Loss: 0.0865
Epoch   9 Batch  201/269 - Train Accuracy: 0.9113, Validation Accuracy: 0.9216, Loss: 0.0817
Epoch   9 Batch  202/269 - Train Accuracy: 0.9274, Validation Accuracy: 0.9185, Loss: 0.0795
Epoch   9 Batch  203/269 - Train Accuracy: 0.9298, Validation Accuracy: 0.9222, Loss: 0.0892
Epoch   9 Batch  204/269 - Train Accuracy: 0.9158, Validation Accuracy: 0.9256, Loss: 0.0834
Epoch   9 Batch  205/269 - Train Accuracy: 0.9223, Validation Accuracy: 0.9233, Loss: 0.0818
Epoch   9 Batch  206/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.9278, Loss: 0.0891
Epoch   9 Batch  207/269 - Train Accuracy: 0.9207, Validation Accuracy: 0.9262, Loss: 0.0818
Epoch   9 Batch  208/269 - Train Accuracy: 0.9243, Validation Accuracy: 0.9252, Loss: 0.0853
Epoch   9 Batch  209/269 - Train Accuracy: 0.9347, Validation Accuracy: 0.9252, Loss: 0.0752
Epoch   9 Batch  210/269 - Train Accuracy: 0.9253, Validation Accuracy: 0.9226, Loss: 0.0774
Epoch   9 Batch  211/269 - Train Accuracy: 0.9292, Validation Accuracy: 0.9243, Loss: 0.0864
Epoch   9 Batch  212/269 - Train Accuracy: 0.9142, Validation Accuracy: 0.9284, Loss: 0.0848
Epoch   9 Batch  213/269 - Train Accuracy: 0.9144, Validation Accuracy: 0.9273, Loss: 0.0822
Epoch   9 Batch  214/269 - Train Accuracy: 0.9159, Validation Accuracy: 0.9251, Loss: 0.0780
Epoch   9 Batch  215/269 - Train Accuracy: 0.9358, Validation Accuracy: 0.9211, Loss: 0.0772
Epoch   9 Batch  216/269 - Train Accuracy: 0.9131, Validation Accuracy: 0.9238, Loss: 0.0940
Epoch   9 Batch  217/269 - Train Accuracy: 0.9077, Validation Accuracy: 0.9242, Loss: 0.0855
Epoch   9 Batch  218/269 - Train Accuracy: 0.9301, Validation Accuracy: 0.9247, Loss: 0.0799
Epoch   9 Batch  219/269 - Train Accuracy: 0.9247, Validation Accuracy: 0.9233, Loss: 0.0842
Epoch   9 Batch  220/269 - Train Accuracy: 0.9312, Validation Accuracy: 0.9247, Loss: 0.0746
Epoch   9 Batch  221/269 - Train Accuracy: 0.9214, Validation Accuracy: 0.9211, Loss: 0.0840
Epoch   9 Batch  222/269 - Train Accuracy: 0.9349, Validation Accuracy: 0.9208, Loss: 0.0760
Epoch   9 Batch  223/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9232, Loss: 0.0750
Epoch   9 Batch  224/269 - Train Accuracy: 0.9218, Validation Accuracy: 0.9277, Loss: 0.0881
Epoch   9 Batch  225/269 - Train Accuracy: 0.9177, Validation Accuracy: 0.9316, Loss: 0.0729
Epoch   9 Batch  226/269 - Train Accuracy: 0.9338, Validation Accuracy: 0.9292, Loss: 0.0806
Epoch   9 Batch  227/269 - Train Accuracy: 0.9393, Validation Accuracy: 0.9285, Loss: 0.0863
Epoch   9 Batch  228/269 - Train Accuracy: 0.9224, Validation Accuracy: 0.9298, Loss: 0.0770
Epoch   9 Batch  229/269 - Train Accuracy: 0.9268, Validation Accuracy: 0.9298, Loss: 0.0817
Epoch   9 Batch  230/269 - Train Accuracy: 0.9214, Validation Accuracy: 0.9335, Loss: 0.0820
Epoch   9 Batch  231/269 - Train Accuracy: 0.9176, Validation Accuracy: 0.9344, Loss: 0.0842
Epoch   9 Batch  232/269 - Train Accuracy: 0.9205, Validation Accuracy: 0.9301, Loss: 0.0785
Epoch   9 Batch  233/269 - Train Accuracy: 0.9314, Validation Accuracy: 0.9285, Loss: 0.0845
Epoch   9 Batch  234/269 - Train Accuracy: 0.9290, Validation Accuracy: 0.9294, Loss: 0.0773
Epoch   9 Batch  235/269 - Train Accuracy: 0.9515, Validation Accuracy: 0.9321, Loss: 0.0678
Epoch   9 Batch  236/269 - Train Accuracy: 0.9156, Validation Accuracy: 0.9307, Loss: 0.0755
Epoch   9 Batch  237/269 - Train Accuracy: 0.9256, Validation Accuracy: 0.9239, Loss: 0.0816
Epoch   9 Batch  238/269 - Train Accuracy: 0.9178, Validation Accuracy: 0.9273, Loss: 0.0799
Epoch   9 Batch  239/269 - Train Accuracy: 0.9206, Validation Accuracy: 0.9298, Loss: 0.0780
Epoch   9 Batch  240/269 - Train Accuracy: 0.9345, Validation Accuracy: 0.9301, Loss: 0.0737
Epoch   9 Batch  241/269 - Train Accuracy: 0.9205, Validation Accuracy: 0.9299, Loss: 0.0876
Epoch   9 Batch  242/269 - Train Accuracy: 0.9341, Validation Accuracy: 0.9294, Loss: 0.0758
Epoch   9 Batch  243/269 - Train Accuracy: 0.9268, Validation Accuracy: 0.9323, Loss: 0.0673
Epoch   9 Batch  244/269 - Train Accuracy: 0.9181, Validation Accuracy: 0.9371, Loss: 0.0764
Epoch   9 Batch  245/269 - Train Accuracy: 0.9119, Validation Accuracy: 0.9305, Loss: 0.0821
Epoch   9 Batch  246/269 - Train Accuracy: 0.9186, Validation Accuracy: 0.9323, Loss: 0.0833
Epoch   9 Batch  247/269 - Train Accuracy: 0.9387, Validation Accuracy: 0.9289, Loss: 0.0751
Epoch   9 Batch  248/269 - Train Accuracy: 0.9299, Validation Accuracy: 0.9297, Loss: 0.0770
Epoch   9 Batch  249/269 - Train Accuracy: 0.9311, Validation Accuracy: 0.9320, Loss: 0.0728
Epoch   9 Batch  250/269 - Train Accuracy: 0.9346, Validation Accuracy: 0.9313, Loss: 0.0759
Epoch   9 Batch  251/269 - Train Accuracy: 0.9524, Validation Accuracy: 0.9340, Loss: 0.0702
Epoch   9 Batch  252/269 - Train Accuracy: 0.9270, Validation Accuracy: 0.9321, Loss: 0.0715
Epoch   9 Batch  253/269 - Train Accuracy: 0.9076, Validation Accuracy: 0.9273, Loss: 0.0832
Epoch   9 Batch  254/269 - Train Accuracy: 0.9305, Validation Accuracy: 0.9244, Loss: 0.0764
Epoch   9 Batch  255/269 - Train Accuracy: 0.9299, Validation Accuracy: 0.9327, Loss: 0.0807
Epoch   9 Batch  256/269 - Train Accuracy: 0.9102, Validation Accuracy: 0.9307, Loss: 0.0781
Epoch   9 Batch  257/269 - Train Accuracy: 0.9086, Validation Accuracy: 0.9276, Loss: 0.0820
Epoch   9 Batch  258/269 - Train Accuracy: 0.9258, Validation Accuracy: 0.9193, Loss: 0.0789
Epoch   9 Batch  259/269 - Train Accuracy: 0.9293, Validation Accuracy: 0.9199, Loss: 0.0824
Epoch   9 Batch  260/269 - Train Accuracy: 0.9251, Validation Accuracy: 0.9287, Loss: 0.0842
Epoch   9 Batch  261/269 - Train Accuracy: 0.9272, Validation Accuracy: 0.9271, Loss: 0.0791
Epoch   9 Batch  262/269 - Train Accuracy: 0.9237, Validation Accuracy: 0.9196, Loss: 0.0761
Epoch   9 Batch  263/269 - Train Accuracy: 0.9172, Validation Accuracy: 0.9300, Loss: 0.0839
Epoch   9 Batch  264/269 - Train Accuracy: 0.8935, Validation Accuracy: 0.9307, Loss: 0.0863
Epoch   9 Batch  265/269 - Train Accuracy: 0.9220, Validation Accuracy: 0.9307, Loss: 0.0798
Epoch   9 Batch  266/269 - Train Accuracy: 0.9249, Validation Accuracy: 0.9288, Loss: 0.0721
Epoch   9 Batch  267/269 - Train Accuracy: 0.9440, Validation Accuracy: 0.9356, Loss: 0.0842
Model Trained and Saved
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Save-Parameters">Save Parameters<a class="anchor-link" href="#Save-Parameters">&#182;</a></h3><p>Save the <code>batch_size</code> and <code>save_path</code> parameters for inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[62]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Save parameters for checkpoint</span>
<span class="n">helper</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[63]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="p">(</span><span class="n">source_int_to_vocab</span><span class="p">,</span> <span class="n">target_int_to_vocab</span><span class="p">)</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">load_path</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_params</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sentence-to-Sequence">Sentence to Sequence<a class="anchor-link" href="#Sentence-to-Sequence">&#182;</a></h2><p>To feed a sentence into the model for translation, you first need to preprocess it.  Implement the function <code>sentence_to_seq()</code> to preprocess new sentences.</p>
<ul>
<li>Convert the sentence to lowercase</li>
<li>Convert words into ids using <code>vocab_to_int</code><ul>
<li>Convert words not in the vocabulary, to the <code>&lt;UNK&gt;</code> word id.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[64]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sentence_to_seq</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a sentence to a sequence of ids</span>
<span class="sd">    :param sentence: String</span>
<span class="sd">    :param vocab_to_int: Dictionary to go from the words to an id</span>
<span class="sd">    :return: List of word ids</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">sentence_int</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab_to_int</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="ow">or</span> <span class="n">vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;UNK&gt;&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>

    <span class="k">return</span> <span class="n">sentence_int</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_sentence_to_seq</span><span class="p">(</span><span class="n">sentence_to_seq</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Translate">Translate<a class="anchor-link" href="#Translate">&#182;</a></h2><p>This will translate <code>translate_sentence</code> from English to French.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[66]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">translate_sentence</span> <span class="o">=</span> <span class="s1">&#39;he saw a old yellow truck .&#39;</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">translate_sentence</span> <span class="o">=</span> <span class="n">sentence_to_seq</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">)</span>

<span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Load saved model</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">load_path</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
    <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">load_path</span><span class="p">)</span>

    <span class="n">input_data</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;input:0&#39;</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;predictions:0&#39;</span><span class="p">)</span>
    <span class="n">target_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;target_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;source_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;keep_prob:0&#39;</span><span class="p">)</span>

    <span class="n">translate_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="p">[</span><span class="n">translate_sentence</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">target_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">source_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  English Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">source_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Prediction&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  French Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">target_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">])))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Restoring parameters from checkpoints/dev
Input
  Word Ids:      [159, 40, 156, 125, 72, 86, 146]
  English Words: [&#39;he&#39;, &#39;saw&#39;, &#39;a&#39;, &#39;old&#39;, &#39;yellow&#39;, &#39;truck&#39;, &#39;.&#39;]

Prediction
  Word Ids:      [336, 326, 174, 196, 316, 341, 65, 1]
  French Words: il a un nouveau camion bleu . &lt;EOS&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Imperfect-Translation">Imperfect Translation<a class="anchor-link" href="#Imperfect-Translation">&#182;</a></h2><p>You might notice that some sentences translate better than others.  Since the dataset you're using only has a vocabulary of 227 English words of the thousands that you use, you're only going to see good results using these words.  For this project, you don't need a perfect translation. However, if you want to create a better translation model, you'll need better data.</p>
<p>You can train on the <a href="http://www.statmt.org/wmt10/training-giga-fren.tar">WMT10 French-English corpus</a>.  This dataset has more vocabulary and richer in topics discussed.  However, this will take you days to train, so make sure you've a GPU and the neural network is performing well on dataset we provided.  Just make sure you play with the WMT10 corpus after you've submitted this project.</p>
<h2 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="#Submitting-This-Project">&#182;</a></h2><p>When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as "dlnd_language_translation.ipynb" and save it as a HTML file under "File" -&gt; "Download as". Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
